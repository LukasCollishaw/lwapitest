[ns_server:info,2020-05-07T02:02:41.970Z,nonode@nohost:<0.89.0>:ns_server:init_logging:150]Started & configured logging
[ns_server:info,2020-05-07T02:02:41.996Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_access,info},
 {disk_sink_opts,[{rotation,[{compress,true},
                             {size,41943040},
                             {num_files,10},
                             {buffer_size_max,52428800}]}]},
 {disk_sink_opts_json_rpc,[{rotation,[{compress,true},
                                      {size,41943040},
                                      {num_files,2},
                                      {buffer_size_max,52428800}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.997Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.998Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.998Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.998Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.998Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.998Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.998Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.998Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.998Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_json_rpc, which is given from command line
[ns_server:warn,2020-05-07T02:02:41.998Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2020-05-07T02:02:42.010Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.138.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:02:42.017Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,76}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-378cfab] [64-bit] [smp:2:2] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2020,5,7},{2,2,42}}},
               {memory,
                   [{total,110105848},
                    {processes,9263072},
                    {processes_used,9261552},
                    {system,100842776},
                    {atom,339441},
                    {atom_used,322610},
                    {binary,50440},
                    {code,7796739},
                    {ets,2241584}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,path_config,calendar,
                    ale_default_formatter,'ale_logger-metakv',
                    'ale_logger-rebalance','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-json_rpc',
                    'ale_logger-access','ale_logger-ns_server',
                    'ale_logger-user','ale_logger-ns_doctor',io_lib_fread,
                    'ale_logger-cluster','ale_logger-xdcr',otp_internal,
                    ns_log_sink,ale_disk_sink,misc,couch_util,ns_server,
                    filelib,cpu_sup,memsup,disksup,os_mon,io,release_handler,
                    overload,alarm_handler,sasl,timer,tftp_sup,httpd_sup,
                    httpc_handler_sup,httpc_cookie,inets_trace,httpc_manager,
                    httpc,httpc_profile_sup,httpc_sup,ftp_sup,inets_sup,
                    inets_app,ssl,lhttpc_manager,lhttpc_sup,lhttpc,
                    tls_connection_sup,ssl_session_cache,ssl_pkix_db,
                    ssl_manager,ssl_sup,ssl_app,crypto_server,crypto_sup,
                    crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_io,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","6.0.3-2895-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","6.0.3-2895-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,105},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [lhttpc_sup,code_server,ale_stats_events,'sink-ns_log',
                    ns_server_cluster_sup,lhttpc_manager,
                    application_controller,ale,httpd_sup,release_handler,
                    kernel_safe_sup,standard_error,ale_sup,overload,
                    'sink-disk_json_rpc',error_logger,alarm_handler,
                    'sink-disk_metakv',ale_dynamic_sup,timer_server,
                    'sink-disk_access_int',standard_error_sup,
                    'sink-disk_access','sink-disk_reports',crypto_server,
                    crypto_sup,sasl_safe_sup,'sink-disk_stats',
                    'sink-disk_xdcr',tftp_sup,inet_db,init,os_mon_sup,
                    'sink-disk_debug',rex,tls_connection_sup,user,
                    'sink-disk_error',ssl_sup,kernel_sup,cpu_sup,
                    global_name_server,memsup,'sink-disk_default',disksup,
                    httpc_sup,file_server_2,ssl_manager,local_tasks,
                    global_group,httpc_profile_sup,httpc_manager,
                    httpc_handler_sup,ftp_sup,sasl_sup,erl_prim_loader,
                    inets_sup]},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,3}]
[ns_server:info,2020-05-07T02:02:42.026Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:27]Manifest:
["<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\" />",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\" />",
 "  ","  <default remote=\"couchbase\" revision=\"master\" />","  ",
 "  <project groups=\"kv\" name=\"HdrHistogram_c\" path=\"third_party/HdrHistogram_c\" remote=\"couchbasedeps\" revision=\"d200fc0f68695d4aef1fad5c3c8cc55f8c033014\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"analytics-dcp-client\" path=\"analytics/java-dcp-client\" revision=\"d6ba66b51c0e589e9d4571264afcb0e33d507aea\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"asterixdb\" path=\"analytics/asterixdb\" revision=\"e8e59d0e6e72ba3fd96074c021ff7180261dcd59\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"c5b9dd8ec0910d2890d215075a7d2da1d6a494c9\" />",
 "  <project groups=\"kv\" name=\"benchmark\" remote=\"couchbasedeps\" revision=\"9e3465560240ffb242b50a47cb7f19251a12ee42\" />",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\" />",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5cd1345cca3ed72f1e63d41d622fcda73e63fea8\" />",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"822d01dab8721cf469beb6d8304c9eadd9c58160\" />",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"f551b6d4f32bb920a83dd28c705bddd5de0d03b2\" />",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"4b158bb555a3297565afecf6fae675c74f1e47df\" />",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\" />",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\" />",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"dc55cf8e9613ddf1bd6db4a662d1ecc3668223da\">",
 "    <annotation name=\"RELEASE\" value=\"alice\" />",
 "    <annotation name=\"PRODUCT\" value=\"couchbase-server\" />",
 "    <annotation name=\"BLD_NUM\" value=\"2895\" />",
 "    <annotation name=\"VERSION\" value=\"6.0.3\" />","  </project>",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas\" path=\"goproj/src/github.com/couchbaselabs/cbas\" remote=\"couchbase-priv\" revision=\"73fa77cd9133a9f779a484ac2caffb0b46a1dd82\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas-core\" path=\"analytics\" remote=\"couchbase-priv\" revision=\"7e513c6bd60a030c3a2477af683b264d61932a75\" />",
 "  <project groups=\"analytics\" name=\"cbas-ui\" revision=\"d8f601c3109887a30deccab09b2177bf499c8711\" />",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"0df84c7e3c6d95ff435c12a3c08c6f064db11e97\" />",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"80d2ad8892d806f5103f602fec0d80adaa4b628f\" />",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"8d4105a904e0282a6928de7392e266c58ea3c7a2\" />",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"0a94f40b9080e0ecb11d3b7531a58c5e6a4a4465\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"93d26dbc120c4f9874abb65aafa4d815334273c6\" />",
 "  <project name=\"cbsummary\" path=\"goproj/src/github.com/couchbase/cbsummary\" revision=\"dbfa1c0d73f0e49f6f04e390f03de8f9a6cee769\" />",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"dcae66272b24600ae0005fa06b511cfae8914d3d\" />",
 "  <project name=\"cobra\" path=\"godeps/src/github.com/spf13/cobra\" remote=\"couchbasedeps\" revision=\"0f056af21f5f368e5b0646079d0094a2c64150f7\" />",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\" />",
 "  <project groups=\"notdefault,kv_ee,enterprise\" name=\"couch_rocks\" remote=\"couchbase-priv\" revision=\"75f37fa46bfe5e445dee077157303968a3e09126\" />",
 "  <project name=\"couchbase-cli\" revision=\"9b383603860ce58885c27015c92635a7b42d3a1f\" />",
 "  <project name=\"couchdb\" revision=\"c2b98200b800f9fbed927c47074884b9f5f53eb4\" />",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"69aa5d92e195a30e06184911d72b8fffcf2534fe\" />",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"c2c458ff2cf93ee63bf4b0386f495b22535daf96\" />",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\" />",
 "  <project name=\"cuckoofilter\" path=\"godeps/src/github.com/seiflotfy/cuckoofilter\" remote=\"couchbasedeps\" revision=\"d04838794ab86926d32b124345777e55e6f43974\" />",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\" />",
 "  <project name=\"docloader\" path=\"goproj/src/github.com/couchbase/docloader\" revision=\"05067021a042a1b63e100a486afd7ebddab4c535\" />",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\" />",
 "  <project name=\"errors\" path=\"godeps/src/github.com/pkg/errors\" remote=\"couchbasedeps\" revision=\"30136e27e2ac8d167177e8a583aa4c3fea5be833\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"eventing\" path=\"goproj/src/github.com/couchbase/eventing\" revision=\"1da67e30a4c8faaf24f067eae280f5764d943dc2\" upstream=\"alice\" />",
 "  <project name=\"flatbuffers\" path=\"godeps/src/github.com/google/flatbuffers\" remote=\"couchbasedeps\" revision=\"1a8968225130caeddd16e227678e6f8af1926303\" />",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"c338e06e6847140f749058184d66de1f2a43474a\" />",
 "  <project name=\"fwd\" path=\"godeps/src/github.com/philhofer/fwd\" remote=\"couchbasedeps\" revision=\"bb6d471dc95d4fe11e432687f8b70ff496cf3136\" />",
 "  <project name=\"geocouch\" revision=\"2a0e73f43451045f157640eec59ced72da18471f\" />",
 "  <project name=\"ghistogram\" path=\"godeps/src/github.com/couchbase/ghistogram\" revision=\"d910dd063dd68fb4d2a1ba344440f834ebb4ef62\" />",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\" />",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"5c0ac9ef0ba7a0356279cee7eadd8874c4a8f8c1\" />",
 "  <project name=\"go-curl\" path=\"godeps/src/github.com/andelf/go-curl\" remote=\"couchbasedeps\" revision=\"f0b2afc926ec79be5d7f30393b3485352781a705\" />",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\" />",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\" />",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\" />",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\" />",
 "  <project name=\"go-sqlite3\" path=\"godeps/src/github.com/mattn/go-sqlite3\" remote=\"couchbasedeps\" revision=\"47fc4e5e9153645da45af6a86a5bce95e63a0f9e\" />",
 "  <project name=\"go-unsnap-stream\" path=\"godeps/src/github.com/glycerine/go-unsnap-stream\" remote=\"couchbasedeps\" revision=\"62a9a9eb44fd8932157b1a8ace2149eff5971af6\" />",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\" />",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"d2f15a425a9c8e4d8447e5f5b89ce14845f7fa05\" />",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\" />",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"699b13a51af5dd4f80ff3deedf41bba60debad32\" />",
 "  <project name=\"gocbconnstr\" path=\"godeps/src/gopkg.in/couchbaselabs/gocbconnstr.v1\" remote=\"couchbaselabs\" revision=\"710456e087a6d497e87f41d0a9d98d6a75672186\" />",
 "  <project name=\"gocbcore\" path=\"godeps/src/gopkg.in/couchbase/gocbcore.v7\" revision=\"a0d26c2d6f5de912499d35a5aba573006e5e036f\" />",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"aecdbe5a5a91f0688df7bdf260ca962178c06828\" />",
 "  <project name=\"gofarmhash\" path=\"godeps/src/github.com/leemcloughlin/gofarmhash\" remote=\"couchbasedeps\" revision=\"0a055c5b87a8c55ce83459cbf2776b563822a942\" />",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\" />",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\" />",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\" />",
 "  <project name=\"golang-tools\" path=\"godeps/src/golang.org/x/tools\" remote=\"couchbasedeps\" revision=\"a28dfb48e06b2296b66678872c2cb638f0304f20\" />",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\" />",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"e05ec3550789be1da2981787ef6444fef75e10bc\" />",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"4809dd3aa2ab88013b1dfce15516d717a35cb6e8\" />",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\" />",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\" />",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\" />",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"f98adca8eb365032cab838ef4d99453931afa112\" />",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"122ae25ed207cca30ceaee9ac66342a603d43a31\" />",
 "  <project groups=\"kv\" name=\"gsl-lite\" path=\"third_party/gsl-lite\" remote=\"couchbasedeps\" revision=\"57542c7e7ced375346e9ac55dad85b942cfad556\" />",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\" />",
 "  <project name=\"httprouter\" path=\"godeps/src/github.com/julienschmidt/httprouter\" remote=\"couchbasedeps\" revision=\"975b5c4c7c21c0e3d2764200bf2aa8e34657ae6e\" />",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"95ed84aad6bf8ecd99da2372dceede6d93f3d43a\" />",
 "  <project name=\"json-iterator-go\" path=\"godeps/src/github.com/json-iterator/go\" remote=\"couchbasedeps\" revision=\"f7279a603edee96fe7764d3de9c6ff8cf9970994\" />",
 "  <project name=\"jsonx\" path=\"godeps/src/gopkg.in/couchbaselabs/jsonx.v1\" remote=\"couchbaselabs\" revision=\"5b7baa20429a46a5543ee259664cc86502738cad\" />",
 "  <project groups=\"kv\" name=\"kv_engine\" revision=\"a30fd9d57cc2101078c8cd2c44968458df965c2b\" />",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"libcouchbase\" revision=\"081e8b16b991bf706eb77f8243935c6fba31b895\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"3681c2a912330352991ecdd642f257efe5b85518\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\" />",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\" />",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\" />",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"956632ec1bc3e28276d00ee2f22c3202f06efb12\" />",
 "  <project name=\"mossScope\" path=\"godeps/src/github.com/couchbase/mossScope\" revision=\"abd3b58b422dbc2e9463a589d0f3d93441726e23\" />",
 "  <project name=\"mousetrap\" path=\"godeps/src/github.com/inconshreveable/mousetrap\" remote=\"couchbasedeps\" revision=\"76626ae9c91c4f2a10f34cad8ce83ea42c93bb75\" />",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"cd8da46b9b953800d430c8b0aa4667790727ed6f\" />",
 "  <project name=\"msgp\" path=\"godeps/src/github.com/tinylib/msgp\" remote=\"couchbasedeps\" revision=\"5bb5e1aed7ba5bcc93307153b020e7ffe79b0509\" />",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"043ee6597c29786140136a5747b6a886364f5282\" />",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"62685c2d7ca23c807425dca88b11a3e2323dab41\" />",
 "  <project name=\"nitro\" path=\"goproj/src/github.com/couchbase/nitro\" revision=\"f3bef3551997be504612a2d05a8b324b3bfdfe1b\" />",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\" />",
 "  <project name=\"ns_server\" revision=\"8117c5307974f397ad831a2b870fb3ee0fd8364d\" />",
 "  <project name=\"opentracing-go\" path=\"godeps/src/github.com/opentracing/opentracing-go\" remote=\"couchbasedeps\" revision=\"1949ddbfd147afd4d964a9f00b24eb291e0e7c38\" />",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\" />",
 "  <project name=\"pflag\" path=\"godeps/src/github.com/spf13/pflag\" remote=\"couchbasedeps\" revision=\"a232f6d9f87afaaa08bafaff5da685f974b83313\" />",
 "  <project groups=\"kv\" name=\"phosphor\" revision=\"96501c57bb0fd61c85cba6f63101aed2bcf41d38\" />",
 "  <project name=\"pierrec-lz4\" path=\"godeps/src/github.com/pierrec/lz4\" remote=\"couchbasedeps\" revision=\"ed8d4cc3b461464e69798080a0092bd028910298\" />",
 "  <project name=\"pierrec-xxHash\" path=\"godeps/src/github.com/pierrec/xxHash\" remote=\"couchbasedeps\" revision=\"a0006b13c722f7f12368c00a3d3c2ae8a999a0c6\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"plasma\" path=\"goproj/src/github.com/couchbase/plasma\" remote=\"couchbase-priv\" revision=\"c0792c8cfb1463ef029f064f34e366442f1f0064\" />",
 "  <project groups=\"kv\" name=\"platform\" revision=\"de77d527bd23012dc67794c81a7b1e76e46e3abd\" />",
 "  <project groups=\"kv\" name=\"product-texts\" revision=\"8cf7d25a1dcb5434ea44983c0bed202fb9cc8351\" />",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\" />",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"d2011f6ee9f6e1dca5d3922d44fbcf86dad78150\" />",
 "  <project name=\"query-ui\" revision=\"15a6461f437fe810e411a6613ec7c143991cd1c6\" />",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\" />",
 "  <project name=\"roaring\" path=\"godeps/src/github.com/RoaringBitmap/roaring\" remote=\"couchbasedeps\" revision=\"fe09428be4c233d726797a1380f7438f4f71a31a\" />",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"762005e7a34fd909a84586299f1dd457371d36ee\" />",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"73353fe6dad8f3d67409feefb9b17f90f6de917b\" />",
 "  <project name=\"snowballstem\" path=\"godeps/src/github.com/blevesearch/snowballstem\" remote=\"blevesearch\" revision=\"26b06a2c243d4f8ca5db3486f94409dd5b2a7467\" />",
 "  <project groups=\"kv\" name=\"spdlog\" path=\"third_party/spdlog\" remote=\"couchbasedeps\" revision=\"4fba14c79f356ae48d6141c561bf9fd7ba33fabd\" />",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\" />",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"c30c3d4c250e68e81c57aa1e8ae91ffd21243cdb\" />",
 "  <project name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\" />",
 "  <project name=\"testrunner\" revision=\"4133fd785987f1ddcdb49dab736ff6e5e67d7c95\" upstream=\"alice\" />",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\" />",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"6dadf98e19803cc10ce9552bf4d9121cc2528965\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\" />",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\" />",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\" />",
 "    <copyfile dest=\".clang-format\" src=\"dot-clang-format\" />",
 "    <copyfile dest=\"third_party/CMakeLists.txt\" src=\"third-party-CMakeLists.txt\" />",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\" />",
 "  <project name=\"uuid\" path=\"godeps/src/github.com/google/uuid\" remote=\"couchbasedeps\" revision=\"dec09d789f3dba190787f8b4454c7d3c936fed9e\" />",
 "  <project name=\"vellum\" path=\"godeps/src/github.com/couchbase/vellum\" revision=\"0ceea4a37442f76199b9259840baf48d17af3c1a\" />",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"b3d83fe61db37bb38a46cd8dee434e5682cba2c7\" />",
 "  <project name=\"zstd\" path=\"godeps/src/github.com/DataDog/zstd\" remote=\"couchbasedeps\" revision=\"aebefd9fcb99f22cd691ef778a12ed68f0e6a1ab\" />",
 "</manifest>"]

[error_logger:info,2020-05-07T02:02:42.071Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.139.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:02:42.080Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2020-05-07T02:02:42.080Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2020-05-07T02:02:42.081Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:init:243]ip config not found. Looks like we're brand new node
[error_logger:info,2020-05-07T02:02:42.081Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.143.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2020-05-07T02:02:42.081Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.142.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:02:42.235Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:bringup:295]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2020-05-07T02:02:42.248Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.145.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:42.248Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.146.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:42.249Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:configure_net_kernel:339]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2020-05-07T02:02:42.249Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.147.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:42.249Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.144.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2020-05-07T02:02:42.255Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:save_node:227]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2020-05-07T02:02:42.266Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:bringup:309]Attempted to save node name to disk: ok
[ns_server:debug,2020-05-07T02:02:42.266Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:316]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2020-05-07T02:02:42.267Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T02:02:42.282Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:328]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2020-05-07T02:02:42.282Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:42.302Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:42.303Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:02:42.305Z,ns_1@127.0.0.1:ns_config_sup<0.154.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2020-05-07T02:02:42.305Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.155.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:42.305Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.156.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:02:42.376Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1095]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2020-05-07T02:02:42.377Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1109]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:info,2020-05-07T02:02:42.377Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1114]No dynamic config file found. Assuming we're brand new node
[ns_server:debug,2020-05-07T02:02:42.381Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1117]Here's full dynamic config we loaded:
[[]]
[ns_server:info,2020-05-07T02:02:42.383Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1138]Here's full dynamic config we loaded + static & default config:
[{{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   false]},
 {password_policy,[{min_length,6},{must_present,[]}]},
 {drop_request_memory_threshold_mib,undefined},
 {{request_limit,capi},undefined},
 {{request_limit,rest},undefined},
 {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
 {auto_failover_cfg,[{enabled,true},{timeout,120},{max_nodes,1},{count,0}]},
 {log_redaction_default_cfg,[{redact_level,none}]},
 {replication,[{enabled,true}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11211},
   {verbosity,[]}]},
 {secure_headers,[]},
 {buckets,[{configs,[]}]},
 {cbas_memory_quota,1024},
 {fts_memory_quota,256},
 {memory_quota,311},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},
          {port,port},
          {maxconn,maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {privilege_debug,privilege_debug},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {rbac_file,{"~s",[rbac_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps},
     {tracing_enabled,tracing_enabled},
     {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
     {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
     {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
     {logger,
      {[{filename,{"~s/~s",[log_path,log_prefix]}},
        {cyclesize,log_cyclesize},
        {sleeptime,log_sleeptime}]}}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"@ns_server"},
   {other_users,
    ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
     "@cbas"]},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {privilege_debug,false},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false},
   {tracing_enabled,true},
   {datatype_snappy,true}]},
 {memcached,[]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {audit,
  [{auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {remote_clusters,[]},
 {read_only_user_creds,null},
 {rest_creds,null},
 {{metakv,<<"/indexing/settings/config">>},
  <<"{\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912}">>},
 {{node,'ns_1@127.0.0.1',eventing_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9140]},
 {{node,'ns_1@127.0.0.1',eventing_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18096]},
 {{node,'ns_1@127.0.0.1',eventing_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8096]},
 {{node,'ns_1@127.0.0.1',cbas_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18095]},
 {{node,'ns_1@127.0.0.1',cbas_parent_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9122]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9121]},
 {{node,'ns_1@127.0.0.1',cbas_replication_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9120]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9119]},
 {{node,'ns_1@127.0.0.1',cbas_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]},
 {{node,'ns_1@127.0.0.1',cbas_messaging_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9118]},
 {{node,'ns_1@127.0.0.1',cbas_result_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9117]},
 {{node,'ns_1@127.0.0.1',cbas_data_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9116]},
 {{node,'ns_1@127.0.0.1',cbas_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9115]},
 {{node,'ns_1@127.0.0.1',cbas_console_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9114]},
 {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9113]},
 {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9112]},
 {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9111]},
 {{node,'ns_1@127.0.0.1',cbas_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9110]},
 {{node,'ns_1@127.0.0.1',cbas_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8095]},
 {{node,'ns_1@127.0.0.1',fts_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18094]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   19102]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,8091},
   {port_meta,global}]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {rest,[{port,8091}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   active]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {quorum_nodes,['ns_1@127.0.0.1']},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {max_bucket_count,10},
 {index_aware_rebalance_disabled,false},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {5,5,3}]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   <<"0f8760945f98b1efdbef0bd1ea6e8446">>]}]
[error_logger:info,2020-05-07T02:02:42.388Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.157.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:42.389Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.163.0>},
                       {name,ns_config_remote},
                       {mfargs,{ns_config_replica,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:42.391Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.164.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:42.391Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:42.392Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.166.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:42.393Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.167.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:42.398Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.170.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:42.399Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2020-05-07T02:02:42.399Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.171.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:42.399Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.172.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:42.402Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.173.0>},
                       {name,memcached_refresh},
                       {mfargs,{memcached_refresh,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:42.404Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.175.0>},
                       {name,ssl_service_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ssl_service_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:02:42.410Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:init:419]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,undefined},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[ns_server:debug,2020-05-07T02:02:42.873Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_server_cert:generate_cert_and_pkey:80]Generated certificate and private key in 461337 us
[ns_server:debug,2020-05-07T02:02:42.874Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cert_and_pkey ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQ"...>>,
  <<"*****">>}]
[ns_server:debug,2020-05-07T02:02:42.874Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:info,2020-05-07T02:02:42.881Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:maybe_generate_local_cert:591]Failed to read node certificate. Perhaps it wasn't created yet. Error: {error,
                                                                        {badmatch,
                                                                         {error,
                                                                          enoent}}}
[ns_server:info,2020-05-07T02:02:43.296Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:do_generate_local_cert:579]Saved local cert for node 'ns_1@127.0.0.1'
[error_logger:info,2020-05-07T02:02:43.340Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.176.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:02:43.362Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T02:02:43.362Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T02:02:43.362Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T02:02:43.362Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[ns_server:debug,2020-05-07T02:02:43.376Z,ns_1@127.0.0.1:<0.183.0>:restartable:start_child:98]Started child process <0.184.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2020-05-07T02:02:43.376Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.183.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:43.376Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.174.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:43.378Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.202.0>},
                       {name,user_storage_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,user_storage_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:43.383Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.204.0>},
                       {name,users_replicator},
                       {mfargs,{menelaus_users,start_replicator,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:43.385Z,ns_1@127.0.0.1:users_replicator<0.204.0>:replicated_storage:wait_for_startup:55]Start waiting for startup
[ns_server:debug,2020-05-07T02:02:43.387Z,ns_1@127.0.0.1:users_storage<0.205.0>:replicated_storage:anounce_startup:69]Announce my startup to <0.204.0>
[ns_server:debug,2020-05-07T02:02:43.387Z,ns_1@127.0.0.1:users_replicator<0.204.0>:replicated_storage:wait_for_startup:58]Received replicated storage registration from <0.205.0>
[ns_server:debug,2020-05-07T02:02:43.389Z,ns_1@127.0.0.1:users_storage<0.205.0>:replicated_dets:open:212]Opening file "/opt/couchbase/var/lib/couchbase/config/users.dets"
[error_logger:info,2020-05-07T02:02:43.389Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.205.0>},
                       {name,users_storage},
                       {mfargs,{menelaus_users,start_storage,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:43.389Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.203.0>},
                       {name,users_storage_sup},
                       {mfargs,{users_storage_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:02:43.401Z,ns_1@127.0.0.1:compiled_roles_cache<0.207.0>:versioned_cache:init:44]Starting versioned cache compiled_roles_cache
[error_logger:info,2020-05-07T02:02:43.401Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.207.0>},
                       {name,compiled_roles_cache},
                       {mfargs,{menelaus_roles,start_compiled_roles_cache,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:43.401Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.201.0>},
                       {name,users_sup},
                       {mfargs,{users_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:43.402Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.210.0>},
                       {name,dets_sup},
                       {mfargs,{dets_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:43.402Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.211.0>},
                       {name,dets},
                       {mfargs,{dets_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:02:43.436Z,ns_1@127.0.0.1:users_storage<0.205.0>:replicated_dets:convert_docs_to_55_in_dets:243]Checking for pre 5.5 records in dets: users_storage
[ns_server:debug,2020-05-07T02:02:43.436Z,ns_1@127.0.0.1:users_storage<0.205.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,'$1','_','$2'},
                                      [],
                                      [{{'$1','$2'}}]}],
                                    100}
[ns_server:debug,2020-05-07T02:02:43.436Z,ns_1@127.0.0.1:users_storage<0.205.0>:replicated_dets:init_after_ack:204]Loading 0 items, 299 words took 0ms
[ns_server:debug,2020-05-07T02:02:43.437Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.215.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:141]Waiting for ns_couchdb node to start
[error_logger:info,2020-05-07T02:02:43.437Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.214.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:43.438Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:02:43.439Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.218.0>,shutdown}}
[error_logger:info,2020-05-07T02:02:43.439Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T02:02:43.439Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[ns_server:debug,2020-05-07T02:02:43.444Z,ns_1@127.0.0.1:users_replicator<0.204.0>:doc_replicator:loop:60]doing replicate_newnodes_docs
[error_logger:info,2020-05-07T02:02:43.640Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:02:43.640Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.221.0>,shutdown}}
[ns_server:debug,2020-05-07T02:02:43.640Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T02:02:43.640Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:02:43.841Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:02:43.841Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.224.0>,shutdown}}
[ns_server:debug,2020-05-07T02:02:43.841Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T02:02:43.841Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:02:44.042Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T02:02:44.105Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T02:02:44.306Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T02:02:44.507Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T02:02:44.708Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T02:02:44.909Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[error_logger:info,2020-05-07T02:02:45.308Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.234.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:02:45.509Z,ns_1@127.0.0.1:ns_couchdb_port<0.214.0>:ns_port_server:log:223]ns_couchdb<0.214.0>: Apache CouchDB v4.5.1-112-gc2b9820 (LogLevel=info) is starting.
ns_couchdb<0.214.0>: Apache CouchDB has started. Time to relax.

[error_logger:info,2020-05-07T02:02:45.613Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.215.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.96617950>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:45.624Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:ns_storage_conf:setup_db_and_ix_paths:47]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2020-05-07T02:02:45.627Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.237.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.628Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.238.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:02:45.629Z,ns_1@127.0.0.1:ns_server_sup<0.236.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2020-05-07T02:02:45.629Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.239.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.631Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.240.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:02:45.649Z,ns_1@127.0.0.1:ns_log<0.241.0>:ns_log:read_logs:92]Couldn't load logs from "/opt/couchbase/var/lib/couchbase/ns_log" (perhaps it's first startup): {error,
                                                                                                 enoent}
[error_logger:info,2020-05-07T02:02:45.649Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.241.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.649Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.242.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:45.658Z,ns_1@127.0.0.1:memcached_passwords<0.243.0>:memcached_cfg:init:62]Init config writer for memcached_passwords, "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T02:02:45.658Z,ns_1@127.0.0.1:memcached_passwords<0.243.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:info,2020-05-07T02:02:45.823Z,ns_1@127.0.0.1:ns_couchdb_port<0.214.0>:ns_port_server:log:223]ns_couchdb<0.214.0>: 180: Booted. Waiting for shutdown request

[ns_server:debug,2020-05-07T02:02:45.886Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[error_logger:info,2020-05-07T02:02:45.886Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.243.0>},
                       {name,memcached_passwords},
                       {mfargs,{memcached_passwords,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:02:45.893Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:02:45.893Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [isasl] failed. Retry in 1000 ms.
[ns_server:debug,2020-05-07T02:02:45.895Z,ns_1@127.0.0.1:memcached_permissions<0.246.0>:memcached_cfg:init:62]Init config writer for memcached_permissions, "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T02:02:45.896Z,ns_1@127.0.0.1:memcached_permissions<0.246.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T02:02:45.906Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of rbac requested
[error_logger:info,2020-05-07T02:02:45.907Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.246.0>},
                       {name,memcached_permissions},
                       {mfargs,{memcached_permissions,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:02:45.908Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:02:45.908Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2020-05-07T02:02:45.907Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.249.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.910Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:45.910Z,ns_1@127.0.0.1:ns_node_disco<0.252.0>:ns_node_disco:init:130]Initting ns_node_disco with []
[ns_server:debug,2020-05-07T02:02:45.910Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T02:02:45.910Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{2,63756036165}}]}]
[user:info,2020-05-07T02:02:45.910Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_init:83]Initial otp cookie generated: {sanitized,
                                  <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:02:45.910Z,ns_1@127.0.0.1:<0.253.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:02:45.910Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
otp ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
 {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]
[ns_server:debug,2020-05-07T02:02:45.912Z,ns_1@127.0.0.1:<0.253.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[error_logger:info,2020-05-07T02:02:45.912Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.252.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.914Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.255.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.917Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.256.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.925Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.257.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:45.926Z,ns_1@127.0.0.1:ns_config_rep<0.258.0>:ns_config_rep:init:69]init pulling
[ns_server:debug,2020-05-07T02:02:45.926Z,ns_1@127.0.0.1:ns_config_rep<0.258.0>:ns_config_rep:init:71]init pushing
[ns_server:debug,2020-05-07T02:02:45.927Z,ns_1@127.0.0.1:ns_config_rep<0.258.0>:ns_config_rep:init:75]init reannouncing
[ns_server:debug,2020-05-07T02:02:45.929Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2020-05-07T02:02:45.929Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2020-05-07T02:02:45.929Z,ns_1@127.0.0.1:compiled_roles_cache<0.207.0>:versioned_cache:handle_info:89]Flushing cache compiled_roles_cache due to version change from undefined to {undefined,
                                                                             {0,
                                                                              3268678210},
                                                                             false,
                                                                             []}
[ns_server:debug,2020-05-07T02:02:45.930Z,ns_1@127.0.0.1:memcached_passwords<0.243.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T02:02:45.931Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
otp ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
 {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]
[ns_server:debug,2020-05-07T02:02:45.932Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cert_and_pkey ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQ"...>>,
  <<"*****">>}]
[ns_server:debug,2020-05-07T02:02:45.932Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2020-05-07T02:02:45.933Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit ->
[{auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2020-05-07T02:02:45.933Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T02:02:45.933Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{enabled,true},{timeout,120},{max_nodes,1},{count,0}]
[ns_server:debug,2020-05-07T02:02:45.934Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_reprovision_cfg ->
[{enabled,true},{max_nodes,1},{count,0}]
[ns_server:debug,2020-05-07T02:02:45.935Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T02:02:45.935Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2020-05-07T02:02:45.935Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
buckets ->
[[],{configs,[]}]
[ns_server:debug,2020-05-07T02:02:45.935Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cbas_memory_quota ->
1024
[ns_server:debug,2020-05-07T02:02:45.935Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2020-05-07T02:02:45.937Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded,communication_issue]}]
[ns_server:debug,2020-05-07T02:02:45.937Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
fts_memory_quota ->
256
[ns_server:debug,2020-05-07T02:02:45.937Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2020-05-07T02:02:45.937Z,ns_1@127.0.0.1:<0.266.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:02:45.937Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
log_redaction_default_cfg ->
[{redact_level,none}]
[ns_server:debug,2020-05-07T02:02:45.938Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
max_bucket_count ->
10
[ns_server:debug,2020-05-07T02:02:45.938Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memcached ->
[]
[ns_server:debug,2020-05-07T02:02:45.939Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memory_quota ->
311
[ns_server:debug,2020-05-07T02:02:45.939Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T02:02:45.939Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
password_policy ->
[{min_length,6},{must_present,[]}]
[ns_server:debug,2020-05-07T02:02:45.940Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
quorum_nodes ->
['ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T02:02:45.940Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
read_only_user_creds ->
null
[ns_server:debug,2020-05-07T02:02:45.940Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
remote_clusters ->
[]
[ns_server:debug,2020-05-07T02:02:45.940Z,ns_1@127.0.0.1:<0.267.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:02:45.940Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2020-05-07T02:02:45.940Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest ->
[{port,8091}]
[ns_server:debug,2020-05-07T02:02:45.940Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest_creds ->
null
[ns_server:debug,2020-05-07T02:02:45.941Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
secure_headers ->
[]
[ns_server:debug,2020-05-07T02:02:45.941Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2020-05-07T02:02:45.941Z,ns_1@127.0.0.1:<0.266.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:02:45.941Z,ns_1@127.0.0.1:<0.267.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:02:45.942Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2020-05-07T02:02:45.942Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2020-05-07T02:02:45.942Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:trigger_ssl_reload:565]Notify services [capi_ssl_service] about secure_headers_changed change
[ns_server:debug,2020-05-07T02:02:45.943Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:525]Going to notify following services: [capi_ssl_service]
[ns_server:debug,2020-05-07T02:02:45.942Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2020-05-07T02:02:45.943Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/indexing/settings/config">>} ->
<<"{\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912}">>
[ns_server:debug,2020-05-07T02:02:45.943Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2020-05-07T02:02:45.943Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2020-05-07T02:02:45.943Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T02:02:45.943Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8092]
[ns_server:debug,2020-05-07T02:02:45.943Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9110]
[ns_server:debug,2020-05-07T02:02:45.943Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_client_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9113]
[ns_server:debug,2020-05-07T02:02:45.943Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9112]
[ns_server:debug,2020-05-07T02:02:45.943Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9111]
[ns_server:debug,2020-05-07T02:02:45.947Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9115]
[ns_server:debug,2020-05-07T02:02:45.947Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_console_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9114]
[ns_server:debug,2020-05-07T02:02:45.947Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_data_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9116]
[ns_server:debug,2020-05-07T02:02:45.947Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]
[ns_server:debug,2020-05-07T02:02:45.947Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8095]
[ns_server:debug,2020-05-07T02:02:45.947Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_messaging_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9118]
[ns_server:debug,2020-05-07T02:02:45.947Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_callback_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9119]
[ns_server:debug,2020-05-07T02:02:45.947Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9121]
[ns_server:debug,2020-05-07T02:02:45.947Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_parent_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9122]
[ns_server:debug,2020-05-07T02:02:45.947Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_replication_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9120]
[ns_server:debug,2020-05-07T02:02:45.947Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_result_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9117]
[ns_server:debug,2020-05-07T02:02:45.947Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18095]
[ns_server:debug,2020-05-07T02:02:45.947Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2020-05-07T02:02:45.949Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {5,5,3}]
[ns_server:debug,2020-05-07T02:02:45.949Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9140]
[ns_server:info,2020-05-07T02:02:45.949Z,ns_1@127.0.0.1:<0.273.0>:ns_ssl_services_setup:notify_service:708]Successfully notified service capi_ssl_service
[ns_server:debug,2020-05-07T02:02:45.949Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8096]
[ns_server:debug,2020-05-07T02:02:45.949Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18096]
[ns_server:debug,2020-05-07T02:02:45.949Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8094]
[ns_server:debug,2020-05-07T02:02:45.949Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18094]
[ns_server:debug,2020-05-07T02:02:45.949Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9100]
[ns_server:debug,2020-05-07T02:02:45.949Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9102]
[ns_server:debug,2020-05-07T02:02:45.949Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|19102]
[ns_server:debug,2020-05-07T02:02:45.949Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9101]
[ns_server:debug,2020-05-07T02:02:45.950Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9104]
[ns_server:debug,2020-05-07T02:02:45.950Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9103]
[ns_server:debug,2020-05-07T02:02:45.950Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9105]
[ns_server:debug,2020-05-07T02:02:45.950Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:info,2020-05-07T02:02:45.950Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:541]Succesfully notified services [capi_ssl_service]
[ns_server:debug,2020-05-07T02:02:45.950Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2020-05-07T02:02:45.950Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:debug,2020-05-07T02:02:45.950Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 active]
[ns_server:debug,2020-05-07T02:02:45.951Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"@ns_server"},
 {other_users,["@cbq-engine","@projector","@goxdcr","@index","@fts",
               "@eventing","@cbas"]},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2020-05-07T02:02:45.951Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},
        {port,port},
        {maxconn,maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {privilege_debug,privilege_debug},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {rbac_file,{"~s",[rbac_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps},
   {tracing_enabled,tracing_enabled},
   {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
   {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
   {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
   {logger,
    {[{filename,{"~s/~s",[log_path,log_prefix]}},
      {cyclesize,log_cyclesize},
      {sleeptime,log_sleeptime}]}}]}]
[ns_server:debug,2020-05-07T02:02:45.951Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {privilege_debug,false},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false},
 {tracing_enabled,true},
 {datatype_snappy,true}]
[ns_server:debug,2020-05-07T02:02:45.951Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2020-05-07T02:02:45.951Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2020-05-07T02:02:45.952Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T02:02:45.952Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9999]
[ns_server:debug,2020-05-07T02:02:45.952Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8093]
[ns_server:debug,2020-05-07T02:02:45.952Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2020-05-07T02:02:45.952Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18092]
[ns_server:debug,2020-05-07T02:02:45.952Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18093]
[ns_server:debug,2020-05-07T02:02:45.952Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18091]
[ns_server:debug,2020-05-07T02:02:45.952Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 <<"0f8760945f98b1efdbef0bd1ea6e8446">>]
[ns_server:debug,2020-05-07T02:02:45.952Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9998]
[ns_server:debug,2020-05-07T02:02:45.952Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|false]
[ns_server:debug,2020-05-07T02:02:45.952Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{2,63756036165}}]}]
[error_logger:info,2020-05-07T02:02:45.952Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.258.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.952Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.250.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:02:45.952Z,ns_1@127.0.0.1:ns_config_rep<0.258.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([alert_limits,audit,auto_failover_cfg,
                               auto_reprovision_cfg,autocompaction,buckets,
                               cbas_memory_quota,cert_and_pkey,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,
                               index_aware_rebalance_disabled,
                               log_redaction_default_cfg,max_bucket_count,
                               memcached,memory_quota,nodes_wanted,otp,
                               password_policy,quorum_nodes,
                               read_only_user_creds,remote_clusters,
                               replication,rest,rest_creds,secure_headers,
                               server_groups,set_view_update_daemon,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {request_limit,capi},
                               {request_limit,rest},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',cbas_admin_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_client_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_http_port},
                               {node,'ns_1@127.0.0.1',cbas_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_console_port},
                               {node,'ns_1@127.0.0.1',cbas_data_port},
                               {node,'ns_1@127.0.0.1',cbas_debug_port},
                               {node,'ns_1@127.0.0.1',cbas_http_port},
                               {node,'ns_1@127.0.0.1',cbas_messaging_port},
                               {node,'ns_1@127.0.0.1',
                                   cbas_metadata_callback_port},
                               {node,'ns_1@127.0.0.1',cbas_metadata_port},
                               {node,'ns_1@127.0.0.1',cbas_parent_port},
                               {node,'ns_1@127.0.0.1',cbas_replication_port},
                               {node,'ns_1@127.0.0.1',cbas_result_port},
                               {node,'ns_1@127.0.0.1',cbas_ssl_port},
                               {node,'ns_1@127.0.0.1',compaction_daemon},
                               {node,'ns_1@127.0.0.1',config_version},
                               {node,'ns_1@127.0.0.1',eventing_debug_port},
                               {node,'ns_1@127.0.0.1',eventing_http_port},
                               {node,'ns_1@127.0.0.1',eventing_https_port},
                               {node,'ns_1@127.0.0.1',fts_http_port},
                               {node,'ns_1@127.0.0.1',fts_ssl_port},
                               {node,'ns_1@127.0.0.1',indexer_admin_port},
                               {node,'ns_1@127.0.0.1',indexer_http_port},
                               {node,'ns_1@127.0.0.1',indexer_https_port},
                               {node,'ns_1@127.0.0.1',indexer_scan_port},
                               {node,'ns_1@127.0.0.1',indexer_stcatchup_port}]..)
[error_logger:info,2020-05-07T02:02:45.955Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.280.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.957Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.282.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.957Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.285.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.957Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.286.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:45.960Z,ns_1@127.0.0.1:ns_log_events<0.249.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2020-05-07T02:02:45.960Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.288.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.960Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.287.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:45.960Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.289.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.962Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.290.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.965Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.292.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.966Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.296.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.966Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.291.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:45.967Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.301.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:45.969Z,ns_1@127.0.0.1:ns_heart<0.292.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2020-05-07T02:02:45.969Z,ns_1@127.0.0.1:ns_heart<0.292.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]}]}}

[ns_server:debug,2020-05-07T02:02:45.972Z,ns_1@127.0.0.1:<0.299.0>:restartable:start_child:98]Started child process <0.300.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2020-05-07T02:02:45.972Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.303.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.972Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.299.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:45.972Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.306.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.975Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.307.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.976Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.308.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.976Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.309.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.976Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.310.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.978Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.312.0>},
                       {name,query_settings_manager},
                       {mfargs,{query_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.981Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.314.0>},
                       {name,eventing_settings_manager},
                       {mfargs,{eventing_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.982Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.316.0>},
                       {name,audit_events},
                       {mfargs,{gen_event,start_link,[{local,audit_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.990Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.319.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:45.991Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.321.0>},
                       {name,scram_sha},
                       {mfargs,{scram_sha,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:45.993Z,ns_1@127.0.0.1:ns_heart<0.292.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2020-05-07T02:02:45.994Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.322.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:45.996Z,ns_1@127.0.0.1:ns_heart<0.292.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T02:02:46.010Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.324.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.017Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.325.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.017Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.326.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:02:46.020Z,ns_1@127.0.0.1:menelaus_sup<0.317.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T02:02:46.020Z,ns_1@127.0.0.1:menelaus_sup<0.317.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T02:02:46.020Z,ns_1@127.0.0.1:menelaus_sup<0.317.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T02:02:46.020Z,ns_1@127.0.0.1:menelaus_sup<0.317.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[error_logger:info,2020-05-07T02:02:46.021Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.327.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.023Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.352.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.024Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.296.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,244}]},
                 {proc_lib,init_p_do_apply,3,
                           [{file,"proc_lib.erl"},{line,239}]}]}}

[ns_server:debug,2020-05-07T02:02:46.024Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.296.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,244}]}]}}

[error_logger:info,2020-05-07T02:02:46.026Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.359.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.026Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.296.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T02:02:46.026Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.296.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T02:02:46.030Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.362.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.033Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.364.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2020-05-07T02:02:46.037Z,ns_1@127.0.0.1:ns_server_sup<0.236.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "6.0.3-2895-enterprise".
[error_logger:info,2020-05-07T02:02:46.037Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.317.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:46.037Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.370.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.040Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.374.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:46.041Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.375.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.31986353>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.041Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.373.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:02:46.046Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[ns_server:warn,2020-05-07T02:02:46.047Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:02:46.047Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[ns_server:debug,2020-05-07T02:02:46.053Z,ns_1@127.0.0.1:ns_ports_setup<0.370.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,goxdcr]
[error_logger:info,2020-05-07T02:02:46.055Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.377.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.055Z,ns_1@127.0.0.1:ns_audit_cfg<0.378.0>:ns_audit_cfg:write_audit_json:265]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{descriptors_path,
                                                                                <<"/opt/couchbase/etc/security">>},
                                                                               {version,
                                                                                1},
                                                                               {auditd_enabled,
                                                                                false},
                                                                               {disabled,
                                                                                []},
                                                                               {log_path,
                                                                                <<"/opt/couchbase/var/lib/couchbase/logs">>},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []}]
[ns_server:debug,2020-05-07T02:02:46.068Z,ns_1@127.0.0.1:ns_audit_cfg<0.378.0>:ns_audit_cfg:notify_memcached:170]Instruct memcached to reload audit config
[error_logger:info,2020-05-07T02:02:46.068Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:02:46.071Z,ns_1@127.0.0.1:<0.381.0>:ns_memcached:connect:1230]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2020-05-07T02:02:46.073Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.382.0>},
                       {name,ns_audit},
                       {mfargs,{ns_audit,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.075Z,ns_1@127.0.0.1:memcached_config_mgr<0.383.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2020-05-07T02:02:46.075Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.383.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:02:46.076Z,ns_1@127.0.0.1:<0.384.0>:ns_memcached_log_rotator:init:42]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2020-05-07T02:02:46.076Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.384.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.081Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.385.0>},
                       {name,testconditions_store},
                       {mfargs,{simple_store,start_link,[testconditions]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.082Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.387.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.084Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.389.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.084Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.388.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:46.084Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.386.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:info,2020-05-07T02:02:46.103Z,ns_1@127.0.0.1:ns_couchdb_port<0.214.0>:ns_port_server:log:223]ns_couchdb<0.214.0>: working as port

[error_logger:info,2020-05-07T02:02:46.104Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.390.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.104Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.394.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.107Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.396.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.109Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.397.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.109Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.399.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.113Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.400.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.113Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.402.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.115Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.403.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.129Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.405.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.129Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.407.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.136Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.408.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.141Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.410.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.145Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.410.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T02:02:46.146Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.410.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2020-05-07T02:02:46.149Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.414.0>},
                       {name,service_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_stats_children_sup},
                                services_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:46.163Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.416.0>},
                       {name,service_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [service_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.169Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.417.0>},
                       {name,service_status_keeper_index},
                       {mfargs,{service_index,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.173Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.420.0>},
                       {name,service_status_keeper_fts},
                       {mfargs,{service_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.177Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.423.0>},
                       {name,service_status_keeper_eventing},
                       {mfargs,{service_eventing,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.177Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.415.0>},
                       {name,service_status_keeper_sup},
                       {mfargs,{service_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:46.177Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.426.0>},
                       {name,service_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<services_stats_sup.0.41280346>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.177Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.413.0>},
                       {name,services_stats_sup},
                       {mfargs,{services_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:46.188Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.428.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.206Z,ns_1@127.0.0.1:<0.431.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.431.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2020-05-07T02:02:46.210Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[error_logger:info,2020-05-07T02:02:46.210Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.429.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.210Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:02:46.210Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:02:46.210Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:02:46.210Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:02:46.210Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2020-05-07T02:02:46.211Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.433.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.211Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.432.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:46.213Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.434.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.219Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.438.0>},
                       {name,leader_activities},
                       {mfargs,{leader_activities,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.226Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.439.0>},
                       {name,leader_lease_agent},
                       {mfargs,{leader_lease_agent,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.226Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.437.0>},
                       {name,leader_leases_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_leases_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:46.226Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.441.0>},
                       {name,leader_events},
                       {mfargs,{gen_event,start_link,[{local,leader_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.231Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.442.0>},
                       {name,leader_registry_server},
                       {mfargs,{leader_registry_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.235Z,ns_1@127.0.0.1:ns_ports_setup<0.370.0>:ns_ports_setup:set_children:90]Monitor ns_child_ports_sup <12401.74.0>
[ns_server:debug,2020-05-07T02:02:46.235Z,ns_1@127.0.0.1:memcached_config_mgr<0.383.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2020-05-07T02:02:46.236Z,ns_1@127.0.0.1:leader_registry_sup<0.440.0>:mb_master:check_master_takeover_needed:270]Sending master node question to the following nodes: []
[ns_server:debug,2020-05-07T02:02:46.236Z,ns_1@127.0.0.1:leader_registry_sup<0.440.0>:mb_master:check_master_takeover_needed:272]Got replies: []
[ns_server:debug,2020-05-07T02:02:46.236Z,ns_1@127.0.0.1:leader_registry_sup<0.440.0>:mb_master:check_master_takeover_needed:278]Was unable to discover master, not going to force mastership takeover
[user:info,2020-05-07T02:02:46.236Z,ns_1@127.0.0.1:mb_master<0.446.0>:mb_master:init:90]I'm the only node, so I'm the master.
[ns_server:debug,2020-05-07T02:02:46.236Z,ns_1@127.0.0.1:leader_registry<0.442.0>:leader_registry_server:handle_new_leader:241]New leader is 'ns_1@127.0.0.1'. Invalidating name cache.
[ns_server:debug,2020-05-07T02:02:46.241Z,ns_1@127.0.0.1:memcached_config_mgr<0.383.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T02:02:46.261Z,ns_1@127.0.0.1:memcached_config_mgr<0.383.0>:memcached_config_mgr:init:79]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[ns_server:debug,2020-05-07T02:02:46.263Z,ns_1@127.0.0.1:leader_lease_acquirer<0.451.0>:leader_utils:wait_cluster_is_55:54]Delaying start since cluster is not fully upgraded to 5.5 yet.
[error_logger:info,2020-05-07T02:02:46.263Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.451.0>},
                       {name,leader_lease_acquirer},
                       {mfargs,{leader_lease_acquirer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.269Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.453.0>:leader_utils:wait_cluster_is_55:54]Delaying start since cluster is not fully upgraded to 5.5 yet.
[error_logger:info,2020-05-07T02:02:46.269Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.453.0>},
                       {name,leader_quorum_nodes_manager},
                       {mfargs,{leader_quorum_nodes_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.270Z,ns_1@127.0.0.1:memcached_config_mgr<0.383.0>:memcached_config_mgr:init:82]activated memcached port server
[ns_server:info,2020-05-07T02:02:46.274Z,ns_1@127.0.0.1:mb_master_sup<0.450.0>:misc:start_singleton:758]start_singleton(gen_server, ns_tick, [], []): started as <0.455.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T02:02:46.274Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.455.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.278Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.458.0>},
                       {name,ns_janitor_server},
                       {mfargs,{ns_janitor_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:02:46.279Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.457.0>:misc:start_singleton:758]start_singleton(gen_server, auto_reprovision, [], []): started as <0.459.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T02:02:46.279Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.459.0>},
                       {name,auto_reprovision},
                       {mfargs,{auto_reprovision,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.287Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[4,0]}]

[ns_server:info,2020-05-07T02:02:46.287Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_online_config_upgrader:do_upgrade_config:46]Performing online config upgrade to [4,1]
[ns_server:debug,2020-05-07T02:02:46.287Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[4,1]},
 {set,{service_map,n1ql},[]},
 {set,{service_map,index},[]}]

[ns_server:info,2020-05-07T02:02:46.287Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_online_config_upgrader:do_upgrade_config:46]Performing online config upgrade to [4,5]
[ns_server:debug,2020-05-07T02:02:46.287Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[4,5]},
 {set,{service_map,fts},[]},
 {set,{metakv,<<"/indexing/settings/config">>},
      <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>}]

[ns_server:info,2020-05-07T02:02:46.287Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_online_config_upgrader:do_upgrade_config:46]Performing online config upgrade to [4,6]
[ns_server:debug,2020-05-07T02:02:46.288Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[4,6]}]

[ns_server:info,2020-05-07T02:02:46.288Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_online_config_upgrader:do_upgrade_config:46]Performing online config upgrade to [5,0]
[ns_server:debug,2020-05-07T02:02:46.288Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[5,0]},
 {delete,roles_definitions},
 {delete,users_upgrade},
 {delete,read_only_user_creds},
 {set,buckets,[{configs,[]}]}]

[ns_server:info,2020-05-07T02:02:46.288Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_online_config_upgrader:do_upgrade_config:46]Performing online config upgrade to [5,1]
[ns_server:debug,2020-05-07T02:02:46.288Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[5,1]},
 {set,client_cert_auth,[{state,"disable"},{prefixes,[]}]},
 {set,buckets,[{configs,[]}]}]

[ns_server:info,2020-05-07T02:02:46.295Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_online_config_upgrader:do_upgrade_config:46]Performing online config upgrade to [5,5]
[ns_server:debug,2020-05-07T02:02:46.296Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[5,5]},
 {set,auto_failover_cfg,
      [{enabled,true},
       {timeout,120},
       {count,0},
       {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
       {failover_server_group,false},
       {max_count,1},
       {failed_over_server_groups,[]}]},
 {set,{metakv,<<"/query/settings/config">>},
      <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>},
 {set,{metakv,<<"/eventing/settings/config">>},<<"{\"ram_quota\":256}">>},
 {set,buckets,[{configs,[]}]},
 {delete,{rbac_upgrade,[5,5]}},
 {set,audit,
      [{enabled,[]},
       {disabled_users,[]},
       {auditd_enabled,false},
       {rotate_interval,86400},
       {rotate_size,20971520},
       {disabled,[]},
       {sync,[]},
       {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {set,quorum_nodes,['ns_1@127.0.0.1']},
 {set,scramsha_fallback_salt,<<169,238,80,91,5,165,74,47,79,135,45,74>>}]

[ns_server:info,2020-05-07T02:02:46.296Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_online_config_upgrader:do_upgrade_config:46]Performing online config upgrade to [6,0]
[ns_server:debug,2020-05-07T02:02:46.298Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[6,0]},
 {set,audit_decriptors,
      [{20480,
        [{name,<<"opened DCP connection">>},
         {description,<<"opened DCP connection">>},
         {enabled,true},
         {module,memcached}]},
       {20482,
        [{name,<<"external memcached bucket flush">>},
         {description,<<"External user flushed the content of a memcached bucket">>},
         {enabled,true},
         {module,memcached}]},
       {20483,
        [{name,<<"invalid packet">>},
         {description,<<"Rejected an invalid packet">>},
         {enabled,true},
         {module,memcached}]},
       {20485,
        [{name,<<"authentication succeeded">>},
         {description,<<"Authentication to the cluster succeeded">>},
         {enabled,false},
         {module,memcached}]},
       {20488,
        [{name,<<"document read">>},
         {description,<<"Document was read">>},
         {enabled,false},
         {module,memcached}]},
       {20489,
        [{name,<<"document locked">>},
         {description,<<"Document was locked">>},
         {enabled,false},
         {module,memcached}]},
       {20490,
        [{name,<<"document modify">>},
         {description,<<"Document was modified">>},
         {enabled,false},
         {module,memcached}]},
       {20491,
        [{name,<<"document delete">>},
         {description,<<"Document was deleted">>},
         {enabled,false},
         {module,memcached}]},
       {20492,
        [{name,<<"select bucket">>},
         {description,<<"The specified bucket was selected">>},
         {enabled,true},
         {module,memcached}]},
       {28672,
        [{name,<<"SELECT statement">>},
         {description,<<"A N1QL SELECT statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28673,
        [{name,<<"EXPLAIN statement">>},
         {description,<<"A N1QL EXPLAIN statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28674,
        [{name,<<"PREPARE statement">>},
         {description,<<"A N1QL PREPARE statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28675,
        [{name,<<"INFER statement">>},
         {description,<<"A N1QL INFER statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28676,
        [{name,<<"INSERT statement">>},
         {description,<<"A N1QL INSERT statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28677,
        [{name,<<"UPSERT statement">>},
         {description,<<"A N1QL UPSERT statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28678,
        [{name,<<"DELETE statement">>},
         {description,<<"A N1QL DELETE statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28679,
        [{name,<<"UPDATE statement">>},
         {description,<<"A N1QL UPDATE statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28680,
        [{name,<<"MERGE statement">>},
         {description,<<"A N1QL MERGE statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28681,
        [{name,<<"CREATE INDEX statement">>},
         {description,<<"A N1QL CREATE INDEX statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28682,
        [{name,<<"DROP INDEX statement">>},
         {description,<<"A N1QL DROP INDEX statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28683,
        [{name,<<"ALTER INDEX statement">>},
         {description,<<"A N1QL ALTER INDEX statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28684,
        [{name,<<"BUILD INDEX statement">>},
         {description,<<"A N1QL BUILD INDEX statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28685,
        [{name,<<"GRANT ROLE statement">>},
         {description,<<"A N1QL GRANT ROLE statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28686,
        [{name,<<"REVOKE ROLE statement">>},
         {description,<<"A N1QL REVOKE ROLE statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28687,
        [{name,<<"UNRECOGNIZED statement">>},
         {description,<<"An unrecognized statement was received by the N1QL query engine">>},
         {enabled,false},
         {module,n1ql}]},
       {28688,
        [{name,<<"CREATE PRIMARY INDEX statement">>},
         {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28689,
        [{name,<<"/admin/stats API request">>},
         {description,<<"An HTTP request was made to the API at /admin/stats.">>},
         {enabled,false},
         {module,n1ql}]},
       {28690,
        [{name,<<"/admin/vitals API request">>},
         {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
         {enabled,false},
         {module,n1ql}]},
       {28691,
        [{name,<<"/admin/prepareds API request">>},
         {description,<<"An HTTP request was made to the API at /admin/prepareds.">>},
         {enabled,false},
         {module,n1ql}]},
       {28692,
        [{name,<<"/admin/active_requests API request">>},
         {description,<<"An HTTP request was made to the API at /admin/active_requests.">>},
         {enabled,false},
         {module,n1ql}]},
       {28693,
        [{name,<<"/admin/indexes/prepareds API request">>},
         {description,<<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
         {enabled,false},
         {module,n1ql}]},
       {28694,
        [{name,<<"/admin/indexes/active_requests API request">>},
         {description,<<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
         {enabled,false},
         {module,n1ql}]},
       {28695,
        [{name,<<"/admin/indexes/completed_requests API request">>},
         {description,<<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
         {enabled,false},
         {module,n1ql}]},
       {28697,
        [{name,<<"/admin/ping API request">>},
         {description,<<"An HTTP request was made to the API at /admin/ping.">>},
         {enabled,false},
         {module,n1ql}]},
       {28698,
        [{name,<<"/admin/config API request">>},
         {description,<<"An HTTP request was made to the API at /admin/config.">>},
         {enabled,false},
         {module,n1ql}]},
       {28699,
        [{name,<<"/admin/ssl_cert API request">>},
         {description,<<"An HTTP request was made to the API at /admin/ssl_cert.">>},
         {enabled,false},
         {module,n1ql}]},
       {28700,
        [{name,<<"/admin/settings API request">>},
         {description,<<"An HTTP request was made to the API at /admin/settings.">>},
         {enabled,false},
         {module,n1ql}]},
       {28701,
        [{name,<<"/admin/clusters API request">>},
         {description,<<"An HTTP request was made to the API at /admin/clusters.">>},
         {enabled,false},
         {module,n1ql}]},
       {28702,
        [{name,<<"/admin/completed_requests API request">>},
         {description,<<"An HTTP request was made to the API at /admin/completed_requests.">>},
         {enabled,false},
         {module,n1ql}]},
       {32768,
        [{name,<<"Create Function">>},
         {description,<<"Eventing function definition was created or updated">>},
         {enabled,true},
         {module,eventing}]},
       {32769,
        [{name,<<"Delete Function">>},
         {description,<<"Eventing function definition was deleted">>},
         {enabled,true},
         {module,eventing}]},
       {32770,
        [{name,<<"Fetch Functions">>},
         {description,<<"Eventing function definition was read">>},
         {enabled,false},
         {module,eventing}]},
       {32771,
        [{name,<<"List Deployed">>},
         {description,<<"Eventing deployed functions list was read">>},
         {enabled,false},
         {module,eventing}]},
       {32772,
        [{name,<<"Fetch Drafts">>},
         {description,<<"Eventing function draft definitions were read">>},
         {enabled,false},
         {module,eventing}]},
       {32773,
        [{name,<<"Delete Drafts">>},
         {description,<<"Eventing function draft definitions were deleted">>},
         {enabled,true},
         {module,eventing}]},
       {32774,
        [{name,<<"Save Draft">>},
         {description,<<"Save a draft definition to the store">>},
         {enabled,true},
         {module,eventing}]},
       {32775,
        [{name,<<"Start Debug">>},
         {description,<<"Start eventing function debugger">>},
         {enabled,true},
         {module,eventing}]},
       {32776,
        [{name,<<"Stop Debug">>},
         {description,<<"Stop eventing function debugger">>},
         {enabled,true},
         {module,eventing}]},
       {32777,
        [{name,<<"Start Tracing">>},
         {description,<<"Start tracing eventing function execution">>},
         {enabled,true},
         {module,eventing}]},
       {32778,
        [{name,<<"Stop Tracing">>},
         {description,<<"Stop tracing eventing function execution">>},
         {enabled,true},
         {module,eventing}]},
       {32779,
        [{name,<<"Set Settings">>},
         {description,<<"Save settings for a given app">>},
         {enabled,true},
         {module,eventing}]},
       {32780,
        [{name,<<"Fetch Config">>},
         {description,<<"Get config for eventing">>},
         {enabled,false},
         {module,eventing}]},
       {32781,
        [{name,<<"Save Config">>},
         {description,<<"Save config for eventing">>},
         {enabled,true},
         {module,eventing}]},
       {32782,
        [{name,<<"Cleanup Eventing">>},
         {description,<<"Clears up app definitions and settings from metakv">>},
         {enabled,true},
         {module,eventing}]},
       {32783,
        [{name,<<"Get Settings">>},
         {description,<<"Get settings for a given app">>},
         {enabled,false},
         {module,eventing}]},
       {32784,
        [{name,<<"Import Functions">>},
         {description,<<"Import a list of functions">>},
         {enabled,false},
         {module,eventing}]},
       {32785,
        [{name,<<"Export Functions">>},
         {description,<<"Export the list of functions">>},
         {enabled,false},
         {module,eventing}]},
       {32786,
        [{name,<<"List Running">>},
         {description,<<"Eventing running function list was read">>},
         {enabled,false},
         {module,eventing}]},
       {36865,
        [{name,<<"Service configuration change">>},
         {description,<<"A successful service configuration change was made.">>},
         {enabled,true},
         {module,analytics}]},
       {36866,
        [{name,<<"Node configuration change">>},
         {description,<<"A successful node configuration change was made.">>},
         {enabled,true},
         {module,analytics}]}]}]

[ns_server:debug,2020-05-07T02:02:46.301Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.453.0>:leader_utils:wait_cluster_is_55_loop:78]Cluster upgraded to 5.5. Starting.
[ns_server:debug,2020-05-07T02:02:46.301Z,ns_1@127.0.0.1:leader_lease_acquirer<0.451.0>:leader_utils:wait_cluster_is_55_loop:78]Cluster upgraded to 5.5. Starting.
[ns_server:debug,2020-05-07T02:02:46.301Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.453.0>:leader_quorum_nodes_manager:pull_config:114]Attempting to pull config from nodes:
[]
[ns_server:debug,2020-05-07T02:02:46.301Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.453.0>:leader_quorum_nodes_manager:pull_config:119]Pulled config successfully.
[ns_server:debug,2020-05-07T02:02:46.301Z,ns_1@127.0.0.1:compiled_roles_cache<0.207.0>:versioned_cache:handle_info:89]Flushing cache compiled_roles_cache due to version change from {undefined,
                                                                {0,3268678210},
                                                                false,[]} to {[6,
                                                                               0],
                                                                              {0,
                                                                               3268678210},
                                                                              false,
                                                                              []}
[ns_server:debug,2020-05-07T02:02:46.302Z,ns_1@127.0.0.1:memcached_permissions<0.246.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T02:02:46.308Z,ns_1@127.0.0.1:users_storage<0.205.0>:replicated_dets:handle_call:354]Suspended by process <0.246.0>
[ns_server:debug,2020-05-07T02:02:46.308Z,ns_1@127.0.0.1:memcached_permissions<0.246.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{user,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T02:02:46.309Z,ns_1@127.0.0.1:users_storage<0.205.0>:replicated_dets:handle_call:361]Released by process <0.246.0>
[ns_server:debug,2020-05-07T02:02:46.311Z,ns_1@127.0.0.1:menelaus_ui_auth<0.319.0>:token_server:handle_cast:202]Purge tokens []
[ns_server:debug,2020-05-07T02:02:46.319Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of rbac requested
[ns_server:debug,2020-05-07T02:02:46.320Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:trigger_ssl_reload:565]Notify services [ssl_service,capi_ssl_service] about client_cert_auth change
[ns_server:debug,2020-05-07T02:02:46.320Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:525]Going to notify following services: [capi_ssl_service,ssl_service]
[ns_server:debug,2020-05-07T02:02:46.322Z,ns_1@127.0.0.1:ns_config_rep<0.258.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([audit,audit_decriptors,auto_failover_cfg,
                               buckets,client_cert_auth,
                               cluster_compat_version,quorum_nodes,
                               read_only_user_creds,roles_definitions,
                               scramsha_fallback_salt,users_upgrade,
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>},
                               {metakv,<<"/eventing/settings/config">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {metakv,<<"/query/settings/config">>},
                               {rbac_upgrade,[5,5]},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql}]..)
[ns_server:warn,2020-05-07T02:02:46.325Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:02:46.325Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[ns_server:warn,2020-05-07T02:02:46.325Z,ns_1@127.0.0.1:<0.475.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:02:46.326Z,ns_1@127.0.0.1:<0.183.0>:restartable:loop:71]Restarting child <0.184.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
  Shutdown policy: 1000
  Caller: {<0.483.0>,#Ref<0.0.0.1616>}
[ns_server:debug,2020-05-07T02:02:46.327Z,ns_1@127.0.0.1:<0.448.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.383.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[ns_server:debug,2020-05-07T02:02:46.326Z,ns_1@127.0.0.1:<0.449.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.383.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.328Z,ns_1@127.0.0.1:<0.183.0>:restartable:shutdown_child:120]Successfully terminated process <0.184.0>
[ns_server:debug,2020-05-07T02:02:46.335Z,ns_1@127.0.0.1:ns_config_rep<0.258.0>:ns_config_rep:handle_call:116]Got full synchronization request from 'ns_1@127.0.0.1'
[ns_server:debug,2020-05-07T02:02:46.335Z,ns_1@127.0.0.1:ns_config_rep<0.258.0>:ns_config_rep:handle_call:122]Fully synchronized config in 11 us
[user:warn,2020-05-07T02:02:46.335Z,ns_1@127.0.0.1:<0.460.0>:ns_orchestrator:consider_switching_compat_mode_dont_exit:925]Changed cluster compat mode from undefined to [6,0]
[ns_server:info,2020-05-07T02:02:46.335Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.457.0>:misc:start_singleton:758]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.460.0> on 'ns_1@127.0.0.1'

[ns_server:debug,2020-05-07T02:02:46.336Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit_decriptors ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {20480,
  [{name,<<"opened DCP connection">>},
   {description,<<"opened DCP connection">>},
   {enabled,true},
   {module,memcached}]},
 {20482,
  [{name,<<"external memcached bucket flush">>},
   {description,<<"External user flushed the content of a memcached bucket">>},
   {enabled,true},
   {module,memcached}]},
 {20483,
  [{name,<<"invalid packet">>},
   {description,<<"Rejected an invalid packet">>},
   {enabled,true},
   {module,memcached}]},
 {20485,
  [{name,<<"authentication succeeded">>},
   {description,<<"Authentication to the cluster succeeded">>},
   {enabled,false},
   {module,memcached}]},
 {20488,
  [{name,<<"document read">>},
   {description,<<"Document was read">>},
   {enabled,false},
   {module,memcached}]},
 {20489,
  [{name,<<"document locked">>},
   {description,<<"Document was locked">>},
   {enabled,false},
   {module,memcached}]},
 {20490,
  [{name,<<"document modify">>},
   {description,<<"Document was modified">>},
   {enabled,false},
   {module,memcached}]},
 {20491,
  [{name,<<"document delete">>},
   {description,<<"Document was deleted">>},
   {enabled,false},
   {module,memcached}]},
 {20492,
  [{name,<<"select bucket">>},
   {description,<<"The specified bucket was selected">>},
   {enabled,true},
   {module,memcached}]},
 {28672,
  [{name,<<"SELECT statement">>},
   {description,<<"A N1QL SELECT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28673,
  [{name,<<"EXPLAIN statement">>},
   {description,<<"A N1QL EXPLAIN statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28674,
  [{name,<<"PREPARE statement">>},
   {description,<<"A N1QL PREPARE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28675,
  [{name,<<"INFER statement">>},
   {description,<<"A N1QL INFER statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28676,
  [{name,<<"INSERT statement">>},
   {description,<<"A N1QL INSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28677,
  [{name,<<"UPSERT statement">>},
   {description,<<"A N1QL UPSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28678,
  [{name,<<"DELETE statement">>},
   {description,<<"A N1QL DELETE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28679,
  [{name,<<"UPDATE statement">>},
   {description,<<"A N1QL UPDATE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28680,
  [{name,<<"MERGE statement">>},
   {description,<<"A N1QL MERGE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28681,
  [{name,<<"CREATE INDEX statement">>},
   {description,<<"A N1QL CREATE INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28682,
  [{name,<<"DROP INDEX statement">>},
   {description,<<"A N1QL DROP INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28683,
  [{name,<<"ALTER INDEX statement">>},
   {description,<<"A N1QL ALTER INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28684,
  [{name,<<"BUILD INDEX statement">>},
   {description,<<"A N1QL BUILD INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28685,
  [{name,<<"GRANT ROLE statement">>},
   {description,<<"A N1QL GRANT ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28686,
  [{name,<<"REVOKE ROLE statement">>},
   {description,<<"A N1QL REVOKE ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28687,
  [{name,<<"UNRECOGNIZED statement">>},
   {description,<<"An unrecognized statement was received by the N1QL query engine">>},
   {enabled,false},
   {module,n1ql}]},
 {28688,
  [{name,<<"CREATE PRIMARY INDEX statement">>},
   {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28689,
  [{name,<<"/admin/stats API request">>},
   {description,<<"An HTTP request was made to the API at /admin/stats.">>},
   {enabled,false},
   {module,n1ql}]},
 {28690,
  [{name,<<"/admin/vitals API request">>},
   {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
   {enabled,false},
   {module,n1ql}]},
 {28691,
  [{name,<<"/admin/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28692,
  [{name,<<"/admin/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28693,
  [{name,<<"/admin/indexes/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28694,
  [{name,<<"/admin/indexes/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28695,
  [{name,<<"/admin/indexes/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28697,
  [{name,<<"/admin/ping API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ping.">>},
   {enabled,false},
   {module,n1ql}]},
 {28698,
  [{name,<<"/admin/config API request">>},
   {description,<<"An HTTP request was made to the API at /admin/config.">>},
   {enabled,false},
   {module,n1ql}]},
 {28699,
  [{name,<<"/admin/ssl_cert API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ssl_cert.">>},
   {enabled,false},
   {module,n1ql}]},
 {28700,
  [{name,<<"/admin/settings API request">>},
   {description,<<"An HTTP request was made to the API at /admin/settings.">>},
   {enabled,false},
   {module,n1ql}]},
 {28701,
  [{name,<<"/admin/clusters API request">>},
   {description,<<"An HTTP request was made to the API at /admin/clusters.">>},
   {enabled,false},
   {module,n1ql}]},
 {28702,
  [{name,<<"/admin/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {32768,
  [{name,<<"Create Function">>},
   {description,<<"Eventing function definition was created or updated">>},
   {enabled,true},
   {module,eventing}]},
 {32769,
  [{name,<<"Delete Function">>},
   {description,<<"Eventing function definition was deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32770,
  [{name,<<"Fetch Functions">>},
   {description,<<"Eventing function definition was read">>},
   {enabled,false},
   {module,eventing}]},
 {32771,
  [{name,<<"List Deployed">>},
   {description,<<"Eventing deployed functions list was read">>},
   {enabled,false},
   {module,eventing}]},
 {32772,
  [{name,<<"Fetch Drafts">>},
   {description,<<"Eventing function draft definitions were read">>},
   {enabled,false},
   {module,eventing}]},
 {32773,
  [{name,<<"Delete Drafts">>},
   {description,<<"Eventing function draft definitions were deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32774,
  [{name,<<"Save Draft">>},
   {description,<<"Save a draft definition to the store">>},
   {enabled,true},
   {module,eventing}]},
 {32775,
  [{name,<<"Start Debug">>},
   {description,<<"Start eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32776,
  [{name,<<"Stop Debug">>},
   {description,<<"Stop eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32777,
  [{name,<<"Start Tracing">>},
   {description,<<"Start tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32778,
  [{name,<<"Stop Tracing">>},
   {description,<<"Stop tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32779,
  [{name,<<"Set Settings">>},
   {description,<<"Save settings for a given app">>},
   {enabled,true},
   {module,eventing}]},
 {32780,
  [{name,<<"Fetch Config">>},
   {description,<<"Get config for eventing">>},
   {enabled,false},
   {module,eventing}]},
 {32781,
  [{name,<<"Save Config">>},
   {description,<<"Save config for eventing">>},
   {enabled,true},
   {module,eventing}]},
 {32782,
  [{name,<<"Cleanup Eventing">>},
   {description,<<"Clears up app definitions and settings from metakv">>},
   {enabled,true},
   {module,eventing}]},
 {32783,
  [{name,<<"Get Settings">>},
   {description,<<"Get settings for a given app">>},
   {enabled,false},
   {module,eventing}]},
 {32784,
  [{name,<<"Import Functions">>},
   {description,<<"Import a list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32785,
  [{name,<<"Export Functions">>},
   {description,<<"Export the list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32786,
  [{name,<<"List Running">>},
   {description,<<"Eventing running function list was read">>},
   {enabled,false},
   {module,eventing}]},
 {36865,
  [{name,<<"Service configuration change">>},
   {description,<<"A successful service configuration change was made.">>},
   {enabled,true},
   {module,analytics}]},
 {36866,
  [{name,<<"Node configuration change">>},
   {description,<<"A successful node configuration change was made.">>},
   {enabled,true},
   {module,analytics}]}]
[ns_server:debug,2020-05-07T02:02:46.336Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
scramsha_fallback_salt ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<169,238,80,91,5,165,74,47,79,135,45,74>>]
[ns_server:debug,2020-05-07T02:02:46.336Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{rbac_upgrade,[5,5]} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T02:02:46.336Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/eventing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"ram_quota\":256}">>]
[ns_server:debug,2020-05-07T02:02:46.336Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/query/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]
[ns_server:debug,2020-05-07T02:02:46.336Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
client_cert_auth ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {state,"disable"},
 {prefixes,[]}]
[ns_server:debug,2020-05-07T02:02:46.336Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
users_upgrade ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T02:02:46.336Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
roles_definitions ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T02:02:46.341Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,fts} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T02:02:46.342Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,index} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T02:02:46.342Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T02:02:46.342Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cluster_compat_version ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},6,0]
[ns_server:debug,2020-05-07T02:02:46.342Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,[]},
 {disabled_users,[]},
 {auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2020-05-07T02:02:46.342Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[ns_server:debug,2020-05-07T02:02:46.342Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
buckets ->
[[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}],{configs,[]}]
[ns_server:debug,2020-05-07T02:02:46.342Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
quorum_nodes ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T02:02:46.342Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
read_only_user_creds ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T02:02:46.342Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2020-05-07T02:02:46.342Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]}]
[ns_server:info,2020-05-07T02:02:46.343Z,ns_1@127.0.0.1:<0.482.0>:ns_ssl_services_setup:notify_service:708]Successfully notified service capi_ssl_service
[ns_server:debug,2020-05-07T02:02:46.353Z,ns_1@127.0.0.1:leader_lease_agent<0.439.0>:leader_lease_agent:do_handle_acquire_lease:147]Granting lease to {lease_holder,<<"aa7283a89b1b123b91b897b397e10db0">>,
                                'ns_1@127.0.0.1'} for 15000ms
[error_logger:error,2020-05-07T02:02:46.369Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.472.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 112
  neighbours:

[error_logger:error,2020-05-07T02:02:46.369Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.383.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[error_logger:error,2020-05-07T02:02:46.370Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.383.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: [do_check,do_check]
    links: [<0.236.0>,<0.449.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 26685
  neighbours:

[error_logger:error,2020-05-07T02:02:46.370Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.475.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[error_logger:info,2020-05-07T02:02:46.370Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.460.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.370Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.457.0>},
                       {name,ns_orchestrator_child_sup},
                       {mfargs,{ns_orchestrator_child_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:info,2020-05-07T02:02:46.377Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T02:02:46.379Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T02:02:46.379Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T02:02:46.380Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[ns_server:debug,2020-05-07T02:02:46.381Z,ns_1@127.0.0.1:<0.183.0>:restartable:start_child:98]Started child process <0.496.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[ns_server:info,2020-05-07T02:02:46.381Z,ns_1@127.0.0.1:<0.483.0>:ns_ssl_services_setup:notify_service:708]Successfully notified service ssl_service
[ns_server:info,2020-05-07T02:02:46.382Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:541]Succesfully notified services [ssl_service,capi_ssl_service]
[ns_server:debug,2020-05-07T02:02:46.390Z,ns_1@127.0.0.1:<0.513.0>:auto_failover:init:211]init auto_failover.
[user:info,2020-05-07T02:02:46.391Z,ns_1@127.0.0.1:<0.513.0>:auto_failover:handle_call:242]Enabled auto-failover with timeout 120 and max count 1
[ns_server:info,2020-05-07T02:02:46.391Z,ns_1@127.0.0.1:<0.471.0>:leader_lease_acquire_worker:handle_fresh_lease_acquired:302]Acquired lease from node 'ns_1@127.0.0.1' (lease uuid: <<"aa7283a89b1b123b91b897b397e10db0">>)
[ns_server:info,2020-05-07T02:02:46.404Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.456.0>:misc:start_singleton:758]start_singleton(gen_server, auto_failover, [], []): started as <0.513.0> on 'ns_1@127.0.0.1'

[ns_server:debug,2020-05-07T02:02:46.405Z,ns_1@127.0.0.1:ns_config_rep<0.258.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([auto_failover_cfg,
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>}]..)
[ns_server:debug,2020-05-07T02:02:46.405Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{4,63756036166}}]}]
[ns_server:debug,2020-05-07T02:02:46.405Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[error_logger:info,2020-05-07T02:02:46.405Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.513.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.405Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.456.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:46.405Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.446.0>},
                       {name,mb_master},
                       {mfargs,{mb_master,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:02:46.405Z,ns_1@127.0.0.1:<0.435.0>:restartable:start_child:98]Started child process <0.436.0>
  MFA: {leader_services_sup,start_link,[]}
[error_logger:info,2020-05-07T02:02:46.405Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.440.0>},
                       {name,leader_registry_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_registry_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:46.405Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.435.0>},
                       {name,leader_services_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{leader_services_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:46.405Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.521.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.406Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.522.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.412Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.523.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.433Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.524.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.452Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.527.0>},
                       {name,ns_server_monitor},
                       {mfargs,{ns_server_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.453Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.529.0>},
                       {name,service_monitor_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_monitor_children_sup},
                                health_monitor_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:46.453Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.530.0>},
                       {name,service_monitor_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<health_monitor_sup.0.81875396>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.460Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.538.0>},
                       {name,node_monitor},
                       {mfargs,{node_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.462Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.546.0>},
                       {name,node_status_analyzer},
                       {mfargs,{node_status_analyzer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:02:46.462Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.526.0>},
                       {name,health_monitor_sup},
                       {mfargs,{health_monitor_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:error,2020-05-07T02:02:46.462Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.383.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[ns_server:debug,2020-05-07T02:02:46.462Z,ns_1@127.0.0.1:memcached_config_mgr<0.548.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:error,2020-05-07T02:02:46.462Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.383.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2020-05-07T02:02:46.463Z,ns_1@127.0.0.1:memcached_config_mgr<0.548.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:info,2020-05-07T02:02:46.463Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.548.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.463Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[ns_server:debug,2020-05-07T02:02:46.463Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.169.0>
[error_logger:info,2020-05-07T02:02:46.463Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.236.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:02:46.463Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2020-05-07T02:02:46.463Z,ns_1@127.0.0.1:<0.168.0>:restartable:start_child:98]Started child process <0.169.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[error_logger:info,2020-05-07T02:02:46.464Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.168.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:02:46.464Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:debug,2020-05-07T02:02:46.464Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:130]138: Entered child_loop
[ns_server:debug,2020-05-07T02:02:46.465Z,ns_1@127.0.0.1:memcached_config_mgr<0.548.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T02:02:46.467Z,ns_1@127.0.0.1:memcached_config_mgr<0.548.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.468Z,ns_1@127.0.0.1:memcached_config_mgr<0.548.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.471Z,ns_1@127.0.0.1:<0.552.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.471Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.552.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[ns_server:debug,2020-05-07T02:02:46.472Z,ns_1@127.0.0.1:<0.550.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.548.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.472Z,ns_1@127.0.0.1:<0.549.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.548.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[ns_server:debug,2020-05-07T02:02:46.472Z,ns_1@127.0.0.1:memcached_config_mgr<0.553.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.472Z,ns_1@127.0.0.1:memcached_config_mgr<0.553.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2020-05-07T02:02:46.473Z,ns_1@127.0.0.1:memcached_config_mgr<0.553.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T02:02:46.474Z,ns_1@127.0.0.1:memcached_config_mgr<0.553.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.475Z,ns_1@127.0.0.1:memcached_config_mgr<0.553.0>:memcached_config_mgr:init:85]found memcached port to be already active
[error_logger:error,2020-05-07T02:02:46.476Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.551.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[error_logger:error,2020-05-07T02:02:46.476Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.548.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[error_logger:error,2020-05-07T02:02:46.477Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.548.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.550.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19576
  neighbours:

[error_logger:error,2020-05-07T02:02:46.477Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.548.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.477Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.548.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2020-05-07T02:02:46.478Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.553.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:02:46.479Z,ns_1@127.0.0.1:<0.558.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.479Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.558.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[ns_server:debug,2020-05-07T02:02:46.480Z,ns_1@127.0.0.1:<0.554.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.553.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[ns_server:debug,2020-05-07T02:02:46.480Z,ns_1@127.0.0.1:<0.556.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.553.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.480Z,ns_1@127.0.0.1:memcached_config_mgr<0.559.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.480Z,ns_1@127.0.0.1:memcached_config_mgr<0.559.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2020-05-07T02:02:46.481Z,ns_1@127.0.0.1:memcached_config_mgr<0.559.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[error_logger:error,2020-05-07T02:02:46.481Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.557.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[error_logger:error,2020-05-07T02:02:46.481Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.553.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[error_logger:error,2020-05-07T02:02:46.483Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.553.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.556.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 4185
    stack_size: 27
    reductions: 19561
  neighbours:

[ns_server:debug,2020-05-07T02:02:46.483Z,ns_1@127.0.0.1:memcached_config_mgr<0.559.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[error_logger:error,2020-05-07T02:02:46.483Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.553.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[ns_server:debug,2020-05-07T02:02:46.484Z,ns_1@127.0.0.1:memcached_config_mgr<0.559.0>:memcached_config_mgr:init:85]found memcached port to be already active
[error_logger:error,2020-05-07T02:02:46.484Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.553.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2020-05-07T02:02:46.485Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.559.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:02:46.488Z,ns_1@127.0.0.1:<0.563.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.488Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.563.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[ns_server:debug,2020-05-07T02:02:46.493Z,ns_1@127.0.0.1:<0.560.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.559.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[ns_server:debug,2020-05-07T02:02:46.492Z,ns_1@127.0.0.1:<0.561.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.559.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.493Z,ns_1@127.0.0.1:memcached_config_mgr<0.564.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.493Z,ns_1@127.0.0.1:memcached_config_mgr<0.564.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2020-05-07T02:02:46.494Z,ns_1@127.0.0.1:memcached_config_mgr<0.564.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[error_logger:error,2020-05-07T02:02:46.492Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.562.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[error_logger:error,2020-05-07T02:02:46.496Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.559.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[error_logger:error,2020-05-07T02:02:46.497Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.559.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.561.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19576
  neighbours:

[error_logger:error,2020-05-07T02:02:46.497Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.559.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.498Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.559.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2020-05-07T02:02:46.498Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.564.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.508Z,ns_1@127.0.0.1:compiled_roles_cache<0.207.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@",admin}
[ns_server:debug,2020-05-07T02:02:46.527Z,ns_1@127.0.0.1:memcached_config_mgr<0.564.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.528Z,ns_1@127.0.0.1:memcached_config_mgr<0.564.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.531Z,ns_1@127.0.0.1:<0.568.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.532Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.567.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[error_logger:error,2020-05-07T02:02:46.532Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.568.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[error_logger:error,2020-05-07T02:02:46.532Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.564.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[error_logger:error,2020-05-07T02:02:46.533Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.564.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.566.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 4185
    stack_size: 27
    reductions: 19566
  neighbours:

[error_logger:error,2020-05-07T02:02:46.533Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.564.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.534Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.564.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2020-05-07T02:02:46.534Z,ns_1@127.0.0.1:<0.565.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.564.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[ns_server:debug,2020-05-07T02:02:46.534Z,ns_1@127.0.0.1:<0.566.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.564.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.534Z,ns_1@127.0.0.1:memcached_config_mgr<0.569.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.534Z,ns_1@127.0.0.1:memcached_config_mgr<0.569.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:info,2020-05-07T02:02:46.534Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.569.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.534Z,ns_1@127.0.0.1:memcached_config_mgr<0.569.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T02:02:46.535Z,ns_1@127.0.0.1:memcached_config_mgr<0.569.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.536Z,ns_1@127.0.0.1:memcached_config_mgr<0.569.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.537Z,ns_1@127.0.0.1:<0.573.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.537Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.573.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[ns_server:debug,2020-05-07T02:02:46.537Z,ns_1@127.0.0.1:<0.570.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.569.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[ns_server:debug,2020-05-07T02:02:46.537Z,ns_1@127.0.0.1:<0.571.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.569.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[error_logger:error,2020-05-07T02:02:46.537Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.572.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[error_logger:error,2020-05-07T02:02:46.537Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.569.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[error_logger:error,2020-05-07T02:02:46.538Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.569.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.571.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 4185
    stack_size: 27
    reductions: 19575
  neighbours:

[error_logger:error,2020-05-07T02:02:46.538Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.569.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.538Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.569.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2020-05-07T02:02:46.538Z,ns_1@127.0.0.1:memcached_config_mgr<0.574.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2020-05-07T02:02:46.538Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.574.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.538Z,ns_1@127.0.0.1:memcached_config_mgr<0.574.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2020-05-07T02:02:46.540Z,ns_1@127.0.0.1:memcached_config_mgr<0.574.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T02:02:46.548Z,ns_1@127.0.0.1:memcached_config_mgr<0.574.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.548Z,ns_1@127.0.0.1:memcached_config_mgr<0.574.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.550Z,ns_1@127.0.0.1:<0.578.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.550Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.578.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[error_logger:error,2020-05-07T02:02:46.553Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.577.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[ns_server:debug,2020-05-07T02:02:46.553Z,ns_1@127.0.0.1:<0.575.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.574.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[error_logger:error,2020-05-07T02:02:46.553Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.574.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[ns_server:debug,2020-05-07T02:02:46.554Z,ns_1@127.0.0.1:<0.576.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.574.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[error_logger:error,2020-05-07T02:02:46.554Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.574.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.576.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19560
  neighbours:

[error_logger:error,2020-05-07T02:02:46.554Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.574.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.554Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.574.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2020-05-07T02:02:46.554Z,ns_1@127.0.0.1:memcached_config_mgr<0.579.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2020-05-07T02:02:46.554Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.579.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.554Z,ns_1@127.0.0.1:memcached_config_mgr<0.579.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2020-05-07T02:02:46.555Z,ns_1@127.0.0.1:memcached_config_mgr<0.579.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T02:02:46.556Z,ns_1@127.0.0.1:memcached_config_mgr<0.579.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.556Z,ns_1@127.0.0.1:memcached_config_mgr<0.579.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:debug,2020-05-07T02:02:46.561Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.584.0>:json_rpc_connection:init:73]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.584.0>
[ns_server:warn,2020-05-07T02:02:46.561Z,ns_1@127.0.0.1:<0.583.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.562Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.583.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[error_logger:error,2020-05-07T02:02:46.562Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.582.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[error_logger:error,2020-05-07T02:02:46.562Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.579.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[error_logger:error,2020-05-07T02:02:46.562Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.579.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.581.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 4185
    stack_size: 27
    reductions: 19559
  neighbours:

[ns_server:debug,2020-05-07T02:02:46.562Z,ns_1@127.0.0.1:<0.580.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.579.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[error_logger:error,2020-05-07T02:02:46.562Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.579.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[ns_server:debug,2020-05-07T02:02:46.562Z,ns_1@127.0.0.1:<0.581.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.579.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.563Z,ns_1@127.0.0.1:memcached_config_mgr<0.586.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.563Z,ns_1@127.0.0.1:memcached_config_mgr<0.586.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2020-05-07T02:02:46.563Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.579.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2020-05-07T02:02:46.563Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.586.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.565Z,ns_1@127.0.0.1:memcached_config_mgr<0.586.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T02:02:46.567Z,ns_1@127.0.0.1:memcached_config_mgr<0.586.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.567Z,ns_1@127.0.0.1:memcached_config_mgr<0.586.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.568Z,ns_1@127.0.0.1:<0.590.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.568Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.590.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[ns_server:debug,2020-05-07T02:02:46.568Z,ns_1@127.0.0.1:<0.587.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.586.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[ns_server:debug,2020-05-07T02:02:46.568Z,ns_1@127.0.0.1:<0.588.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.586.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.568Z,ns_1@127.0.0.1:memcached_config_mgr<0.591.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.568Z,ns_1@127.0.0.1:memcached_config_mgr<0.591.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2020-05-07T02:02:46.568Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.589.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[error_logger:error,2020-05-07T02:02:46.568Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.586.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[error_logger:error,2020-05-07T02:02:46.569Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.586.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.588.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 4185
    stack_size: 27
    reductions: 19562
  neighbours:

[error_logger:error,2020-05-07T02:02:46.569Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.586.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.569Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.586.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2020-05-07T02:02:46.569Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.591.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.569Z,ns_1@127.0.0.1:memcached_config_mgr<0.591.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T02:02:46.570Z,ns_1@127.0.0.1:memcached_config_mgr<0.591.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.571Z,ns_1@127.0.0.1:memcached_config_mgr<0.591.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.571Z,ns_1@127.0.0.1:<0.595.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.572Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.595.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[ns_server:debug,2020-05-07T02:02:46.572Z,ns_1@127.0.0.1:<0.592.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.591.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[ns_server:debug,2020-05-07T02:02:46.572Z,ns_1@127.0.0.1:<0.593.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.591.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.572Z,ns_1@127.0.0.1:memcached_config_mgr<0.596.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.572Z,ns_1@127.0.0.1:memcached_config_mgr<0.596.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2020-05-07T02:02:46.572Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.594.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[ns_server:debug,2020-05-07T02:02:46.572Z,ns_1@127.0.0.1:memcached_config_mgr<0.596.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[error_logger:error,2020-05-07T02:02:46.572Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.591.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[error_logger:error,2020-05-07T02:02:46.572Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.591.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.593.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 4185
    stack_size: 27
    reductions: 19566
  neighbours:

[error_logger:error,2020-05-07T02:02:46.572Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.591.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.573Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.591.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2020-05-07T02:02:46.573Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.596.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.573Z,ns_1@127.0.0.1:memcached_config_mgr<0.596.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.574Z,ns_1@127.0.0.1:memcached_config_mgr<0.596.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.580Z,ns_1@127.0.0.1:<0.600.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:02:46.580Z,ns_1@127.0.0.1:<0.597.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.596.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[ns_server:debug,2020-05-07T02:02:46.580Z,ns_1@127.0.0.1:<0.598.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.596.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.580Z,ns_1@127.0.0.1:memcached_config_mgr<0.601.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.580Z,ns_1@127.0.0.1:memcached_config_mgr<0.601.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2020-05-07T02:02:46.580Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.599.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[error_logger:error,2020-05-07T02:02:46.580Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.600.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[error_logger:error,2020-05-07T02:02:46.580Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.596.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[error_logger:error,2020-05-07T02:02:46.581Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.596.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.598.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 4185
    stack_size: 27
    reductions: 19580
  neighbours:

[error_logger:error,2020-05-07T02:02:46.581Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.596.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.581Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.596.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2020-05-07T02:02:46.581Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.601.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.581Z,ns_1@127.0.0.1:memcached_config_mgr<0.601.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T02:02:46.585Z,ns_1@127.0.0.1:memcached_config_mgr<0.601.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.585Z,ns_1@127.0.0.1:memcached_config_mgr<0.601.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.586Z,ns_1@127.0.0.1:<0.605.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:02:46.586Z,ns_1@127.0.0.1:<0.602.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.601.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[error_logger:error,2020-05-07T02:02:46.586Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.605.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[ns_server:debug,2020-05-07T02:02:46.586Z,ns_1@127.0.0.1:<0.603.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.601.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.586Z,ns_1@127.0.0.1:memcached_config_mgr<0.606.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.586Z,ns_1@127.0.0.1:memcached_config_mgr<0.606.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2020-05-07T02:02:46.586Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.604.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[error_logger:error,2020-05-07T02:02:46.586Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.601.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[ns_server:debug,2020-05-07T02:02:46.587Z,ns_1@127.0.0.1:memcached_config_mgr<0.606.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[error_logger:error,2020-05-07T02:02:46.587Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.601.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.603.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 4185
    stack_size: 27
    reductions: 19565
  neighbours:

[error_logger:error,2020-05-07T02:02:46.587Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.601.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.587Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.601.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2020-05-07T02:02:46.587Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.606.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.588Z,ns_1@127.0.0.1:memcached_config_mgr<0.606.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.588Z,ns_1@127.0.0.1:memcached_config_mgr<0.606.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.589Z,ns_1@127.0.0.1:<0.610.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.589Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.610.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[ns_server:debug,2020-05-07T02:02:46.589Z,ns_1@127.0.0.1:<0.607.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.606.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[ns_server:debug,2020-05-07T02:02:46.589Z,ns_1@127.0.0.1:<0.608.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.606.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.589Z,ns_1@127.0.0.1:memcached_config_mgr<0.612.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.590Z,ns_1@127.0.0.1:memcached_config_mgr<0.612.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2020-05-07T02:02:46.590Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.609.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[ns_server:debug,2020-05-07T02:02:46.590Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.613.0>:json_rpc_connection:init:73]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.613.0>
[error_logger:error,2020-05-07T02:02:46.590Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.606.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[ns_server:debug,2020-05-07T02:02:46.590Z,ns_1@127.0.0.1:memcached_config_mgr<0.612.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T02:02:46.590Z,ns_1@127.0.0.1:menelaus_cbauth<0.364.0>:menelaus_cbauth:handle_cast:102]Observed json rpc process {"goxdcr-cbauth",<0.613.0>} started
[error_logger:error,2020-05-07T02:02:46.590Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.606.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.608.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19584
  neighbours:

[error_logger:error,2020-05-07T02:02:46.590Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.606.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.590Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.606.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2020-05-07T02:02:46.590Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.612.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.597Z,ns_1@127.0.0.1:compiled_roles_cache<0.207.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@goxdcr-cbauth",admin}
[ns_server:debug,2020-05-07T02:02:46.597Z,ns_1@127.0.0.1:memcached_config_mgr<0.612.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.598Z,ns_1@127.0.0.1:memcached_config_mgr<0.612.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.598Z,ns_1@127.0.0.1:<0.619.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:02:46.598Z,ns_1@127.0.0.1:<0.615.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.612.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[ns_server:debug,2020-05-07T02:02:46.598Z,ns_1@127.0.0.1:<0.617.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.612.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[error_logger:error,2020-05-07T02:02:46.599Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.619.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[ns_server:debug,2020-05-07T02:02:46.599Z,ns_1@127.0.0.1:memcached_config_mgr<0.620.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.599Z,ns_1@127.0.0.1:memcached_config_mgr<0.620.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2020-05-07T02:02:46.599Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.618.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[error_logger:error,2020-05-07T02:02:46.599Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.612.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[ns_server:debug,2020-05-07T02:02:46.599Z,ns_1@127.0.0.1:memcached_config_mgr<0.620.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[error_logger:error,2020-05-07T02:02:46.599Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.612.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.617.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 4185
    stack_size: 27
    reductions: 19570
  neighbours:

[error_logger:error,2020-05-07T02:02:46.599Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.612.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.600Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.612.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2020-05-07T02:02:46.600Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.620.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.618Z,ns_1@127.0.0.1:memcached_config_mgr<0.620.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.619Z,ns_1@127.0.0.1:memcached_config_mgr<0.620.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.620Z,ns_1@127.0.0.1:<0.624.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.621Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.624.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[error_logger:error,2020-05-07T02:02:46.621Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.623.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[ns_server:debug,2020-05-07T02:02:46.621Z,ns_1@127.0.0.1:<0.621.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.620.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[ns_server:debug,2020-05-07T02:02:46.621Z,ns_1@127.0.0.1:<0.622.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.620.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[error_logger:error,2020-05-07T02:02:46.621Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.620.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[ns_server:debug,2020-05-07T02:02:46.621Z,ns_1@127.0.0.1:memcached_config_mgr<0.625.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.621Z,ns_1@127.0.0.1:memcached_config_mgr<0.625.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2020-05-07T02:02:46.621Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.620.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.622.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 4185
    stack_size: 27
    reductions: 19566
  neighbours:

[error_logger:error,2020-05-07T02:02:46.621Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.620.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.621Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.620.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2020-05-07T02:02:46.622Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.625.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.624Z,ns_1@127.0.0.1:memcached_config_mgr<0.625.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T02:02:46.627Z,ns_1@127.0.0.1:memcached_config_mgr<0.625.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.628Z,ns_1@127.0.0.1:memcached_config_mgr<0.625.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.631Z,ns_1@127.0.0.1:<0.629.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.631Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.629.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[ns_server:debug,2020-05-07T02:02:46.631Z,ns_1@127.0.0.1:<0.627.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.625.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.631Z,ns_1@127.0.0.1:memcached_config_mgr<0.630.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.631Z,ns_1@127.0.0.1:memcached_config_mgr<0.630.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2020-05-07T02:02:46.631Z,ns_1@127.0.0.1:<0.626.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.625.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[error_logger:error,2020-05-07T02:02:46.632Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.628.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[ns_server:debug,2020-05-07T02:02:46.632Z,ns_1@127.0.0.1:memcached_config_mgr<0.630.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[error_logger:error,2020-05-07T02:02:46.632Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.625.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[error_logger:error,2020-05-07T02:02:46.634Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.625.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.627.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19568
  neighbours:

[error_logger:error,2020-05-07T02:02:46.634Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.625.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.634Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.625.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2020-05-07T02:02:46.635Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.630.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.635Z,ns_1@127.0.0.1:memcached_config_mgr<0.630.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.637Z,ns_1@127.0.0.1:memcached_config_mgr<0.630.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.638Z,ns_1@127.0.0.1:<0.636.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:02:46.638Z,ns_1@127.0.0.1:<0.631.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.630.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[ns_server:debug,2020-05-07T02:02:46.638Z,ns_1@127.0.0.1:<0.634.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.630.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.639Z,ns_1@127.0.0.1:memcached_config_mgr<0.637.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.639Z,ns_1@127.0.0.1:memcached_config_mgr<0.637.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2020-05-07T02:02:46.639Z,ns_1@127.0.0.1:memcached_config_mgr<0.637.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[error_logger:error,2020-05-07T02:02:46.641Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.635.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[error_logger:error,2020-05-07T02:02:46.642Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.630.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[ns_server:debug,2020-05-07T02:02:46.642Z,ns_1@127.0.0.1:memcached_config_mgr<0.637.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[error_logger:error,2020-05-07T02:02:46.642Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.636.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[error_logger:error,2020-05-07T02:02:46.643Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.630.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.634.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 4185
    stack_size: 27
    reductions: 19566
  neighbours:

[error_logger:error,2020-05-07T02:02:46.643Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.630.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.644Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.630.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2020-05-07T02:02:46.644Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.637.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.644Z,ns_1@127.0.0.1:memcached_config_mgr<0.637.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.645Z,ns_1@127.0.0.1:<0.642.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.645Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.642.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[ns_server:debug,2020-05-07T02:02:46.645Z,ns_1@127.0.0.1:<0.638.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.637.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[ns_server:debug,2020-05-07T02:02:46.645Z,ns_1@127.0.0.1:<0.639.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.637.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.645Z,ns_1@127.0.0.1:memcached_config_mgr<0.643.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:46.645Z,ns_1@127.0.0.1:memcached_config_mgr<0.643.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2020-05-07T02:02:46.645Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.641.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[ns_server:debug,2020-05-07T02:02:46.645Z,ns_1@127.0.0.1:memcached_config_mgr<0.643.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[error_logger:error,2020-05-07T02:02:46.645Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.637.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[ns_server:debug,2020-05-07T02:02:46.646Z,ns_1@127.0.0.1:memcached_config_mgr<0.643.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[error_logger:error,2020-05-07T02:02:46.647Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.637.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.639.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19560
  neighbours:

[error_logger:error,2020-05-07T02:02:46.647Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.637.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.647Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.637.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2020-05-07T02:02:46.647Z,ns_1@127.0.0.1:memcached_config_mgr<0.643.0>:memcached_config_mgr:init:85]found memcached port to be already active
[error_logger:info,2020-05-07T02:02:46.647Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.643.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:02:46.648Z,ns_1@127.0.0.1:<0.647.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.648Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.647.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[ns_server:debug,2020-05-07T02:02:46.648Z,ns_1@127.0.0.1:<0.644.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.643.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[error_logger:error,2020-05-07T02:02:46.649Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.646.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[ns_server:debug,2020-05-07T02:02:46.648Z,ns_1@127.0.0.1:<0.645.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.643.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.649Z,ns_1@127.0.0.1:memcached_config_mgr<0.648.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:error,2020-05-07T02:02:46.649Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.643.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[ns_server:debug,2020-05-07T02:02:46.649Z,ns_1@127.0.0.1:memcached_config_mgr<0.648.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2020-05-07T02:02:46.649Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.643.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.645.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19567
  neighbours:

[error_logger:error,2020-05-07T02:02:46.649Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.643.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.649Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.643.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2020-05-07T02:02:46.649Z,ns_1@127.0.0.1:memcached_config_mgr<0.648.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[error_logger:info,2020-05-07T02:02:46.650Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.648.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.651Z,ns_1@127.0.0.1:memcached_config_mgr<0.648.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.652Z,ns_1@127.0.0.1:memcached_config_mgr<0.648.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.652Z,ns_1@127.0.0.1:<0.652.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.653Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.652.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[error_logger:error,2020-05-07T02:02:46.653Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.651.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[ns_server:debug,2020-05-07T02:02:46.653Z,ns_1@127.0.0.1:<0.649.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.648.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[error_logger:error,2020-05-07T02:02:46.653Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.648.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[ns_server:debug,2020-05-07T02:02:46.653Z,ns_1@127.0.0.1:<0.650.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.648.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.653Z,ns_1@127.0.0.1:memcached_config_mgr<0.653.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:error,2020-05-07T02:02:46.653Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.648.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.650.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 4185
    stack_size: 27
    reductions: 19561
  neighbours:

[error_logger:error,2020-05-07T02:02:46.653Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.648.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[ns_server:debug,2020-05-07T02:02:46.653Z,ns_1@127.0.0.1:memcached_config_mgr<0.653.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2020-05-07T02:02:46.653Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.648.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2020-05-07T02:02:46.653Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.653.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:46.654Z,ns_1@127.0.0.1:memcached_config_mgr<0.653.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T02:02:46.655Z,ns_1@127.0.0.1:memcached_config_mgr<0.653.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:46.656Z,ns_1@127.0.0.1:memcached_config_mgr<0.653.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2020-05-07T02:02:46.657Z,ns_1@127.0.0.1:<0.657.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2020-05-07T02:02:46.657Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.657.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}


[ns_server:debug,2020-05-07T02:02:46.657Z,ns_1@127.0.0.1:<0.655.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.653.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-1-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    201}]}]}
[ns_server:debug,2020-05-07T02:02:46.657Z,ns_1@127.0.0.1:<0.654.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.653.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-1-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,201}]}]}. Exiting
[error_logger:error,2020-05-07T02:02:46.657Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.656.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-1-',3,
                                 [{file,"src/async.erl"},{line,201}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 357)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 376
    stack_size: 27
    reductions: 115
  neighbours:

[error_logger:error,2020-05-07T02:02:46.657Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.653.0> terminating 
** Last message in was do_check
** When Server state == {state,<12401.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-1-',3,[{file,"src/async.erl"},{line,201}]}]}

[error_logger:error,2020-05-07T02:02:46.658Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.653.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-1-',3,
                             [{file,"src/async.erl"},{line,201}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.236.0>,<0.655.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19560
  neighbours:

[error_logger:error,2020-05-07T02:02:46.658Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.653.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-1-',3,
                                             [{file,"src/async.erl"},
                                              {line,201}]}]}}}

[error_logger:error,2020-05-07T02:02:46.658Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-1-',3,
                          [{file,"src/async.erl"},{line,201}]}]}
     Offender:   [{pid,<0.653.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2020-05-07T02:02:46.904Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:89]Refresh of [rbac,isasl] succeeded
[ns_server:debug,2020-05-07T02:02:47.079Z,ns_1@127.0.0.1:ns_audit_cfg<0.378.0>:ns_audit_cfg:write_audit_json:265]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{descriptors_path,
                                                                                <<"/opt/couchbase/etc/security">>},
                                                                               {version,
                                                                                2},
                                                                               {uuid,
                                                                                <<"18411111">>},
                                                                               {event_states,
                                                                                {[]}},
                                                                               {filtering_enabled,
                                                                                true},
                                                                               {disabled_userids,
                                                                                []},
                                                                               {auditd_enabled,
                                                                                false},
                                                                               {log_path,
                                                                                <<"/opt/couchbase/var/lib/couchbase/logs">>},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []}]
[ns_server:debug,2020-05-07T02:02:47.086Z,ns_1@127.0.0.1:ns_audit_cfg<0.378.0>:ns_audit_cfg:notify_memcached:170]Instruct memcached to reload audit config
[ns_server:debug,2020-05-07T02:02:47.392Z,ns_1@127.0.0.1:<0.513.0>:auto_failover_logic:log_master_activity:170]Transitioned node {'ns_1@127.0.0.1',<<"0f8760945f98b1efdbef0bd1ea6e8446">>} state new -> up
[ns_server:debug,2020-05-07T02:02:50.658Z,ns_1@127.0.0.1:memcached_config_mgr<0.739.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2020-05-07T02:02:50.658Z,ns_1@127.0.0.1:memcached_config_mgr<0.739.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:info,2020-05-07T02:02:50.658Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.739.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:02:50.658Z,ns_1@127.0.0.1:memcached_config_mgr<0.739.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T02:02:50.661Z,ns_1@127.0.0.1:memcached_config_mgr<0.739.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2020-05-07T02:02:50.661Z,ns_1@127.0.0.1:memcached_config_mgr<0.739.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:debug,2020-05-07T02:02:50.663Z,ns_1@127.0.0.1:memcached_config_mgr<0.739.0>:memcached_config_mgr:apply_changed_memcached_config:163]New memcached config is hot-reloadable.
[ns_server:debug,2020-05-07T02:02:50.664Z,ns_1@127.0.0.1:memcached_config_mgr<0.739.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[user:info,2020-05-07T02:02:50.692Z,ns_1@127.0.0.1:memcached_config_mgr<0.739.0>:memcached_config_mgr:hot_reload_config:223]Hot-reloaded memcached.json for config change of the following keys: [<<"client_cert_auth">>,
                                                                      <<"datatype_snappy">>,
                                                                      <<"scramsha_fallback_salt">>,
                                                                      <<"xattr_enabled">>]
[ns_server:debug,2020-05-07T02:03:16.211Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:03:16.211Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:03:16.211Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:03:16.211Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[error_logger:info,2020-05-07T02:03:41.115Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
       alarm_handler: {set,{system_memory_high_watermark,[]}}

[ns_server:debug,2020-05-07T02:03:46.212Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:03:46.212Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:03:46.212Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:03:46.212Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:04:16.213Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:04:16.213Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:04:16.213Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:04:16.213Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:04:46.214Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:04:46.214Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:04:46.214Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:04:46.214Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:05:16.215Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:05:16.215Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:05:16.215Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:05:16.215Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:05:46.216Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:05:46.216Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:05:46.216Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:05:46.216Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:06:16.217Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:06:16.217Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:06:16.217Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:06:16.217Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:06:46.218Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:06:46.218Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:06:46.218Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:06:46.218Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:07:16.219Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:07:16.219Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:07:16.219Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:07:16.219Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:07:46.220Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:07:46.220Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:07:46.220Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:07:46.220Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:08:16.221Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:08:16.221Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:08:16.221Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:08:16.221Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:08:46.222Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:08:46.222Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:08:46.222Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:08:46.222Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:09:16.223Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:09:16.223Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:09:16.223Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:09:16.223Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:09:46.224Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:09:46.224Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:09:46.224Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:09:46.224Z,ns_1@127.0.0.1:compaction_new_daemon<0.429.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:info,2020-05-07T02:21:50.296Z,nonode@nohost:<0.89.0>:ns_server:init_logging:150]Started & configured logging
[ns_server:info,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_access,info},
 {disk_sink_opts,[{rotation,[{compress,true},
                             {size,41943040},
                             {num_files,10},
                             {buffer_size_max,52428800}]}]},
 {disk_sink_opts_json_rpc,[{rotation,[{compress,true},
                                      {size,41943040},
                                      {num_files,2},
                                      {buffer_size_max,52428800}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.325Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.326Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.326Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.326Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.326Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.326Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.326Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.326Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.326Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.326Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_json_rpc, which is given from command line
[ns_server:warn,2020-05-07T02:21:50.326Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2020-05-07T02:21:50.336Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.138.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:50.341Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,76}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-378cfab] [64-bit] [smp:2:2] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2020,5,7},{2,21,50}}},
               {memory,
                   [{total,110382760},
                    {processes,9509288},
                    {processes_used,9507616},
                    {system,100873472},
                    {atom,339441},
                    {atom_used,322610},
                    {binary,78480},
                    {code,7796739},
                    {ets,2241584}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,path_config,calendar,
                    ale_default_formatter,'ale_logger-metakv',
                    'ale_logger-rebalance','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-json_rpc',
                    'ale_logger-access','ale_logger-ns_server',
                    'ale_logger-user','ale_logger-ns_doctor',io_lib_fread,
                    'ale_logger-cluster','ale_logger-xdcr',otp_internal,
                    ns_log_sink,ale_disk_sink,misc,couch_util,ns_server,
                    filelib,cpu_sup,memsup,disksup,os_mon,io,release_handler,
                    overload,alarm_handler,sasl,timer,tftp_sup,httpd_sup,
                    httpc_handler_sup,httpc_cookie,inets_trace,httpc_manager,
                    httpc,httpc_profile_sup,httpc_sup,ftp_sup,inets_sup,
                    inets_app,ssl,lhttpc_manager,lhttpc_sup,lhttpc,
                    tls_connection_sup,ssl_session_cache,ssl_pkix_db,
                    ssl_manager,ssl_sup,ssl_app,crypto_server,crypto_sup,
                    crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_io,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","6.0.3-2895-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","6.0.3-2895-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,105},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [lhttpc_sup,code_server,ale_stats_events,'sink-ns_log',
                    ns_server_cluster_sup,lhttpc_manager,
                    application_controller,ale,httpd_sup,release_handler,
                    kernel_safe_sup,standard_error,ale_sup,overload,
                    'sink-disk_json_rpc',error_logger,alarm_handler,
                    'sink-disk_metakv',ale_dynamic_sup,timer_server,
                    'sink-disk_access_int',standard_error_sup,
                    'sink-disk_access','sink-disk_reports',crypto_server,
                    crypto_sup,sasl_safe_sup,'sink-disk_stats',
                    'sink-disk_xdcr',tftp_sup,inet_db,init,os_mon_sup,
                    'sink-disk_debug',rex,tls_connection_sup,user,
                    'sink-disk_error',ssl_sup,kernel_sup,cpu_sup,
                    global_name_server,memsup,'sink-disk_default',disksup,
                    httpc_sup,file_server_2,ssl_manager,local_tasks,
                    global_group,httpc_profile_sup,httpc_manager,
                    httpc_handler_sup,ftp_sup,sasl_sup,erl_prim_loader,
                    inets_sup]},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,1}]
[ns_server:info,2020-05-07T02:21:50.350Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:27]Manifest:
["<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\" />",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\" />",
 "  ","  <default remote=\"couchbase\" revision=\"master\" />","  ",
 "  <project groups=\"kv\" name=\"HdrHistogram_c\" path=\"third_party/HdrHistogram_c\" remote=\"couchbasedeps\" revision=\"d200fc0f68695d4aef1fad5c3c8cc55f8c033014\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"analytics-dcp-client\" path=\"analytics/java-dcp-client\" revision=\"d6ba66b51c0e589e9d4571264afcb0e33d507aea\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"asterixdb\" path=\"analytics/asterixdb\" revision=\"e8e59d0e6e72ba3fd96074c021ff7180261dcd59\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"c5b9dd8ec0910d2890d215075a7d2da1d6a494c9\" />",
 "  <project groups=\"kv\" name=\"benchmark\" remote=\"couchbasedeps\" revision=\"9e3465560240ffb242b50a47cb7f19251a12ee42\" />",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\" />",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5cd1345cca3ed72f1e63d41d622fcda73e63fea8\" />",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"822d01dab8721cf469beb6d8304c9eadd9c58160\" />",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"f551b6d4f32bb920a83dd28c705bddd5de0d03b2\" />",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"4b158bb555a3297565afecf6fae675c74f1e47df\" />",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\" />",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\" />",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"dc55cf8e9613ddf1bd6db4a662d1ecc3668223da\">",
 "    <annotation name=\"RELEASE\" value=\"alice\" />",
 "    <annotation name=\"PRODUCT\" value=\"couchbase-server\" />",
 "    <annotation name=\"BLD_NUM\" value=\"2895\" />",
 "    <annotation name=\"VERSION\" value=\"6.0.3\" />","  </project>",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas\" path=\"goproj/src/github.com/couchbaselabs/cbas\" remote=\"couchbase-priv\" revision=\"73fa77cd9133a9f779a484ac2caffb0b46a1dd82\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas-core\" path=\"analytics\" remote=\"couchbase-priv\" revision=\"7e513c6bd60a030c3a2477af683b264d61932a75\" />",
 "  <project groups=\"analytics\" name=\"cbas-ui\" revision=\"d8f601c3109887a30deccab09b2177bf499c8711\" />",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"0df84c7e3c6d95ff435c12a3c08c6f064db11e97\" />",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"80d2ad8892d806f5103f602fec0d80adaa4b628f\" />",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"8d4105a904e0282a6928de7392e266c58ea3c7a2\" />",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"0a94f40b9080e0ecb11d3b7531a58c5e6a4a4465\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"93d26dbc120c4f9874abb65aafa4d815334273c6\" />",
 "  <project name=\"cbsummary\" path=\"goproj/src/github.com/couchbase/cbsummary\" revision=\"dbfa1c0d73f0e49f6f04e390f03de8f9a6cee769\" />",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"dcae66272b24600ae0005fa06b511cfae8914d3d\" />",
 "  <project name=\"cobra\" path=\"godeps/src/github.com/spf13/cobra\" remote=\"couchbasedeps\" revision=\"0f056af21f5f368e5b0646079d0094a2c64150f7\" />",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\" />",
 "  <project groups=\"notdefault,kv_ee,enterprise\" name=\"couch_rocks\" remote=\"couchbase-priv\" revision=\"75f37fa46bfe5e445dee077157303968a3e09126\" />",
 "  <project name=\"couchbase-cli\" revision=\"9b383603860ce58885c27015c92635a7b42d3a1f\" />",
 "  <project name=\"couchdb\" revision=\"c2b98200b800f9fbed927c47074884b9f5f53eb4\" />",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"69aa5d92e195a30e06184911d72b8fffcf2534fe\" />",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"c2c458ff2cf93ee63bf4b0386f495b22535daf96\" />",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\" />",
 "  <project name=\"cuckoofilter\" path=\"godeps/src/github.com/seiflotfy/cuckoofilter\" remote=\"couchbasedeps\" revision=\"d04838794ab86926d32b124345777e55e6f43974\" />",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\" />",
 "  <project name=\"docloader\" path=\"goproj/src/github.com/couchbase/docloader\" revision=\"05067021a042a1b63e100a486afd7ebddab4c535\" />",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\" />",
 "  <project name=\"errors\" path=\"godeps/src/github.com/pkg/errors\" remote=\"couchbasedeps\" revision=\"30136e27e2ac8d167177e8a583aa4c3fea5be833\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"eventing\" path=\"goproj/src/github.com/couchbase/eventing\" revision=\"1da67e30a4c8faaf24f067eae280f5764d943dc2\" upstream=\"alice\" />",
 "  <project name=\"flatbuffers\" path=\"godeps/src/github.com/google/flatbuffers\" remote=\"couchbasedeps\" revision=\"1a8968225130caeddd16e227678e6f8af1926303\" />",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"c338e06e6847140f749058184d66de1f2a43474a\" />",
 "  <project name=\"fwd\" path=\"godeps/src/github.com/philhofer/fwd\" remote=\"couchbasedeps\" revision=\"bb6d471dc95d4fe11e432687f8b70ff496cf3136\" />",
 "  <project name=\"geocouch\" revision=\"2a0e73f43451045f157640eec59ced72da18471f\" />",
 "  <project name=\"ghistogram\" path=\"godeps/src/github.com/couchbase/ghistogram\" revision=\"d910dd063dd68fb4d2a1ba344440f834ebb4ef62\" />",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\" />",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"5c0ac9ef0ba7a0356279cee7eadd8874c4a8f8c1\" />",
 "  <project name=\"go-curl\" path=\"godeps/src/github.com/andelf/go-curl\" remote=\"couchbasedeps\" revision=\"f0b2afc926ec79be5d7f30393b3485352781a705\" />",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\" />",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\" />",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\" />",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\" />",
 "  <project name=\"go-sqlite3\" path=\"godeps/src/github.com/mattn/go-sqlite3\" remote=\"couchbasedeps\" revision=\"47fc4e5e9153645da45af6a86a5bce95e63a0f9e\" />",
 "  <project name=\"go-unsnap-stream\" path=\"godeps/src/github.com/glycerine/go-unsnap-stream\" remote=\"couchbasedeps\" revision=\"62a9a9eb44fd8932157b1a8ace2149eff5971af6\" />",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\" />",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"d2f15a425a9c8e4d8447e5f5b89ce14845f7fa05\" />",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\" />",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"699b13a51af5dd4f80ff3deedf41bba60debad32\" />",
 "  <project name=\"gocbconnstr\" path=\"godeps/src/gopkg.in/couchbaselabs/gocbconnstr.v1\" remote=\"couchbaselabs\" revision=\"710456e087a6d497e87f41d0a9d98d6a75672186\" />",
 "  <project name=\"gocbcore\" path=\"godeps/src/gopkg.in/couchbase/gocbcore.v7\" revision=\"a0d26c2d6f5de912499d35a5aba573006e5e036f\" />",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"aecdbe5a5a91f0688df7bdf260ca962178c06828\" />",
 "  <project name=\"gofarmhash\" path=\"godeps/src/github.com/leemcloughlin/gofarmhash\" remote=\"couchbasedeps\" revision=\"0a055c5b87a8c55ce83459cbf2776b563822a942\" />",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\" />",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\" />",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\" />",
 "  <project name=\"golang-tools\" path=\"godeps/src/golang.org/x/tools\" remote=\"couchbasedeps\" revision=\"a28dfb48e06b2296b66678872c2cb638f0304f20\" />",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\" />",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"e05ec3550789be1da2981787ef6444fef75e10bc\" />",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"4809dd3aa2ab88013b1dfce15516d717a35cb6e8\" />",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\" />",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\" />",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\" />",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"f98adca8eb365032cab838ef4d99453931afa112\" />",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"122ae25ed207cca30ceaee9ac66342a603d43a31\" />",
 "  <project groups=\"kv\" name=\"gsl-lite\" path=\"third_party/gsl-lite\" remote=\"couchbasedeps\" revision=\"57542c7e7ced375346e9ac55dad85b942cfad556\" />",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\" />",
 "  <project name=\"httprouter\" path=\"godeps/src/github.com/julienschmidt/httprouter\" remote=\"couchbasedeps\" revision=\"975b5c4c7c21c0e3d2764200bf2aa8e34657ae6e\" />",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"95ed84aad6bf8ecd99da2372dceede6d93f3d43a\" />",
 "  <project name=\"json-iterator-go\" path=\"godeps/src/github.com/json-iterator/go\" remote=\"couchbasedeps\" revision=\"f7279a603edee96fe7764d3de9c6ff8cf9970994\" />",
 "  <project name=\"jsonx\" path=\"godeps/src/gopkg.in/couchbaselabs/jsonx.v1\" remote=\"couchbaselabs\" revision=\"5b7baa20429a46a5543ee259664cc86502738cad\" />",
 "  <project groups=\"kv\" name=\"kv_engine\" revision=\"a30fd9d57cc2101078c8cd2c44968458df965c2b\" />",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"libcouchbase\" revision=\"081e8b16b991bf706eb77f8243935c6fba31b895\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"3681c2a912330352991ecdd642f257efe5b85518\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\" />",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\" />",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\" />",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"956632ec1bc3e28276d00ee2f22c3202f06efb12\" />",
 "  <project name=\"mossScope\" path=\"godeps/src/github.com/couchbase/mossScope\" revision=\"abd3b58b422dbc2e9463a589d0f3d93441726e23\" />",
 "  <project name=\"mousetrap\" path=\"godeps/src/github.com/inconshreveable/mousetrap\" remote=\"couchbasedeps\" revision=\"76626ae9c91c4f2a10f34cad8ce83ea42c93bb75\" />",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"cd8da46b9b953800d430c8b0aa4667790727ed6f\" />",
 "  <project name=\"msgp\" path=\"godeps/src/github.com/tinylib/msgp\" remote=\"couchbasedeps\" revision=\"5bb5e1aed7ba5bcc93307153b020e7ffe79b0509\" />",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"043ee6597c29786140136a5747b6a886364f5282\" />",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"62685c2d7ca23c807425dca88b11a3e2323dab41\" />",
 "  <project name=\"nitro\" path=\"goproj/src/github.com/couchbase/nitro\" revision=\"f3bef3551997be504612a2d05a8b324b3bfdfe1b\" />",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\" />",
 "  <project name=\"ns_server\" revision=\"8117c5307974f397ad831a2b870fb3ee0fd8364d\" />",
 "  <project name=\"opentracing-go\" path=\"godeps/src/github.com/opentracing/opentracing-go\" remote=\"couchbasedeps\" revision=\"1949ddbfd147afd4d964a9f00b24eb291e0e7c38\" />",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\" />",
 "  <project name=\"pflag\" path=\"godeps/src/github.com/spf13/pflag\" remote=\"couchbasedeps\" revision=\"a232f6d9f87afaaa08bafaff5da685f974b83313\" />",
 "  <project groups=\"kv\" name=\"phosphor\" revision=\"96501c57bb0fd61c85cba6f63101aed2bcf41d38\" />",
 "  <project name=\"pierrec-lz4\" path=\"godeps/src/github.com/pierrec/lz4\" remote=\"couchbasedeps\" revision=\"ed8d4cc3b461464e69798080a0092bd028910298\" />",
 "  <project name=\"pierrec-xxHash\" path=\"godeps/src/github.com/pierrec/xxHash\" remote=\"couchbasedeps\" revision=\"a0006b13c722f7f12368c00a3d3c2ae8a999a0c6\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"plasma\" path=\"goproj/src/github.com/couchbase/plasma\" remote=\"couchbase-priv\" revision=\"c0792c8cfb1463ef029f064f34e366442f1f0064\" />",
 "  <project groups=\"kv\" name=\"platform\" revision=\"de77d527bd23012dc67794c81a7b1e76e46e3abd\" />",
 "  <project groups=\"kv\" name=\"product-texts\" revision=\"8cf7d25a1dcb5434ea44983c0bed202fb9cc8351\" />",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\" />",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"d2011f6ee9f6e1dca5d3922d44fbcf86dad78150\" />",
 "  <project name=\"query-ui\" revision=\"15a6461f437fe810e411a6613ec7c143991cd1c6\" />",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\" />",
 "  <project name=\"roaring\" path=\"godeps/src/github.com/RoaringBitmap/roaring\" remote=\"couchbasedeps\" revision=\"fe09428be4c233d726797a1380f7438f4f71a31a\" />",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"762005e7a34fd909a84586299f1dd457371d36ee\" />",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"73353fe6dad8f3d67409feefb9b17f90f6de917b\" />",
 "  <project name=\"snowballstem\" path=\"godeps/src/github.com/blevesearch/snowballstem\" remote=\"blevesearch\" revision=\"26b06a2c243d4f8ca5db3486f94409dd5b2a7467\" />",
 "  <project groups=\"kv\" name=\"spdlog\" path=\"third_party/spdlog\" remote=\"couchbasedeps\" revision=\"4fba14c79f356ae48d6141c561bf9fd7ba33fabd\" />",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\" />",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"c30c3d4c250e68e81c57aa1e8ae91ffd21243cdb\" />",
 "  <project name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\" />",
 "  <project name=\"testrunner\" revision=\"4133fd785987f1ddcdb49dab736ff6e5e67d7c95\" upstream=\"alice\" />",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\" />",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"6dadf98e19803cc10ce9552bf4d9121cc2528965\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\" />",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\" />",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\" />",
 "    <copyfile dest=\".clang-format\" src=\"dot-clang-format\" />",
 "    <copyfile dest=\"third_party/CMakeLists.txt\" src=\"third-party-CMakeLists.txt\" />",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\" />",
 "  <project name=\"uuid\" path=\"godeps/src/github.com/google/uuid\" remote=\"couchbasedeps\" revision=\"dec09d789f3dba190787f8b4454c7d3c936fed9e\" />",
 "  <project name=\"vellum\" path=\"godeps/src/github.com/couchbase/vellum\" revision=\"0ceea4a37442f76199b9259840baf48d17af3c1a\" />",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"b3d83fe61db37bb38a46cd8dee434e5682cba2c7\" />",
 "  <project name=\"zstd\" path=\"godeps/src/github.com/DataDog/zstd\" remote=\"couchbasedeps\" revision=\"aebefd9fcb99f22cd691ef778a12ed68f0e6a1ab\" />",
 "</manifest>"]

[error_logger:info,2020-05-07T02:21:50.381Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.139.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:50.383Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2020-05-07T02:21:50.384Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2020-05-07T02:21:50.385Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:init:243]ip config not found. Looks like we're brand new node
[error_logger:info,2020-05-07T02:21:50.385Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.143.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2020-05-07T02:21:50.385Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.142.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:50.536Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:bringup:295]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2020-05-07T02:21:50.542Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.145.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.542Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.146.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:50.543Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:configure_net_kernel:339]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2020-05-07T02:21:50.543Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.147.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.543Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.144.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2020-05-07T02:21:50.545Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:save_node:227]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2020-05-07T02:21:50.552Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:bringup:309]Attempted to save node name to disk: ok
[ns_server:debug,2020-05-07T02:21:50.552Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:316]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2020-05-07T02:21:50.552Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T02:21:50.561Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:328]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2020-05-07T02:21:50.562Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.570Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.571Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:50.572Z,ns_1@127.0.0.1:ns_config_sup<0.154.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2020-05-07T02:21:50.572Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.155.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.573Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.156.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:50.608Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1095]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2020-05-07T02:21:50.609Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1109]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:debug,2020-05-07T02:21:50.622Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1117]Here's full dynamic config we loaded:
[[{auto_failover_cfg,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {enabled,true},
    {timeout,120},
    {count,0},
    {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
    {failover_server_group,false},
    {max_count,1},
    {failed_over_server_groups,[]}]},
  {audit_decriptors,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {20480,
     [{name,<<"opened DCP connection">>},
      {description,<<"opened DCP connection">>},
      {enabled,true},
      {module,memcached}]},
    {20482,
     [{name,<<"external memcached bucket flush">>},
      {description,
       <<"External user flushed the content of a memcached bucket">>},
      {enabled,true},
      {module,memcached}]},
    {20483,
     [{name,<<"invalid packet">>},
      {description,<<"Rejected an invalid packet">>},
      {enabled,true},
      {module,memcached}]},
    {20485,
     [{name,<<"authentication succeeded">>},
      {description,<<"Authentication to the cluster succeeded">>},
      {enabled,false},
      {module,memcached}]},
    {20488,
     [{name,<<"document read">>},
      {description,<<"Document was read">>},
      {enabled,false},
      {module,memcached}]},
    {20489,
     [{name,<<"document locked">>},
      {description,<<"Document was locked">>},
      {enabled,false},
      {module,memcached}]},
    {20490,
     [{name,<<"document modify">>},
      {description,<<"Document was modified">>},
      {enabled,false},
      {module,memcached}]},
    {20491,
     [{name,<<"document delete">>},
      {description,<<"Document was deleted">>},
      {enabled,false},
      {module,memcached}]},
    {20492,
     [{name,<<"select bucket">>},
      {description,<<"The specified bucket was selected">>},
      {enabled,true},
      {module,memcached}]},
    {28672,
     [{name,<<"SELECT statement">>},
      {description,<<"A N1QL SELECT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28673,
     [{name,<<"EXPLAIN statement">>},
      {description,<<"A N1QL EXPLAIN statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28674,
     [{name,<<"PREPARE statement">>},
      {description,<<"A N1QL PREPARE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28675,
     [{name,<<"INFER statement">>},
      {description,<<"A N1QL INFER statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28676,
     [{name,<<"INSERT statement">>},
      {description,<<"A N1QL INSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28677,
     [{name,<<"UPSERT statement">>},
      {description,<<"A N1QL UPSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28678,
     [{name,<<"DELETE statement">>},
      {description,<<"A N1QL DELETE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28679,
     [{name,<<"UPDATE statement">>},
      {description,<<"A N1QL UPDATE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28680,
     [{name,<<"MERGE statement">>},
      {description,<<"A N1QL MERGE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28681,
     [{name,<<"CREATE INDEX statement">>},
      {description,<<"A N1QL CREATE INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28682,
     [{name,<<"DROP INDEX statement">>},
      {description,<<"A N1QL DROP INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28683,
     [{name,<<"ALTER INDEX statement">>},
      {description,<<"A N1QL ALTER INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28684,
     [{name,<<"BUILD INDEX statement">>},
      {description,<<"A N1QL BUILD INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28685,
     [{name,<<"GRANT ROLE statement">>},
      {description,<<"A N1QL GRANT ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28686,
     [{name,<<"REVOKE ROLE statement">>},
      {description,<<"A N1QL REVOKE ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28687,
     [{name,<<"UNRECOGNIZED statement">>},
      {description,
       <<"An unrecognized statement was received by the N1QL query engine">>},
      {enabled,false},
      {module,n1ql}]},
    {28688,
     [{name,<<"CREATE PRIMARY INDEX statement">>},
      {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28689,
     [{name,<<"/admin/stats API request">>},
      {description,<<"An HTTP request was made to the API at /admin/stats.">>},
      {enabled,false},
      {module,n1ql}]},
    {28690,
     [{name,<<"/admin/vitals API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/vitals.">>},
      {enabled,false},
      {module,n1ql}]},
    {28691,
     [{name,<<"/admin/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28692,
     [{name,<<"/admin/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28693,
     [{name,<<"/admin/indexes/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28694,
     [{name,<<"/admin/indexes/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28695,
     [{name,<<"/admin/indexes/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28697,
     [{name,<<"/admin/ping API request">>},
      {description,<<"An HTTP request was made to the API at /admin/ping.">>},
      {enabled,false},
      {module,n1ql}]},
    {28698,
     [{name,<<"/admin/config API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/config.">>},
      {enabled,false},
      {module,n1ql}]},
    {28699,
     [{name,<<"/admin/ssl_cert API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
      {enabled,false},
      {module,n1ql}]},
    {28700,
     [{name,<<"/admin/settings API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/settings.">>},
      {enabled,false},
      {module,n1ql}]},
    {28701,
     [{name,<<"/admin/clusters API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/clusters.">>},
      {enabled,false},
      {module,n1ql}]},
    {28702,
     [{name,<<"/admin/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {32768,
     [{name,<<"Create Function">>},
      {description,<<"Eventing function definition was created or updated">>},
      {enabled,true},
      {module,eventing}]},
    {32769,
     [{name,<<"Delete Function">>},
      {description,<<"Eventing function definition was deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32770,
     [{name,<<"Fetch Functions">>},
      {description,<<"Eventing function definition was read">>},
      {enabled,false},
      {module,eventing}]},
    {32771,
     [{name,<<"List Deployed">>},
      {description,<<"Eventing deployed functions list was read">>},
      {enabled,false},
      {module,eventing}]},
    {32772,
     [{name,<<"Fetch Drafts">>},
      {description,<<"Eventing function draft definitions were read">>},
      {enabled,false},
      {module,eventing}]},
    {32773,
     [{name,<<"Delete Drafts">>},
      {description,<<"Eventing function draft definitions were deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32774,
     [{name,<<"Save Draft">>},
      {description,<<"Save a draft definition to the store">>},
      {enabled,true},
      {module,eventing}]},
    {32775,
     [{name,<<"Start Debug">>},
      {description,<<"Start eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32776,
     [{name,<<"Stop Debug">>},
      {description,<<"Stop eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32777,
     [{name,<<"Start Tracing">>},
      {description,<<"Start tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32778,
     [{name,<<"Stop Tracing">>},
      {description,<<"Stop tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32779,
     [{name,<<"Set Settings">>},
      {description,<<"Save settings for a given app">>},
      {enabled,true},
      {module,eventing}]},
    {32780,
     [{name,<<"Fetch Config">>},
      {description,<<"Get config for eventing">>},
      {enabled,false},
      {module,eventing}]},
    {32781,
     [{name,<<"Save Config">>},
      {description,<<"Save config for eventing">>},
      {enabled,true},
      {module,eventing}]},
    {32782,
     [{name,<<"Cleanup Eventing">>},
      {description,<<"Clears up app definitions and settings from metakv">>},
      {enabled,true},
      {module,eventing}]},
    {32783,
     [{name,<<"Get Settings">>},
      {description,<<"Get settings for a given app">>},
      {enabled,false},
      {module,eventing}]},
    {32784,
     [{name,<<"Import Functions">>},
      {description,<<"Import a list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32785,
     [{name,<<"Export Functions">>},
      {description,<<"Export the list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32786,
     [{name,<<"List Running">>},
      {description,<<"Eventing running function list was read">>},
      {enabled,false},
      {module,eventing}]},
    {36865,
     [{name,<<"Service configuration change">>},
      {description,<<"A successful service configuration change was made.">>},
      {enabled,true},
      {module,analytics}]},
    {36866,
     [{name,<<"Node configuration change">>},
      {description,<<"A successful node configuration change was made.">>},
      {enabled,true},
      {module,analytics}]}]},
  {scramsha_fallback_salt,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<169,238,80,91,5,165,74,47,79,135,45,74>>]},
  {{rbac_upgrade,[5,5]},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {{metakv,<<"/eventing/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"ram_quota\":256}">>]},
  {{metakv,<<"/query/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
  {client_cert_auth,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {state,"disable"},
    {prefixes,[]}]},
  {users_upgrade,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {roles_definitions,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {{service_map,fts},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{service_map,index},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{service_map,n1ql},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {cluster_compat_version,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},
    6,0]},
  {otp,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
    {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]},
  {cert_and_pkey,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQlsomKQ7qhDcAeKZ3inWuCQuv8NxCAMb8M\nXhrVTrshZyFDiXdKS3Xbshyc9dEOiDwuDwAEgfwJQsXzzx0eCRtyTZfWAWTOH06O\nXdQps+9iTfr2KBFj27uag5c5ns+0ojsNyqZhA4+dbS7zK3CZ1dx7LPkL3+4HTlMh\nmH1/2fib3Lbp6dW3B55GV8/RHbkzgcRMyBicYtinqh6JMmmzjO/3KEyVHs3h0W1E\n00JdAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCKWU+bCvjKUlhW\niMiAN7r/3Vxkah7KEqp8BajCnLrlTMeiV+24TlPrsCWz4VBmOgt8OcijS3axdEik\nXeteeJp+R8nb2XPGivHOg/Hx2NlLxCrtXaYVGM0PiVydo24iCv0ZlqMCBsrzRLky\n5otbfQi8ngdfuR88C0/r3RLqvuFnOtFkLbKXuT/qshXfM8O/OgiJkr6CTBFYNd8w\nTCxN2syK41/HXoYzexdA/OTSm+kuEIuDpQYxKS0M4oKKZApJM70y/CYTzwG3JOnp\nuteZPYrwhIqxz01fkbLnj3QLGxPpSexRsp52GOoCv/YEE7tl3Olt4+p+MvhEZPdZ\ndqB53mNJ\n-----END CERTIFICATE-----\n">>,
     <<"*****">>}]},
  {alert_limits,
   [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
  {audit,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {enabled,[]},
    {disabled_users,[]},
    {auditd_enabled,false},
    {rotate_interval,86400},
    {rotate_size,20971520},
    {disabled,[]},
    {sync,[]},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
  {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
  {autocompaction,
   [{database_fragmentation_threshold,{30,undefined}},
    {view_fragmentation_threshold,{30,undefined}}]},
  {buckets,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]},
    {configs,[]}]},
  {cbas_memory_quota,1024},
  {drop_request_memory_threshold_mib,undefined},
  {email_alerts,
   [{recipients,["root@localhost"]},
    {sender,"couchbase@localhost"},
    {enabled,false},
    {email_server,
     [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
    {alerts,
     [auto_failover_node,auto_failover_maximum_reached,
      auto_failover_other_nodes_down,auto_failover_cluster_too_small,
      auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
      ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
      ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
  {fts_memory_quota,256},
  {index_aware_rebalance_disabled,false},
  {log_redaction_default_cfg,[{redact_level,none}]},
  {max_bucket_count,10},
  {memcached,[]},
  {memory_quota,311},
  {nodes_wanted,['ns_1@127.0.0.1']},
  {password_policy,[{min_length,6},{must_present,[]}]},
  {quorum_nodes,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    'ns_1@127.0.0.1']},
  {read_only_user_creds,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {remote_clusters,[]},
  {replication,[{enabled,true}]},
  {rest,[{port,8091}]},
  {rest_creds,null},
  {secure_headers,[]},
  {server_groups,
   [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
  {set_view_update_daemon,
   [{update_interval,5000},
    {update_min_changes,5000},
    {replica_update_min_changes,5000}]},
  {{couchdb,max_parallel_indexers},4},
  {{couchdb,max_parallel_replica_indexers},2},
  {{metakv,<<"/indexing/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
  {{request_limit,capi},undefined},
  {{request_limit,rest},undefined},
  {{node,'ns_1@127.0.0.1',audit},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
  {{node,'ns_1@127.0.0.1',capi_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8092]},
  {{node,'ns_1@127.0.0.1',cbas_admin_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9110]},
  {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9113]},
  {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9112]},
  {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9111]},
  {{node,'ns_1@127.0.0.1',cbas_cluster_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9115]},
  {{node,'ns_1@127.0.0.1',cbas_console_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9114]},
  {{node,'ns_1@127.0.0.1',cbas_data_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9116]},
  {{node,'ns_1@127.0.0.1',cbas_debug_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    -1]},
  {{node,'ns_1@127.0.0.1',cbas_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8095]},
  {{node,'ns_1@127.0.0.1',cbas_messaging_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9118]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9119]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9121]},
  {{node,'ns_1@127.0.0.1',cbas_parent_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9122]},
  {{node,'ns_1@127.0.0.1',cbas_replication_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9120]},
  {{node,'ns_1@127.0.0.1',cbas_result_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9117]},
  {{node,'ns_1@127.0.0.1',cbas_ssl_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18095]},
  {{node,'ns_1@127.0.0.1',compaction_daemon},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {check_interval,30},
    {min_db_file_size,131072},
    {min_view_file_size,20971520}]},
  {{node,'ns_1@127.0.0.1',config_version},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {5,5,3}]},
  {{node,'ns_1@127.0.0.1',eventing_debug_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9140]},
  {{node,'ns_1@127.0.0.1',eventing_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8096]},
  {{node,'ns_1@127.0.0.1',eventing_https_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18096]},
  {{node,'ns_1@127.0.0.1',fts_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8094]},
  {{node,'ns_1@127.0.0.1',fts_ssl_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18094]},
  {{node,'ns_1@127.0.0.1',indexer_admin_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9100]},
  {{node,'ns_1@127.0.0.1',indexer_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9102]},
  {{node,'ns_1@127.0.0.1',indexer_https_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    19102]},
  {{node,'ns_1@127.0.0.1',indexer_scan_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9101]},
  {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9104]},
  {{node,'ns_1@127.0.0.1',indexer_stinit_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9103]},
  {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9105]},
  {{node,'ns_1@127.0.0.1',is_enterprise},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',isasl},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
  {{node,'ns_1@127.0.0.1',ldap_enabled},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',membership},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    active]},
  {{node,'ns_1@127.0.0.1',memcached},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,11210},
    {dedicated_port,11209},
    {ssl_port,11207},
    {admin_user,"@ns_server"},
    {other_users,
     ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
      "@cbas"]},
    {admin_pass,"*****"},
    {engines,
     [{membase,
       [{engine,"/opt/couchbase/lib/memcached/ep.so"},
        {static_config_string,"failpartialwarmup=false"}]},
      {memcached,
       [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
        {static_config_string,"vb0=true"}]}]},
    {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
    {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
    {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
    {log_prefix,"memcached.log"},
    {log_generations,20},
    {log_cyclesize,10485760},
    {log_sleeptime,19},
    {log_rotation_period,39003}]},
  {{node,'ns_1@127.0.0.1',memcached_config},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {[{interfaces,
       {memcached_config_mgr,omit_missing_mcd_ports,
        [{[{host,<<"*">>},
           {port,port},
           {maxconn,maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,dedicated_port},
           {maxconn,dedicated_port_maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,ssl_port},
           {maxconn,maxconn},
           {ssl,
            {[{key,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
              {cert,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]}]}},
      {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
      {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
      {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
      {connection_idle_time,connection_idle_time},
      {privilege_debug,privilege_debug},
      {breakpad,
       {[{enabled,breakpad_enabled},
         {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
      {admin,{"~s",[admin_user]}},
      {verbosity,verbosity},
      {audit_file,{"~s",[audit_file]}},
      {rbac_file,{"~s",[rbac_file]}},
      {dedupe_nmvb_maps,dedupe_nmvb_maps},
      {tracing_enabled,tracing_enabled},
      {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
      {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
      {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
      {logger,
       {[{filename,{"~s/~s",[log_path,log_prefix]}},
         {cyclesize,log_cyclesize},
         {sleeptime,log_sleeptime}]}}]}]},
  {{node,'ns_1@127.0.0.1',memcached_defaults},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {maxconn,30000},
    {dedicated_port_maxconn,5000},
    {ssl_cipher_list,"HIGH"},
    {connection_idle_time,0},
    {verbosity,0},
    {privilege_debug,false},
    {breakpad_enabled,true},
    {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
    {dedupe_nmvb_maps,false},
    {tracing_enabled,true},
    {datatype_snappy,true}]},
  {{node,'ns_1@127.0.0.1',moxi},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,11211},
    {verbosity,[]}]},
  {{node,'ns_1@127.0.0.1',ns_log},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
  {{node,'ns_1@127.0.0.1',port_servers},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
  {{node,'ns_1@127.0.0.1',projector_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9999]},
  {{node,'ns_1@127.0.0.1',query_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8093]},
  {{node,'ns_1@127.0.0.1',rest},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,8091},
    {port_meta,global}]},
  {{node,'ns_1@127.0.0.1',ssl_capi_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18092]},
  {{node,'ns_1@127.0.0.1',ssl_query_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18093]},
  {{node,'ns_1@127.0.0.1',ssl_rest_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18091]},
  {{node,'ns_1@127.0.0.1',uuid},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    <<"0f8760945f98b1efdbef0bd1ea6e8446">>]},
  {{node,'ns_1@127.0.0.1',xdcr_rest_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9998]},
  {{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    false]},
  {{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{4,63756036166}}]}]}]]
[ns_server:info,2020-05-07T02:21:50.627Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1138]Here's full dynamic config we loaded + static & default config:
[{{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{4,63756036166}}]}]},
 {{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   false]},
 {{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   <<"0f8760945f98b1efdbef0bd1ea6e8446">>]},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,8091},
   {port_meta,global}]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11211},
   {verbosity,[]}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {privilege_debug,false},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false},
   {tracing_enabled,true},
   {datatype_snappy,true}]},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},
          {port,port},
          {maxconn,maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {privilege_debug,privilege_debug},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {rbac_file,{"~s",[rbac_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps},
     {tracing_enabled,tracing_enabled},
     {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
     {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
     {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
     {logger,
      {[{filename,{"~s/~s",[log_path,log_prefix]}},
        {cyclesize,log_cyclesize},
        {sleeptime,log_sleeptime}]}}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"@ns_server"},
   {other_users,
    ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
     "@cbas"]},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   active]},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   19102]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',fts_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18094]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',eventing_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18096]},
 {{node,'ns_1@127.0.0.1',eventing_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8096]},
 {{node,'ns_1@127.0.0.1',eventing_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9140]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {5,5,3}]},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {{node,'ns_1@127.0.0.1',cbas_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18095]},
 {{node,'ns_1@127.0.0.1',cbas_result_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9117]},
 {{node,'ns_1@127.0.0.1',cbas_replication_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9120]},
 {{node,'ns_1@127.0.0.1',cbas_parent_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9122]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9121]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9119]},
 {{node,'ns_1@127.0.0.1',cbas_messaging_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9118]},
 {{node,'ns_1@127.0.0.1',cbas_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8095]},
 {{node,'ns_1@127.0.0.1',cbas_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]},
 {{node,'ns_1@127.0.0.1',cbas_data_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9116]},
 {{node,'ns_1@127.0.0.1',cbas_console_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9114]},
 {{node,'ns_1@127.0.0.1',cbas_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9115]},
 {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9111]},
 {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9112]},
 {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9113]},
 {{node,'ns_1@127.0.0.1',cbas_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9110]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{request_limit,rest},undefined},
 {{request_limit,capi},undefined},
 {{metakv,<<"/indexing/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {secure_headers,[]},
 {rest_creds,null},
 {rest,[{port,8091}]},
 {replication,[{enabled,true}]},
 {remote_clusters,[]},
 {read_only_user_creds,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {quorum_nodes,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   'ns_1@127.0.0.1']},
 {password_policy,[{min_length,6},{must_present,[]}]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {memory_quota,311},
 {memcached,[]},
 {max_bucket_count,10},
 {log_redaction_default_cfg,[{redact_level,none}]},
 {index_aware_rebalance_disabled,false},
 {fts_memory_quota,256},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
 {drop_request_memory_threshold_mib,undefined},
 {cbas_memory_quota,1024},
 {buckets,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]},
   {configs,[]}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
 {audit,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {enabled,[]},
   {disabled_users,[]},
   {auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {cert_and_pkey,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQlsomKQ7qhDcAeKZ3inWuCQuv8NxCAMb8M\nXhrVTrshZyFDiXdKS3Xbshyc9dEOiDwuDwAEgfwJQsXzzx0eCRtyTZfWAWTOH06O\nXdQps+9iTfr2KBFj27uag5c5ns+0ojsNyqZhA4+dbS7zK3CZ1dx7LPkL3+4HTlMh\nmH1/2fib3Lbp6dW3B55GV8/RHbkzgcRMyBicYtinqh6JMmmzjO/3KEyVHs3h0W1E\n00JdAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCKWU+bCvjKUlhW\niMiAN7r/3Vxkah7KEqp8BajCnLrlTMeiV+24TlPrsCWz4VBmOgt8OcijS3axdEik\nXeteeJp+R8nb2XPGivHOg/Hx2NlLxCrtXaYVGM0PiVydo24iCv0ZlqMCBsrzRLky\n5otbfQi8ngdfuR88C0/r3RLqvuFnOtFkLbKXuT/qshXfM8O/OgiJkr6CTBFYNd8w\nTCxN2syK41/HXoYzexdA/OTSm+kuEIuDpQYxKS0M4oKKZApJM70y/CYTzwG3JOnp\nuteZPYrwhIqxz01fkbLnj3QLGxPpSexRsp52GOoCv/YEE7tl3Olt4+p+MvhEZPdZ\ndqB53mNJ\n-----END CERTIFICATE-----\n">>,
    <<"*****">>}]},
 {otp,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
   {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]},
 {cluster_compat_version,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},
   6,0]},
 {{service_map,n1ql},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{service_map,index},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{service_map,fts},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {roles_definitions,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {users_upgrade,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {client_cert_auth,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {state,"disable"},
   {prefixes,[]}]},
 {{metakv,<<"/query/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
 {{metakv,<<"/eventing/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"ram_quota\":256}">>]},
 {{rbac_upgrade,[5,5]},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {scramsha_fallback_salt,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<169,238,80,91,5,165,74,47,79,135,45,74>>]},
 {audit_decriptors,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {20480,
    [{name,<<"opened DCP connection">>},
     {description,<<"opened DCP connection">>},
     {enabled,true},
     {module,memcached}]},
   {20482,
    [{name,<<"external memcached bucket flush">>},
     {description,
      <<"External user flushed the content of a memcached bucket">>},
     {enabled,true},
     {module,memcached}]},
   {20483,
    [{name,<<"invalid packet">>},
     {description,<<"Rejected an invalid packet">>},
     {enabled,true},
     {module,memcached}]},
   {20485,
    [{name,<<"authentication succeeded">>},
     {description,<<"Authentication to the cluster succeeded">>},
     {enabled,false},
     {module,memcached}]},
   {20488,
    [{name,<<"document read">>},
     {description,<<"Document was read">>},
     {enabled,false},
     {module,memcached}]},
   {20489,
    [{name,<<"document locked">>},
     {description,<<"Document was locked">>},
     {enabled,false},
     {module,memcached}]},
   {20490,
    [{name,<<"document modify">>},
     {description,<<"Document was modified">>},
     {enabled,false},
     {module,memcached}]},
   {20491,
    [{name,<<"document delete">>},
     {description,<<"Document was deleted">>},
     {enabled,false},
     {module,memcached}]},
   {20492,
    [{name,<<"select bucket">>},
     {description,<<"The specified bucket was selected">>},
     {enabled,true},
     {module,memcached}]},
   {28672,
    [{name,<<"SELECT statement">>},
     {description,<<"A N1QL SELECT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28673,
    [{name,<<"EXPLAIN statement">>},
     {description,<<"A N1QL EXPLAIN statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28674,
    [{name,<<"PREPARE statement">>},
     {description,<<"A N1QL PREPARE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28675,
    [{name,<<"INFER statement">>},
     {description,<<"A N1QL INFER statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28676,
    [{name,<<"INSERT statement">>},
     {description,<<"A N1QL INSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28677,
    [{name,<<"UPSERT statement">>},
     {description,<<"A N1QL UPSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28678,
    [{name,<<"DELETE statement">>},
     {description,<<"A N1QL DELETE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28679,
    [{name,<<"UPDATE statement">>},
     {description,<<"A N1QL UPDATE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28680,
    [{name,<<"MERGE statement">>},
     {description,<<"A N1QL MERGE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28681,
    [{name,<<"CREATE INDEX statement">>},
     {description,<<"A N1QL CREATE INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28682,
    [{name,<<"DROP INDEX statement">>},
     {description,<<"A N1QL DROP INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28683,
    [{name,<<"ALTER INDEX statement">>},
     {description,<<"A N1QL ALTER INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28684,
    [{name,<<"BUILD INDEX statement">>},
     {description,<<"A N1QL BUILD INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28685,
    [{name,<<"GRANT ROLE statement">>},
     {description,<<"A N1QL GRANT ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28686,
    [{name,<<"REVOKE ROLE statement">>},
     {description,<<"A N1QL REVOKE ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28687,
    [{name,<<"UNRECOGNIZED statement">>},
     {description,
      <<"An unrecognized statement was received by the N1QL query engine">>},
     {enabled,false},
     {module,n1ql}]},
   {28688,
    [{name,<<"CREATE PRIMARY INDEX statement">>},
     {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28689,
    [{name,<<"/admin/stats API request">>},
     {description,<<"An HTTP request was made to the API at /admin/stats.">>},
     {enabled,false},
     {module,n1ql}]},
   {28690,
    [{name,<<"/admin/vitals API request">>},
     {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
     {enabled,false},
     {module,n1ql}]},
   {28691,
    [{name,<<"/admin/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28692,
    [{name,<<"/admin/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28693,
    [{name,<<"/admin/indexes/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28694,
    [{name,<<"/admin/indexes/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28695,
    [{name,<<"/admin/indexes/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28697,
    [{name,<<"/admin/ping API request">>},
     {description,<<"An HTTP request was made to the API at /admin/ping.">>},
     {enabled,false},
     {module,n1ql}]},
   {28698,
    [{name,<<"/admin/config API request">>},
     {description,<<"An HTTP request was made to the API at /admin/config.">>},
     {enabled,false},
     {module,n1ql}]},
   {28699,
    [{name,<<"/admin/ssl_cert API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
     {enabled,false},
     {module,n1ql}]},
   {28700,
    [{name,<<"/admin/settings API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/settings.">>},
     {enabled,false},
     {module,n1ql}]},
   {28701,
    [{name,<<"/admin/clusters API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/clusters.">>},
     {enabled,false},
     {module,n1ql}]},
   {28702,
    [{name,<<"/admin/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {32768,
    [{name,<<"Create Function">>},
     {description,<<"Eventing function definition was created or updated">>},
     {enabled,true},
     {module,eventing}]},
   {32769,
    [{name,<<"Delete Function">>},
     {description,<<"Eventing function definition was deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32770,
    [{name,<<"Fetch Functions">>},
     {description,<<"Eventing function definition was read">>},
     {enabled,false},
     {module,eventing}]},
   {32771,
    [{name,<<"List Deployed">>},
     {description,<<"Eventing deployed functions list was read">>},
     {enabled,false},
     {module,eventing}]},
   {32772,
    [{name,<<"Fetch Drafts">>},
     {description,<<"Eventing function draft definitions were read">>},
     {enabled,false},
     {module,eventing}]},
   {32773,
    [{name,<<"Delete Drafts">>},
     {description,<<"Eventing function draft definitions were deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32774,
    [{name,<<"Save Draft">>},
     {description,<<"Save a draft definition to the store">>},
     {enabled,true},
     {module,eventing}]},
   {32775,
    [{name,<<"Start Debug">>},
     {description,<<"Start eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32776,
    [{name,<<"Stop Debug">>},
     {description,<<"Stop eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32777,
    [{name,<<"Start Tracing">>},
     {description,<<"Start tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32778,
    [{name,<<"Stop Tracing">>},
     {description,<<"Stop tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32779,
    [{name,<<"Set Settings">>},
     {description,<<"Save settings for a given app">>},
     {enabled,true},
     {module,eventing}]},
   {32780,
    [{name,<<"Fetch Config">>},
     {description,<<"Get config for eventing">>},
     {enabled,false},
     {module,eventing}]},
   {32781,
    [{name,<<"Save Config">>},
     {description,<<"Save config for eventing">>},
     {enabled,true},
     {module,eventing}]},
   {32782,
    [{name,<<"Cleanup Eventing">>},
     {description,<<"Clears up app definitions and settings from metakv">>},
     {enabled,true},
     {module,eventing}]},
   {32783,
    [{name,<<"Get Settings">>},
     {description,<<"Get settings for a given app">>},
     {enabled,false},
     {module,eventing}]},
   {32784,
    [{name,<<"Import Functions">>},
     {description,<<"Import a list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32785,
    [{name,<<"Export Functions">>},
     {description,<<"Export the list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32786,
    [{name,<<"List Running">>},
     {description,<<"Eventing running function list was read">>},
     {enabled,false},
     {module,eventing}]},
   {36865,
    [{name,<<"Service configuration change">>},
     {description,<<"A successful service configuration change was made.">>},
     {enabled,true},
     {module,analytics}]},
   {36866,
    [{name,<<"Node configuration change">>},
     {description,<<"A successful node configuration change was made.">>},
     {enabled,true},
     {module,analytics}]}]},
 {auto_failover_cfg,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {enabled,true},
   {timeout,120},
   {count,0},
   {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
   {failover_server_group,false},
   {max_count,1},
   {failed_over_server_groups,[]}]}]
[error_logger:info,2020-05-07T02:21:50.634Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.157.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.636Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.163.0>},
                       {name,ns_config_remote},
                       {mfargs,{ns_config_replica,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.637Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.164.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.638Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:50.639Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.166.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.641Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.167.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:50.648Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.170.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:50.651Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2020-05-07T02:21:50.651Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.171.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.651Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.172.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.657Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.173.0>},
                       {name,memcached_refresh},
                       {mfargs,{memcached_refresh,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.659Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.175.0>},
                       {name,ssl_service_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ssl_service_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:50.674Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:init:419]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem-ca"},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[error_logger:info,2020-05-07T02:21:50.736Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.176.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:50.750Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T02:21:50.751Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T02:21:50.751Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T02:21:50.751Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[ns_server:debug,2020-05-07T02:21:50.769Z,ns_1@127.0.0.1:<0.178.0>:restartable:start_child:98]Started child process <0.179.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2020-05-07T02:21:50.769Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.178.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.769Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.174.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:50.770Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.197.0>},
                       {name,user_storage_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,user_storage_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.776Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.199.0>},
                       {name,users_replicator},
                       {mfargs,{menelaus_users,start_replicator,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:50.777Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:55]Start waiting for startup
[ns_server:debug,2020-05-07T02:21:50.779Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_storage:anounce_startup:69]Announce my startup to <0.199.0>
[ns_server:debug,2020-05-07T02:21:50.779Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:58]Received replicated storage registration from <0.200.0>
[ns_server:debug,2020-05-07T02:21:50.781Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:open:212]Opening file "/opt/couchbase/var/lib/couchbase/config/users.dets"
[error_logger:info,2020-05-07T02:21:50.781Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.200.0>},
                       {name,users_storage},
                       {mfargs,{menelaus_users,start_storage,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.781Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.198.0>},
                       {name,users_storage_sup},
                       {mfargs,{users_storage_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:21:50.793Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:init:44]Starting versioned cache compiled_roles_cache
[error_logger:info,2020-05-07T02:21:50.793Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.202.0>},
                       {name,compiled_roles_cache},
                       {mfargs,{menelaus_roles,start_compiled_roles_cache,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.793Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.196.0>},
                       {name,users_sup},
                       {mfargs,{users_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:50.796Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.205.0>},
                       {name,dets_sup},
                       {mfargs,{dets_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:50.796Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.206.0>},
                       {name,dets},
                       {mfargs,{dets_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:50.813Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:convert_docs_to_55_in_dets:243]Checking for pre 5.5 records in dets: users_storage
[ns_server:debug,2020-05-07T02:21:50.813Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,'$1','_','$2'},
                                      [],
                                      [{{'$1','$2'}}]}],
                                    100}
[ns_server:debug,2020-05-07T02:21:50.813Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:init_after_ack:204]Loading 0 items, 299 words took 0ms
[ns_server:debug,2020-05-07T02:21:50.816Z,ns_1@127.0.0.1:users_replicator<0.199.0>:doc_replicator:loop:60]doing replicate_newnodes_docs
[ns_server:debug,2020-05-07T02:21:50.818Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.210.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:141]Waiting for ns_couchdb node to start
[error_logger:info,2020-05-07T02:21:50.818Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.209.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:50.818Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:21:50.821Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.213.0>,shutdown}}
[ns_server:debug,2020-05-07T02:21:50.822Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T02:21:50.822Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:21:51.023Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:21:51.023Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.216.0>,shutdown}}
[ns_server:debug,2020-05-07T02:21:51.023Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T02:21:51.023Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:21:51.224Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:21:51.224Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.219.0>,shutdown}}
[error_logger:info,2020-05-07T02:21:51.224Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T02:21:51.224Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T02:21:51.425Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T02:21:51.449Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T02:21:51.650Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T02:21:51.851Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T02:21:52.052Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[error_logger:info,2020-05-07T02:21:52.543Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.228.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:52.744Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: Apache CouchDB v4.5.1-112-gc2b9820 (LogLevel=info) is starting.
ns_couchdb<0.209.0>: Apache CouchDB has started. Time to relax.

[error_logger:info,2020-05-07T02:21:52.831Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.210.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.96617950>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:52.848Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:ns_storage_conf:setup_db_and_ix_paths:47]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2020-05-07T02:21:52.855Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.231.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:52.857Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.232.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:52.863Z,ns_1@127.0.0.1:ns_server_sup<0.230.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2020-05-07T02:21:52.869Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.233.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:52.871Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.234.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:52.874Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.235.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:52.874Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.236.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:52.902Z,ns_1@127.0.0.1:memcached_passwords<0.237.0>:memcached_cfg:init:62]Init config writer for memcached_passwords, "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T02:21:52.902Z,ns_1@127.0.0.1:memcached_passwords<0.237.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T02:21:52.945Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.237.0>
[ns_server:debug,2020-05-07T02:21:52.945Z,ns_1@127.0.0.1:memcached_passwords<0.237.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T02:21:52.953Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.237.0>
[error_logger:info,2020-05-07T02:21:52.980Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.237.0>},
                       {name,memcached_passwords},
                       {mfargs,{memcached_passwords,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:52.980Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[ns_server:debug,2020-05-07T02:21:52.987Z,ns_1@127.0.0.1:memcached_permissions<0.240.0>:memcached_cfg:init:62]Init config writer for memcached_permissions, "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T02:21:52.988Z,ns_1@127.0.0.1:memcached_permissions<0.240.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T02:21:52.993Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.240.0>
[ns_server:debug,2020-05-07T02:21:52.993Z,ns_1@127.0.0.1:memcached_permissions<0.240.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{user,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T02:21:52.993Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.240.0>
[error_logger:info,2020-05-07T02:21:52.995Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.240.0>},
                       {name,memcached_permissions},
                       {mfargs,{memcached_permissions,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:52.996Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.243.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:21:52.999Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:21:52.999Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [isasl] failed. Retry in 1000 ms.
[ns_server:debug,2020-05-07T02:21:52.999Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of rbac requested
[error_logger:info,2020-05-07T02:21:53.000Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.245.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:21:53.001Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:21:53.001Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[ns_server:debug,2020-05-07T02:21:53.001Z,ns_1@127.0.0.1:ns_node_disco<0.246.0>:ns_node_disco:init:130]Initting ns_node_disco with []
[ns_server:debug,2020-05-07T02:21:53.001Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[user:info,2020-05-07T02:21:53.001Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:127]Node 'ns_1@127.0.0.1' synchronized otp cookie {sanitized,
                                               <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>} from cluster
[ns_server:debug,2020-05-07T02:21:53.001Z,ns_1@127.0.0.1:<0.247.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:21:53.006Z,ns_1@127.0.0.1:<0.247.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[error_logger:info,2020-05-07T02:21:53.006Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.246.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.008Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.248.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.010Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.249.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.018Z,ns_1@127.0.0.1:ns_config_rep<0.251.0>:ns_config_rep:init:69]init pulling
[error_logger:info,2020-05-07T02:21:53.018Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.250.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.018Z,ns_1@127.0.0.1:ns_config_rep<0.251.0>:ns_config_rep:init:71]init pushing
[ns_server:debug,2020-05-07T02:21:53.026Z,ns_1@127.0.0.1:ns_config_rep<0.251.0>:ns_config_rep:init:75]init reannouncing
[ns_server:debug,2020-05-07T02:21:53.026Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2020-05-07T02:21:53.026Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2020-05-07T02:21:53.026Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T02:21:53.026Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T02:21:53.026Z,ns_1@127.0.0.1:<0.259.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:21:53.026Z,ns_1@127.0.0.1:<0.260.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:21:53.026Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:handle_info:89]Flushing cache compiled_roles_cache due to version change from undefined to {[6,
                                                                              0],
                                                                             {0,
                                                                              122835136},
                                                                             false,
                                                                             []}
[ns_server:debug,2020-05-07T02:21:53.026Z,ns_1@127.0.0.1:<0.259.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:21:53.026Z,ns_1@127.0.0.1:<0.260.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:21:53.026Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2020-05-07T02:21:53.027Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,[]},
 {disabled_users,[]},
 {auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2020-05-07T02:21:53.028Z,ns_1@127.0.0.1:memcached_passwords<0.237.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T02:21:53.028Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit_decriptors ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {20480,
  [{name,<<"opened DCP connection">>},
   {description,<<"opened DCP connection">>},
   {enabled,true},
   {module,memcached}]},
 {20482,
  [{name,<<"external memcached bucket flush">>},
   {description,<<"External user flushed the content of a memcached bucket">>},
   {enabled,true},
   {module,memcached}]},
 {20483,
  [{name,<<"invalid packet">>},
   {description,<<"Rejected an invalid packet">>},
   {enabled,true},
   {module,memcached}]},
 {20485,
  [{name,<<"authentication succeeded">>},
   {description,<<"Authentication to the cluster succeeded">>},
   {enabled,false},
   {module,memcached}]},
 {20488,
  [{name,<<"document read">>},
   {description,<<"Document was read">>},
   {enabled,false},
   {module,memcached}]},
 {20489,
  [{name,<<"document locked">>},
   {description,<<"Document was locked">>},
   {enabled,false},
   {module,memcached}]},
 {20490,
  [{name,<<"document modify">>},
   {description,<<"Document was modified">>},
   {enabled,false},
   {module,memcached}]},
 {20491,
  [{name,<<"document delete">>},
   {description,<<"Document was deleted">>},
   {enabled,false},
   {module,memcached}]},
 {20492,
  [{name,<<"select bucket">>},
   {description,<<"The specified bucket was selected">>},
   {enabled,true},
   {module,memcached}]},
 {28672,
  [{name,<<"SELECT statement">>},
   {description,<<"A N1QL SELECT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28673,
  [{name,<<"EXPLAIN statement">>},
   {description,<<"A N1QL EXPLAIN statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28674,
  [{name,<<"PREPARE statement">>},
   {description,<<"A N1QL PREPARE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28675,
  [{name,<<"INFER statement">>},
   {description,<<"A N1QL INFER statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28676,
  [{name,<<"INSERT statement">>},
   {description,<<"A N1QL INSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28677,
  [{name,<<"UPSERT statement">>},
   {description,<<"A N1QL UPSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28678,
  [{name,<<"DELETE statement">>},
   {description,<<"A N1QL DELETE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28679,
  [{name,<<"UPDATE statement">>},
   {description,<<"A N1QL UPDATE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28680,
  [{name,<<"MERGE statement">>},
   {description,<<"A N1QL MERGE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28681,
  [{name,<<"CREATE INDEX statement">>},
   {description,<<"A N1QL CREATE INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28682,
  [{name,<<"DROP INDEX statement">>},
   {description,<<"A N1QL DROP INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28683,
  [{name,<<"ALTER INDEX statement">>},
   {description,<<"A N1QL ALTER INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28684,
  [{name,<<"BUILD INDEX statement">>},
   {description,<<"A N1QL BUILD INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28685,
  [{name,<<"GRANT ROLE statement">>},
   {description,<<"A N1QL GRANT ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28686,
  [{name,<<"REVOKE ROLE statement">>},
   {description,<<"A N1QL REVOKE ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28687,
  [{name,<<"UNRECOGNIZED statement">>},
   {description,<<"An unrecognized statement was received by the N1QL query engine">>},
   {enabled,false},
   {module,n1ql}]},
 {28688,
  [{name,<<"CREATE PRIMARY INDEX statement">>},
   {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28689,
  [{name,<<"/admin/stats API request">>},
   {description,<<"An HTTP request was made to the API at /admin/stats.">>},
   {enabled,false},
   {module,n1ql}]},
 {28690,
  [{name,<<"/admin/vitals API request">>},
   {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
   {enabled,false},
   {module,n1ql}]},
 {28691,
  [{name,<<"/admin/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28692,
  [{name,<<"/admin/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28693,
  [{name,<<"/admin/indexes/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28694,
  [{name,<<"/admin/indexes/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28695,
  [{name,<<"/admin/indexes/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28697,
  [{name,<<"/admin/ping API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ping.">>},
   {enabled,false},
   {module,n1ql}]},
 {28698,
  [{name,<<"/admin/config API request">>},
   {description,<<"An HTTP request was made to the API at /admin/config.">>},
   {enabled,false},
   {module,n1ql}]},
 {28699,
  [{name,<<"/admin/ssl_cert API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ssl_cert.">>},
   {enabled,false},
   {module,n1ql}]},
 {28700,
  [{name,<<"/admin/settings API request">>},
   {description,<<"An HTTP request was made to the API at /admin/settings.">>},
   {enabled,false},
   {module,n1ql}]},
 {28701,
  [{name,<<"/admin/clusters API request">>},
   {description,<<"An HTTP request was made to the API at /admin/clusters.">>},
   {enabled,false},
   {module,n1ql}]},
 {28702,
  [{name,<<"/admin/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {32768,
  [{name,<<"Create Function">>},
   {description,<<"Eventing function definition was created or updated">>},
   {enabled,true},
   {module,eventing}]},
 {32769,
  [{name,<<"Delete Function">>},
   {description,<<"Eventing function definition was deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32770,
  [{name,<<"Fetch Functions">>},
   {description,<<"Eventing function definition was read">>},
   {enabled,false},
   {module,eventing}]},
 {32771,
  [{name,<<"List Deployed">>},
   {description,<<"Eventing deployed functions list was read">>},
   {enabled,false},
   {module,eventing}]},
 {32772,
  [{name,<<"Fetch Drafts">>},
   {description,<<"Eventing function draft definitions were read">>},
   {enabled,false},
   {module,eventing}]},
 {32773,
  [{name,<<"Delete Drafts">>},
   {description,<<"Eventing function draft definitions were deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32774,
  [{name,<<"Save Draft">>},
   {description,<<"Save a draft definition to the store">>},
   {enabled,true},
   {module,eventing}]},
 {32775,
  [{name,<<"Start Debug">>},
   {description,<<"Start eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32776,
  [{name,<<"Stop Debug">>},
   {description,<<"Stop eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32777,
  [{name,<<"Start Tracing">>},
   {description,<<"Start tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32778,
  [{name,<<"Stop Tracing">>},
   {description,<<"Stop tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32779,
  [{name,<<"Set Settings">>},
   {description,<<"Save settings for a given app">>},
   {enabled,true},
   {module,eventing}]},
 {32780,
  [{name,<<"Fetch Config">>},
   {description,<<"Get config for eventing">>},
   {enabled,false},
   {module,eventing}]},
 {32781,
  [{name,<<"Save Config">>},
   {description,<<"Save config for eventing">>},
   {enabled,true},
   {module,eventing}]},
 {32782,
  [{name,<<"Cleanup Eventing">>},
   {description,<<"Clears up app definitions and settings from metakv">>},
   {enabled,true},
   {module,eventing}]},
 {32783,
  [{name,<<"Get Settings">>},
   {description,<<"Get settings for a given app">>},
   {enabled,false},
   {module,eventing}]},
 {32784,
  [{name,<<"Import Functions">>},
   {description,<<"Import a list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32785,
  [{name,<<"Export Functions">>},
   {description,<<"Export the list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32786,
  [{name,<<"List Running">>},
   {description,<<"Eventing running function list was read">>},
   {enabled,false},
   {module,eventing}]},
 {36865,
  [{name,<<"Service configuration change">>},
   {description,<<"A successful service configuration change was made.">>},
   {enabled,true},
   {module,analytics}]},
 {36866,
  [{name,<<"Node configuration change">>},
   {description,<<"A successful node configuration change was made.">>},
   {enabled,true},
   {module,analytics}]}]
[ns_server:debug,2020-05-07T02:21:53.028Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[ns_server:debug,2020-05-07T02:21:53.028Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_reprovision_cfg ->
[{enabled,true},{max_nodes,1},{count,0}]
[ns_server:debug,2020-05-07T02:21:53.028Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2020-05-07T02:21:53.028Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
buckets ->
[[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}],{configs,[]}]
[ns_server:debug,2020-05-07T02:21:53.028Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cbas_memory_quota ->
1024
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cert_and_pkey ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQ"...>>,
  <<"*****">>}]
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
client_cert_auth ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {state,"disable"},
 {prefixes,[]}]
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cluster_compat_version ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},6,0]
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded,communication_issue]}]
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
fts_memory_quota ->
256
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
log_redaction_default_cfg ->
[{redact_level,none}]
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
max_bucket_count ->
10
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memcached ->
[]
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memory_quota ->
311
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
otp ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
 {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
password_policy ->
[{min_length,6},{must_present,[]}]
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
quorum_nodes ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
read_only_user_creds ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
remote_clusters ->
[]
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest ->
[{port,8091}]
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest_creds ->
null
[ns_server:debug,2020-05-07T02:21:53.029Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
roles_definitions ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T02:21:53.030Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
scramsha_fallback_salt ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<169,238,80,91,5,165,74,47,79,135,45,74>>]
[ns_server:debug,2020-05-07T02:21:53.030Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
secure_headers ->
[]
[ns_server:debug,2020-05-07T02:21:53.030Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2020-05-07T02:21:53.030Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2020-05-07T02:21:53.030Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
users_upgrade ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T02:21:53.030Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2020-05-07T02:21:53.030Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2020-05-07T02:21:53.030Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{4,63756036166}}]}]
[ns_server:debug,2020-05-07T02:21:53.030Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/eventing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"ram_quota\":256}">>]
[ns_server:debug,2020-05-07T02:21:53.031Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2020-05-07T02:21:53.031Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/query/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]
[ns_server:debug,2020-05-07T02:21:53.031Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{rbac_upgrade,[5,5]} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T02:21:53.031Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2020-05-07T02:21:53.031Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2020-05-07T02:21:53.031Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,fts} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T02:21:53.031Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,index} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T02:21:53.031Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T02:21:53.031Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T02:21:53.031Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8092]
[ns_server:debug,2020-05-07T02:21:53.031Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9110]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_client_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9113]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9112]
[ns_server:info,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: 172: Booted. Waiting for shutdown request
ns_couchdb<0.209.0>: working as port

[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9111]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9115]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_console_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9114]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_data_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9116]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8095]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_messaging_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9118]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_callback_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9119]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9121]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_parent_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9122]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_replication_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9120]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_result_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9117]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18095]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {5,5,3}]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9140]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8096]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18096]
[ns_server:debug,2020-05-07T02:21:53.032Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8094]
[ns_server:debug,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18094]
[ns_server:debug,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9100]
[ns_server:debug,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9102]
[ns_server:debug,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|19102]
[error_logger:info,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9101]
[ns_server:debug,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9104]
[ns_server:debug,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:ns_config_rep<0.251.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([alert_limits,audit,audit_decriptors,
                               auto_failover_cfg,auto_reprovision_cfg,
                               autocompaction,buckets,cbas_memory_quota,
                               cert_and_pkey,client_cert_auth,
                               cluster_compat_version,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,
                               index_aware_rebalance_disabled,
                               log_redaction_default_cfg,max_bucket_count,
                               memcached,memory_quota,nodes_wanted,otp,
                               password_policy,quorum_nodes,
                               read_only_user_creds,remote_clusters,
                               replication,rest,rest_creds,roles_definitions,
                               scramsha_fallback_salt,secure_headers,
                               server_groups,set_view_update_daemon,
                               users_upgrade,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>},
                               {metakv,<<"/eventing/settings/config">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {metakv,<<"/query/settings/config">>},
                               {rbac_upgrade,[5,5]},
                               {request_limit,capi},
                               {request_limit,rest},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',cbas_admin_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_client_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_http_port},
                               {node,'ns_1@127.0.0.1',cbas_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_console_port},
                               {node,'ns_1@127.0.0.1',cbas_data_port},
                               {node,'ns_1@127.0.0.1',cbas_debug_port},
                               {node,'ns_1@127.0.0.1',cbas_http_port},
                               {node,'ns_1@127.0.0.1',cbas_messaging_port},
                               {node,'ns_1@127.0.0.1',
                                   cbas_metadata_callback_port},
                               {node,'ns_1@127.0.0.1',cbas_metadata_port},
                               {node,'ns_1@127.0.0.1',cbas_parent_port},
                               {node,'ns_1@127.0.0.1',cbas_replication_port},
                               {node,'ns_1@127.0.0.1',cbas_result_port},
                               {node,'ns_1@127.0.0.1',cbas_ssl_port}]..)
[ns_server:debug,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9103]
[error_logger:info,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.244.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9105]
[ns_server:debug,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:debug,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:debug,2020-05-07T02:21:53.033Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 active]
[ns_server:debug,2020-05-07T02:21:53.034Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"@ns_server"},
 {other_users,["@cbq-engine","@projector","@goxdcr","@index","@fts",
               "@eventing","@cbas"]},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2020-05-07T02:21:53.034Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},
        {port,port},
        {maxconn,maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {privilege_debug,privilege_debug},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {rbac_file,{"~s",[rbac_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps},
   {tracing_enabled,tracing_enabled},
   {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
   {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
   {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
   {logger,
    {[{filename,{"~s/~s",[log_path,log_prefix]}},
      {cyclesize,log_cyclesize},
      {sleeptime,log_sleeptime}]}}]}]
[ns_server:debug,2020-05-07T02:21:53.034Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {privilege_debug,false},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false},
 {tracing_enabled,true},
 {datatype_snappy,true}]
[ns_server:debug,2020-05-07T02:21:53.034Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2020-05-07T02:21:53.034Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2020-05-07T02:21:53.034Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T02:21:53.035Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9999]
[ns_server:debug,2020-05-07T02:21:53.035Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8093]
[ns_server:debug,2020-05-07T02:21:53.035Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2020-05-07T02:21:53.035Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18092]
[ns_server:debug,2020-05-07T02:21:53.035Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18093]
[ns_server:debug,2020-05-07T02:21:53.035Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18091]
[ns_server:debug,2020-05-07T02:21:53.035Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 <<"0f8760945f98b1efdbef0bd1ea6e8446">>]
[ns_server:debug,2020-05-07T02:21:53.035Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9998]
[ns_server:debug,2020-05-07T02:21:53.035Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|false]
[ns_server:debug,2020-05-07T02:21:53.050Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:trigger_ssl_reload:565]Notify services [capi_ssl_service] about secure_headers_changed change
[ns_server:debug,2020-05-07T02:21:53.050Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:525]Going to notify following services: [capi_ssl_service]
[ns_server:info,2020-05-07T02:21:53.058Z,ns_1@127.0.0.1:<0.272.0>:ns_ssl_services_setup:notify_service:708]Successfully notified service capi_ssl_service
[ns_server:info,2020-05-07T02:21:53.058Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:541]Succesfully notified services [capi_ssl_service]
[error_logger:info,2020-05-07T02:21:53.061Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.273.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.063Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.237.0>
[ns_server:debug,2020-05-07T02:21:53.063Z,ns_1@127.0.0.1:memcached_passwords<0.237.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[error_logger:info,2020-05-07T02:21:53.065Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.275.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.065Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.237.0>
[error_logger:info,2020-05-07T02:21:53.065Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.278.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.065Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.279.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.070Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[ns_server:warn,2020-05-07T02:21:53.072Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:21:53.072Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[ns_server:debug,2020-05-07T02:21:53.073Z,ns_1@127.0.0.1:ns_log_events<0.243.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2020-05-07T02:21:53.073Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.281.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.073Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.280.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.074Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.282.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.075Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.283.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.093Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.285.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.093Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.291.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.093Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.284.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:21:53.095Z,ns_1@127.0.0.1:ns_heart<0.285.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2020-05-07T02:21:53.095Z,ns_1@127.0.0.1:ns_heart<0.285.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]}]}}

[error_logger:info,2020-05-07T02:21:53.096Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.295.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.100Z,ns_1@127.0.0.1:<0.292.0>:restartable:start_child:98]Started child process <0.294.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2020-05-07T02:21:53.100Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.296.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.100Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.292.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.100Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.299.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.109Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.300.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.109Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.301.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.109Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.302.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.109Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.303.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.111Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.305.0>},
                       {name,query_settings_manager},
                       {mfargs,{query_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.114Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.308.0>},
                       {name,eventing_settings_manager},
                       {mfargs,{eventing_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.115Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.310.0>},
                       {name,audit_events},
                       {mfargs,{gen_event,start_link,[{local,audit_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.126Z,ns_1@127.0.0.1:ns_heart<0.285.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2020-05-07T02:21:53.127Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.312.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.127Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.314.0>},
                       {name,scram_sha},
                       {mfargs,{scram_sha,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.129Z,ns_1@127.0.0.1:ns_heart<0.285.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T02:21:53.131Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.316.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.138Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.317.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.146Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.320.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:53.146Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[error_logger:info,2020-05-07T02:21:53.146Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.321.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:53.146Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T02:21:53.146Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T02:21:53.146Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[error_logger:info,2020-05-07T02:21:53.147Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.322.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.150Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.339.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.152Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.340.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.158Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.341.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.163Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.342.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2020-05-07T02:21:53.163Z,ns_1@127.0.0.1:ns_server_sup<0.230.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "6.0.3-2895-enterprise".
[error_logger:info,2020-05-07T02:21:53.163Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.311.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.163Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.348.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.166Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.352.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.167Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.353.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.31986353>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.167Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.351.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:21:53.170Z,ns_1@127.0.0.1:ns_ports_setup<0.348.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,goxdcr]
[error_logger:info,2020-05-07T02:21:53.176Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.355.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.176Z,ns_1@127.0.0.1:ns_audit_cfg<0.356.0>:ns_audit_cfg:write_audit_json:265]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{descriptors_path,
                                                                                <<"/opt/couchbase/etc/security">>},
                                                                               {version,
                                                                                2},
                                                                               {uuid,
                                                                                <<"18411111">>},
                                                                               {event_states,
                                                                                {[]}},
                                                                               {filtering_enabled,
                                                                                true},
                                                                               {disabled_userids,
                                                                                []},
                                                                               {auditd_enabled,
                                                                                false},
                                                                               {log_path,
                                                                                <<"/opt/couchbase/var/lib/couchbase/logs">>},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []}]
[ns_server:debug,2020-05-07T02:21:53.198Z,ns_1@127.0.0.1:ns_audit_cfg<0.356.0>:ns_audit_cfg:notify_memcached:170]Instruct memcached to reload audit config
[error_logger:info,2020-05-07T02:21:53.199Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.356.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:21:53.201Z,ns_1@127.0.0.1:<0.359.0>:ns_memcached:connect:1230]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2020-05-07T02:21:53.207Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.360.0>},
                       {name,ns_audit},
                       {mfargs,{ns_audit,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.209Z,ns_1@127.0.0.1:memcached_config_mgr<0.361.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2020-05-07T02:21:53.209Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.361.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:53.216Z,ns_1@127.0.0.1:<0.362.0>:ns_memcached_log_rotator:init:42]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2020-05-07T02:21:53.216Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.362.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.217Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.363.0>},
                       {name,testconditions_store},
                       {mfargs,{simple_store,start_link,[testconditions]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.219Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.365.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.221Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.367.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.221Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.366.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.221Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.364.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.232Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.368.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.233Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.372.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.235Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.374.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.236Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.375.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.236Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.377.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.237Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.237Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.380.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.263Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.381.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.265Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.383.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.265Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.385.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.281Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.386.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.293Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.388.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.294Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.388.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T02:21:53.295Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.388.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2020-05-07T02:21:53.298Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.392.0>},
                       {name,service_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_stats_children_sup},
                                services_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.303Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.394.0>},
                       {name,service_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [service_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.308Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.291.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T02:21:53.309Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.291.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T02:21:53.311Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.408.0>},
                       {name,service_status_keeper_index},
                       {mfargs,{service_index,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.316Z,ns_1@127.0.0.1:ns_ports_setup<0.348.0>:ns_ports_setup:set_children:90]Monitor ns_child_ports_sup <12401.74.0>
[ns_server:debug,2020-05-07T02:21:53.316Z,ns_1@127.0.0.1:memcached_config_mgr<0.361.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:info,2020-05-07T02:21:53.318Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.414.0>},
                       {name,service_status_keeper_fts},
                       {mfargs,{service_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.324Z,ns_1@127.0.0.1:memcached_config_mgr<0.361.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.80.0>
[error_logger:info,2020-05-07T02:21:53.326Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.419.0>},
                       {name,service_status_keeper_eventing},
                       {mfargs,{service_eventing,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.326Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.393.0>},
                       {name,service_status_keeper_sup},
                       {mfargs,{service_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.326Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.422.0>},
                       {name,service_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<services_stats_sup.0.41280346>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.326Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.391.0>},
                       {name,services_stats_sup},
                       {mfargs,{services_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:21:53.338Z,ns_1@127.0.0.1:memcached_config_mgr<0.361.0>:memcached_config_mgr:init:79]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[error_logger:info,2020-05-07T02:21:53.347Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.424.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.353Z,ns_1@127.0.0.1:memcached_config_mgr<0.361.0>:memcached_config_mgr:init:82]activated memcached port server
[ns_server:debug,2020-05-07T02:21:53.357Z,ns_1@127.0.0.1:<0.427.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.427.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2020-05-07T02:21:53.365Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:21:53.365Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:21:53.365Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:21:53.365Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[error_logger:info,2020-05-07T02:21:53.365Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.425.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.366Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:21:53.366Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2020-05-07T02:21:53.367Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.429.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.367Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.428.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.368Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.430.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.380Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.434.0>},
                       {name,leader_activities},
                       {mfargs,{leader_activities,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:21:53.391Z,ns_1@127.0.0.1:leader_lease_agent<0.435.0>:leader_lease_agent:maybe_recover_persisted_lease:397]Found persisted lease [{node,'ns_1@127.0.0.1'},
                       {uuid,<<"aa7283a89b1b123b91b897b397e10db0">>},
                       {time_left,15000},
                       {status,active}]
[error_logger:info,2020-05-07T02:21:53.391Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.435.0>},
                       {name,leader_lease_agent},
                       {mfargs,{leader_lease_agent,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.391Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.433.0>},
                       {name,leader_leases_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_leases_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.391Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.437.0>},
                       {name,leader_events},
                       {mfargs,{gen_event,start_link,[{local,leader_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.398Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.438.0>},
                       {name,leader_registry_server},
                       {mfargs,{leader_registry_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.400Z,ns_1@127.0.0.1:leader_registry_sup<0.436.0>:mb_master:check_master_takeover_needed:270]Sending master node question to the following nodes: []
[ns_server:debug,2020-05-07T02:21:53.400Z,ns_1@127.0.0.1:leader_registry_sup<0.436.0>:mb_master:check_master_takeover_needed:272]Got replies: []
[ns_server:debug,2020-05-07T02:21:53.400Z,ns_1@127.0.0.1:leader_registry_sup<0.436.0>:mb_master:check_master_takeover_needed:278]Was unable to discover master, not going to force mastership takeover
[user:info,2020-05-07T02:21:53.400Z,ns_1@127.0.0.1:mb_master<0.441.0>:mb_master:init:90]I'm the only node, so I'm the master.
[ns_server:debug,2020-05-07T02:21:53.400Z,ns_1@127.0.0.1:leader_registry<0.438.0>:leader_registry_server:handle_new_leader:241]New leader is 'ns_1@127.0.0.1'. Invalidating name cache.
[error_logger:info,2020-05-07T02:21:53.412Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.444.0>},
                       {name,leader_lease_acquirer},
                       {mfargs,{leader_lease_acquirer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.417Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.446.0>:leader_quorum_nodes_manager:pull_config:114]Attempting to pull config from nodes:
[]
[ns_server:debug,2020-05-07T02:21:53.417Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.446.0>:leader_quorum_nodes_manager:pull_config:119]Pulled config successfully.
[error_logger:info,2020-05-07T02:21:53.417Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.446.0>},
                       {name,leader_quorum_nodes_manager},
                       {mfargs,{leader_quorum_nodes_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:21:53.428Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"aa7283a89b1b123b91b897b397e10db0">>} (valid for 14963ms)
[ns_server:info,2020-05-07T02:21:53.431Z,ns_1@127.0.0.1:mb_master_sup<0.443.0>:misc:start_singleton:758]start_singleton(gen_server, ns_tick, [], []): started as <0.455.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T02:21:53.431Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.455.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.438Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.458.0>},
                       {name,ns_janitor_server},
                       {mfargs,{ns_janitor_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:53.444Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.457.0>:misc:start_singleton:758]start_singleton(gen_server, auto_reprovision, [], []): started as <0.459.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T02:21:53.445Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.459.0>},
                       {name,auto_reprovision},
                       {mfargs,{auto_reprovision,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:21:53.445Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.457.0>:misc:start_singleton:758]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.460.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T02:21:53.445Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.460.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.445Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.457.0>},
                       {name,ns_orchestrator_child_sup},
                       {mfargs,{ns_orchestrator_child_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:21:53.452Z,ns_1@127.0.0.1:<0.462.0>:auto_failover:init:211]init auto_failover.
[user:info,2020-05-07T02:21:53.452Z,ns_1@127.0.0.1:<0.462.0>:auto_failover:handle_call:242]Enabled auto-failover with timeout 120 and max count 1
[ns_server:debug,2020-05-07T02:21:53.458Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{5,63756037313}}]}]
[ns_server:debug,2020-05-07T02:21:53.458Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[ns_server:info,2020-05-07T02:21:53.458Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.456.0>:misc:start_singleton:758]start_singleton(gen_server, auto_failover, [], []): started as <0.462.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T02:21:53.458Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.462.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.458Z,ns_1@127.0.0.1:ns_config_rep<0.251.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([auto_failover_cfg,
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>}]..)
[error_logger:info,2020-05-07T02:21:53.458Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.456.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.459Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.441.0>},
                       {name,mb_master},
                       {mfargs,{mb_master,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:21:53.459Z,ns_1@127.0.0.1:<0.431.0>:restartable:start_child:98]Started child process <0.432.0>
  MFA: {leader_services_sup,start_link,[]}
[error_logger:info,2020-05-07T02:21:53.459Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.436.0>},
                       {name,leader_registry_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_registry_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.459Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.431.0>},
                       {name,leader_services_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{leader_services_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.459Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.470.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.459Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.471.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.469Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.472.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.485Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.473.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.489Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.476.0>},
                       {name,ns_server_monitor},
                       {mfargs,{ns_server_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.490Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.478.0>},
                       {name,service_monitor_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_monitor_children_sup},
                                health_monitor_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.490Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.479.0>},
                       {name,service_monitor_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<health_monitor_sup.0.81875396>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:21:53.496Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.487.0>},
                       {name,node_monitor},
                       {mfargs,{node_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.497Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[ns_server:debug,2020-05-07T02:21:53.497Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.169.0>
[error_logger:info,2020-05-07T02:21:53.497Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.495.0>},
                       {name,node_status_analyzer},
                       {mfargs,{node_status_analyzer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:21:53.497Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2020-05-07T02:21:53.498Z,ns_1@127.0.0.1:<0.168.0>:restartable:start_child:98]Started child process <0.169.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[error_logger:info,2020-05-07T02:21:53.498Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.475.0>},
                       {name,health_monitor_sup},
                       {mfargs,{health_monitor_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:21:53.498Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:130]138: Entered child_loop
[error_logger:info,2020-05-07T02:21:53.498Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.230.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.498Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.168.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:21:53.498Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:debug,2020-05-07T02:21:53.611Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@",admin}
[ns_server:debug,2020-05-07T02:21:53.667Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.498.0>:json_rpc_connection:init:73]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.498.0>
[ns_server:debug,2020-05-07T02:21:53.691Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.501.0>:json_rpc_connection:init:73]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.501.0>
[ns_server:debug,2020-05-07T02:21:53.692Z,ns_1@127.0.0.1:menelaus_cbauth<0.342.0>:menelaus_cbauth:handle_cast:102]Observed json rpc process {"goxdcr-cbauth",<0.501.0>} started
[ns_server:debug,2020-05-07T02:21:53.709Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@goxdcr-cbauth",admin}
[ns_server:debug,2020-05-07T02:21:54.022Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:89]Refresh of [rbac,isasl] succeeded
[ns_server:debug,2020-05-07T02:21:54.453Z,ns_1@127.0.0.1:<0.462.0>:auto_failover_logic:log_master_activity:170]Transitioned node {'ns_1@127.0.0.1',<<"0f8760945f98b1efdbef0bd1ea6e8446">>} state new -> up
[ns_server:debug,2020-05-07T02:22:08.392Z,ns_1@127.0.0.1:leader_lease_agent<0.435.0>:leader_lease_agent:handle_lease_expired:284]Lease held by {lease_holder,<<"aa7283a89b1b123b91b897b397e10db0">>,
                            'ns_1@127.0.0.1'} expired. Starting expirer.
[ns_server:warn,2020-05-07T02:22:08.392Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"aa7283a89b1b123b91b897b397e10db0">>} (valid for 0ms)
[ns_server:debug,2020-05-07T02:22:08.393Z,ns_1@127.0.0.1:leader_lease_agent<0.435.0>:leader_lease_agent:do_handle_acquire_lease:147]Granting lease to {lease_holder,<<"52bfb87503e39b537b887732cb6c7de9">>,
                                'ns_1@127.0.0.1'} for 15000ms
[ns_server:info,2020-05-07T02:22:08.404Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_fresh_lease_acquired:302]Acquired lease from node 'ns_1@127.0.0.1' (lease uuid: <<"52bfb87503e39b537b887732cb6c7de9">>)
[ns_server:debug,2020-05-07T02:22:23.366Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:22:23.366Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:22:23.366Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:22:23.366Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:22:53.367Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:22:53.367Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:22:53.367Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:22:53.367Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:23:23.368Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:23:23.368Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:23:23.368Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:23:23.368Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[error_logger:info,2020-05-07T02:23:49.612Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
       alarm_handler: {clear,system_memory_high_watermark}

[ns_server:debug,2020-05-07T02:23:53.369Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:23:53.369Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:23:53.369Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:23:53.369Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:24:23.370Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:24:23.370Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:24:23.370Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:24:23.370Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:24:53.371Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:24:53.371Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:24:53.371Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:24:53.371Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:25:23.372Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:25:23.372Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:25:23.372Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:25:23.372Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[error_logger:info,2020-05-07T02:25:49.612Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
       alarm_handler: {set,{system_memory_high_watermark,[]}}

[ns_server:debug,2020-05-07T02:25:53.373Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:25:53.373Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:25:53.373Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:25:53.373Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:26:23.374Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:26:23.374Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:26:23.374Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:26:23.374Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:26:53.375Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:26:53.375Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:26:53.375Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:26:53.375Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:27:23.376Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:27:23.376Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:27:23.376Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:27:23.376Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:27:53.377Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:27:53.377Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:27:53.377Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:27:53.377Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:28:23.378Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:28:23.378Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:28:23.378Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:28:23.378Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:28:53.379Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:28:53.379Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:28:53.379Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:28:53.379Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:29:23.380Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:29:23.380Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:29:23.380Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:29:23.380Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:29:53.381Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:29:53.381Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:29:53.381Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:29:53.381Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:30:23.382Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:30:23.382Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:30:23.382Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:30:23.382Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:30:53.383Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:30:53.383Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:30:53.383Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:30:53.383Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:31:23.384Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:31:23.384Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:31:23.384Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:31:23.384Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:31:53.385Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:31:53.385Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:31:53.385Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:31:53.385Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:32:23.386Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:32:23.386Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:32:23.386Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:32:23.386Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:32:53.387Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:32:53.387Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:32:53.387Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:32:53.387Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:33:23.388Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:33:23.388Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:33:23.388Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:33:23.388Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:33:53.389Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:33:53.389Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:33:53.389Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:33:53.389Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:34:23.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:34:23.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:34:23.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:34:23.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:34:53.391Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:34:53.391Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:34:53.391Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:34:53.391Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:35:23.392Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:35:23.392Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:35:23.392Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:35:23.392Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:35:53.393Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:35:53.393Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:35:53.393Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:35:53.393Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:36:23.394Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:36:23.394Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:36:23.394Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:36:23.394Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:36:53.395Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:36:53.395Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:36:53.395Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:36:53.395Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:37:23.396Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:37:23.396Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:37:23.396Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:37:23.396Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:37:53.397Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:37:53.397Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:37:53.397Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:37:53.397Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:38:23.398Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:38:23.398Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:38:23.398Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:38:23.398Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:38:53.399Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:38:53.399Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:38:53.399Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:38:53.399Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:39:23.400Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:39:23.400Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:39:23.400Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:39:23.400Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:39:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:39:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:39:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:39:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:40:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:40:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:40:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:40:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:40:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:40:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:40:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:40:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:41:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:41:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:41:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:41:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:41:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:41:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:41:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:41:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:42:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:42:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:42:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:42:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:42:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:42:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:42:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:42:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:43:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:43:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:43:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:43:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:43:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:43:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:43:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:43:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:44:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:44:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:44:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:44:23.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:44:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:44:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:44:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:44:53.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:info,2020-05-07T02:45:28.700Z,nonode@nohost:<0.89.0>:ns_server:init_logging:150]Started & configured logging
[ns_server:info,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_access,info},
 {disk_sink_opts,[{rotation,[{compress,true},
                             {size,41943040},
                             {num_files,10},
                             {buffer_size_max,52428800}]}]},
 {disk_sink_opts_json_rpc,[{rotation,[{compress,true},
                                      {size,41943040},
                                      {num_files,2},
                                      {buffer_size_max,52428800}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.710Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.711Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.711Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.711Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.711Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_json_rpc, which is given from command line
[ns_server:warn,2020-05-07T02:45:28.711Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2020-05-07T02:45:28.722Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.138.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:28.727Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,76}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-378cfab] [64-bit] [smp:2:2] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2020,5,7},{2,45,28}}},
               {memory,
                   [{total,110239504},
                    {processes,9377728},
                    {processes_used,9376680},
                    {system,100861776},
                    {atom,339441},
                    {atom_used,322610},
                    {binary,69472},
                    {code,7796739},
                    {ets,2241584}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,path_config,calendar,
                    ale_default_formatter,'ale_logger-metakv',
                    'ale_logger-rebalance','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-json_rpc',
                    'ale_logger-access','ale_logger-ns_server',
                    'ale_logger-user','ale_logger-ns_doctor',
                    'ale_logger-cluster',io_lib_fread,'ale_logger-xdcr',
                    otp_internal,ns_log_sink,ale_disk_sink,misc,couch_util,
                    ns_server,filelib,cpu_sup,memsup,disksup,os_mon,io,
                    release_handler,overload,alarm_handler,sasl,timer,
                    tftp_sup,httpd_sup,httpc_handler_sup,httpc_cookie,
                    inets_trace,httpc_manager,httpc,httpc_profile_sup,
                    httpc_sup,ftp_sup,inets_sup,inets_app,ssl,lhttpc_manager,
                    lhttpc_sup,lhttpc,tls_connection_sup,ssl_session_cache,
                    ssl_pkix_db,ssl_manager,ssl_sup,ssl_app,crypto_server,
                    crypto_sup,crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_io,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","6.0.3-2895-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","6.0.3-2895-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,105},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [lhttpc_sup,code_server,ale_stats_events,'sink-ns_log',
                    ns_server_cluster_sup,lhttpc_manager,
                    application_controller,ale,httpd_sup,release_handler,
                    kernel_safe_sup,standard_error,ale_sup,overload,
                    'sink-disk_json_rpc',error_logger,alarm_handler,
                    'sink-disk_metakv',ale_dynamic_sup,timer_server,
                    'sink-disk_access_int',standard_error_sup,
                    'sink-disk_access','sink-disk_reports',crypto_server,
                    crypto_sup,sasl_safe_sup,'sink-disk_stats',
                    'sink-disk_xdcr',tftp_sup,inet_db,init,os_mon_sup,
                    'sink-disk_debug',rex,tls_connection_sup,user,
                    'sink-disk_error',ssl_sup,kernel_sup,cpu_sup,
                    global_name_server,memsup,'sink-disk_default',disksup,
                    httpc_sup,file_server_2,ssl_manager,local_tasks,
                    global_group,httpc_profile_sup,httpc_manager,
                    httpc_handler_sup,ftp_sup,sasl_sup,erl_prim_loader,
                    inets_sup]},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,1}]
[ns_server:info,2020-05-07T02:45:28.733Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:27]Manifest:
["<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\" />",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\" />",
 "  ","  <default remote=\"couchbase\" revision=\"master\" />","  ",
 "  <project groups=\"kv\" name=\"HdrHistogram_c\" path=\"third_party/HdrHistogram_c\" remote=\"couchbasedeps\" revision=\"d200fc0f68695d4aef1fad5c3c8cc55f8c033014\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"analytics-dcp-client\" path=\"analytics/java-dcp-client\" revision=\"d6ba66b51c0e589e9d4571264afcb0e33d507aea\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"asterixdb\" path=\"analytics/asterixdb\" revision=\"e8e59d0e6e72ba3fd96074c021ff7180261dcd59\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"c5b9dd8ec0910d2890d215075a7d2da1d6a494c9\" />",
 "  <project groups=\"kv\" name=\"benchmark\" remote=\"couchbasedeps\" revision=\"9e3465560240ffb242b50a47cb7f19251a12ee42\" />",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\" />",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5cd1345cca3ed72f1e63d41d622fcda73e63fea8\" />",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"822d01dab8721cf469beb6d8304c9eadd9c58160\" />",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"f551b6d4f32bb920a83dd28c705bddd5de0d03b2\" />",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"4b158bb555a3297565afecf6fae675c74f1e47df\" />",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\" />",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\" />",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"dc55cf8e9613ddf1bd6db4a662d1ecc3668223da\">",
 "    <annotation name=\"RELEASE\" value=\"alice\" />",
 "    <annotation name=\"PRODUCT\" value=\"couchbase-server\" />",
 "    <annotation name=\"BLD_NUM\" value=\"2895\" />",
 "    <annotation name=\"VERSION\" value=\"6.0.3\" />","  </project>",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas\" path=\"goproj/src/github.com/couchbaselabs/cbas\" remote=\"couchbase-priv\" revision=\"73fa77cd9133a9f779a484ac2caffb0b46a1dd82\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas-core\" path=\"analytics\" remote=\"couchbase-priv\" revision=\"7e513c6bd60a030c3a2477af683b264d61932a75\" />",
 "  <project groups=\"analytics\" name=\"cbas-ui\" revision=\"d8f601c3109887a30deccab09b2177bf499c8711\" />",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"0df84c7e3c6d95ff435c12a3c08c6f064db11e97\" />",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"80d2ad8892d806f5103f602fec0d80adaa4b628f\" />",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"8d4105a904e0282a6928de7392e266c58ea3c7a2\" />",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"0a94f40b9080e0ecb11d3b7531a58c5e6a4a4465\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"93d26dbc120c4f9874abb65aafa4d815334273c6\" />",
 "  <project name=\"cbsummary\" path=\"goproj/src/github.com/couchbase/cbsummary\" revision=\"dbfa1c0d73f0e49f6f04e390f03de8f9a6cee769\" />",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"dcae66272b24600ae0005fa06b511cfae8914d3d\" />",
 "  <project name=\"cobra\" path=\"godeps/src/github.com/spf13/cobra\" remote=\"couchbasedeps\" revision=\"0f056af21f5f368e5b0646079d0094a2c64150f7\" />",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\" />",
 "  <project groups=\"notdefault,kv_ee,enterprise\" name=\"couch_rocks\" remote=\"couchbase-priv\" revision=\"75f37fa46bfe5e445dee077157303968a3e09126\" />",
 "  <project name=\"couchbase-cli\" revision=\"9b383603860ce58885c27015c92635a7b42d3a1f\" />",
 "  <project name=\"couchdb\" revision=\"c2b98200b800f9fbed927c47074884b9f5f53eb4\" />",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"69aa5d92e195a30e06184911d72b8fffcf2534fe\" />",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"c2c458ff2cf93ee63bf4b0386f495b22535daf96\" />",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\" />",
 "  <project name=\"cuckoofilter\" path=\"godeps/src/github.com/seiflotfy/cuckoofilter\" remote=\"couchbasedeps\" revision=\"d04838794ab86926d32b124345777e55e6f43974\" />",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\" />",
 "  <project name=\"docloader\" path=\"goproj/src/github.com/couchbase/docloader\" revision=\"05067021a042a1b63e100a486afd7ebddab4c535\" />",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\" />",
 "  <project name=\"errors\" path=\"godeps/src/github.com/pkg/errors\" remote=\"couchbasedeps\" revision=\"30136e27e2ac8d167177e8a583aa4c3fea5be833\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"eventing\" path=\"goproj/src/github.com/couchbase/eventing\" revision=\"1da67e30a4c8faaf24f067eae280f5764d943dc2\" upstream=\"alice\" />",
 "  <project name=\"flatbuffers\" path=\"godeps/src/github.com/google/flatbuffers\" remote=\"couchbasedeps\" revision=\"1a8968225130caeddd16e227678e6f8af1926303\" />",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"c338e06e6847140f749058184d66de1f2a43474a\" />",
 "  <project name=\"fwd\" path=\"godeps/src/github.com/philhofer/fwd\" remote=\"couchbasedeps\" revision=\"bb6d471dc95d4fe11e432687f8b70ff496cf3136\" />",
 "  <project name=\"geocouch\" revision=\"2a0e73f43451045f157640eec59ced72da18471f\" />",
 "  <project name=\"ghistogram\" path=\"godeps/src/github.com/couchbase/ghistogram\" revision=\"d910dd063dd68fb4d2a1ba344440f834ebb4ef62\" />",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\" />",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"5c0ac9ef0ba7a0356279cee7eadd8874c4a8f8c1\" />",
 "  <project name=\"go-curl\" path=\"godeps/src/github.com/andelf/go-curl\" remote=\"couchbasedeps\" revision=\"f0b2afc926ec79be5d7f30393b3485352781a705\" />",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\" />",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\" />",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\" />",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\" />",
 "  <project name=\"go-sqlite3\" path=\"godeps/src/github.com/mattn/go-sqlite3\" remote=\"couchbasedeps\" revision=\"47fc4e5e9153645da45af6a86a5bce95e63a0f9e\" />",
 "  <project name=\"go-unsnap-stream\" path=\"godeps/src/github.com/glycerine/go-unsnap-stream\" remote=\"couchbasedeps\" revision=\"62a9a9eb44fd8932157b1a8ace2149eff5971af6\" />",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\" />",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"d2f15a425a9c8e4d8447e5f5b89ce14845f7fa05\" />",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\" />",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"699b13a51af5dd4f80ff3deedf41bba60debad32\" />",
 "  <project name=\"gocbconnstr\" path=\"godeps/src/gopkg.in/couchbaselabs/gocbconnstr.v1\" remote=\"couchbaselabs\" revision=\"710456e087a6d497e87f41d0a9d98d6a75672186\" />",
 "  <project name=\"gocbcore\" path=\"godeps/src/gopkg.in/couchbase/gocbcore.v7\" revision=\"a0d26c2d6f5de912499d35a5aba573006e5e036f\" />",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"aecdbe5a5a91f0688df7bdf260ca962178c06828\" />",
 "  <project name=\"gofarmhash\" path=\"godeps/src/github.com/leemcloughlin/gofarmhash\" remote=\"couchbasedeps\" revision=\"0a055c5b87a8c55ce83459cbf2776b563822a942\" />",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\" />",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\" />",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\" />",
 "  <project name=\"golang-tools\" path=\"godeps/src/golang.org/x/tools\" remote=\"couchbasedeps\" revision=\"a28dfb48e06b2296b66678872c2cb638f0304f20\" />",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\" />",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"e05ec3550789be1da2981787ef6444fef75e10bc\" />",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"4809dd3aa2ab88013b1dfce15516d717a35cb6e8\" />",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\" />",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\" />",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\" />",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"f98adca8eb365032cab838ef4d99453931afa112\" />",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"122ae25ed207cca30ceaee9ac66342a603d43a31\" />",
 "  <project groups=\"kv\" name=\"gsl-lite\" path=\"third_party/gsl-lite\" remote=\"couchbasedeps\" revision=\"57542c7e7ced375346e9ac55dad85b942cfad556\" />",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\" />",
 "  <project name=\"httprouter\" path=\"godeps/src/github.com/julienschmidt/httprouter\" remote=\"couchbasedeps\" revision=\"975b5c4c7c21c0e3d2764200bf2aa8e34657ae6e\" />",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"95ed84aad6bf8ecd99da2372dceede6d93f3d43a\" />",
 "  <project name=\"json-iterator-go\" path=\"godeps/src/github.com/json-iterator/go\" remote=\"couchbasedeps\" revision=\"f7279a603edee96fe7764d3de9c6ff8cf9970994\" />",
 "  <project name=\"jsonx\" path=\"godeps/src/gopkg.in/couchbaselabs/jsonx.v1\" remote=\"couchbaselabs\" revision=\"5b7baa20429a46a5543ee259664cc86502738cad\" />",
 "  <project groups=\"kv\" name=\"kv_engine\" revision=\"a30fd9d57cc2101078c8cd2c44968458df965c2b\" />",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"libcouchbase\" revision=\"081e8b16b991bf706eb77f8243935c6fba31b895\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"3681c2a912330352991ecdd642f257efe5b85518\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\" />",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\" />",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\" />",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"956632ec1bc3e28276d00ee2f22c3202f06efb12\" />",
 "  <project name=\"mossScope\" path=\"godeps/src/github.com/couchbase/mossScope\" revision=\"abd3b58b422dbc2e9463a589d0f3d93441726e23\" />",
 "  <project name=\"mousetrap\" path=\"godeps/src/github.com/inconshreveable/mousetrap\" remote=\"couchbasedeps\" revision=\"76626ae9c91c4f2a10f34cad8ce83ea42c93bb75\" />",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"cd8da46b9b953800d430c8b0aa4667790727ed6f\" />",
 "  <project name=\"msgp\" path=\"godeps/src/github.com/tinylib/msgp\" remote=\"couchbasedeps\" revision=\"5bb5e1aed7ba5bcc93307153b020e7ffe79b0509\" />",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"043ee6597c29786140136a5747b6a886364f5282\" />",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"62685c2d7ca23c807425dca88b11a3e2323dab41\" />",
 "  <project name=\"nitro\" path=\"goproj/src/github.com/couchbase/nitro\" revision=\"f3bef3551997be504612a2d05a8b324b3bfdfe1b\" />",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\" />",
 "  <project name=\"ns_server\" revision=\"8117c5307974f397ad831a2b870fb3ee0fd8364d\" />",
 "  <project name=\"opentracing-go\" path=\"godeps/src/github.com/opentracing/opentracing-go\" remote=\"couchbasedeps\" revision=\"1949ddbfd147afd4d964a9f00b24eb291e0e7c38\" />",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\" />",
 "  <project name=\"pflag\" path=\"godeps/src/github.com/spf13/pflag\" remote=\"couchbasedeps\" revision=\"a232f6d9f87afaaa08bafaff5da685f974b83313\" />",
 "  <project groups=\"kv\" name=\"phosphor\" revision=\"96501c57bb0fd61c85cba6f63101aed2bcf41d38\" />",
 "  <project name=\"pierrec-lz4\" path=\"godeps/src/github.com/pierrec/lz4\" remote=\"couchbasedeps\" revision=\"ed8d4cc3b461464e69798080a0092bd028910298\" />",
 "  <project name=\"pierrec-xxHash\" path=\"godeps/src/github.com/pierrec/xxHash\" remote=\"couchbasedeps\" revision=\"a0006b13c722f7f12368c00a3d3c2ae8a999a0c6\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"plasma\" path=\"goproj/src/github.com/couchbase/plasma\" remote=\"couchbase-priv\" revision=\"c0792c8cfb1463ef029f064f34e366442f1f0064\" />",
 "  <project groups=\"kv\" name=\"platform\" revision=\"de77d527bd23012dc67794c81a7b1e76e46e3abd\" />",
 "  <project groups=\"kv\" name=\"product-texts\" revision=\"8cf7d25a1dcb5434ea44983c0bed202fb9cc8351\" />",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\" />",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"d2011f6ee9f6e1dca5d3922d44fbcf86dad78150\" />",
 "  <project name=\"query-ui\" revision=\"15a6461f437fe810e411a6613ec7c143991cd1c6\" />",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\" />",
 "  <project name=\"roaring\" path=\"godeps/src/github.com/RoaringBitmap/roaring\" remote=\"couchbasedeps\" revision=\"fe09428be4c233d726797a1380f7438f4f71a31a\" />",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"762005e7a34fd909a84586299f1dd457371d36ee\" />",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"73353fe6dad8f3d67409feefb9b17f90f6de917b\" />",
 "  <project name=\"snowballstem\" path=\"godeps/src/github.com/blevesearch/snowballstem\" remote=\"blevesearch\" revision=\"26b06a2c243d4f8ca5db3486f94409dd5b2a7467\" />",
 "  <project groups=\"kv\" name=\"spdlog\" path=\"third_party/spdlog\" remote=\"couchbasedeps\" revision=\"4fba14c79f356ae48d6141c561bf9fd7ba33fabd\" />",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\" />",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"c30c3d4c250e68e81c57aa1e8ae91ffd21243cdb\" />",
 "  <project name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\" />",
 "  <project name=\"testrunner\" revision=\"4133fd785987f1ddcdb49dab736ff6e5e67d7c95\" upstream=\"alice\" />",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\" />",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"6dadf98e19803cc10ce9552bf4d9121cc2528965\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\" />",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\" />",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\" />",
 "    <copyfile dest=\".clang-format\" src=\"dot-clang-format\" />",
 "    <copyfile dest=\"third_party/CMakeLists.txt\" src=\"third-party-CMakeLists.txt\" />",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\" />",
 "  <project name=\"uuid\" path=\"godeps/src/github.com/google/uuid\" remote=\"couchbasedeps\" revision=\"dec09d789f3dba190787f8b4454c7d3c936fed9e\" />",
 "  <project name=\"vellum\" path=\"godeps/src/github.com/couchbase/vellum\" revision=\"0ceea4a37442f76199b9259840baf48d17af3c1a\" />",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"b3d83fe61db37bb38a46cd8dee434e5682cba2c7\" />",
 "  <project name=\"zstd\" path=\"godeps/src/github.com/DataDog/zstd\" remote=\"couchbasedeps\" revision=\"aebefd9fcb99f22cd691ef778a12ed68f0e6a1ab\" />",
 "</manifest>"]

[error_logger:info,2020-05-07T02:45:28.768Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.139.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:28.772Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2020-05-07T02:45:28.773Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2020-05-07T02:45:28.774Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:init:243]ip config not found. Looks like we're brand new node
[error_logger:info,2020-05-07T02:45:28.774Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.143.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2020-05-07T02:45:28.774Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.142.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:28.912Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:bringup:295]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2020-05-07T02:45:28.920Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.145.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:28.920Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.146.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:28.920Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:configure_net_kernel:339]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2020-05-07T02:45:28.920Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.147.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:28.921Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.144.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2020-05-07T02:45:28.933Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:save_node:227]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2020-05-07T02:45:28.943Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:bringup:309]Attempted to save node name to disk: ok
[ns_server:debug,2020-05-07T02:45:28.943Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:316]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2020-05-07T02:45:28.943Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T02:45:28.951Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:328]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2020-05-07T02:45:28.951Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:28.956Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:28.956Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:28.958Z,ns_1@127.0.0.1:ns_config_sup<0.154.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2020-05-07T02:45:28.958Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.155.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:28.958Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.156.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:29.008Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1095]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2020-05-07T02:45:29.009Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1109]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:debug,2020-05-07T02:45:29.025Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1117]Here's full dynamic config we loaded:
[[{auto_failover_cfg,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {enabled,true},
    {timeout,120},
    {count,0},
    {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
    {failover_server_group,false},
    {max_count,1},
    {failed_over_server_groups,[]}]},
  {alert_limits,
   [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
  {audit,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {enabled,[]},
    {disabled_users,[]},
    {auditd_enabled,false},
    {rotate_interval,86400},
    {rotate_size,20971520},
    {disabled,[]},
    {sync,[]},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
  {audit_decriptors,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {20480,
     [{name,<<"opened DCP connection">>},
      {description,<<"opened DCP connection">>},
      {enabled,true},
      {module,memcached}]},
    {20482,
     [{name,<<"external memcached bucket flush">>},
      {description,
       <<"External user flushed the content of a memcached bucket">>},
      {enabled,true},
      {module,memcached}]},
    {20483,
     [{name,<<"invalid packet">>},
      {description,<<"Rejected an invalid packet">>},
      {enabled,true},
      {module,memcached}]},
    {20485,
     [{name,<<"authentication succeeded">>},
      {description,<<"Authentication to the cluster succeeded">>},
      {enabled,false},
      {module,memcached}]},
    {20488,
     [{name,<<"document read">>},
      {description,<<"Document was read">>},
      {enabled,false},
      {module,memcached}]},
    {20489,
     [{name,<<"document locked">>},
      {description,<<"Document was locked">>},
      {enabled,false},
      {module,memcached}]},
    {20490,
     [{name,<<"document modify">>},
      {description,<<"Document was modified">>},
      {enabled,false},
      {module,memcached}]},
    {20491,
     [{name,<<"document delete">>},
      {description,<<"Document was deleted">>},
      {enabled,false},
      {module,memcached}]},
    {20492,
     [{name,<<"select bucket">>},
      {description,<<"The specified bucket was selected">>},
      {enabled,true},
      {module,memcached}]},
    {28672,
     [{name,<<"SELECT statement">>},
      {description,<<"A N1QL SELECT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28673,
     [{name,<<"EXPLAIN statement">>},
      {description,<<"A N1QL EXPLAIN statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28674,
     [{name,<<"PREPARE statement">>},
      {description,<<"A N1QL PREPARE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28675,
     [{name,<<"INFER statement">>},
      {description,<<"A N1QL INFER statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28676,
     [{name,<<"INSERT statement">>},
      {description,<<"A N1QL INSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28677,
     [{name,<<"UPSERT statement">>},
      {description,<<"A N1QL UPSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28678,
     [{name,<<"DELETE statement">>},
      {description,<<"A N1QL DELETE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28679,
     [{name,<<"UPDATE statement">>},
      {description,<<"A N1QL UPDATE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28680,
     [{name,<<"MERGE statement">>},
      {description,<<"A N1QL MERGE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28681,
     [{name,<<"CREATE INDEX statement">>},
      {description,<<"A N1QL CREATE INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28682,
     [{name,<<"DROP INDEX statement">>},
      {description,<<"A N1QL DROP INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28683,
     [{name,<<"ALTER INDEX statement">>},
      {description,<<"A N1QL ALTER INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28684,
     [{name,<<"BUILD INDEX statement">>},
      {description,<<"A N1QL BUILD INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28685,
     [{name,<<"GRANT ROLE statement">>},
      {description,<<"A N1QL GRANT ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28686,
     [{name,<<"REVOKE ROLE statement">>},
      {description,<<"A N1QL REVOKE ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28687,
     [{name,<<"UNRECOGNIZED statement">>},
      {description,
       <<"An unrecognized statement was received by the N1QL query engine">>},
      {enabled,false},
      {module,n1ql}]},
    {28688,
     [{name,<<"CREATE PRIMARY INDEX statement">>},
      {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28689,
     [{name,<<"/admin/stats API request">>},
      {description,<<"An HTTP request was made to the API at /admin/stats.">>},
      {enabled,false},
      {module,n1ql}]},
    {28690,
     [{name,<<"/admin/vitals API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/vitals.">>},
      {enabled,false},
      {module,n1ql}]},
    {28691,
     [{name,<<"/admin/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28692,
     [{name,<<"/admin/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28693,
     [{name,<<"/admin/indexes/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28694,
     [{name,<<"/admin/indexes/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28695,
     [{name,<<"/admin/indexes/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28697,
     [{name,<<"/admin/ping API request">>},
      {description,<<"An HTTP request was made to the API at /admin/ping.">>},
      {enabled,false},
      {module,n1ql}]},
    {28698,
     [{name,<<"/admin/config API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/config.">>},
      {enabled,false},
      {module,n1ql}]},
    {28699,
     [{name,<<"/admin/ssl_cert API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
      {enabled,false},
      {module,n1ql}]},
    {28700,
     [{name,<<"/admin/settings API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/settings.">>},
      {enabled,false},
      {module,n1ql}]},
    {28701,
     [{name,<<"/admin/clusters API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/clusters.">>},
      {enabled,false},
      {module,n1ql}]},
    {28702,
     [{name,<<"/admin/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {32768,
     [{name,<<"Create Function">>},
      {description,<<"Eventing function definition was created or updated">>},
      {enabled,true},
      {module,eventing}]},
    {32769,
     [{name,<<"Delete Function">>},
      {description,<<"Eventing function definition was deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32770,
     [{name,<<"Fetch Functions">>},
      {description,<<"Eventing function definition was read">>},
      {enabled,false},
      {module,eventing}]},
    {32771,
     [{name,<<"List Deployed">>},
      {description,<<"Eventing deployed functions list was read">>},
      {enabled,false},
      {module,eventing}]},
    {32772,
     [{name,<<"Fetch Drafts">>},
      {description,<<"Eventing function draft definitions were read">>},
      {enabled,false},
      {module,eventing}]},
    {32773,
     [{name,<<"Delete Drafts">>},
      {description,<<"Eventing function draft definitions were deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32774,
     [{name,<<"Save Draft">>},
      {description,<<"Save a draft definition to the store">>},
      {enabled,true},
      {module,eventing}]},
    {32775,
     [{name,<<"Start Debug">>},
      {description,<<"Start eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32776,
     [{name,<<"Stop Debug">>},
      {description,<<"Stop eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32777,
     [{name,<<"Start Tracing">>},
      {description,<<"Start tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32778,
     [{name,<<"Stop Tracing">>},
      {description,<<"Stop tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32779,
     [{name,<<"Set Settings">>},
      {description,<<"Save settings for a given app">>},
      {enabled,true},
      {module,eventing}]},
    {32780,
     [{name,<<"Fetch Config">>},
      {description,<<"Get config for eventing">>},
      {enabled,false},
      {module,eventing}]},
    {32781,
     [{name,<<"Save Config">>},
      {description,<<"Save config for eventing">>},
      {enabled,true},
      {module,eventing}]},
    {32782,
     [{name,<<"Cleanup Eventing">>},
      {description,<<"Clears up app definitions and settings from metakv">>},
      {enabled,true},
      {module,eventing}]},
    {32783,
     [{name,<<"Get Settings">>},
      {description,<<"Get settings for a given app">>},
      {enabled,false},
      {module,eventing}]},
    {32784,
     [{name,<<"Import Functions">>},
      {description,<<"Import a list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32785,
     [{name,<<"Export Functions">>},
      {description,<<"Export the list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32786,
     [{name,<<"List Running">>},
      {description,<<"Eventing running function list was read">>},
      {enabled,false},
      {module,eventing}]},
    {36865,
     [{name,<<"Service configuration change">>},
      {description,<<"A successful service configuration change was made.">>},
      {enabled,true},
      {module,analytics}]},
    {36866,
     [{name,<<"Node configuration change">>},
      {description,<<"A successful node configuration change was made.">>},
      {enabled,true},
      {module,analytics}]}]},
  {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
  {autocompaction,
   [{database_fragmentation_threshold,{30,undefined}},
    {view_fragmentation_threshold,{30,undefined}}]},
  {buckets,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]},
    {configs,[]}]},
  {cbas_memory_quota,1024},
  {cert_and_pkey,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQlsomKQ7qhDcAeKZ3inWuCQuv8NxCAMb8M\nXhrVTrshZyFDiXdKS3Xbshyc9dEOiDwuDwAEgfwJQsXzzx0eCRtyTZfWAWTOH06O\nXdQps+9iTfr2KBFj27uag5c5ns+0ojsNyqZhA4+dbS7zK3CZ1dx7LPkL3+4HTlMh\nmH1/2fib3Lbp6dW3B55GV8/RHbkzgcRMyBicYtinqh6JMmmzjO/3KEyVHs3h0W1E\n00JdAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCKWU+bCvjKUlhW\niMiAN7r/3Vxkah7KEqp8BajCnLrlTMeiV+24TlPrsCWz4VBmOgt8OcijS3axdEik\nXeteeJp+R8nb2XPGivHOg/Hx2NlLxCrtXaYVGM0PiVydo24iCv0ZlqMCBsrzRLky\n5otbfQi8ngdfuR88C0/r3RLqvuFnOtFkLbKXuT/qshXfM8O/OgiJkr6CTBFYNd8w\nTCxN2syK41/HXoYzexdA/OTSm+kuEIuDpQYxKS0M4oKKZApJM70y/CYTzwG3JOnp\nuteZPYrwhIqxz01fkbLnj3QLGxPpSexRsp52GOoCv/YEE7tl3Olt4+p+MvhEZPdZ\ndqB53mNJ\n-----END CERTIFICATE-----\n">>,
     <<"*****">>}]},
  {client_cert_auth,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {state,"disable"},
    {prefixes,[]}]},
  {cluster_compat_version,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},
    6,0]},
  {drop_request_memory_threshold_mib,undefined},
  {email_alerts,
   [{recipients,["root@localhost"]},
    {sender,"couchbase@localhost"},
    {enabled,false},
    {email_server,
     [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
    {alerts,
     [auto_failover_node,auto_failover_maximum_reached,
      auto_failover_other_nodes_down,auto_failover_cluster_too_small,
      auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
      ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
      ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
  {fts_memory_quota,256},
  {index_aware_rebalance_disabled,false},
  {log_redaction_default_cfg,[{redact_level,none}]},
  {max_bucket_count,10},
  {memcached,[]},
  {memory_quota,311},
  {nodes_wanted,['ns_1@127.0.0.1']},
  {otp,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
    {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]},
  {password_policy,[{min_length,6},{must_present,[]}]},
  {quorum_nodes,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    'ns_1@127.0.0.1']},
  {read_only_user_creds,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {remote_clusters,[]},
  {replication,[{enabled,true}]},
  {rest,[{port,8091}]},
  {rest_creds,null},
  {roles_definitions,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {scramsha_fallback_salt,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<169,238,80,91,5,165,74,47,79,135,45,74>>]},
  {secure_headers,[]},
  {server_groups,
   [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
  {set_view_update_daemon,
   [{update_interval,5000},
    {update_min_changes,5000},
    {replica_update_min_changes,5000}]},
  {users_upgrade,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {{couchdb,max_parallel_indexers},4},
  {{couchdb,max_parallel_replica_indexers},2},
  {{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{5,63756037313}}]}]},
  {{metakv,<<"/eventing/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"ram_quota\":256}">>]},
  {{metakv,<<"/indexing/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
  {{metakv,<<"/query/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
  {{rbac_upgrade,[5,5]},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {{request_limit,capi},undefined},
  {{request_limit,rest},undefined},
  {{service_map,fts},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{service_map,index},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{service_map,n1ql},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{node,'ns_1@127.0.0.1',audit},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
  {{node,'ns_1@127.0.0.1',capi_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8092]},
  {{node,'ns_1@127.0.0.1',cbas_admin_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9110]},
  {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9113]},
  {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9112]},
  {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9111]},
  {{node,'ns_1@127.0.0.1',cbas_cluster_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9115]},
  {{node,'ns_1@127.0.0.1',cbas_console_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9114]},
  {{node,'ns_1@127.0.0.1',cbas_data_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9116]},
  {{node,'ns_1@127.0.0.1',cbas_debug_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    -1]},
  {{node,'ns_1@127.0.0.1',cbas_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8095]},
  {{node,'ns_1@127.0.0.1',cbas_messaging_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9118]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9119]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9121]},
  {{node,'ns_1@127.0.0.1',cbas_parent_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9122]},
  {{node,'ns_1@127.0.0.1',cbas_replication_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9120]},
  {{node,'ns_1@127.0.0.1',cbas_result_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9117]},
  {{node,'ns_1@127.0.0.1',cbas_ssl_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18095]},
  {{node,'ns_1@127.0.0.1',compaction_daemon},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {check_interval,30},
    {min_db_file_size,131072},
    {min_view_file_size,20971520}]},
  {{node,'ns_1@127.0.0.1',config_version},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {5,5,3}]},
  {{node,'ns_1@127.0.0.1',eventing_debug_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9140]},
  {{node,'ns_1@127.0.0.1',eventing_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8096]},
  {{node,'ns_1@127.0.0.1',eventing_https_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18096]},
  {{node,'ns_1@127.0.0.1',fts_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8094]},
  {{node,'ns_1@127.0.0.1',fts_ssl_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18094]},
  {{node,'ns_1@127.0.0.1',indexer_admin_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9100]},
  {{node,'ns_1@127.0.0.1',indexer_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9102]},
  {{node,'ns_1@127.0.0.1',indexer_https_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    19102]},
  {{node,'ns_1@127.0.0.1',indexer_scan_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9101]},
  {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9104]},
  {{node,'ns_1@127.0.0.1',indexer_stinit_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9103]},
  {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9105]},
  {{node,'ns_1@127.0.0.1',is_enterprise},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',isasl},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
  {{node,'ns_1@127.0.0.1',ldap_enabled},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',membership},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    active]},
  {{node,'ns_1@127.0.0.1',memcached},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,11210},
    {dedicated_port,11209},
    {ssl_port,11207},
    {admin_user,"@ns_server"},
    {other_users,
     ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
      "@cbas"]},
    {admin_pass,"*****"},
    {engines,
     [{membase,
       [{engine,"/opt/couchbase/lib/memcached/ep.so"},
        {static_config_string,"failpartialwarmup=false"}]},
      {memcached,
       [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
        {static_config_string,"vb0=true"}]}]},
    {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
    {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
    {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
    {log_prefix,"memcached.log"},
    {log_generations,20},
    {log_cyclesize,10485760},
    {log_sleeptime,19},
    {log_rotation_period,39003}]},
  {{node,'ns_1@127.0.0.1',memcached_config},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {[{interfaces,
       {memcached_config_mgr,omit_missing_mcd_ports,
        [{[{host,<<"*">>},
           {port,port},
           {maxconn,maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,dedicated_port},
           {maxconn,dedicated_port_maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,ssl_port},
           {maxconn,maxconn},
           {ssl,
            {[{key,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
              {cert,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]}]}},
      {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
      {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
      {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
      {connection_idle_time,connection_idle_time},
      {privilege_debug,privilege_debug},
      {breakpad,
       {[{enabled,breakpad_enabled},
         {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
      {admin,{"~s",[admin_user]}},
      {verbosity,verbosity},
      {audit_file,{"~s",[audit_file]}},
      {rbac_file,{"~s",[rbac_file]}},
      {dedupe_nmvb_maps,dedupe_nmvb_maps},
      {tracing_enabled,tracing_enabled},
      {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
      {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
      {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
      {logger,
       {[{filename,{"~s/~s",[log_path,log_prefix]}},
         {cyclesize,log_cyclesize},
         {sleeptime,log_sleeptime}]}}]}]},
  {{node,'ns_1@127.0.0.1',memcached_defaults},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {maxconn,30000},
    {dedicated_port_maxconn,5000},
    {ssl_cipher_list,"HIGH"},
    {connection_idle_time,0},
    {verbosity,0},
    {privilege_debug,false},
    {breakpad_enabled,true},
    {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
    {dedupe_nmvb_maps,false},
    {tracing_enabled,true},
    {datatype_snappy,true}]},
  {{node,'ns_1@127.0.0.1',moxi},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,11211},
    {verbosity,[]}]},
  {{node,'ns_1@127.0.0.1',ns_log},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
  {{node,'ns_1@127.0.0.1',port_servers},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
  {{node,'ns_1@127.0.0.1',projector_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9999]},
  {{node,'ns_1@127.0.0.1',query_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8093]},
  {{node,'ns_1@127.0.0.1',rest},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,8091},
    {port_meta,global}]},
  {{node,'ns_1@127.0.0.1',ssl_capi_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18092]},
  {{node,'ns_1@127.0.0.1',ssl_query_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18093]},
  {{node,'ns_1@127.0.0.1',ssl_rest_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18091]},
  {{node,'ns_1@127.0.0.1',uuid},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    <<"0f8760945f98b1efdbef0bd1ea6e8446">>]},
  {{node,'ns_1@127.0.0.1',xdcr_rest_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9998]},
  {{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    false]}]]
[ns_server:info,2020-05-07T02:45:29.030Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1138]Here's full dynamic config we loaded + static & default config:
[{{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   false]},
 {{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   <<"0f8760945f98b1efdbef0bd1ea6e8446">>]},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,8091},
   {port_meta,global}]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11211},
   {verbosity,[]}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {privilege_debug,false},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false},
   {tracing_enabled,true},
   {datatype_snappy,true}]},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},
          {port,port},
          {maxconn,maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {privilege_debug,privilege_debug},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {rbac_file,{"~s",[rbac_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps},
     {tracing_enabled,tracing_enabled},
     {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
     {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
     {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
     {logger,
      {[{filename,{"~s/~s",[log_path,log_prefix]}},
        {cyclesize,log_cyclesize},
        {sleeptime,log_sleeptime}]}}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"@ns_server"},
   {other_users,
    ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
     "@cbas"]},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   active]},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   19102]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',fts_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18094]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',eventing_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18096]},
 {{node,'ns_1@127.0.0.1',eventing_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8096]},
 {{node,'ns_1@127.0.0.1',eventing_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9140]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {5,5,3}]},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {{node,'ns_1@127.0.0.1',cbas_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18095]},
 {{node,'ns_1@127.0.0.1',cbas_result_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9117]},
 {{node,'ns_1@127.0.0.1',cbas_replication_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9120]},
 {{node,'ns_1@127.0.0.1',cbas_parent_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9122]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9121]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9119]},
 {{node,'ns_1@127.0.0.1',cbas_messaging_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9118]},
 {{node,'ns_1@127.0.0.1',cbas_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8095]},
 {{node,'ns_1@127.0.0.1',cbas_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]},
 {{node,'ns_1@127.0.0.1',cbas_data_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9116]},
 {{node,'ns_1@127.0.0.1',cbas_console_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9114]},
 {{node,'ns_1@127.0.0.1',cbas_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9115]},
 {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9111]},
 {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9112]},
 {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9113]},
 {{node,'ns_1@127.0.0.1',cbas_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9110]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{service_map,n1ql},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{service_map,index},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{service_map,fts},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{request_limit,rest},undefined},
 {{request_limit,capi},undefined},
 {{rbac_upgrade,[5,5]},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {{metakv,<<"/query/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
 {{metakv,<<"/indexing/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
 {{metakv,<<"/eventing/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"ram_quota\":256}">>]},
 {{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{5,63756037313}}]}]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {users_upgrade,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {secure_headers,[]},
 {scramsha_fallback_salt,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<169,238,80,91,5,165,74,47,79,135,45,74>>]},
 {roles_definitions,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {rest_creds,null},
 {rest,[{port,8091}]},
 {replication,[{enabled,true}]},
 {remote_clusters,[]},
 {read_only_user_creds,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {quorum_nodes,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   'ns_1@127.0.0.1']},
 {password_policy,[{min_length,6},{must_present,[]}]},
 {otp,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
   {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {memory_quota,311},
 {memcached,[]},
 {max_bucket_count,10},
 {log_redaction_default_cfg,[{redact_level,none}]},
 {index_aware_rebalance_disabled,false},
 {fts_memory_quota,256},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
 {drop_request_memory_threshold_mib,undefined},
 {cluster_compat_version,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},
   6,0]},
 {client_cert_auth,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {state,"disable"},
   {prefixes,[]}]},
 {cert_and_pkey,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQlsomKQ7qhDcAeKZ3inWuCQuv8NxCAMb8M\nXhrVTrshZyFDiXdKS3Xbshyc9dEOiDwuDwAEgfwJQsXzzx0eCRtyTZfWAWTOH06O\nXdQps+9iTfr2KBFj27uag5c5ns+0ojsNyqZhA4+dbS7zK3CZ1dx7LPkL3+4HTlMh\nmH1/2fib3Lbp6dW3B55GV8/RHbkzgcRMyBicYtinqh6JMmmzjO/3KEyVHs3h0W1E\n00JdAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCKWU+bCvjKUlhW\niMiAN7r/3Vxkah7KEqp8BajCnLrlTMeiV+24TlPrsCWz4VBmOgt8OcijS3axdEik\nXeteeJp+R8nb2XPGivHOg/Hx2NlLxCrtXaYVGM0PiVydo24iCv0ZlqMCBsrzRLky\n5otbfQi8ngdfuR88C0/r3RLqvuFnOtFkLbKXuT/qshXfM8O/OgiJkr6CTBFYNd8w\nTCxN2syK41/HXoYzexdA/OTSm+kuEIuDpQYxKS0M4oKKZApJM70y/CYTzwG3JOnp\nuteZPYrwhIqxz01fkbLnj3QLGxPpSexRsp52GOoCv/YEE7tl3Olt4+p+MvhEZPdZ\ndqB53mNJ\n-----END CERTIFICATE-----\n">>,
    <<"*****">>}]},
 {cbas_memory_quota,1024},
 {buckets,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]},
   {configs,[]}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
 {audit_decriptors,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {20480,
    [{name,<<"opened DCP connection">>},
     {description,<<"opened DCP connection">>},
     {enabled,true},
     {module,memcached}]},
   {20482,
    [{name,<<"external memcached bucket flush">>},
     {description,
      <<"External user flushed the content of a memcached bucket">>},
     {enabled,true},
     {module,memcached}]},
   {20483,
    [{name,<<"invalid packet">>},
     {description,<<"Rejected an invalid packet">>},
     {enabled,true},
     {module,memcached}]},
   {20485,
    [{name,<<"authentication succeeded">>},
     {description,<<"Authentication to the cluster succeeded">>},
     {enabled,false},
     {module,memcached}]},
   {20488,
    [{name,<<"document read">>},
     {description,<<"Document was read">>},
     {enabled,false},
     {module,memcached}]},
   {20489,
    [{name,<<"document locked">>},
     {description,<<"Document was locked">>},
     {enabled,false},
     {module,memcached}]},
   {20490,
    [{name,<<"document modify">>},
     {description,<<"Document was modified">>},
     {enabled,false},
     {module,memcached}]},
   {20491,
    [{name,<<"document delete">>},
     {description,<<"Document was deleted">>},
     {enabled,false},
     {module,memcached}]},
   {20492,
    [{name,<<"select bucket">>},
     {description,<<"The specified bucket was selected">>},
     {enabled,true},
     {module,memcached}]},
   {28672,
    [{name,<<"SELECT statement">>},
     {description,<<"A N1QL SELECT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28673,
    [{name,<<"EXPLAIN statement">>},
     {description,<<"A N1QL EXPLAIN statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28674,
    [{name,<<"PREPARE statement">>},
     {description,<<"A N1QL PREPARE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28675,
    [{name,<<"INFER statement">>},
     {description,<<"A N1QL INFER statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28676,
    [{name,<<"INSERT statement">>},
     {description,<<"A N1QL INSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28677,
    [{name,<<"UPSERT statement">>},
     {description,<<"A N1QL UPSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28678,
    [{name,<<"DELETE statement">>},
     {description,<<"A N1QL DELETE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28679,
    [{name,<<"UPDATE statement">>},
     {description,<<"A N1QL UPDATE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28680,
    [{name,<<"MERGE statement">>},
     {description,<<"A N1QL MERGE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28681,
    [{name,<<"CREATE INDEX statement">>},
     {description,<<"A N1QL CREATE INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28682,
    [{name,<<"DROP INDEX statement">>},
     {description,<<"A N1QL DROP INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28683,
    [{name,<<"ALTER INDEX statement">>},
     {description,<<"A N1QL ALTER INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28684,
    [{name,<<"BUILD INDEX statement">>},
     {description,<<"A N1QL BUILD INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28685,
    [{name,<<"GRANT ROLE statement">>},
     {description,<<"A N1QL GRANT ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28686,
    [{name,<<"REVOKE ROLE statement">>},
     {description,<<"A N1QL REVOKE ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28687,
    [{name,<<"UNRECOGNIZED statement">>},
     {description,
      <<"An unrecognized statement was received by the N1QL query engine">>},
     {enabled,false},
     {module,n1ql}]},
   {28688,
    [{name,<<"CREATE PRIMARY INDEX statement">>},
     {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28689,
    [{name,<<"/admin/stats API request">>},
     {description,<<"An HTTP request was made to the API at /admin/stats.">>},
     {enabled,false},
     {module,n1ql}]},
   {28690,
    [{name,<<"/admin/vitals API request">>},
     {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
     {enabled,false},
     {module,n1ql}]},
   {28691,
    [{name,<<"/admin/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28692,
    [{name,<<"/admin/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28693,
    [{name,<<"/admin/indexes/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28694,
    [{name,<<"/admin/indexes/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28695,
    [{name,<<"/admin/indexes/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28697,
    [{name,<<"/admin/ping API request">>},
     {description,<<"An HTTP request was made to the API at /admin/ping.">>},
     {enabled,false},
     {module,n1ql}]},
   {28698,
    [{name,<<"/admin/config API request">>},
     {description,<<"An HTTP request was made to the API at /admin/config.">>},
     {enabled,false},
     {module,n1ql}]},
   {28699,
    [{name,<<"/admin/ssl_cert API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
     {enabled,false},
     {module,n1ql}]},
   {28700,
    [{name,<<"/admin/settings API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/settings.">>},
     {enabled,false},
     {module,n1ql}]},
   {28701,
    [{name,<<"/admin/clusters API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/clusters.">>},
     {enabled,false},
     {module,n1ql}]},
   {28702,
    [{name,<<"/admin/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {32768,
    [{name,<<"Create Function">>},
     {description,<<"Eventing function definition was created or updated">>},
     {enabled,true},
     {module,eventing}]},
   {32769,
    [{name,<<"Delete Function">>},
     {description,<<"Eventing function definition was deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32770,
    [{name,<<"Fetch Functions">>},
     {description,<<"Eventing function definition was read">>},
     {enabled,false},
     {module,eventing}]},
   {32771,
    [{name,<<"List Deployed">>},
     {description,<<"Eventing deployed functions list was read">>},
     {enabled,false},
     {module,eventing}]},
   {32772,
    [{name,<<"Fetch Drafts">>},
     {description,<<"Eventing function draft definitions were read">>},
     {enabled,false},
     {module,eventing}]},
   {32773,
    [{name,<<"Delete Drafts">>},
     {description,<<"Eventing function draft definitions were deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32774,
    [{name,<<"Save Draft">>},
     {description,<<"Save a draft definition to the store">>},
     {enabled,true},
     {module,eventing}]},
   {32775,
    [{name,<<"Start Debug">>},
     {description,<<"Start eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32776,
    [{name,<<"Stop Debug">>},
     {description,<<"Stop eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32777,
    [{name,<<"Start Tracing">>},
     {description,<<"Start tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32778,
    [{name,<<"Stop Tracing">>},
     {description,<<"Stop tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32779,
    [{name,<<"Set Settings">>},
     {description,<<"Save settings for a given app">>},
     {enabled,true},
     {module,eventing}]},
   {32780,
    [{name,<<"Fetch Config">>},
     {description,<<"Get config for eventing">>},
     {enabled,false},
     {module,eventing}]},
   {32781,
    [{name,<<"Save Config">>},
     {description,<<"Save config for eventing">>},
     {enabled,true},
     {module,eventing}]},
   {32782,
    [{name,<<"Cleanup Eventing">>},
     {description,<<"Clears up app definitions and settings from metakv">>},
     {enabled,true},
     {module,eventing}]},
   {32783,
    [{name,<<"Get Settings">>},
     {description,<<"Get settings for a given app">>},
     {enabled,false},
     {module,eventing}]},
   {32784,
    [{name,<<"Import Functions">>},
     {description,<<"Import a list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32785,
    [{name,<<"Export Functions">>},
     {description,<<"Export the list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32786,
    [{name,<<"List Running">>},
     {description,<<"Eventing running function list was read">>},
     {enabled,false},
     {module,eventing}]},
   {36865,
    [{name,<<"Service configuration change">>},
     {description,<<"A successful service configuration change was made.">>},
     {enabled,true},
     {module,analytics}]},
   {36866,
    [{name,<<"Node configuration change">>},
     {description,<<"A successful node configuration change was made.">>},
     {enabled,true},
     {module,analytics}]}]},
 {audit,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {enabled,[]},
   {disabled_users,[]},
   {auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {auto_failover_cfg,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {enabled,true},
   {timeout,120},
   {count,0},
   {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
   {failover_server_group,false},
   {max_count,1},
   {failed_over_server_groups,[]}]}]
[error_logger:info,2020-05-07T02:45:29.042Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.157.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:29.044Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.163.0>},
                       {name,ns_config_remote},
                       {mfargs,{ns_config_replica,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:29.046Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.164.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:29.046Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:29.048Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.166.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:29.050Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.167.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:29.060Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.170.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:29.062Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2020-05-07T02:45:29.062Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.171.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:29.063Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.172.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:29.067Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.173.0>},
                       {name,memcached_refresh},
                       {mfargs,{memcached_refresh,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:29.068Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.175.0>},
                       {name,ssl_service_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ssl_service_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:29.082Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:init:419]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem-ca"},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[error_logger:info,2020-05-07T02:45:29.120Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.176.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:29.134Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T02:45:29.134Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T02:45:29.135Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T02:45:29.135Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[ns_server:debug,2020-05-07T02:45:29.156Z,ns_1@127.0.0.1:<0.178.0>:restartable:start_child:98]Started child process <0.179.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2020-05-07T02:45:29.156Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.178.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:29.157Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.174.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:29.158Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.197.0>},
                       {name,user_storage_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,user_storage_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:29.164Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.199.0>},
                       {name,users_replicator},
                       {mfargs,{menelaus_users,start_replicator,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:29.165Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:55]Start waiting for startup
[ns_server:debug,2020-05-07T02:45:29.167Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_storage:anounce_startup:69]Announce my startup to <0.199.0>
[ns_server:debug,2020-05-07T02:45:29.168Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:58]Received replicated storage registration from <0.200.0>
[ns_server:debug,2020-05-07T02:45:29.170Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:open:212]Opening file "/opt/couchbase/var/lib/couchbase/config/users.dets"
[error_logger:info,2020-05-07T02:45:29.170Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.200.0>},
                       {name,users_storage},
                       {mfargs,{menelaus_users,start_storage,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:29.171Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.198.0>},
                       {name,users_storage_sup},
                       {mfargs,{users_storage_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:45:29.184Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:init:44]Starting versioned cache compiled_roles_cache
[error_logger:info,2020-05-07T02:45:29.184Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.202.0>},
                       {name,compiled_roles_cache},
                       {mfargs,{menelaus_roles,start_compiled_roles_cache,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:29.184Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.196.0>},
                       {name,users_sup},
                       {mfargs,{users_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:29.186Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.205.0>},
                       {name,dets_sup},
                       {mfargs,{dets_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:29.186Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.206.0>},
                       {name,dets},
                       {mfargs,{dets_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:29.216Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:convert_docs_to_55_in_dets:243]Checking for pre 5.5 records in dets: users_storage
[ns_server:debug,2020-05-07T02:45:29.217Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,'$1','_','$2'},
                                      [],
                                      [{{'$1','$2'}}]}],
                                    100}
[ns_server:debug,2020-05-07T02:45:29.217Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:init_after_ack:204]Loading 0 items, 299 words took 0ms
[ns_server:debug,2020-05-07T02:45:29.228Z,ns_1@127.0.0.1:users_replicator<0.199.0>:doc_replicator:loop:60]doing replicate_newnodes_docs
[ns_server:debug,2020-05-07T02:45:29.230Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.210.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:141]Waiting for ns_couchdb node to start
[error_logger:info,2020-05-07T02:45:29.230Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.209.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:29.230Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:45:29.234Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.213.0>,shutdown}}
[error_logger:info,2020-05-07T02:45:29.234Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T02:45:29.234Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T02:45:29.435Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:45:29.436Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.216.0>,shutdown}}
[ns_server:debug,2020-05-07T02:45:29.436Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T02:45:29.436Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:45:29.637Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T02:45:29.637Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T02:45:29.637Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.219.0>,shutdown}}
[error_logger:info,2020-05-07T02:45:29.638Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:45:29.838Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T02:45:29.840Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.222.0>,shutdown}}
[error_logger:info,2020-05-07T02:45:29.840Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T02:45:29.840Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T02:45:30.041Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T02:45:30.065Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T02:45:30.266Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T02:45:30.467Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T02:45:30.668Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[error_logger:info,2020-05-07T02:45:31.140Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.231.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:31.341Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: Apache CouchDB v4.5.1-112-gc2b9820 (LogLevel=info) is starting.
ns_couchdb<0.209.0>: Apache CouchDB has started. Time to relax.

[error_logger:info,2020-05-07T02:45:31.463Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.210.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.96617950>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:31.473Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:ns_storage_conf:setup_db_and_ix_paths:47]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2020-05-07T02:45:31.479Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.234.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.481Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.235.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:31.482Z,ns_1@127.0.0.1:ns_server_sup<0.233.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2020-05-07T02:45:31.490Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.236.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.492Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.237.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.495Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.238.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.495Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.239.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:31.521Z,ns_1@127.0.0.1:memcached_passwords<0.240.0>:memcached_cfg:init:62]Init config writer for memcached_passwords, "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T02:45:31.521Z,ns_1@127.0.0.1:memcached_passwords<0.240.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T02:45:31.559Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.240.0>
[ns_server:debug,2020-05-07T02:45:31.559Z,ns_1@127.0.0.1:memcached_passwords<0.240.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T02:45:31.566Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.240.0>
[ns_server:debug,2020-05-07T02:45:31.575Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[error_logger:info,2020-05-07T02:45:31.575Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.240.0>},
                       {name,memcached_passwords},
                       {mfargs,{memcached_passwords,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:45:31.580Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:45:31.580Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [isasl] failed. Retry in 1000 ms.
[ns_server:debug,2020-05-07T02:45:31.587Z,ns_1@127.0.0.1:memcached_permissions<0.243.0>:memcached_cfg:init:62]Init config writer for memcached_permissions, "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T02:45:31.590Z,ns_1@127.0.0.1:memcached_permissions<0.243.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T02:45:31.607Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.243.0>
[ns_server:debug,2020-05-07T02:45:31.607Z,ns_1@127.0.0.1:memcached_permissions<0.243.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{user,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T02:45:31.607Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.243.0>
[ns_server:debug,2020-05-07T02:45:31.614Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of rbac requested
[error_logger:info,2020-05-07T02:45:31.614Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.243.0>},
                       {name,memcached_permissions},
                       {mfargs,{memcached_permissions,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.614Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.246.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:45:31.615Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:45:31.615Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2020-05-07T02:45:31.617Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.248.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:31.618Z,ns_1@127.0.0.1:ns_node_disco<0.249.0>:ns_node_disco:init:130]Initting ns_node_disco with []
[ns_server:debug,2020-05-07T02:45:31.618Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[user:info,2020-05-07T02:45:31.618Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:127]Node 'ns_1@127.0.0.1' synchronized otp cookie {sanitized,
                                               <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>} from cluster
[ns_server:debug,2020-05-07T02:45:31.618Z,ns_1@127.0.0.1:<0.250.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:45:31.619Z,ns_1@127.0.0.1:<0.250.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[error_logger:info,2020-05-07T02:45:31.619Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.249.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.621Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.625Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.252.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.627Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.253.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:31.627Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:init:69]init pulling
[ns_server:debug,2020-05-07T02:45:31.627Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:init:71]init pushing
[ns_server:debug,2020-05-07T02:45:31.636Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:init:75]init reannouncing
[ns_server:debug,2020-05-07T02:45:31.636Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2020-05-07T02:45:31.636Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2020-05-07T02:45:31.637Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T02:45:31.637Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T02:45:31.637Z,ns_1@127.0.0.1:<0.262.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:45:31.637Z,ns_1@127.0.0.1:<0.263.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:45:31.637Z,ns_1@127.0.0.1:<0.262.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:45:31.637Z,ns_1@127.0.0.1:<0.263.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T02:45:31.638Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:handle_info:89]Flushing cache compiled_roles_cache due to version change from undefined to {[6,
                                                                              0],
                                                                             {0,
                                                                              1830781587},
                                                                             false,
                                                                             []}
[ns_server:debug,2020-05-07T02:45:31.638Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2020-05-07T02:45:31.638Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,[]},
 {disabled_users,[]},
 {auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2020-05-07T02:45:31.639Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit_decriptors ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {20480,
  [{name,<<"opened DCP connection">>},
   {description,<<"opened DCP connection">>},
   {enabled,true},
   {module,memcached}]},
 {20482,
  [{name,<<"external memcached bucket flush">>},
   {description,<<"External user flushed the content of a memcached bucket">>},
   {enabled,true},
   {module,memcached}]},
 {20483,
  [{name,<<"invalid packet">>},
   {description,<<"Rejected an invalid packet">>},
   {enabled,true},
   {module,memcached}]},
 {20485,
  [{name,<<"authentication succeeded">>},
   {description,<<"Authentication to the cluster succeeded">>},
   {enabled,false},
   {module,memcached}]},
 {20488,
  [{name,<<"document read">>},
   {description,<<"Document was read">>},
   {enabled,false},
   {module,memcached}]},
 {20489,
  [{name,<<"document locked">>},
   {description,<<"Document was locked">>},
   {enabled,false},
   {module,memcached}]},
 {20490,
  [{name,<<"document modify">>},
   {description,<<"Document was modified">>},
   {enabled,false},
   {module,memcached}]},
 {20491,
  [{name,<<"document delete">>},
   {description,<<"Document was deleted">>},
   {enabled,false},
   {module,memcached}]},
 {20492,
  [{name,<<"select bucket">>},
   {description,<<"The specified bucket was selected">>},
   {enabled,true},
   {module,memcached}]},
 {28672,
  [{name,<<"SELECT statement">>},
   {description,<<"A N1QL SELECT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28673,
  [{name,<<"EXPLAIN statement">>},
   {description,<<"A N1QL EXPLAIN statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28674,
  [{name,<<"PREPARE statement">>},
   {description,<<"A N1QL PREPARE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28675,
  [{name,<<"INFER statement">>},
   {description,<<"A N1QL INFER statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28676,
  [{name,<<"INSERT statement">>},
   {description,<<"A N1QL INSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28677,
  [{name,<<"UPSERT statement">>},
   {description,<<"A N1QL UPSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28678,
  [{name,<<"DELETE statement">>},
   {description,<<"A N1QL DELETE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28679,
  [{name,<<"UPDATE statement">>},
   {description,<<"A N1QL UPDATE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28680,
  [{name,<<"MERGE statement">>},
   {description,<<"A N1QL MERGE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28681,
  [{name,<<"CREATE INDEX statement">>},
   {description,<<"A N1QL CREATE INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28682,
  [{name,<<"DROP INDEX statement">>},
   {description,<<"A N1QL DROP INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28683,
  [{name,<<"ALTER INDEX statement">>},
   {description,<<"A N1QL ALTER INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28684,
  [{name,<<"BUILD INDEX statement">>},
   {description,<<"A N1QL BUILD INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28685,
  [{name,<<"GRANT ROLE statement">>},
   {description,<<"A N1QL GRANT ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28686,
  [{name,<<"REVOKE ROLE statement">>},
   {description,<<"A N1QL REVOKE ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28687,
  [{name,<<"UNRECOGNIZED statement">>},
   {description,<<"An unrecognized statement was received by the N1QL query engine">>},
   {enabled,false},
   {module,n1ql}]},
 {28688,
  [{name,<<"CREATE PRIMARY INDEX statement">>},
   {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28689,
  [{name,<<"/admin/stats API request">>},
   {description,<<"An HTTP request was made to the API at /admin/stats.">>},
   {enabled,false},
   {module,n1ql}]},
 {28690,
  [{name,<<"/admin/vitals API request">>},
   {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
   {enabled,false},
   {module,n1ql}]},
 {28691,
  [{name,<<"/admin/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28692,
  [{name,<<"/admin/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28693,
  [{name,<<"/admin/indexes/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28694,
  [{name,<<"/admin/indexes/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28695,
  [{name,<<"/admin/indexes/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28697,
  [{name,<<"/admin/ping API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ping.">>},
   {enabled,false},
   {module,n1ql}]},
 {28698,
  [{name,<<"/admin/config API request">>},
   {description,<<"An HTTP request was made to the API at /admin/config.">>},
   {enabled,false},
   {module,n1ql}]},
 {28699,
  [{name,<<"/admin/ssl_cert API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ssl_cert.">>},
   {enabled,false},
   {module,n1ql}]},
 {28700,
  [{name,<<"/admin/settings API request">>},
   {description,<<"An HTTP request was made to the API at /admin/settings.">>},
   {enabled,false},
   {module,n1ql}]},
 {28701,
  [{name,<<"/admin/clusters API request">>},
   {description,<<"An HTTP request was made to the API at /admin/clusters.">>},
   {enabled,false},
   {module,n1ql}]},
 {28702,
  [{name,<<"/admin/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {32768,
  [{name,<<"Create Function">>},
   {description,<<"Eventing function definition was created or updated">>},
   {enabled,true},
   {module,eventing}]},
 {32769,
  [{name,<<"Delete Function">>},
   {description,<<"Eventing function definition was deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32770,
  [{name,<<"Fetch Functions">>},
   {description,<<"Eventing function definition was read">>},
   {enabled,false},
   {module,eventing}]},
 {32771,
  [{name,<<"List Deployed">>},
   {description,<<"Eventing deployed functions list was read">>},
   {enabled,false},
   {module,eventing}]},
 {32772,
  [{name,<<"Fetch Drafts">>},
   {description,<<"Eventing function draft definitions were read">>},
   {enabled,false},
   {module,eventing}]},
 {32773,
  [{name,<<"Delete Drafts">>},
   {description,<<"Eventing function draft definitions were deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32774,
  [{name,<<"Save Draft">>},
   {description,<<"Save a draft definition to the store">>},
   {enabled,true},
   {module,eventing}]},
 {32775,
  [{name,<<"Start Debug">>},
   {description,<<"Start eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32776,
  [{name,<<"Stop Debug">>},
   {description,<<"Stop eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32777,
  [{name,<<"Start Tracing">>},
   {description,<<"Start tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32778,
  [{name,<<"Stop Tracing">>},
   {description,<<"Stop tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32779,
  [{name,<<"Set Settings">>},
   {description,<<"Save settings for a given app">>},
   {enabled,true},
   {module,eventing}]},
 {32780,
  [{name,<<"Fetch Config">>},
   {description,<<"Get config for eventing">>},
   {enabled,false},
   {module,eventing}]},
 {32781,
  [{name,<<"Save Config">>},
   {description,<<"Save config for eventing">>},
   {enabled,true},
   {module,eventing}]},
 {32782,
  [{name,<<"Cleanup Eventing">>},
   {description,<<"Clears up app definitions and settings from metakv">>},
   {enabled,true},
   {module,eventing}]},
 {32783,
  [{name,<<"Get Settings">>},
   {description,<<"Get settings for a given app">>},
   {enabled,false},
   {module,eventing}]},
 {32784,
  [{name,<<"Import Functions">>},
   {description,<<"Import a list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32785,
  [{name,<<"Export Functions">>},
   {description,<<"Export the list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32786,
  [{name,<<"List Running">>},
   {description,<<"Eventing running function list was read">>},
   {enabled,false},
   {module,eventing}]},
 {36865,
  [{name,<<"Service configuration change">>},
   {description,<<"A successful service configuration change was made.">>},
   {enabled,true},
   {module,analytics}]},
 {36866,
  [{name,<<"Node configuration change">>},
   {description,<<"A successful node configuration change was made.">>},
   {enabled,true},
   {module,analytics}]}]
[ns_server:debug,2020-05-07T02:45:31.639Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[ns_server:debug,2020-05-07T02:45:31.639Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_reprovision_cfg ->
[{enabled,true},{max_nodes,1},{count,0}]
[ns_server:debug,2020-05-07T02:45:31.639Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
buckets ->
[[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}],{configs,[]}]
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cbas_memory_quota ->
1024
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cert_and_pkey ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQ"...>>,
  <<"*****">>}]
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
client_cert_auth ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {state,"disable"},
 {prefixes,[]}]
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cluster_compat_version ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},6,0]
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded,communication_issue]}]
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
fts_memory_quota ->
256
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
log_redaction_default_cfg ->
[{redact_level,none}]
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
max_bucket_count ->
10
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memcached ->
[]
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memory_quota ->
311
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
otp ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
 {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
password_policy ->
[{min_length,6},{must_present,[]}]
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
quorum_nodes ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
read_only_user_creds ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
remote_clusters ->
[]
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:memcached_passwords<0.240.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T02:45:31.640Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest ->
[{port,8091}]
[ns_server:debug,2020-05-07T02:45:31.641Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest_creds ->
null
[ns_server:debug,2020-05-07T02:45:31.642Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
roles_definitions ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T02:45:31.642Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
scramsha_fallback_salt ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<169,238,80,91,5,165,74,47,79,135,45,74>>]
[ns_server:debug,2020-05-07T02:45:31.642Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
secure_headers ->
[]
[ns_server:debug,2020-05-07T02:45:31.642Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2020-05-07T02:45:31.642Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2020-05-07T02:45:31.642Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
users_upgrade ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T02:45:31.642Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2020-05-07T02:45:31.642Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2020-05-07T02:45:31.642Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{5,63756037313}}]}]
[ns_server:debug,2020-05-07T02:45:31.642Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/eventing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"ram_quota\":256}">>]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/query/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{rbac_upgrade,[5,5]} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,fts} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,index} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8092]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9110]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_client_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9113]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9112]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9111]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9115]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_console_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9114]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_data_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9116]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8095]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_messaging_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9118]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_callback_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9119]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9121]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_parent_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9122]
[ns_server:debug,2020-05-07T02:45:31.643Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_replication_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9120]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_result_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9117]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18095]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {5,5,3}]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9140]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8096]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18096]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8094]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18094]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9100]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9102]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|19102]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9101]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9104]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9103]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9105]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:debug,2020-05-07T02:45:31.644Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 active]
[ns_server:debug,2020-05-07T02:45:31.645Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"@ns_server"},
 {other_users,["@cbq-engine","@projector","@goxdcr","@index","@fts",
               "@eventing","@cbas"]},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2020-05-07T02:45:31.645Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},
        {port,port},
        {maxconn,maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {privilege_debug,privilege_debug},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {rbac_file,{"~s",[rbac_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps},
   {tracing_enabled,tracing_enabled},
   {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
   {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
   {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
   {logger,
    {[{filename,{"~s/~s",[log_path,log_prefix]}},
      {cyclesize,log_cyclesize},
      {sleeptime,log_sleeptime}]}}]}]
[ns_server:debug,2020-05-07T02:45:31.645Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {privilege_debug,false},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false},
 {tracing_enabled,true},
 {datatype_snappy,true}]
[ns_server:debug,2020-05-07T02:45:31.645Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2020-05-07T02:45:31.645Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2020-05-07T02:45:31.645Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T02:45:31.645Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9999]
[ns_server:debug,2020-05-07T02:45:31.645Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8093]
[ns_server:debug,2020-05-07T02:45:31.645Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2020-05-07T02:45:31.645Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18092]
[ns_server:debug,2020-05-07T02:45:31.645Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18093]
[ns_server:debug,2020-05-07T02:45:31.646Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18091]
[ns_server:debug,2020-05-07T02:45:31.646Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 <<"0f8760945f98b1efdbef0bd1ea6e8446">>]
[ns_server:debug,2020-05-07T02:45:31.646Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9998]
[ns_server:debug,2020-05-07T02:45:31.646Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|false]
[error_logger:info,2020-05-07T02:45:31.650Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.254.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:31.650Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([alert_limits,audit,audit_decriptors,
                               auto_failover_cfg,auto_reprovision_cfg,
                               autocompaction,buckets,cbas_memory_quota,
                               cert_and_pkey,client_cert_auth,
                               cluster_compat_version,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,
                               index_aware_rebalance_disabled,
                               log_redaction_default_cfg,max_bucket_count,
                               memcached,memory_quota,nodes_wanted,otp,
                               password_policy,quorum_nodes,
                               read_only_user_creds,remote_clusters,
                               replication,rest,rest_creds,roles_definitions,
                               scramsha_fallback_salt,secure_headers,
                               server_groups,set_view_update_daemon,
                               users_upgrade,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>},
                               {metakv,<<"/eventing/settings/config">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {metakv,<<"/query/settings/config">>},
                               {rbac_upgrade,[5,5]},
                               {request_limit,capi},
                               {request_limit,rest},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',cbas_admin_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_client_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_http_port},
                               {node,'ns_1@127.0.0.1',cbas_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_console_port},
                               {node,'ns_1@127.0.0.1',cbas_data_port},
                               {node,'ns_1@127.0.0.1',cbas_debug_port},
                               {node,'ns_1@127.0.0.1',cbas_http_port},
                               {node,'ns_1@127.0.0.1',cbas_messaging_port},
                               {node,'ns_1@127.0.0.1',
                                   cbas_metadata_callback_port},
                               {node,'ns_1@127.0.0.1',cbas_metadata_port},
                               {node,'ns_1@127.0.0.1',cbas_parent_port},
                               {node,'ns_1@127.0.0.1',cbas_replication_port},
                               {node,'ns_1@127.0.0.1',cbas_result_port},
                               {node,'ns_1@127.0.0.1',cbas_ssl_port}]..)
[error_logger:info,2020-05-07T02:45:31.651Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.247.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:info,2020-05-07T02:45:31.666Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: 172: Booted. Waiting for shutdown request

[ns_server:debug,2020-05-07T02:45:31.675Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.240.0>
[ns_server:debug,2020-05-07T02:45:31.675Z,ns_1@127.0.0.1:memcached_passwords<0.240.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T02:45:31.675Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.240.0>
[error_logger:info,2020-05-07T02:45:31.676Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.270.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:31.677Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:trigger_ssl_reload:565]Notify services [capi_ssl_service] about secure_headers_changed change
[ns_server:debug,2020-05-07T02:45:31.677Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:525]Going to notify following services: [capi_ssl_service]
[ns_server:debug,2020-05-07T02:45:31.682Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[ns_server:warn,2020-05-07T02:45:31.683Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T02:45:31.683Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2020-05-07T02:45:31.685Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.278.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.685Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.281.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.685Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.282.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:31.685Z,ns_1@127.0.0.1:<0.277.0>:ns_ssl_services_setup:notify_service:708]Successfully notified service capi_ssl_service
[ns_server:info,2020-05-07T02:45:31.686Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:541]Succesfully notified services [capi_ssl_service]
[ns_server:debug,2020-05-07T02:45:31.693Z,ns_1@127.0.0.1:ns_log_events<0.246.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2020-05-07T02:45:31.693Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.284.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.693Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.283.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:31.693Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.285.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.695Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.286.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.699Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.288.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.699Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.292.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.699Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.287.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:31.704Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.297.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:31.711Z,ns_1@127.0.0.1:ns_heart<0.288.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2020-05-07T02:45:31.711Z,ns_1@127.0.0.1:ns_heart<0.288.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]}]}}

[ns_server:debug,2020-05-07T02:45:31.714Z,ns_1@127.0.0.1:<0.295.0>:restartable:start_child:98]Started child process <0.296.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2020-05-07T02:45:31.714Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.299.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.714Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.295.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:31.714Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.302.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.733Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.303.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.733Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.304.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.733Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.305.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.733Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.306.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.736Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.308.0>},
                       {name,query_settings_manager},
                       {mfargs,{query_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.739Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.310.0>},
                       {name,eventing_settings_manager},
                       {mfargs,{eventing_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.740Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.312.0>},
                       {name,audit_events},
                       {mfargs,{gen_event,start_link,[{local,audit_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.748Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.315.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.748Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.317.0>},
                       {name,scram_sha},
                       {mfargs,{scram_sha,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:31.752Z,ns_1@127.0.0.1:ns_heart<0.288.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2020-05-07T02:45:31.753Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.318.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:31.755Z,ns_1@127.0.0.1:ns_heart<0.288.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T02:45:31.777Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.320.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.786Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.323.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.786Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.324.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:31.787Z,ns_1@127.0.0.1:menelaus_sup<0.313.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T02:45:31.787Z,ns_1@127.0.0.1:menelaus_sup<0.313.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T02:45:31.787Z,ns_1@127.0.0.1:menelaus_sup<0.313.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T02:45:31.787Z,ns_1@127.0.0.1:menelaus_sup<0.313.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[error_logger:info,2020-05-07T02:45:31.788Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.325.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.791Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.342.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.794Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.343.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.798Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.344.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.801Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.345.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2020-05-07T02:45:31.801Z,ns_1@127.0.0.1:ns_server_sup<0.233.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "6.0.3-2895-enterprise".
[error_logger:info,2020-05-07T02:45:31.801Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.313.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:31.801Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.351.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.803Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.355.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:31.804Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.356.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.31986353>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.804Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.354.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:45:31.808Z,ns_1@127.0.0.1:ns_ports_setup<0.351.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,goxdcr]
[ns_server:debug,2020-05-07T02:45:31.818Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.292.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,244}]},
                 {proc_lib,init_p_do_apply,3,
                           [{file,"proc_lib.erl"},{line,239}]}]}}

[ns_server:debug,2020-05-07T02:45:31.818Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.292.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,244}]}]}}

[ns_server:debug,2020-05-07T02:45:31.820Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.292.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T02:45:31.820Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.292.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T02:45:31.822Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.373.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:31.822Z,ns_1@127.0.0.1:ns_audit_cfg<0.374.0>:ns_audit_cfg:write_audit_json:265]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{descriptors_path,
                                                                                <<"/opt/couchbase/etc/security">>},
                                                                               {version,
                                                                                2},
                                                                               {uuid,
                                                                                <<"18411111">>},
                                                                               {event_states,
                                                                                {[]}},
                                                                               {filtering_enabled,
                                                                                true},
                                                                               {disabled_userids,
                                                                                []},
                                                                               {auditd_enabled,
                                                                                false},
                                                                               {log_path,
                                                                                <<"/opt/couchbase/var/lib/couchbase/logs">>},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []}]
[ns_server:debug,2020-05-07T02:45:31.848Z,ns_1@127.0.0.1:ns_audit_cfg<0.374.0>:ns_audit_cfg:notify_memcached:170]Instruct memcached to reload audit config
[error_logger:info,2020-05-07T02:45:31.848Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.374.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:45:31.851Z,ns_1@127.0.0.1:<0.377.0>:ns_memcached:connect:1230]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2020-05-07T02:45:31.861Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,ns_audit},
                       {mfargs,{ns_audit,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:31.863Z,ns_1@127.0.0.1:memcached_config_mgr<0.379.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2020-05-07T02:45:31.863Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.379.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:31.866Z,ns_1@127.0.0.1:<0.380.0>:ns_memcached_log_rotator:init:42]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2020-05-07T02:45:31.866Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.380.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.866Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.381.0>},
                       {name,testconditions_store},
                       {mfargs,{simple_store,start_link,[testconditions]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.872Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.383.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.874Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.385.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.874Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.384.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:31.875Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.382.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:31.878Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.386.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.879Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.390.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:31.882Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: working as port

[error_logger:info,2020-05-07T02:45:31.884Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.392.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.885Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.393.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.886Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.395.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.887Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.396.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.887Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.398.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.900Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.399.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.917Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.401.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.919Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.403.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.968Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.404.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:31.978Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.406.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:31.981Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.406.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T02:45:31.982Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.406.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2020-05-07T02:45:31.984Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.410.0>},
                       {name,service_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_stats_children_sup},
                                services_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:45:31.984Z,ns_1@127.0.0.1:ns_ports_setup<0.351.0>:ns_ports_setup:set_children:90]Monitor ns_child_ports_sup <12401.74.0>
[ns_server:debug,2020-05-07T02:45:31.984Z,ns_1@127.0.0.1:memcached_config_mgr<0.379.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:info,2020-05-07T02:45:31.987Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.413.0>},
                       {name,service_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [service_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:32.010Z,ns_1@127.0.0.1:memcached_config_mgr<0.379.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.80.0>
[ns_server:debug,2020-05-07T02:45:32.019Z,ns_1@127.0.0.1:memcached_config_mgr<0.379.0>:memcached_config_mgr:init:79]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[ns_server:debug,2020-05-07T02:45:32.029Z,ns_1@127.0.0.1:memcached_config_mgr<0.379.0>:memcached_config_mgr:init:82]activated memcached port server
[error_logger:info,2020-05-07T02:45:32.029Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.416.0>},
                       {name,service_status_keeper_index},
                       {mfargs,{service_index,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.035Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.419.0>},
                       {name,service_status_keeper_fts},
                       {mfargs,{service_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.038Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.422.0>},
                       {name,service_status_keeper_eventing},
                       {mfargs,{service_eventing,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.038Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.412.0>},
                       {name,service_status_keeper_sup},
                       {mfargs,{service_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:32.038Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.425.0>},
                       {name,service_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<services_stats_sup.0.41280346>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.038Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.409.0>},
                       {name,services_stats_sup},
                       {mfargs,{services_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:32.046Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.427.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:32.062Z,ns_1@127.0.0.1:<0.430.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.430.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2020-05-07T02:45:32.067Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[error_logger:info,2020-05-07T02:45:32.067Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.428.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:32.067Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:45:32.068Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:45:32.068Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:45:32.068Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:45:32.068Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2020-05-07T02:45:32.069Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.432.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.069Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.431.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:32.071Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.433.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.087Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.437.0>},
                       {name,leader_activities},
                       {mfargs,{leader_activities,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T02:45:32.092Z,ns_1@127.0.0.1:leader_lease_agent<0.438.0>:leader_lease_agent:maybe_recover_persisted_lease:397]Found persisted lease [{node,'ns_1@127.0.0.1'},
                       {uuid,<<"52bfb87503e39b537b887732cb6c7de9">>},
                       {time_left,15000},
                       {status,active}]
[error_logger:info,2020-05-07T02:45:32.092Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.438.0>},
                       {name,leader_lease_agent},
                       {mfargs,{leader_lease_agent,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.092Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.436.0>},
                       {name,leader_leases_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_leases_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:32.092Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.440.0>},
                       {name,leader_events},
                       {mfargs,{gen_event,start_link,[{local,leader_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.098Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.441.0>},
                       {name,leader_registry_server},
                       {mfargs,{leader_registry_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:32.107Z,ns_1@127.0.0.1:leader_registry_sup<0.439.0>:mb_master:check_master_takeover_needed:270]Sending master node question to the following nodes: []
[ns_server:debug,2020-05-07T02:45:32.107Z,ns_1@127.0.0.1:leader_registry_sup<0.439.0>:mb_master:check_master_takeover_needed:272]Got replies: []
[ns_server:debug,2020-05-07T02:45:32.107Z,ns_1@127.0.0.1:leader_registry_sup<0.439.0>:mb_master:check_master_takeover_needed:278]Was unable to discover master, not going to force mastership takeover
[user:info,2020-05-07T02:45:32.107Z,ns_1@127.0.0.1:mb_master<0.444.0>:mb_master:init:90]I'm the only node, so I'm the master.
[ns_server:debug,2020-05-07T02:45:32.108Z,ns_1@127.0.0.1:leader_registry<0.441.0>:leader_registry_server:handle_new_leader:241]New leader is 'ns_1@127.0.0.1'. Invalidating name cache.
[error_logger:info,2020-05-07T02:45:32.136Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.447.0>},
                       {name,leader_lease_acquirer},
                       {mfargs,{leader_lease_acquirer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:32.153Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.449.0>:leader_quorum_nodes_manager:pull_config:114]Attempting to pull config from nodes:
[]
[error_logger:info,2020-05-07T02:45:32.153Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.449.0>},
                       {name,leader_quorum_nodes_manager},
                       {mfargs,{leader_quorum_nodes_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:32.153Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.449.0>:leader_quorum_nodes_manager:pull_config:119]Pulled config successfully.
[ns_server:warn,2020-05-07T02:45:32.164Z,ns_1@127.0.0.1:<0.455.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"52bfb87503e39b537b887732cb6c7de9">>} (valid for 14928ms)
[ns_server:info,2020-05-07T02:45:32.166Z,ns_1@127.0.0.1:mb_master_sup<0.446.0>:misc:start_singleton:758]start_singleton(gen_server, ns_tick, [], []): started as <0.458.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T02:45:32.166Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.458.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.176Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.461.0>},
                       {name,ns_janitor_server},
                       {mfargs,{ns_janitor_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:32.178Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.460.0>:misc:start_singleton:758]start_singleton(gen_server, auto_reprovision, [], []): started as <0.462.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T02:45:32.179Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.462.0>},
                       {name,auto_reprovision},
                       {mfargs,{auto_reprovision,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T02:45:32.179Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.460.0>:misc:start_singleton:758]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.463.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T02:45:32.179Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.463.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.179Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.460.0>},
                       {name,ns_orchestrator_child_sup},
                       {mfargs,{ns_orchestrator_child_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:45:32.185Z,ns_1@127.0.0.1:<0.465.0>:auto_failover:init:211]init auto_failover.
[user:info,2020-05-07T02:45:32.185Z,ns_1@127.0.0.1:<0.465.0>:auto_failover:handle_call:242]Enabled auto-failover with timeout 120 and max count 1
[ns_server:debug,2020-05-07T02:45:32.195Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{6,63756038732}}]}]
[ns_server:debug,2020-05-07T02:45:32.195Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[ns_server:debug,2020-05-07T02:45:32.195Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([auto_failover_cfg,
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>}]..)
[ns_server:info,2020-05-07T02:45:32.198Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.459.0>:misc:start_singleton:758]start_singleton(gen_server, auto_failover, [], []): started as <0.465.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T02:45:32.205Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.465.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.205Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.459.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:32.206Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.444.0>},
                       {name,mb_master},
                       {mfargs,{mb_master,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:45:32.206Z,ns_1@127.0.0.1:<0.434.0>:restartable:start_child:98]Started child process <0.435.0>
  MFA: {leader_services_sup,start_link,[]}
[error_logger:info,2020-05-07T02:45:32.206Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.439.0>},
                       {name,leader_registry_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_registry_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:32.206Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.434.0>},
                       {name,leader_services_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{leader_services_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:32.206Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.473.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.206Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.474.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.212Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.476.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.236Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.477.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.266Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.480.0>},
                       {name,ns_server_monitor},
                       {mfargs,{ns_server_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.266Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.482.0>},
                       {name,service_monitor_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_monitor_children_sup},
                                health_monitor_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:32.267Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.483.0>},
                       {name,service_monitor_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<health_monitor_sup.0.81875396>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.270Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.491.0>},
                       {name,node_monitor},
                       {mfargs,{node_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T02:45:32.271Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.499.0>},
                       {name,node_status_analyzer},
                       {mfargs,{node_status_analyzer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T02:45:32.271Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[error_logger:info,2020-05-07T02:45:32.271Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.479.0>},
                       {name,health_monitor_sup},
                       {mfargs,{health_monitor_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:32.271Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.233.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T02:45:32.272Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.169.0>
[ns_server:debug,2020-05-07T02:45:32.272Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2020-05-07T02:45:32.272Z,ns_1@127.0.0.1:<0.168.0>:restartable:start_child:98]Started child process <0.169.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[error_logger:info,2020-05-07T02:45:32.272Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.168.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T02:45:32.272Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:debug,2020-05-07T02:45:32.272Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:130]138: Entered child_loop
[ns_server:debug,2020-05-07T02:45:32.274Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@",admin}
[ns_server:debug,2020-05-07T02:45:32.291Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.501.0>:json_rpc_connection:init:73]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.501.0>
[ns_server:debug,2020-05-07T02:45:32.382Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.504.0>:json_rpc_connection:init:73]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.504.0>
[ns_server:debug,2020-05-07T02:45:32.382Z,ns_1@127.0.0.1:menelaus_cbauth<0.345.0>:menelaus_cbauth:handle_cast:102]Observed json rpc process {"goxdcr-cbauth",<0.504.0>} started
[ns_server:debug,2020-05-07T02:45:32.394Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@goxdcr-cbauth",admin}
[ns_server:debug,2020-05-07T02:45:32.595Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:89]Refresh of [rbac,isasl] succeeded
[ns_server:debug,2020-05-07T02:45:33.187Z,ns_1@127.0.0.1:<0.465.0>:auto_failover_logic:log_master_activity:170]Transitioned node {'ns_1@127.0.0.1',<<"0f8760945f98b1efdbef0bd1ea6e8446">>} state new -> up
[ns_server:debug,2020-05-07T02:45:47.093Z,ns_1@127.0.0.1:leader_lease_agent<0.438.0>:leader_lease_agent:handle_lease_expired:284]Lease held by {lease_holder,<<"52bfb87503e39b537b887732cb6c7de9">>,
                            'ns_1@127.0.0.1'} expired. Starting expirer.
[ns_server:warn,2020-05-07T02:45:47.093Z,ns_1@127.0.0.1:<0.455.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"52bfb87503e39b537b887732cb6c7de9">>} (valid for 0ms)
[ns_server:debug,2020-05-07T02:45:47.094Z,ns_1@127.0.0.1:leader_lease_agent<0.438.0>:leader_lease_agent:do_handle_acquire_lease:147]Granting lease to {lease_holder,<<"510c4d8812fc511414a6608f96c5fb7e">>,
                                'ns_1@127.0.0.1'} for 15000ms
[ns_server:info,2020-05-07T02:45:47.104Z,ns_1@127.0.0.1:<0.455.0>:leader_lease_acquire_worker:handle_fresh_lease_acquired:302]Acquired lease from node 'ns_1@127.0.0.1' (lease uuid: <<"510c4d8812fc511414a6608f96c5fb7e">>)
[ns_server:debug,2020-05-07T02:46:02.069Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:46:02.069Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:46:02.069Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:46:02.069Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:46:32.070Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:46:32.070Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:46:32.070Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:46:32.070Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:47:02.071Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:47:02.071Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:47:02.071Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:47:02.071Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:47:32.072Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:47:32.072Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:47:32.072Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:47:32.072Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:48:02.073Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:48:02.073Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:48:02.073Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:48:02.073Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:48:32.074Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:48:32.074Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:48:32.074Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:48:32.074Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:49:02.075Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:49:02.075Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:49:02.075Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:49:02.075Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:49:32.076Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:49:32.076Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:49:32.076Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:49:32.076Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:50:02.077Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:50:02.077Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:50:02.077Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:50:02.077Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:50:32.078Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:50:32.078Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:50:32.078Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:50:32.078Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:51:02.079Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:51:02.079Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:51:02.079Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:51:02.079Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:51:32.080Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:51:32.080Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:51:32.080Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:51:32.080Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:52:02.081Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:52:02.081Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:52:02.081Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:52:02.081Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:52:32.082Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:52:32.082Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:52:32.082Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:52:32.082Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:53:02.083Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:53:02.083Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:53:02.083Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:53:02.083Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:53:32.084Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:53:32.084Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:53:32.084Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:53:32.084Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:54:02.085Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:54:02.085Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:54:02.085Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:54:02.085Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:54:32.086Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:54:32.086Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:54:32.086Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:54:32.086Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:55:02.087Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:55:02.087Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:55:02.087Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:55:02.087Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:55:32.088Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:55:32.088Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:55:32.088Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:55:32.088Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:56:02.089Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:56:02.089Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:56:02.089Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:56:02.089Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:56:32.090Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:56:32.090Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:56:32.090Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:56:32.090Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:57:02.091Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:57:02.091Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:57:02.091Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:57:02.091Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:57:32.092Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:57:32.092Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:57:32.092Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:57:32.092Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:58:02.093Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:58:02.093Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:58:02.093Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:58:02.093Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:58:32.094Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:58:32.094Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:58:32.094Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:58:32.094Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:59:02.095Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:59:02.095Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:59:02.095Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:59:02.095Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:59:32.096Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:59:32.096Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T02:59:32.096Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T02:59:32.096Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:00:02.097Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:00:02.097Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:00:02.097Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:00:02.097Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:00:32.098Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:00:32.098Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:00:32.098Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:00:32.098Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:01:02.099Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:01:02.099Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:01:02.099Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:01:02.099Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:01:32.100Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:01:32.100Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:01:32.100Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:01:32.100Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:02:02.101Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:02:02.101Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:02:02.101Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:02:02.101Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:02:32.102Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:02:32.102Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:02:32.102Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:02:32.102Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:03:02.103Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:03:02.103Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:03:02.103Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:03:02.103Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:03:32.104Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:03:32.104Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:03:32.104Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:03:32.104Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:04:02.105Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:04:02.105Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:04:02.105Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:04:02.105Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:04:32.106Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:04:32.106Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:04:32.106Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:04:32.106Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:05:02.107Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:05:02.107Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:05:02.107Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:05:02.107Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:05:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:05:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:05:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:05:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:06:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:06:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:06:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:06:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:06:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:06:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:06:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:06:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:07:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:07:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:07:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:07:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:07:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:07:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:07:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:07:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:08:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:08:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:08:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:08:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:08:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:08:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:08:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:08:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:09:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:09:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:09:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:09:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:09:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:09:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:09:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:09:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:10:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:10:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:10:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:10:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:10:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:10:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:10:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:10:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:11:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:11:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:11:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:11:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:11:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:11:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:11:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:11:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:12:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:12:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:12:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:12:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:12:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:12:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:12:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:12:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:13:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:13:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:13:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:13:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:13:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:13:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:13:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:13:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:14:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:14:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:14:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:14:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:14:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:14:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:14:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:14:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:15:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:15:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:15:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:15:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:15:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:15:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:15:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:15:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:16:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:16:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:16:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:16:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:16:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:16:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:16:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:16:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:17:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:17:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:17:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:17:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:17:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:17:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:17:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:17:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:18:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:18:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:18:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:18:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:18:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:18:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:18:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:18:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:19:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:19:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:19:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:19:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:19:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:19:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:19:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:19:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:20:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:20:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:20:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:20:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:20:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:20:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:20:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:20:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:21:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:21:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:21:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:21:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:21:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:21:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:21:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:21:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:22:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:22:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:22:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:22:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:22:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:22:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:22:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:22:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:23:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:23:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:23:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:23:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:23:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:23:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:23:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:23:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:24:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:24:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:24:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:24:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:24:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:24:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:24:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:24:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:25:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:25:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:25:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:25:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:25:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:25:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:25:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:25:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:26:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:26:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:26:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:26:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:26:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:26:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:26:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:26:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:27:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:27:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:27:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:27:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:27:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:27:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:27:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:27:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:28:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:28:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:28:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:28:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:28:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:28:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:28:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:28:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:29:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:29:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:29:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:29:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:29:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:29:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:29:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:29:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:30:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:30:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:30:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:30:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:30:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:30:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:30:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:30:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:31:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:31:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:31:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:31:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:31:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:31:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:31:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:31:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:32:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:32:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:32:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:32:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:32:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:32:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:32:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:32:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:33:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:33:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:33:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:33:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:33:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:33:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:33:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:33:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:34:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:34:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:34:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:34:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:34:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:34:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:34:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:34:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:35:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:35:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:35:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:35:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:35:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:35:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:35:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:35:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:36:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:36:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:36:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:36:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:36:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:36:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:36:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:36:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:37:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:37:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:37:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:37:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:37:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:37:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:37:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:37:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:38:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:38:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:38:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:38:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:38:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:38:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:38:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:38:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:39:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:39:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:39:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:39:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:39:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:39:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:39:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:39:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:40:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:40:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:40:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:40:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:40:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:40:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:40:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:40:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:41:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:41:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:41:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:41:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:41:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:41:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:41:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:41:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:42:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:42:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:42:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:42:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:42:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:42:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:42:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:42:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:43:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:43:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:43:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:43:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:43:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:43:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:43:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:43:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:44:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:44:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:44:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:44:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:44:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:44:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:44:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:44:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:45:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:45:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:45:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:45:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:45:32.069Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:45:32.069Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[ns_server:debug,2020-05-07T03:45:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:45:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:45:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:45:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:46:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:46:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:46:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:46:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:46:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:46:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:46:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:46:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:47:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:47:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:47:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:47:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:47:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:47:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:47:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:47:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:48:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:48:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:48:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:48:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:48:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:48:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:48:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:48:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:49:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:49:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:49:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:49:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:49:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:49:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:49:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:49:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:50:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:50:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:50:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:50:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:50:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:50:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:50:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:50:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:51:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:51:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:51:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:51:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:51:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:51:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:51:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:51:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:52:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:52:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:52:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:52:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:52:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:52:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:52:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:52:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:53:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:53:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:53:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:53:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:53:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:53:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:53:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:53:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:54:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:54:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:54:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:54:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:54:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:54:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:54:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:54:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:55:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:55:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:55:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:55:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:55:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:55:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:55:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:55:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:56:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:56:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:56:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:56:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:56:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:56:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:56:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:56:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:57:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:57:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:57:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:57:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:57:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:57:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:57:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:57:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:58:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:58:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:58:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:58:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:58:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:58:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:58:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:58:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:59:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:59:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:59:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:59:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:59:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:59:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T03:59:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T03:59:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:00:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:00:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:00:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:00:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:00:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:00:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:00:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:00:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:01:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:01:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:01:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:01:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:01:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:01:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:01:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:01:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:02:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:02:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:02:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:02:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:02:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:02:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:02:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:02:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:03:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:03:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:03:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:03:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:03:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:03:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:03:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:03:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:04:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:04:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:04:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:04:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:04:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:04:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:04:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:04:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:05:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:05:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:05:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:05:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:05:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:05:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:05:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:05:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:06:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:06:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:06:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:06:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:06:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:06:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:06:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:06:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:07:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:07:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:07:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:07:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:07:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:07:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:07:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:07:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:08:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:08:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:08:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:08:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:08:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:08:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:08:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:08:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:09:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:09:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:09:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:09:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:09:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:09:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:09:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:09:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:10:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:10:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:10:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:10:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:10:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:10:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:10:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:10:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:11:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:11:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:11:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:11:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:11:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:11:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:11:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:11:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:12:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:12:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:12:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:12:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:12:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:12:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:12:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:12:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:13:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:13:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:13:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:13:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:13:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:13:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:13:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:13:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:14:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:14:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:14:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:14:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:14:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:14:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:14:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:14:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:15:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:15:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:15:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:15:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:15:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:15:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:15:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:15:32.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:16:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:16:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:16:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:16:02.108Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:16:32.109Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:16:32.109Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:16:32.109Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:16:32.109Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:17:02.110Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:17:02.110Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:17:02.110Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:17:02.110Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:17:32.111Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:17:32.111Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:17:32.111Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:17:32.111Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:18:02.112Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:18:02.112Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:18:02.112Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:18:02.112Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:18:32.113Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:18:32.113Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:18:32.113Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:18:32.113Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:19:02.114Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:19:02.114Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:19:02.114Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:19:02.114Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:19:32.115Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:19:32.115Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:19:32.115Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:19:32.115Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:20:02.116Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:20:02.116Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:20:02.116Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:20:02.116Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:20:32.117Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:20:32.117Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:20:32.117Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:20:32.117Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:21:02.118Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:21:02.118Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:21:02.118Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:21:02.118Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:21:32.119Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:21:32.119Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:21:32.119Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:21:32.119Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:22:02.120Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:22:02.120Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:22:02.120Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:22:02.120Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:22:32.121Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:22:32.121Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:22:32.121Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:22:32.121Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:23:02.122Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:23:02.122Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:23:02.122Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:23:02.122Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:23:32.123Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:23:32.123Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:23:32.123Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:23:32.123Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:24:02.124Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:24:02.124Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:24:02.124Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:24:02.124Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:24:32.125Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:24:32.125Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:24:32.125Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:24:32.125Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:25:02.126Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:25:02.126Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:25:02.126Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:25:02.126Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:25:32.127Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:25:32.127Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:25:32.127Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:25:32.127Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:26:02.128Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:26:02.128Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:26:02.128Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:26:02.128Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:26:32.129Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:26:32.129Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:26:32.129Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:26:32.129Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:27:02.130Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:27:02.130Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:27:02.130Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:27:02.130Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:27:32.131Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:27:32.131Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:27:32.131Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:27:32.131Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:28:02.132Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:28:02.132Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:28:02.132Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:28:02.132Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:28:32.133Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:28:32.133Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:28:32.133Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:28:32.133Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:29:02.134Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:29:02.134Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:29:02.134Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:29:02.134Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:29:32.135Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:29:32.135Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:29:32.135Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:29:32.135Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:30:02.136Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:30:02.136Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:30:02.136Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:30:02.136Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:30:32.137Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:30:32.137Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:30:32.137Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:30:32.137Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:31:02.138Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:31:02.138Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:31:02.138Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:31:02.138Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:31:32.139Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:31:32.139Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:31:32.139Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:31:32.139Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:32:02.140Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:32:02.140Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:32:02.140Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:32:02.140Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:32:32.141Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:32:32.141Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:32:32.141Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:32:32.141Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:33:02.142Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:33:02.142Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:33:02.142Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:33:02.142Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:33:32.143Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:33:32.143Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:33:32.143Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:33:32.143Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:34:02.144Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:34:02.144Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:34:02.144Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:34:02.144Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:34:32.145Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:34:32.145Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:34:32.145Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:34:32.145Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:35:02.146Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:35:02.146Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:35:02.146Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:35:02.146Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:35:32.147Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:35:32.147Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:35:32.147Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:35:32.147Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:36:02.148Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:36:02.148Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:36:02.148Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:36:02.148Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:36:32.149Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:36:32.149Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:36:32.149Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:36:32.149Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:37:02.150Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:37:02.150Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:37:02.150Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:37:02.150Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:37:32.151Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:37:32.151Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:37:32.151Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:37:32.151Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:38:02.152Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:38:02.152Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:38:02.152Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:38:02.152Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:38:32.153Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:38:32.153Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:38:32.153Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:38:32.153Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:39:02.154Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:39:02.154Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:39:02.154Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:39:02.154Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:39:32.155Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:39:32.155Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:39:32.155Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:39:32.155Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:40:02.156Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:40:02.156Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:40:02.156Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:40:02.156Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:40:32.157Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:40:32.157Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:40:32.157Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:40:32.157Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:41:02.158Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:41:02.158Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:41:02.158Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:41:02.158Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:41:32.159Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:41:32.159Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:41:32.159Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:41:32.159Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:42:02.160Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:42:02.160Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:42:02.160Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:42:02.160Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:42:32.161Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:42:32.161Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:42:32.161Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:42:32.161Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:43:02.162Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:43:02.162Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:43:02.162Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:43:02.162Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:43:32.163Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:43:32.163Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:43:32.163Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:43:32.163Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:44:02.164Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:44:02.164Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:44:02.164Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:44:02.164Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:44:32.165Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:44:32.165Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:44:32.165Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:44:32.165Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:45:02.166Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:45:02.166Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:45:02.166Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:45:02.166Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:45:32.070Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:45:32.070Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[ns_server:debug,2020-05-07T04:45:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:45:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:45:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:45:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:46:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:46:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:46:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:46:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:46:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:46:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:46:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:46:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:47:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:47:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:47:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:47:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:47:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:47:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:47:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:47:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:48:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:48:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:48:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:48:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:48:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:48:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:48:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:48:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:49:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:49:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:49:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:49:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:49:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:49:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:49:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:49:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:50:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:50:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:50:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:50:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:50:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:50:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:50:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:50:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:51:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:51:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:51:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:51:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:51:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:51:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:51:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:51:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:52:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:52:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:52:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:52:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:52:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:52:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:52:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:52:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:53:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:53:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:53:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:53:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:53:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:53:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:53:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:53:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:54:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:54:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:54:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:54:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:54:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:54:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:54:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:54:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:55:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:55:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:55:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:55:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:55:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:55:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:55:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:55:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:56:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:56:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:56:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:56:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:56:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:56:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:56:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:56:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:57:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:57:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:57:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:57:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:57:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:57:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:57:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:57:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:58:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:58:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:58:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:58:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:58:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:58:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:58:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:58:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:59:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:59:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:59:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:59:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:59:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:59:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T04:59:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T04:59:32.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:00:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:00:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:00:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:00:02.167Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:00:32.168Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:00:32.168Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:00:32.168Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:00:32.168Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:01:02.169Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:01:02.169Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:01:02.169Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:01:02.169Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:01:32.170Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:01:32.170Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:01:32.170Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:01:32.170Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:02:02.171Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:02:02.171Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:02:02.171Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:02:02.171Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:02:32.172Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:02:32.172Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:02:32.172Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:02:32.172Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:03:02.173Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:03:02.173Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:03:02.173Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:03:02.173Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:03:32.174Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:03:32.174Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:03:32.174Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:03:32.174Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:04:02.175Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:04:02.175Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:04:02.175Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:04:02.175Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:04:32.176Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:04:32.176Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:04:32.176Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:04:32.176Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:05:02.177Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:05:02.177Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:05:02.177Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:05:02.177Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:05:32.178Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:05:32.178Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:05:32.178Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:05:32.178Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:06:02.179Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:06:02.179Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:06:02.179Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:06:02.179Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:06:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:06:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:06:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:06:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:07:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:07:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:07:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:07:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:07:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:07:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:07:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:07:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:08:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:08:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:08:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:08:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:08:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:08:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:08:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:08:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:09:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:09:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:09:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:09:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:09:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:09:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:09:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:09:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:10:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:10:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:10:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:10:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:10:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:10:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:10:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:10:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:11:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:11:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:11:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:11:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:11:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:11:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:11:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:11:32.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:12:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:12:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:12:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:12:02.180Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:12:32.185Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:12:32.185Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:12:32.185Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:12:32.185Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:13:02.186Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:13:02.186Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:13:02.186Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:13:02.186Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:13:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:13:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:13:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:13:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:14:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:14:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:14:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:14:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:14:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:14:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:14:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:14:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:15:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:15:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:15:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:15:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:15:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:15:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:15:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:15:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:16:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:16:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:16:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:16:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:16:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:16:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:16:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:16:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:17:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:17:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:17:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:17:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:17:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:17:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:17:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:17:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:18:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:18:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:18:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:18:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:18:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:18:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:18:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:18:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:19:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:19:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:19:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:19:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:19:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:19:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:19:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:19:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:20:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:20:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:20:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:20:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:20:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:20:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:20:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:20:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:21:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:21:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:21:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:21:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:21:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:21:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:21:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:21:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:22:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:22:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:22:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:22:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:22:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:22:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:22:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:22:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:23:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:23:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:23:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:23:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:23:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:23:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:23:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:23:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:24:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:24:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:24:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:24:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:24:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:24:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:24:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:24:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:25:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:25:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:25:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:25:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:25:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:25:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:25:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:25:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:26:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:26:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:26:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:26:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:26:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:26:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:26:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:26:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:27:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:27:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:27:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:27:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:27:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:27:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:27:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:27:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:28:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:28:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:28:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:28:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:28:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:28:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:28:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:28:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:29:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:29:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:29:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:29:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:29:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:29:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:29:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:29:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:30:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:30:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:30:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:30:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:30:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:30:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:30:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:30:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:31:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:31:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:31:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:31:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:31:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:31:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:31:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:31:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:32:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:32:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:32:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:32:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:32:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:32:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:32:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:32:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:33:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:33:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:33:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:33:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:33:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:33:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:33:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:33:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:34:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:34:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:34:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:34:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:34:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:34:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:34:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:34:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:35:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:35:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:35:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:35:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:35:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:35:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:35:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:35:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:36:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:36:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:36:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:36:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:36:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:36:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:36:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:36:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:37:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:37:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:37:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:37:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:37:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:37:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:37:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:37:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:38:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:38:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:38:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:38:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:38:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:38:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:38:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:38:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:39:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:39:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:39:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:39:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:39:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:39:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:39:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:39:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:40:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:40:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:40:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:40:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:40:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:40:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:40:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:40:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:41:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:41:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:41:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:41:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:41:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:41:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:41:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:41:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:42:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:42:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:42:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:42:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:42:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:42:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:42:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:42:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:43:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:43:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:43:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:43:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:43:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:43:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:43:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:43:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:44:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:44:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:44:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:44:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:44:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:44:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:44:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:44:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:45:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:45:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:45:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:45:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:45:32.071Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:45:32.071Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[ns_server:debug,2020-05-07T05:45:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:45:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:45:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:45:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:46:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:46:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:46:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:46:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:46:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:46:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:46:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:46:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:47:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:47:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:47:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:47:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:47:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:47:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:47:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:47:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:48:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:48:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:48:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:48:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:48:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:48:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:48:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:48:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:49:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:49:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:49:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:49:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:49:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:49:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:49:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:49:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:50:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:50:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:50:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:50:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:50:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:50:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:50:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:50:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:51:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:51:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:51:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:51:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:51:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:51:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:51:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:51:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:52:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:52:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:52:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:52:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:52:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:52:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:52:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:52:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:53:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:53:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:53:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:53:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:53:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:53:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:53:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:53:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:54:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:54:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:54:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:54:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:54:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:54:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:54:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:54:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:55:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:55:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:55:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:55:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:55:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:55:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:55:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:55:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:56:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:56:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:56:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:56:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:56:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:56:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:56:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:56:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:57:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:57:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:57:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:57:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:57:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:57:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:57:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:57:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:58:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:58:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:58:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:58:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:58:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:58:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:58:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:58:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:59:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:59:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:59:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:59:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:59:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:59:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T05:59:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T05:59:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:00:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:00:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:00:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:00:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:00:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:00:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:00:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:00:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:01:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:01:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:01:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:01:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:01:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:01:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:01:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:01:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:02:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:02:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:02:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:02:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:02:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:02:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:02:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:02:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:03:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:03:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:03:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:03:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:03:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:03:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:03:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:03:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:04:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:04:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:04:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:04:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:04:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:04:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:04:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:04:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:05:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:05:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:05:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:05:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:05:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:05:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:05:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:05:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:06:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:06:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:06:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:06:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:06:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:06:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:06:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:06:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:07:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:07:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:07:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:07:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:07:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:07:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:07:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:07:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:08:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:08:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:08:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:08:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:08:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:08:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:08:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:08:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:09:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:09:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:09:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:09:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:09:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:09:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:09:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:09:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:10:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:10:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:10:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:10:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:10:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:10:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:10:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:10:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:11:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:11:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:11:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:11:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:11:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:11:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:11:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:11:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:12:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:12:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:12:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:12:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:12:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:12:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:12:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:12:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:13:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:13:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:13:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:13:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:13:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:13:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:13:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:13:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:14:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:14:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:14:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:14:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:14:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:14:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:14:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:14:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:15:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:15:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:15:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:15:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:15:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:15:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:15:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:15:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:16:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:16:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:16:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:16:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:16:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:16:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:16:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:16:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:17:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:17:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:17:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:17:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:17:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:17:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:17:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:17:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:18:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:18:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:18:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:18:02.188Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:18:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:18:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:18:32.189Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:18:32.189Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:19:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:19:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:19:02.190Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:19:02.190Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:19:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:19:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:19:32.193Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:19:32.193Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:20:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:20:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:20:02.194Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:20:02.194Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:20:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:20:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:20:32.195Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:20:32.195Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:21:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:21:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:21:02.196Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:21:02.196Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:21:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:21:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:21:32.197Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:21:32.197Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:22:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:22:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:22:02.198Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:22:02.198Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:22:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:22:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:22:32.199Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:22:32.199Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:23:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:23:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:23:02.200Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:23:02.200Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:23:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:23:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:23:32.201Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:23:32.201Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:24:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:24:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:24:02.202Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:24:02.202Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:24:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:24:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:24:32.203Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:24:32.203Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:25:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:25:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:25:02.204Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:25:02.204Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:25:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:25:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:25:32.205Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:25:32.205Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:26:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:26:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:26:02.206Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:26:02.206Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:26:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:26:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:26:32.207Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:26:32.207Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:27:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:27:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:27:02.208Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:27:02.208Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:27:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:27:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:27:32.209Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:27:32.209Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:28:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:28:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:28:02.210Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:28:02.210Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:28:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:28:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:28:32.211Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:28:32.211Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:29:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:29:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:29:02.212Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:29:02.212Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:29:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:29:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:29:32.213Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:29:32.213Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:30:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:30:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:30:02.214Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:30:02.214Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:30:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:30:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:30:32.215Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:30:32.215Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:31:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:31:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:31:02.216Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:31:02.216Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:31:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:31:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:31:32.217Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:31:32.217Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:32:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:32:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:32:02.218Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:32:02.218Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:32:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:32:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:32:32.219Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:32:32.219Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:33:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:33:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:33:02.220Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:33:02.220Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:33:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:33:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:33:32.221Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:33:32.221Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:34:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:34:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:34:02.222Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:34:02.222Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:34:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:34:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:34:32.223Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:34:32.223Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:35:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:35:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:35:02.224Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:35:02.224Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:35:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:35:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:35:32.225Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:35:32.225Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:36:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:36:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:36:02.226Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:36:02.226Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:36:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:36:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:36:32.227Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:36:32.227Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:37:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:37:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:37:02.228Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:37:02.228Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:37:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:37:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:37:32.229Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:37:32.229Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:38:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:38:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:38:02.230Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:38:02.230Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:38:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:38:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:38:32.231Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:38:32.231Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:39:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:39:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:39:02.232Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:39:02.232Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:39:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:39:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:39:32.233Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:39:32.233Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:40:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:40:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:40:02.234Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:40:02.234Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:40:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:40:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:40:32.235Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:40:32.235Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:41:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:41:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:41:02.236Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:41:02.236Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:41:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:41:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:41:32.237Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:41:32.237Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:42:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:42:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:42:02.238Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:42:02.238Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:42:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:42:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:42:32.239Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:42:32.239Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:43:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:43:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:43:02.240Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:43:02.240Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:43:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:43:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:43:32.241Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:43:32.241Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:44:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:44:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:44:02.242Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:44:02.242Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:44:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:44:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:44:32.243Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:44:32.243Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:45:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:45:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:45:02.249Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:45:02.249Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:45:32.072Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:45:32.072Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[ns_server:debug,2020-05-07T06:45:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:45:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:45:32.250Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:45:32.250Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:46:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:46:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:46:02.251Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:46:02.251Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:46:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:46:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:46:32.252Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:46:32.252Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:47:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:47:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:47:02.253Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:47:02.253Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:47:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:47:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:47:32.254Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:47:32.254Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:48:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:48:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:48:02.255Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:48:02.255Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:48:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:48:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:48:32.256Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:48:32.256Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:49:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:49:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:49:02.257Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:49:02.257Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:49:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:49:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:49:32.258Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:49:32.258Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:50:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:50:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:50:02.259Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:50:02.259Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:50:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:50:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:50:32.260Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:50:32.260Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:51:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:51:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:51:02.261Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:51:02.261Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:51:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:51:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:51:32.262Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:51:32.262Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:52:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:52:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:52:02.263Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:52:02.263Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:52:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:52:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:52:32.264Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:52:32.264Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:53:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:53:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:53:02.265Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:53:02.265Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:53:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:53:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:53:32.266Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:53:32.266Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:54:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:54:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:54:02.267Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:54:02.267Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:54:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:54:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:54:32.268Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:54:32.268Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:55:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:55:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:55:02.269Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:55:02.269Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:55:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:55:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:55:32.270Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:55:32.270Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:56:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:56:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:56:02.271Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:56:02.271Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:56:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:56:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:56:32.272Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:56:32.272Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:57:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:57:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:57:02.273Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:57:02.273Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:57:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:57:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:57:32.274Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:57:32.274Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:58:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:58:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:58:02.275Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:58:02.275Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:58:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:58:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:58:32.276Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:58:32.276Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:59:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:59:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:59:02.277Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:59:02.277Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:59:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:59:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T06:59:32.278Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T06:59:32.278Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:00:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:00:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:00:02.279Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:00:02.279Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:00:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:00:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:00:32.280Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:00:32.280Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:01:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:01:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:01:02.280Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:01:02.280Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:01:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:01:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:01:32.281Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:01:32.281Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:02:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:02:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:02:02.282Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:02:02.282Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:02:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:02:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:02:32.283Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:02:32.283Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:03:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:03:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:03:02.284Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:03:02.284Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:03:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:03:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:03:32.285Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:03:32.285Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:04:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:04:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:04:02.286Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:04:02.286Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:04:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:04:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:04:32.287Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:04:32.287Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:05:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:05:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:05:02.288Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:05:02.288Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:05:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:05:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:05:32.289Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:05:32.289Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:06:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:06:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:06:02.290Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:06:02.290Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:06:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:06:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:06:32.291Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:06:32.291Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:07:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:07:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:07:02.292Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:07:02.292Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:07:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:07:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:07:32.293Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:07:32.293Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:08:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:08:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:08:02.294Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:08:02.294Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:08:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:08:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:08:32.295Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:08:32.295Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:09:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:09:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:09:02.296Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:09:02.296Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:09:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:09:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:09:32.297Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:09:32.297Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:10:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:10:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:10:02.298Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:10:02.298Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:10:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:10:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:10:32.299Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:10:32.299Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:11:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:11:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:11:02.300Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:11:02.300Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:11:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:11:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:11:32.301Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:11:32.301Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:12:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:12:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:12:02.302Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:12:02.302Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:12:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:12:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:12:32.303Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:12:32.303Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:13:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:13:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:13:02.304Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:13:02.304Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:13:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:13:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:13:32.305Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:13:32.305Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:14:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:14:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:14:02.306Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:14:02.306Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:14:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:14:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:14:32.307Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:14:32.307Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:15:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:15:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:15:02.308Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:15:02.308Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:15:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:15:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:15:32.309Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:15:32.309Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:16:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:16:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:16:02.310Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:16:02.310Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:16:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:16:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:16:32.311Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:16:32.311Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:17:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:17:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:17:02.312Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:17:02.312Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:17:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:17:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:17:32.313Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:17:32.313Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:18:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:18:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:18:02.314Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:18:02.314Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:18:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:18:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:18:32.315Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:18:32.315Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:19:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:19:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:19:02.316Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:19:02.316Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:19:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:19:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:19:32.317Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:19:32.317Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:20:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:20:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:20:02.318Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:20:02.318Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:20:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:20:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:20:32.319Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:20:32.319Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:21:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:21:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:21:02.320Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:21:02.320Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:21:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:21:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:21:32.321Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:21:32.321Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:22:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:22:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:22:02.322Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:22:02.322Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:22:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:22:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:22:32.323Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:22:32.323Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:23:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:23:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:23:02.324Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:23:02.324Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:23:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:23:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:23:32.325Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:23:32.325Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:24:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:24:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:24:02.326Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:24:02.326Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:24:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:24:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:24:32.327Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:24:32.327Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:25:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:25:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:25:02.328Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:25:02.328Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:25:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:25:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:25:32.329Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:25:32.329Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:26:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:26:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:26:02.330Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:26:02.330Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:26:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:26:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:26:32.331Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:26:32.331Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:27:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:27:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:27:02.332Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:27:02.332Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:27:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:27:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:27:32.333Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:27:32.333Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:28:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:28:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:28:02.334Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:28:02.334Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:28:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:28:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:28:32.335Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:28:32.335Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:29:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:29:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:29:02.336Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:29:02.336Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:29:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:29:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:29:32.337Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:29:32.337Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:30:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:30:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:30:02.338Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:30:02.338Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:30:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:30:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:30:32.339Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:30:32.339Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:31:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:31:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:31:02.340Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:31:02.340Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:31:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:31:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:31:32.341Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:31:32.341Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:32:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:32:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:32:02.342Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:32:02.342Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:32:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:32:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:32:32.343Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:32:32.343Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:33:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:33:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:33:02.344Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:33:02.344Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:33:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:33:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:33:32.345Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:33:32.345Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:34:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:34:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:34:02.346Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:34:02.346Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:34:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:34:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:34:32.347Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:34:32.347Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:35:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:35:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:35:02.348Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:35:02.348Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:35:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:35:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:35:32.349Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:35:32.349Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:36:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:36:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:36:02.350Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:36:02.350Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:36:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:36:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:36:32.351Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:36:32.351Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:37:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:37:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:37:02.352Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:37:02.352Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:37:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:37:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:37:32.353Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:37:32.353Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:38:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:38:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:38:02.354Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:38:02.354Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:38:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:38:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:38:32.355Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:38:32.355Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:39:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:39:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:39:02.356Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:39:02.356Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:39:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:39:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:39:32.357Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:39:32.357Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:40:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:40:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:40:02.358Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:40:02.358Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:40:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:40:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:40:32.359Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:40:32.359Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:41:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:41:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:41:02.360Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:41:02.360Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:41:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:41:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:41:32.361Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:41:32.361Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:42:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:42:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:42:02.362Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:42:02.362Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:42:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:42:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:42:32.363Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:42:32.363Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:43:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:43:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:43:02.364Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:43:02.364Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:43:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:43:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:43:32.365Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:43:32.365Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:44:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:44:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:44:02.366Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:44:02.366Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:44:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:44:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:44:32.367Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:44:32.367Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:45:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:45:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:45:02.368Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:45:02.368Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:45:32.073Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:45:32.073Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[ns_server:debug,2020-05-07T07:45:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:45:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:45:32.369Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:45:32.369Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:46:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:46:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:46:02.370Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:46:02.370Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:46:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:46:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:46:32.371Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:46:32.371Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:47:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:47:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:47:02.372Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:47:02.372Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:47:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:47:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:47:32.373Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:47:32.373Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:48:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:48:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:48:02.374Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:48:02.374Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:48:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:48:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:48:32.375Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:48:32.375Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:49:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:49:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:49:02.376Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:49:02.376Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:49:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:49:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:49:32.377Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:49:32.377Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:50:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:50:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:50:02.378Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:50:02.378Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:50:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:50:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:50:32.379Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:50:32.379Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:51:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:51:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:51:02.380Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:51:02.380Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:51:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:51:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:51:32.381Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:51:32.381Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:52:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:52:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:52:02.382Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:52:02.382Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:52:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:52:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:52:32.383Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:52:32.383Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:53:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:53:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:53:02.384Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:53:02.384Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:53:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:53:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:53:32.385Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:53:32.385Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:54:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:54:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:54:02.386Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:54:02.386Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:54:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:54:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:54:32.387Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:54:32.387Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:55:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:55:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:55:02.388Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:55:02.388Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:55:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:55:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:55:32.389Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:55:32.389Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:56:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:56:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:56:02.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:56:02.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:56:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:56:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:56:32.391Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:56:32.391Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:57:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:57:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:57:02.392Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:57:02.392Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:57:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:57:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:57:32.393Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:57:32.393Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:58:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:58:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:58:02.394Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:58:02.394Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:58:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:58:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:58:32.395Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:58:32.395Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:59:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:59:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:59:02.396Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:59:02.396Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:59:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:59:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T07:59:32.397Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T07:59:32.397Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:00:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:00:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:00:02.398Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:00:02.398Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:00:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:00:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:00:32.399Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:00:32.399Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:01:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:01:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:01:02.400Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:01:02.400Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:01:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:01:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:01:32.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:01:32.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:02:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:02:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:02:02.402Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:02:02.402Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:02:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:02:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:02:32.403Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:02:32.403Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:03:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:03:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:03:02.404Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:03:02.404Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:03:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:03:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:03:32.405Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:03:32.405Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:04:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:04:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:04:02.406Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:04:02.406Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:04:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:04:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:04:32.407Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:04:32.407Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:05:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:05:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:05:02.408Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:05:02.408Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:05:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:05:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:05:32.409Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:05:32.409Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:06:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:06:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:06:02.410Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:06:02.410Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:06:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:06:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:06:32.411Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:06:32.411Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:07:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:07:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:07:02.412Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:07:02.412Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:07:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:07:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:07:32.413Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:07:32.413Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:08:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:08:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:08:02.414Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:08:02.414Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:08:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:08:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:08:32.415Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:08:32.415Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:09:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:09:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:09:02.416Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:09:02.416Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:09:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:09:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:09:32.417Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:09:32.417Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:10:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:10:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:10:02.418Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:10:02.418Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:10:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:10:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:10:32.419Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:10:32.419Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:11:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:11:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:11:02.420Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:11:02.420Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:11:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:11:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:11:32.421Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:11:32.421Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:12:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:12:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:12:02.422Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:12:02.422Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:12:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:12:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:12:32.423Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:12:32.423Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:13:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:13:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:13:02.424Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:13:02.424Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:13:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:13:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:13:32.425Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:13:32.425Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:14:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:14:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:14:02.426Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:14:02.426Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:14:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:14:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:14:32.427Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:14:32.427Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:15:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:15:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:15:02.428Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:15:02.428Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:15:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:15:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:15:32.429Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:15:32.429Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:16:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:16:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:16:02.430Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:16:02.430Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:16:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:16:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:16:32.431Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:16:32.431Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:17:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:17:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:17:02.432Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:17:02.432Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:17:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:17:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:17:32.433Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:17:32.433Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:18:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:18:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:18:02.434Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:18:02.434Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:18:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:18:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:18:32.435Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:18:32.435Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:19:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:19:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:19:02.436Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:19:02.436Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:19:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:19:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:19:32.437Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:19:32.437Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:20:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:20:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:20:02.438Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:20:02.438Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:20:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:20:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:20:32.439Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:20:32.439Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:21:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:21:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:21:02.440Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:21:02.440Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:21:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:21:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:21:32.441Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:21:32.441Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:22:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:22:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:22:02.442Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:22:02.442Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:22:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:22:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:22:32.443Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:22:32.443Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:23:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:23:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:23:02.444Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:23:02.444Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:23:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:23:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:23:32.445Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:23:32.445Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:24:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:24:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:24:02.446Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:24:02.446Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:24:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:24:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:24:32.447Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:24:32.447Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:25:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:25:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:25:02.448Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:25:02.448Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:25:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:25:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:25:32.449Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:25:32.449Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:26:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:26:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:26:02.450Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:26:02.450Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:26:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:26:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:26:32.451Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:26:32.451Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:27:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:27:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:27:02.452Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:27:02.452Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:27:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:27:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:27:32.453Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:27:32.453Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:28:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:28:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:28:02.454Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:28:02.454Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:28:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:28:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:28:32.455Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:28:32.455Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:29:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:29:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:29:02.456Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:29:02.456Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:29:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:29:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:29:32.457Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:29:32.457Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:30:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:30:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:30:02.458Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:30:02.458Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:30:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:30:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:30:32.459Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:30:32.459Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:31:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:31:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:31:02.460Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:31:02.460Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:31:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:31:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:31:32.461Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:31:32.461Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:32:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:32:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:32:02.462Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:32:02.462Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:32:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:32:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:32:32.463Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:32:32.463Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:33:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:33:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:33:02.464Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:33:02.464Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:33:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:33:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:33:32.465Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:33:32.465Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:34:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:34:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:34:02.466Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:34:02.466Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:34:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:34:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:34:32.467Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:34:32.467Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:35:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:35:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:35:02.468Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:35:02.468Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:35:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:35:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:35:32.469Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:35:32.469Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:36:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:36:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:36:02.470Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:36:02.470Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:36:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:36:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:36:32.471Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:36:32.471Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:37:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:37:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:37:02.472Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:37:02.472Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:37:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:37:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:37:32.473Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:37:32.473Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:38:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:38:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:38:02.474Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:38:02.474Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:38:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:38:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:38:32.475Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:38:32.475Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:39:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:39:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:39:02.476Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:39:02.476Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:39:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:39:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:39:32.477Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:39:32.477Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:40:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:40:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:40:02.478Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:40:02.478Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:40:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:40:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:40:32.479Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:40:32.479Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:41:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:41:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:41:02.480Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:41:02.480Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:41:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:41:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:41:32.481Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:41:32.481Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:42:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:42:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:42:02.482Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:42:02.482Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:42:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:42:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:42:32.483Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:42:32.483Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:43:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:43:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:43:02.484Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:43:02.484Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:43:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:43:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:43:32.485Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:43:32.485Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:44:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:44:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:44:02.486Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:44:02.486Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:44:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:44:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:44:32.487Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:44:32.487Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:45:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:45:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:45:02.488Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:45:02.488Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:45:32.074Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:45:32.074Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[ns_server:debug,2020-05-07T08:45:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:45:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:45:32.489Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:45:32.489Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:46:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:46:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:46:02.490Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:46:02.490Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:46:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:46:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:46:32.491Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:46:32.491Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:47:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:47:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:47:02.492Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:47:02.492Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:47:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:47:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:47:32.493Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:47:32.493Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:48:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:48:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:48:02.494Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:48:02.494Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:48:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:48:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:48:32.495Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:48:32.495Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:49:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:49:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:49:02.496Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:49:02.496Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:49:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:49:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:49:32.497Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:49:32.497Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:50:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:50:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:50:02.498Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:50:02.498Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:50:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:50:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:50:32.499Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:50:32.499Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:51:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:51:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:51:02.500Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:51:02.500Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:51:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:51:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:51:32.501Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:51:32.501Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:52:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:52:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:52:02.502Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:52:02.502Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:52:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:52:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:52:32.503Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:52:32.503Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:53:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:53:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:53:02.504Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:53:02.504Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:53:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:53:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:53:32.505Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:53:32.505Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:54:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:54:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:54:02.506Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:54:02.506Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:54:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:54:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:54:32.507Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:54:32.507Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:55:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:55:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:55:02.508Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:55:02.508Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:55:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:55:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:55:32.509Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:55:32.509Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:56:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:56:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:56:02.510Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:56:02.510Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:56:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:56:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:56:32.511Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:56:32.511Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:57:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:57:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:57:02.512Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:57:02.512Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:57:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:57:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:57:32.513Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:57:32.513Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:58:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:58:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:58:02.514Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:58:02.514Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:58:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:58:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:58:32.515Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:58:32.515Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:59:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:59:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:59:02.516Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:59:02.516Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:59:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:59:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T08:59:32.517Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T08:59:32.517Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:00:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:00:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:00:02.518Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:00:02.518Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:00:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:00:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:00:32.519Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:00:32.519Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:01:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:01:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:01:02.520Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:01:02.520Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:01:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:01:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:01:32.521Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:01:32.521Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:02:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:02:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:02:02.522Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:02:02.522Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:02:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:02:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:02:32.523Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:02:32.523Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:03:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:03:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:03:02.524Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:03:02.524Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:03:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:03:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:03:32.525Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:03:32.525Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:04:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:04:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:04:02.526Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:04:02.526Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:04:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:04:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:04:32.527Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:04:32.527Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:05:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:05:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:05:02.528Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:05:02.528Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:05:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:05:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:05:32.529Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:05:32.529Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:06:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:06:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:06:02.530Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:06:02.530Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:06:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:06:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:06:32.531Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:06:32.531Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:07:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:07:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:07:02.532Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:07:02.532Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:07:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:07:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:07:32.533Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:07:32.533Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:08:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:08:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:08:02.534Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:08:02.534Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:08:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:08:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:08:32.535Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:08:32.535Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:09:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:09:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:09:02.536Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:09:02.536Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:09:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:09:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:09:32.537Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:09:32.537Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:10:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:10:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:10:02.538Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:10:02.538Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:10:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:10:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:10:32.539Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:10:32.539Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:11:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:11:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:11:02.540Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:11:02.540Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:11:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:11:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:11:32.541Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:11:32.541Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:12:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:12:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:12:02.542Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:12:02.542Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:12:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:12:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:12:32.543Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:12:32.543Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:13:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:13:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:13:02.544Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:13:02.544Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:13:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:13:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:13:32.545Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:13:32.545Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:14:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:14:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:14:02.546Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:14:02.546Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:14:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:14:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:14:32.547Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:14:32.547Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:15:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:15:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:15:02.548Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:15:02.548Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:15:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:15:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:15:32.549Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:15:32.549Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:16:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:16:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:16:02.550Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:16:02.550Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:16:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:16:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:16:32.551Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:16:32.551Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:17:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:17:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:17:02.552Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:17:02.552Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:17:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:17:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:17:32.553Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:17:32.553Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:18:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:18:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:18:02.554Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:18:02.554Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:18:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:18:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:18:32.555Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:18:32.555Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:19:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:19:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:19:02.556Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:19:02.556Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:19:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:19:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:19:32.557Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:19:32.557Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:20:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:20:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:20:02.558Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:20:02.558Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:20:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:20:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:20:32.559Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:20:32.559Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:21:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:21:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:21:02.560Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:21:02.560Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:21:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:21:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:21:32.561Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:21:32.561Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:22:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:22:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:22:02.562Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:22:02.562Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:22:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:22:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:22:32.563Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:22:32.563Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:23:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:23:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:23:02.564Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:23:02.564Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:23:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:23:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:23:32.565Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:23:32.565Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:24:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:24:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:24:02.566Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:24:02.566Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:24:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:24:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:24:32.567Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:24:32.567Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:25:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:25:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:25:02.568Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:25:02.568Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:25:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:25:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:25:32.569Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:25:32.569Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:26:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:26:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:26:02.570Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:26:02.570Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:26:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:26:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:26:32.571Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:26:32.571Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:27:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:27:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:27:02.572Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:27:02.572Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:27:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:27:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:27:32.573Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:27:32.573Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:28:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:28:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:28:02.574Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:28:02.574Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:28:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:28:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:28:32.575Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:28:32.575Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:29:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:29:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:29:02.576Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:29:02.576Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:29:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:29:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:29:32.577Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:29:32.577Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:30:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:30:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:30:02.578Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:30:02.578Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:30:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:30:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:30:32.579Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:30:32.579Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:31:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:31:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:31:02.580Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:31:02.580Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:31:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:31:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:31:32.581Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:31:32.581Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:32:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:32:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:32:02.582Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:32:02.582Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:32:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:32:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:32:32.583Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:32:32.583Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:33:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:33:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:33:02.584Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:33:02.584Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:33:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:33:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:33:32.585Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:33:32.585Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:34:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:34:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:34:02.586Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:34:02.586Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:34:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:34:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:34:32.587Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:34:32.587Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:35:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:35:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:35:02.588Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:35:02.588Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:35:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:35:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:35:32.589Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:35:32.589Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:36:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:36:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:36:02.590Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:36:02.590Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:36:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:36:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:36:32.591Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:36:32.591Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:37:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:37:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:37:02.592Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:37:02.592Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:37:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:37:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:37:32.593Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:37:32.593Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:38:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:38:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:38:02.594Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:38:02.594Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:38:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:38:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:38:32.595Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:38:32.595Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:39:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:39:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:39:02.596Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:39:02.596Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:39:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:39:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:39:32.597Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:39:32.597Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:40:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:40:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:40:02.598Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:40:02.598Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:40:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:40:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:40:32.599Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:40:32.599Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:41:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:41:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:41:02.600Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:41:02.600Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:41:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:41:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:41:32.601Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:41:32.601Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:42:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:42:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:42:02.602Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:42:02.602Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:42:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:42:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:42:32.603Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:42:32.603Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:43:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:43:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:43:02.604Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:43:02.604Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:43:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:43:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:43:32.605Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:43:32.605Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:44:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:44:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:44:02.606Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:44:02.606Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:44:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:44:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:44:32.607Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:44:32.607Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:45:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:45:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:45:02.608Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:45:02.608Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:45:32.075Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:45:32.075Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[ns_server:debug,2020-05-07T09:45:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:45:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:45:32.609Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:45:32.609Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:46:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:46:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:46:02.610Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:46:02.610Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:46:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:46:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:46:32.611Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:46:32.611Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:47:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:47:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:47:02.612Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:47:02.612Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:47:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:47:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:47:32.613Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:47:32.613Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:48:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:48:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:48:02.614Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:48:02.614Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:48:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:48:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:48:32.615Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:48:32.615Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:49:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:49:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:49:02.616Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:49:02.616Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:49:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:49:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:49:32.617Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:49:32.617Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:50:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:50:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:50:02.618Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:50:02.618Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:50:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:50:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:50:32.619Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:50:32.619Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:51:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:51:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:51:02.620Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:51:02.620Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:51:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:51:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:51:32.621Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:51:32.621Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:52:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:52:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:52:02.622Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:52:02.622Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:52:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:52:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:52:32.623Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:52:32.623Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:53:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:53:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:53:02.624Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:53:02.624Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:53:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:53:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:53:32.625Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:53:32.625Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:54:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:54:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:54:02.626Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:54:02.626Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:54:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:54:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:54:32.627Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:54:32.627Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:55:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:55:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:55:02.628Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:55:02.628Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:55:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:55:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:55:32.629Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:55:32.629Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:56:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:56:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:56:02.630Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:56:02.630Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:56:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:56:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:56:32.631Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:56:32.631Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:57:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:57:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:57:02.632Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:57:02.632Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:57:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:57:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:57:32.633Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:57:32.633Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:58:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:58:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:58:02.634Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:58:02.634Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:58:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:58:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:58:32.635Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:58:32.635Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:59:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:59:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:59:02.636Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:59:02.636Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:59:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:59:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T09:59:32.637Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T09:59:32.637Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:00:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:00:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:00:02.638Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:00:02.638Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:00:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:00:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:00:32.639Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:00:32.639Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:01:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:01:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:01:02.640Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:01:02.640Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:01:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:01:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:01:32.641Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:01:32.641Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:02:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:02:02.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:02:02.642Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:02:02.642Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:02:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:02:32.187Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:02:32.643Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:02:32.643Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:03:02.194Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:03:02.194Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:03:02.644Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:03:02.644Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:03:32.195Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:03:32.195Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:03:32.645Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:03:32.645Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:04:02.196Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:04:02.196Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:04:02.646Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:04:02.646Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:04:32.197Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:04:32.197Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:04:32.647Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:04:32.647Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:05:02.198Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:05:02.198Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:05:02.648Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:05:02.648Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:05:32.199Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:05:32.199Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:05:32.649Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:05:32.649Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:06:02.200Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:06:02.200Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:06:02.650Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:06:02.650Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:06:32.201Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:06:32.201Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:06:32.651Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:06:32.651Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:07:02.202Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:07:02.202Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:07:02.652Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:07:02.652Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:07:32.203Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:07:32.203Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:07:32.653Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:07:32.653Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:08:02.204Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:08:02.204Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:08:02.654Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:08:02.654Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:08:32.205Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:08:32.205Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:08:32.655Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:08:32.655Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:09:02.206Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:09:02.206Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:09:02.656Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:09:02.656Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:09:32.207Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:09:32.207Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:09:32.657Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:09:32.657Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:10:02.208Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:10:02.208Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:10:02.658Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:10:02.658Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:10:32.209Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:10:32.209Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:10:32.659Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:10:32.659Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:11:02.210Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:11:02.210Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:11:02.660Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:11:02.660Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:11:32.211Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:11:32.211Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:11:32.661Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:11:32.661Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:12:02.212Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:12:02.212Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:12:02.662Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:12:02.662Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:12:32.213Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:12:32.213Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:12:32.663Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:12:32.663Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:13:02.214Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:13:02.214Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:13:02.664Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:13:02.664Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:13:32.215Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:13:32.215Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:13:32.665Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:13:32.665Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:14:02.216Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:14:02.216Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:14:02.666Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:14:02.666Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:14:32.217Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:14:32.217Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:14:32.667Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:14:32.667Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:15:02.218Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:15:02.218Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:15:02.668Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:15:02.668Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:15:32.219Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:15:32.219Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:15:32.669Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:15:32.669Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:16:02.220Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:16:02.220Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:16:02.670Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:16:02.670Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:16:32.221Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:16:32.221Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:16:32.671Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:16:32.671Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:17:02.222Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:17:02.222Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:17:02.672Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:17:02.672Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:17:32.223Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:17:32.223Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:17:32.673Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:17:32.673Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:18:02.224Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:18:02.224Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:18:02.674Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:18:02.674Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:18:32.225Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:18:32.225Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:18:32.675Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:18:32.675Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:19:02.226Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:19:02.226Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:19:02.676Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:19:02.676Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:19:32.227Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:19:32.227Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:19:32.677Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:19:32.677Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:20:02.228Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:20:02.228Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:20:02.678Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:20:02.678Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:20:32.229Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:20:32.229Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:20:32.679Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:20:32.679Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:21:02.230Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:21:02.230Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:21:02.680Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:21:02.680Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:21:32.231Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:21:32.231Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:21:32.680Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:21:32.680Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:22:02.232Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:22:02.232Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:22:02.681Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:22:02.681Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:22:32.233Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:22:32.233Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:22:32.682Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:22:32.682Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:23:02.234Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:23:02.234Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:23:02.683Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:23:02.683Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:23:32.235Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:23:32.235Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:23:32.684Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:23:32.684Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:24:02.236Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:24:02.236Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:24:02.685Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:24:02.685Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:24:32.237Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:24:32.237Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:24:32.686Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:24:32.686Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:25:02.238Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:25:02.238Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:25:02.687Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:25:02.687Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:25:32.239Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:25:32.239Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:25:32.688Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:25:32.688Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:26:02.240Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:26:02.240Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:26:02.689Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:26:02.689Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:26:32.241Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:26:32.241Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:26:32.690Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:26:32.690Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:27:02.242Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:27:02.242Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:27:02.691Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:27:02.691Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:27:32.243Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:27:32.243Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:27:32.692Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:27:32.692Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:28:02.244Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:28:02.244Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:28:02.693Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:28:02.693Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:28:32.245Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:28:32.245Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:28:32.694Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:28:32.694Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:29:02.246Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:29:02.246Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:29:02.695Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:29:02.695Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:29:32.247Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:29:32.247Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:29:32.696Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:29:32.696Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:30:02.248Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:30:02.248Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:30:02.697Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:30:02.697Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:30:32.249Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:30:32.249Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:30:32.698Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:30:32.698Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:31:02.250Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:31:02.250Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:31:02.699Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:31:02.699Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:31:32.251Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:31:32.251Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:31:32.700Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:31:32.700Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:32:02.252Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:32:02.252Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:32:02.701Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:32:02.701Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:32:32.253Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:32:32.253Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:32:32.702Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:32:32.702Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:33:02.254Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:33:02.254Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:33:02.703Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:33:02.703Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:33:32.255Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:33:32.255Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:33:32.704Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:33:32.704Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:34:02.256Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:34:02.256Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:34:02.705Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:34:02.705Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:34:32.257Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:34:32.257Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:34:32.706Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:34:32.706Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:35:02.258Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:35:02.258Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:35:02.707Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:35:02.707Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:35:32.259Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:35:32.259Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:35:32.708Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:35:32.708Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:36:02.260Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:36:02.260Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:36:02.709Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:36:02.709Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:36:32.261Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:36:32.261Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:36:32.710Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:36:32.710Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:37:02.262Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:37:02.262Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:37:02.711Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:37:02.711Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:37:32.263Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:37:32.263Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:37:32.712Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:37:32.712Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:38:02.264Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:38:02.264Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:38:02.713Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:38:02.713Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:38:32.265Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:38:32.265Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:38:32.714Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:38:32.714Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:39:02.266Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:39:02.266Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:39:02.715Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:39:02.715Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:39:32.267Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:39:32.267Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:39:32.716Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:39:32.716Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:40:02.268Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:40:02.268Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:40:02.717Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:40:02.717Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:40:32.269Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:40:32.269Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:40:32.718Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:40:32.718Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:41:02.270Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:41:02.270Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:41:02.719Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:41:02.719Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:41:32.271Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:41:32.271Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:41:32.722Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:41:32.722Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:42:02.272Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:42:02.272Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:42:02.723Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:42:02.723Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:42:32.273Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:42:32.273Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:42:32.724Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:42:32.724Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:43:02.274Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:43:02.274Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:43:02.725Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:43:02.725Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:43:32.275Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:43:32.275Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:43:32.726Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:43:32.726Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:44:02.276Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:44:02.276Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:44:02.727Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:44:02.727Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:44:32.277Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:44:32.277Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:44:32.728Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:44:32.728Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:45:02.278Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:45:02.278Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:45:02.729Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:45:02.729Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:45:32.076Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:45:32.076Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[ns_server:debug,2020-05-07T10:45:32.279Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:45:32.279Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:45:32.730Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:45:32.730Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:46:02.280Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:46:02.280Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:46:02.731Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:46:02.731Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:46:32.281Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:46:32.281Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:46:32.732Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:46:32.732Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:47:02.282Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:47:02.282Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:47:02.733Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:47:02.733Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:47:32.283Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:47:32.283Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:47:32.734Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:47:32.734Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:48:02.284Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:48:02.284Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:48:02.735Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:48:02.735Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:48:32.285Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:48:32.285Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:48:32.736Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:48:32.736Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:49:02.286Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:49:02.286Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:49:02.737Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:49:02.737Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:49:32.287Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:49:32.287Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:49:32.738Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:49:32.738Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:50:02.293Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:50:02.293Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:50:02.739Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:50:02.739Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:50:32.295Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:50:32.295Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:50:32.740Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:50:32.740Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:51:02.296Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:51:02.296Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:51:02.741Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:51:02.741Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:51:32.297Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:51:32.297Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:51:32.742Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:51:32.742Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:52:02.298Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:52:02.298Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:52:02.743Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:52:02.743Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:52:32.299Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:52:32.299Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:52:32.744Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:52:32.744Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:53:02.300Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:53:02.300Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:53:02.745Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:53:02.745Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:53:32.301Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:53:32.301Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:53:32.746Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:53:32.746Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:54:02.302Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:54:02.302Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:54:02.747Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:54:02.747Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:54:32.303Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:54:32.303Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:54:32.748Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:54:32.748Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:55:02.304Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:55:02.304Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:55:02.749Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:55:02.749Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:55:32.305Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:55:32.305Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:55:32.750Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:55:32.750Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:56:02.306Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:56:02.306Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:56:02.751Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:56:02.751Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:56:32.307Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:56:32.307Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:56:32.752Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:56:32.752Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:57:02.308Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:57:02.308Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:57:02.753Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:57:02.753Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:57:32.309Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:57:32.309Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:57:32.754Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:57:32.754Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:58:02.310Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:58:02.310Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:58:02.755Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:58:02.755Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:58:32.311Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:58:32.311Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:58:32.756Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:58:32.756Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:59:02.312Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:59:02.312Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:59:02.757Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:59:02.757Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:59:32.313Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:59:32.313Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T10:59:32.758Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T10:59:32.758Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:00:02.314Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:00:02.314Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:00:02.759Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:00:02.759Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:00:32.315Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:00:32.315Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:00:32.760Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:00:32.760Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:01:02.316Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:01:02.316Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:01:02.761Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:01:02.761Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:01:32.317Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:01:32.317Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:01:32.762Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:01:32.762Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:02:02.318Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:02:02.318Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:02:02.763Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:02:02.763Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:02:32.319Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:02:32.319Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:02:32.764Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:02:32.764Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:03:02.320Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:03:02.320Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:03:02.765Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:03:02.765Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:03:32.321Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:03:32.321Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:03:32.766Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:03:32.766Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:04:02.322Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:04:02.322Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:04:02.767Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:04:02.767Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:04:32.323Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:04:32.323Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:04:32.768Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:04:32.768Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:05:02.324Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:05:02.324Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:05:02.769Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:05:02.769Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:05:32.325Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:05:32.325Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:05:32.770Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:05:32.770Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:06:02.326Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:06:02.326Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:06:02.771Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:06:02.771Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:06:32.327Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:06:32.327Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:06:32.772Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:06:32.772Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:07:02.328Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:07:02.328Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:07:02.773Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:07:02.773Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:07:32.329Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:07:32.329Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:07:32.774Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:07:32.774Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:08:02.330Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:08:02.330Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:08:02.775Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:08:02.775Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:08:32.331Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:08:32.331Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:08:32.776Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:08:32.776Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:09:02.332Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:09:02.332Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:09:02.777Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:09:02.777Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:09:32.333Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:09:32.333Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:09:32.778Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:09:32.778Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:10:02.334Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:10:02.334Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:10:02.779Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:10:02.779Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:10:32.335Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:10:32.335Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:10:32.780Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:10:32.780Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:11:02.336Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:11:02.336Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:11:02.781Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:11:02.781Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:11:32.337Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:11:32.337Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:11:32.782Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:11:32.782Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:12:02.338Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:12:02.338Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:12:02.783Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:12:02.783Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:12:32.339Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:12:32.339Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:12:32.784Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:12:32.784Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:13:02.340Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:13:02.340Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:13:02.785Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:13:02.785Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:13:32.341Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:13:32.341Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:13:32.786Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:13:32.786Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:14:02.342Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:14:02.342Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:14:02.787Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:14:02.787Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:14:32.343Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:14:32.343Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:14:32.788Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:14:32.788Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:15:02.344Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:15:02.344Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:15:02.789Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:15:02.789Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:15:32.345Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:15:32.345Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:15:32.790Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:15:32.790Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:16:02.346Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:16:02.346Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:16:02.791Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:16:02.791Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:16:32.347Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:16:32.347Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:16:32.792Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:16:32.792Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:17:02.348Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:17:02.348Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:17:02.793Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:17:02.793Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:17:32.349Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:17:32.349Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:17:32.794Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:17:32.794Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:18:02.350Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:18:02.350Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:18:02.795Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:18:02.795Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:18:32.351Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:18:32.351Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:18:32.796Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:18:32.796Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:19:02.352Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:19:02.352Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:19:02.797Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:19:02.797Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:19:32.353Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:19:32.353Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:19:32.798Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:19:32.798Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:20:02.354Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:20:02.354Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:20:02.799Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:20:02.799Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:20:32.355Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:20:32.355Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:20:32.800Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:20:32.800Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:21:02.356Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:21:02.356Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:21:02.801Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:21:02.801Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:21:32.356Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:21:32.356Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:21:32.802Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:21:32.802Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:22:02.357Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:22:02.357Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:22:02.803Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:22:02.803Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:22:32.358Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:22:32.358Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:22:32.804Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:22:32.804Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:23:02.359Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:23:02.359Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:23:02.805Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:23:02.805Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:23:32.360Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:23:32.360Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:23:32.806Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:23:32.806Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:24:02.361Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:24:02.361Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:24:02.807Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:24:02.807Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:24:32.362Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:24:32.362Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:24:32.808Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:24:32.808Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:25:02.363Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:25:02.363Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:25:02.809Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:25:02.809Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:25:32.364Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:25:32.364Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:25:32.810Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:25:32.810Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:26:02.365Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:26:02.365Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:26:02.811Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:26:02.811Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:26:32.366Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:26:32.366Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:26:32.812Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:26:32.812Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:27:02.367Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:27:02.367Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:27:02.813Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:27:02.813Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:27:32.368Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:27:32.368Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:27:32.814Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:27:32.814Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:28:02.369Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:28:02.369Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:28:02.815Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:28:02.815Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:28:32.370Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:28:32.370Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:28:32.816Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:28:32.816Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:29:02.371Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:29:02.371Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:29:02.817Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:29:02.817Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:29:32.372Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:29:32.372Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:29:32.818Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:29:32.818Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:30:02.373Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:30:02.373Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:30:02.819Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:30:02.819Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:30:32.374Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:30:32.374Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:30:32.820Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:30:32.820Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:31:02.375Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:31:02.375Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:31:02.821Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:31:02.821Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:31:32.376Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:31:32.376Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:31:32.822Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:31:32.822Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:32:02.377Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:32:02.377Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:32:02.823Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:32:02.823Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:32:32.378Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:32:32.378Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:32:32.824Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:32:32.824Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:33:02.379Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:33:02.379Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:33:02.825Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:33:02.825Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:33:32.380Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:33:32.380Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:33:32.826Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:33:32.826Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:34:02.381Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:34:02.381Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:34:02.827Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:34:02.827Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:34:32.382Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:34:32.382Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:34:32.828Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:34:32.828Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:35:02.383Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:35:02.383Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:35:02.829Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:35:02.829Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:35:32.384Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:35:32.384Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:35:32.830Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:35:32.830Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:36:02.385Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:36:02.385Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:36:02.831Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:36:02.831Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:36:32.386Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:36:32.386Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:36:32.832Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:36:32.832Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:37:02.387Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:37:02.387Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:37:02.833Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:37:02.833Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:37:32.388Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:37:32.388Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:37:32.834Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:37:32.834Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:38:02.389Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:38:02.389Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:38:02.835Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:38:02.835Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:38:32.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:38:32.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:38:32.836Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:38:32.836Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:39:02.391Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:39:02.391Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:39:02.837Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:39:02.837Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:39:32.392Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:39:32.392Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:39:32.838Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:39:32.838Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:40:02.393Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:40:02.393Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:40:02.839Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:40:02.839Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:40:32.394Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:40:32.394Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:40:32.840Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:40:32.840Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:41:02.395Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:41:02.395Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:41:02.841Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:41:02.841Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:41:32.396Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:41:32.396Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:41:32.842Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:41:32.842Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:42:02.397Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:42:02.397Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:42:02.843Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:42:02.843Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:42:32.398Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:42:32.398Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:42:32.844Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:42:32.844Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:43:02.399Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:43:02.399Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:43:02.845Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:43:02.845Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:43:32.400Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:43:32.400Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:43:32.846Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:43:32.846Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:44:02.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:44:02.401Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:44:02.847Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:44:02.847Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:44:32.402Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:44:32.402Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:44:32.848Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:44:32.848Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:45:02.403Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:45:02.403Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:45:02.849Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:45:02.849Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:45:32.077Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:45:32.077Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[ns_server:debug,2020-05-07T11:45:32.404Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:45:32.404Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:45:32.850Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:45:32.850Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:46:02.405Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:46:02.405Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:46:02.851Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:46:02.851Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:46:32.406Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:46:32.406Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:46:32.852Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:46:32.852Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:47:02.407Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:47:02.407Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:47:02.853Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:47:02.853Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:47:32.408Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:47:32.408Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:47:32.854Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:47:32.854Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:48:02.409Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:48:02.409Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:48:02.855Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:48:02.855Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:48:32.410Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:48:32.410Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:48:32.856Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:48:32.856Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:49:02.411Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:49:02.411Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:49:02.857Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:49:02.857Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:49:32.412Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:49:32.412Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:49:32.858Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:49:32.858Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:50:02.413Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:50:02.413Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:50:02.859Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:50:02.859Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:50:32.414Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:50:32.414Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:50:32.860Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:50:32.860Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:51:02.415Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:51:02.415Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:51:02.861Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:51:02.861Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:51:32.416Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:51:32.416Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:51:32.862Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:51:32.862Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:52:02.417Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:52:02.417Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:52:02.863Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:52:02.863Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:52:32.418Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:52:32.418Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:52:32.864Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:52:32.864Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:53:02.419Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:53:02.419Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:53:02.865Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:53:02.865Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:53:32.420Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:53:32.420Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:53:32.866Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:53:32.866Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:54:02.421Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:54:02.421Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:54:02.867Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:54:02.867Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:54:32.422Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:54:32.422Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:54:32.868Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:54:32.868Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:55:02.423Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:55:02.423Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:55:02.869Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:55:02.869Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:55:32.424Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:55:32.424Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:55:32.870Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:55:32.870Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:56:02.425Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:56:02.425Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:56:02.871Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:56:02.871Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:56:32.426Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:56:32.426Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:56:32.872Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:56:32.872Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:57:02.427Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:57:02.427Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:57:02.873Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:57:02.873Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:57:32.428Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:57:32.428Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:57:32.874Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:57:32.874Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:58:02.429Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:58:02.429Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:58:02.875Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:58:02.875Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:58:32.430Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:58:32.430Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:58:32.876Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:58:32.876Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:59:02.431Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:59:02.431Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:59:02.877Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:59:02.877Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:59:32.432Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:59:32.432Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T11:59:32.878Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T11:59:32.878Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:00:02.433Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:00:02.433Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:00:02.879Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:00:02.879Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:00:32.434Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:00:32.434Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:00:32.880Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:00:32.880Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:01:02.435Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:01:02.435Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:01:02.881Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:01:02.881Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:01:32.436Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:01:32.436Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:01:32.882Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:01:32.882Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:02:02.437Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:02:02.437Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:02:02.883Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:02:02.883Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:02:32.438Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:02:32.438Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:02:32.884Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:02:32.884Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:03:02.439Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:03:02.439Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:03:02.885Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:03:02.885Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:03:32.440Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:03:32.440Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:03:32.886Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:03:32.886Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:04:02.441Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:04:02.441Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:04:02.887Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:04:02.887Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:04:32.442Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:04:32.442Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:04:32.888Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:04:32.888Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:05:02.443Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:05:02.443Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:05:02.889Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:05:02.889Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:05:32.444Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:05:32.444Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:05:32.890Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:05:32.890Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:06:02.445Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:06:02.445Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:06:02.891Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:06:02.891Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:06:32.446Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:06:32.446Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:06:32.892Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:06:32.892Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:07:02.447Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:07:02.447Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:07:02.893Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:07:02.893Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:07:32.448Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:07:32.448Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:07:32.894Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:07:32.894Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:08:02.449Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:08:02.449Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:08:02.895Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:08:02.895Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:08:32.450Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:08:32.450Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:08:32.896Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:08:32.896Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:09:02.451Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:09:02.451Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:09:02.897Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:09:02.897Z,ns_1@127.0.0.1:compaction_new_daemon<0.428.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:info,2020-05-07T12:09:33.702Z,nonode@nohost:<0.89.0>:ns_server:init_logging:150]Started & configured logging
[ns_server:info,2020-05-07T12:09:33.713Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_access,info},
 {disk_sink_opts,[{rotation,[{compress,true},
                             {size,41943040},
                             {num_files,10},
                             {buffer_size_max,52428800}]}]},
 {disk_sink_opts_json_rpc,[{rotation,[{compress,true},
                                      {size,41943040},
                                      {num_files,2},
                                      {buffer_size_max,52428800}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2020-05-07T12:09:33.713Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.713Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.713Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.713Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.713Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.713Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.713Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.713Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_json_rpc, which is given from command line
[ns_server:warn,2020-05-07T12:09:33.714Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2020-05-07T12:09:33.729Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.138.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:33.734Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,76}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-378cfab] [64-bit] [smp:2:2] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2020,5,7},{12,9,33}}},
               {memory,
                   [{total,110236400},
                    {processes,9362920},
                    {processes_used,9362016},
                    {system,100873480},
                    {atom,339441},
                    {atom_used,322610},
                    {binary,78472},
                    {code,7796739},
                    {ets,2241528}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,path_config,calendar,
                    ale_default_formatter,'ale_logger-metakv',
                    'ale_logger-rebalance','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-json_rpc',
                    'ale_logger-access','ale_logger-ns_server',
                    'ale_logger-user','ale_logger-ns_doctor',io_lib_fread,
                    'ale_logger-cluster','ale_logger-xdcr',otp_internal,
                    ns_log_sink,ale_disk_sink,misc,couch_util,ns_server,
                    filelib,cpu_sup,memsup,disksup,os_mon,io,release_handler,
                    overload,alarm_handler,sasl,timer,tftp_sup,httpd_sup,
                    httpc_handler_sup,httpc_cookie,inets_trace,httpc_manager,
                    httpc,httpc_profile_sup,httpc_sup,ftp_sup,inets_sup,
                    inets_app,ssl,lhttpc_manager,lhttpc_sup,lhttpc,
                    tls_connection_sup,ssl_session_cache,ssl_pkix_db,
                    ssl_manager,ssl_sup,ssl_app,crypto_server,crypto_sup,
                    crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_io,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","6.0.3-2895-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","6.0.3-2895-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,105},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [lhttpc_sup,code_server,ale_stats_events,'sink-ns_log',
                    ns_server_cluster_sup,lhttpc_manager,
                    application_controller,ale,httpd_sup,release_handler,
                    kernel_safe_sup,standard_error,ale_sup,overload,
                    'sink-disk_json_rpc',error_logger,alarm_handler,
                    'sink-disk_metakv',ale_dynamic_sup,timer_server,
                    'sink-disk_access_int',standard_error_sup,
                    'sink-disk_access','sink-disk_reports',crypto_server,
                    crypto_sup,sasl_safe_sup,'sink-disk_stats',
                    'sink-disk_xdcr',tftp_sup,inet_db,init,os_mon_sup,
                    'sink-disk_debug',rex,tls_connection_sup,user,
                    'sink-disk_error',ssl_sup,kernel_sup,cpu_sup,
                    global_name_server,memsup,'sink-disk_default',disksup,
                    httpc_sup,file_server_2,ssl_manager,local_tasks,
                    global_group,httpc_profile_sup,httpc_manager,
                    httpc_handler_sup,ftp_sup,sasl_sup,erl_prim_loader,
                    inets_sup]},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,1}]
[ns_server:info,2020-05-07T12:09:33.740Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:27]Manifest:
["<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\" />",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\" />",
 "  ","  <default remote=\"couchbase\" revision=\"master\" />","  ",
 "  <project groups=\"kv\" name=\"HdrHistogram_c\" path=\"third_party/HdrHistogram_c\" remote=\"couchbasedeps\" revision=\"d200fc0f68695d4aef1fad5c3c8cc55f8c033014\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"analytics-dcp-client\" path=\"analytics/java-dcp-client\" revision=\"d6ba66b51c0e589e9d4571264afcb0e33d507aea\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"asterixdb\" path=\"analytics/asterixdb\" revision=\"e8e59d0e6e72ba3fd96074c021ff7180261dcd59\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"c5b9dd8ec0910d2890d215075a7d2da1d6a494c9\" />",
 "  <project groups=\"kv\" name=\"benchmark\" remote=\"couchbasedeps\" revision=\"9e3465560240ffb242b50a47cb7f19251a12ee42\" />",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\" />",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5cd1345cca3ed72f1e63d41d622fcda73e63fea8\" />",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"822d01dab8721cf469beb6d8304c9eadd9c58160\" />",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"f551b6d4f32bb920a83dd28c705bddd5de0d03b2\" />",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"4b158bb555a3297565afecf6fae675c74f1e47df\" />",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\" />",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\" />",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"dc55cf8e9613ddf1bd6db4a662d1ecc3668223da\">",
 "    <annotation name=\"RELEASE\" value=\"alice\" />",
 "    <annotation name=\"PRODUCT\" value=\"couchbase-server\" />",
 "    <annotation name=\"BLD_NUM\" value=\"2895\" />",
 "    <annotation name=\"VERSION\" value=\"6.0.3\" />","  </project>",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas\" path=\"goproj/src/github.com/couchbaselabs/cbas\" remote=\"couchbase-priv\" revision=\"73fa77cd9133a9f779a484ac2caffb0b46a1dd82\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas-core\" path=\"analytics\" remote=\"couchbase-priv\" revision=\"7e513c6bd60a030c3a2477af683b264d61932a75\" />",
 "  <project groups=\"analytics\" name=\"cbas-ui\" revision=\"d8f601c3109887a30deccab09b2177bf499c8711\" />",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"0df84c7e3c6d95ff435c12a3c08c6f064db11e97\" />",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"80d2ad8892d806f5103f602fec0d80adaa4b628f\" />",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"8d4105a904e0282a6928de7392e266c58ea3c7a2\" />",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"0a94f40b9080e0ecb11d3b7531a58c5e6a4a4465\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"93d26dbc120c4f9874abb65aafa4d815334273c6\" />",
 "  <project name=\"cbsummary\" path=\"goproj/src/github.com/couchbase/cbsummary\" revision=\"dbfa1c0d73f0e49f6f04e390f03de8f9a6cee769\" />",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"dcae66272b24600ae0005fa06b511cfae8914d3d\" />",
 "  <project name=\"cobra\" path=\"godeps/src/github.com/spf13/cobra\" remote=\"couchbasedeps\" revision=\"0f056af21f5f368e5b0646079d0094a2c64150f7\" />",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\" />",
 "  <project groups=\"notdefault,kv_ee,enterprise\" name=\"couch_rocks\" remote=\"couchbase-priv\" revision=\"75f37fa46bfe5e445dee077157303968a3e09126\" />",
 "  <project name=\"couchbase-cli\" revision=\"9b383603860ce58885c27015c92635a7b42d3a1f\" />",
 "  <project name=\"couchdb\" revision=\"c2b98200b800f9fbed927c47074884b9f5f53eb4\" />",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"69aa5d92e195a30e06184911d72b8fffcf2534fe\" />",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"c2c458ff2cf93ee63bf4b0386f495b22535daf96\" />",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\" />",
 "  <project name=\"cuckoofilter\" path=\"godeps/src/github.com/seiflotfy/cuckoofilter\" remote=\"couchbasedeps\" revision=\"d04838794ab86926d32b124345777e55e6f43974\" />",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\" />",
 "  <project name=\"docloader\" path=\"goproj/src/github.com/couchbase/docloader\" revision=\"05067021a042a1b63e100a486afd7ebddab4c535\" />",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\" />",
 "  <project name=\"errors\" path=\"godeps/src/github.com/pkg/errors\" remote=\"couchbasedeps\" revision=\"30136e27e2ac8d167177e8a583aa4c3fea5be833\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"eventing\" path=\"goproj/src/github.com/couchbase/eventing\" revision=\"1da67e30a4c8faaf24f067eae280f5764d943dc2\" upstream=\"alice\" />",
 "  <project name=\"flatbuffers\" path=\"godeps/src/github.com/google/flatbuffers\" remote=\"couchbasedeps\" revision=\"1a8968225130caeddd16e227678e6f8af1926303\" />",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"c338e06e6847140f749058184d66de1f2a43474a\" />",
 "  <project name=\"fwd\" path=\"godeps/src/github.com/philhofer/fwd\" remote=\"couchbasedeps\" revision=\"bb6d471dc95d4fe11e432687f8b70ff496cf3136\" />",
 "  <project name=\"geocouch\" revision=\"2a0e73f43451045f157640eec59ced72da18471f\" />",
 "  <project name=\"ghistogram\" path=\"godeps/src/github.com/couchbase/ghistogram\" revision=\"d910dd063dd68fb4d2a1ba344440f834ebb4ef62\" />",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\" />",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"5c0ac9ef0ba7a0356279cee7eadd8874c4a8f8c1\" />",
 "  <project name=\"go-curl\" path=\"godeps/src/github.com/andelf/go-curl\" remote=\"couchbasedeps\" revision=\"f0b2afc926ec79be5d7f30393b3485352781a705\" />",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\" />",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\" />",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\" />",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\" />",
 "  <project name=\"go-sqlite3\" path=\"godeps/src/github.com/mattn/go-sqlite3\" remote=\"couchbasedeps\" revision=\"47fc4e5e9153645da45af6a86a5bce95e63a0f9e\" />",
 "  <project name=\"go-unsnap-stream\" path=\"godeps/src/github.com/glycerine/go-unsnap-stream\" remote=\"couchbasedeps\" revision=\"62a9a9eb44fd8932157b1a8ace2149eff5971af6\" />",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\" />",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"d2f15a425a9c8e4d8447e5f5b89ce14845f7fa05\" />",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\" />",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"699b13a51af5dd4f80ff3deedf41bba60debad32\" />",
 "  <project name=\"gocbconnstr\" path=\"godeps/src/gopkg.in/couchbaselabs/gocbconnstr.v1\" remote=\"couchbaselabs\" revision=\"710456e087a6d497e87f41d0a9d98d6a75672186\" />",
 "  <project name=\"gocbcore\" path=\"godeps/src/gopkg.in/couchbase/gocbcore.v7\" revision=\"a0d26c2d6f5de912499d35a5aba573006e5e036f\" />",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"aecdbe5a5a91f0688df7bdf260ca962178c06828\" />",
 "  <project name=\"gofarmhash\" path=\"godeps/src/github.com/leemcloughlin/gofarmhash\" remote=\"couchbasedeps\" revision=\"0a055c5b87a8c55ce83459cbf2776b563822a942\" />",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\" />",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\" />",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\" />",
 "  <project name=\"golang-tools\" path=\"godeps/src/golang.org/x/tools\" remote=\"couchbasedeps\" revision=\"a28dfb48e06b2296b66678872c2cb638f0304f20\" />",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\" />",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"e05ec3550789be1da2981787ef6444fef75e10bc\" />",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"4809dd3aa2ab88013b1dfce15516d717a35cb6e8\" />",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\" />",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\" />",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\" />",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"f98adca8eb365032cab838ef4d99453931afa112\" />",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"122ae25ed207cca30ceaee9ac66342a603d43a31\" />",
 "  <project groups=\"kv\" name=\"gsl-lite\" path=\"third_party/gsl-lite\" remote=\"couchbasedeps\" revision=\"57542c7e7ced375346e9ac55dad85b942cfad556\" />",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\" />",
 "  <project name=\"httprouter\" path=\"godeps/src/github.com/julienschmidt/httprouter\" remote=\"couchbasedeps\" revision=\"975b5c4c7c21c0e3d2764200bf2aa8e34657ae6e\" />",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"95ed84aad6bf8ecd99da2372dceede6d93f3d43a\" />",
 "  <project name=\"json-iterator-go\" path=\"godeps/src/github.com/json-iterator/go\" remote=\"couchbasedeps\" revision=\"f7279a603edee96fe7764d3de9c6ff8cf9970994\" />",
 "  <project name=\"jsonx\" path=\"godeps/src/gopkg.in/couchbaselabs/jsonx.v1\" remote=\"couchbaselabs\" revision=\"5b7baa20429a46a5543ee259664cc86502738cad\" />",
 "  <project groups=\"kv\" name=\"kv_engine\" revision=\"a30fd9d57cc2101078c8cd2c44968458df965c2b\" />",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"libcouchbase\" revision=\"081e8b16b991bf706eb77f8243935c6fba31b895\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"3681c2a912330352991ecdd642f257efe5b85518\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\" />",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\" />",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\" />",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"956632ec1bc3e28276d00ee2f22c3202f06efb12\" />",
 "  <project name=\"mossScope\" path=\"godeps/src/github.com/couchbase/mossScope\" revision=\"abd3b58b422dbc2e9463a589d0f3d93441726e23\" />",
 "  <project name=\"mousetrap\" path=\"godeps/src/github.com/inconshreveable/mousetrap\" remote=\"couchbasedeps\" revision=\"76626ae9c91c4f2a10f34cad8ce83ea42c93bb75\" />",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"cd8da46b9b953800d430c8b0aa4667790727ed6f\" />",
 "  <project name=\"msgp\" path=\"godeps/src/github.com/tinylib/msgp\" remote=\"couchbasedeps\" revision=\"5bb5e1aed7ba5bcc93307153b020e7ffe79b0509\" />",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"043ee6597c29786140136a5747b6a886364f5282\" />",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"62685c2d7ca23c807425dca88b11a3e2323dab41\" />",
 "  <project name=\"nitro\" path=\"goproj/src/github.com/couchbase/nitro\" revision=\"f3bef3551997be504612a2d05a8b324b3bfdfe1b\" />",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\" />",
 "  <project name=\"ns_server\" revision=\"8117c5307974f397ad831a2b870fb3ee0fd8364d\" />",
 "  <project name=\"opentracing-go\" path=\"godeps/src/github.com/opentracing/opentracing-go\" remote=\"couchbasedeps\" revision=\"1949ddbfd147afd4d964a9f00b24eb291e0e7c38\" />",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\" />",
 "  <project name=\"pflag\" path=\"godeps/src/github.com/spf13/pflag\" remote=\"couchbasedeps\" revision=\"a232f6d9f87afaaa08bafaff5da685f974b83313\" />",
 "  <project groups=\"kv\" name=\"phosphor\" revision=\"96501c57bb0fd61c85cba6f63101aed2bcf41d38\" />",
 "  <project name=\"pierrec-lz4\" path=\"godeps/src/github.com/pierrec/lz4\" remote=\"couchbasedeps\" revision=\"ed8d4cc3b461464e69798080a0092bd028910298\" />",
 "  <project name=\"pierrec-xxHash\" path=\"godeps/src/github.com/pierrec/xxHash\" remote=\"couchbasedeps\" revision=\"a0006b13c722f7f12368c00a3d3c2ae8a999a0c6\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"plasma\" path=\"goproj/src/github.com/couchbase/plasma\" remote=\"couchbase-priv\" revision=\"c0792c8cfb1463ef029f064f34e366442f1f0064\" />",
 "  <project groups=\"kv\" name=\"platform\" revision=\"de77d527bd23012dc67794c81a7b1e76e46e3abd\" />",
 "  <project groups=\"kv\" name=\"product-texts\" revision=\"8cf7d25a1dcb5434ea44983c0bed202fb9cc8351\" />",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\" />",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"d2011f6ee9f6e1dca5d3922d44fbcf86dad78150\" />",
 "  <project name=\"query-ui\" revision=\"15a6461f437fe810e411a6613ec7c143991cd1c6\" />",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\" />",
 "  <project name=\"roaring\" path=\"godeps/src/github.com/RoaringBitmap/roaring\" remote=\"couchbasedeps\" revision=\"fe09428be4c233d726797a1380f7438f4f71a31a\" />",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"762005e7a34fd909a84586299f1dd457371d36ee\" />",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"73353fe6dad8f3d67409feefb9b17f90f6de917b\" />",
 "  <project name=\"snowballstem\" path=\"godeps/src/github.com/blevesearch/snowballstem\" remote=\"blevesearch\" revision=\"26b06a2c243d4f8ca5db3486f94409dd5b2a7467\" />",
 "  <project groups=\"kv\" name=\"spdlog\" path=\"third_party/spdlog\" remote=\"couchbasedeps\" revision=\"4fba14c79f356ae48d6141c561bf9fd7ba33fabd\" />",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\" />",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"c30c3d4c250e68e81c57aa1e8ae91ffd21243cdb\" />",
 "  <project name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\" />",
 "  <project name=\"testrunner\" revision=\"4133fd785987f1ddcdb49dab736ff6e5e67d7c95\" upstream=\"alice\" />",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\" />",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"6dadf98e19803cc10ce9552bf4d9121cc2528965\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\" />",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\" />",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\" />",
 "    <copyfile dest=\".clang-format\" src=\"dot-clang-format\" />",
 "    <copyfile dest=\"third_party/CMakeLists.txt\" src=\"third-party-CMakeLists.txt\" />",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\" />",
 "  <project name=\"uuid\" path=\"godeps/src/github.com/google/uuid\" remote=\"couchbasedeps\" revision=\"dec09d789f3dba190787f8b4454c7d3c936fed9e\" />",
 "  <project name=\"vellum\" path=\"godeps/src/github.com/couchbase/vellum\" revision=\"0ceea4a37442f76199b9259840baf48d17af3c1a\" />",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"b3d83fe61db37bb38a46cd8dee434e5682cba2c7\" />",
 "  <project name=\"zstd\" path=\"godeps/src/github.com/DataDog/zstd\" remote=\"couchbasedeps\" revision=\"aebefd9fcb99f22cd691ef778a12ed68f0e6a1ab\" />",
 "</manifest>"]

[error_logger:info,2020-05-07T12:09:33.772Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.139.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:33.774Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2020-05-07T12:09:33.775Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2020-05-07T12:09:33.776Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:init:243]ip config not found. Looks like we're brand new node
[error_logger:info,2020-05-07T12:09:33.776Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.143.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2020-05-07T12:09:33.776Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.142.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:33.915Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:bringup:295]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2020-05-07T12:09:33.920Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.145.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:33.921Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.146.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:33.921Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:configure_net_kernel:339]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2020-05-07T12:09:33.921Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.147.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:33.921Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.144.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2020-05-07T12:09:33.922Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:save_node:227]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2020-05-07T12:09:33.929Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:bringup:309]Attempted to save node name to disk: ok
[ns_server:debug,2020-05-07T12:09:33.930Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:316]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2020-05-07T12:09:33.930Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T12:09:33.939Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:328]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2020-05-07T12:09:33.939Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:33.944Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:33.945Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:33.947Z,ns_1@127.0.0.1:ns_config_sup<0.154.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2020-05-07T12:09:33.947Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.155.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:33.947Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.156.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:33.978Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1095]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2020-05-07T12:09:33.980Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1109]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:debug,2020-05-07T12:09:33.993Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1117]Here's full dynamic config we loaded:
[[{auto_failover_cfg,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {enabled,true},
    {timeout,120},
    {count,0},
    {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
    {failover_server_group,false},
    {max_count,1},
    {failed_over_server_groups,[]}]},
  {alert_limits,
   [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
  {audit,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {enabled,[]},
    {disabled_users,[]},
    {auditd_enabled,false},
    {rotate_interval,86400},
    {rotate_size,20971520},
    {disabled,[]},
    {sync,[]},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
  {audit_decriptors,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {20480,
     [{name,<<"opened DCP connection">>},
      {description,<<"opened DCP connection">>},
      {enabled,true},
      {module,memcached}]},
    {20482,
     [{name,<<"external memcached bucket flush">>},
      {description,
       <<"External user flushed the content of a memcached bucket">>},
      {enabled,true},
      {module,memcached}]},
    {20483,
     [{name,<<"invalid packet">>},
      {description,<<"Rejected an invalid packet">>},
      {enabled,true},
      {module,memcached}]},
    {20485,
     [{name,<<"authentication succeeded">>},
      {description,<<"Authentication to the cluster succeeded">>},
      {enabled,false},
      {module,memcached}]},
    {20488,
     [{name,<<"document read">>},
      {description,<<"Document was read">>},
      {enabled,false},
      {module,memcached}]},
    {20489,
     [{name,<<"document locked">>},
      {description,<<"Document was locked">>},
      {enabled,false},
      {module,memcached}]},
    {20490,
     [{name,<<"document modify">>},
      {description,<<"Document was modified">>},
      {enabled,false},
      {module,memcached}]},
    {20491,
     [{name,<<"document delete">>},
      {description,<<"Document was deleted">>},
      {enabled,false},
      {module,memcached}]},
    {20492,
     [{name,<<"select bucket">>},
      {description,<<"The specified bucket was selected">>},
      {enabled,true},
      {module,memcached}]},
    {28672,
     [{name,<<"SELECT statement">>},
      {description,<<"A N1QL SELECT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28673,
     [{name,<<"EXPLAIN statement">>},
      {description,<<"A N1QL EXPLAIN statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28674,
     [{name,<<"PREPARE statement">>},
      {description,<<"A N1QL PREPARE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28675,
     [{name,<<"INFER statement">>},
      {description,<<"A N1QL INFER statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28676,
     [{name,<<"INSERT statement">>},
      {description,<<"A N1QL INSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28677,
     [{name,<<"UPSERT statement">>},
      {description,<<"A N1QL UPSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28678,
     [{name,<<"DELETE statement">>},
      {description,<<"A N1QL DELETE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28679,
     [{name,<<"UPDATE statement">>},
      {description,<<"A N1QL UPDATE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28680,
     [{name,<<"MERGE statement">>},
      {description,<<"A N1QL MERGE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28681,
     [{name,<<"CREATE INDEX statement">>},
      {description,<<"A N1QL CREATE INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28682,
     [{name,<<"DROP INDEX statement">>},
      {description,<<"A N1QL DROP INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28683,
     [{name,<<"ALTER INDEX statement">>},
      {description,<<"A N1QL ALTER INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28684,
     [{name,<<"BUILD INDEX statement">>},
      {description,<<"A N1QL BUILD INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28685,
     [{name,<<"GRANT ROLE statement">>},
      {description,<<"A N1QL GRANT ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28686,
     [{name,<<"REVOKE ROLE statement">>},
      {description,<<"A N1QL REVOKE ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28687,
     [{name,<<"UNRECOGNIZED statement">>},
      {description,
       <<"An unrecognized statement was received by the N1QL query engine">>},
      {enabled,false},
      {module,n1ql}]},
    {28688,
     [{name,<<"CREATE PRIMARY INDEX statement">>},
      {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28689,
     [{name,<<"/admin/stats API request">>},
      {description,<<"An HTTP request was made to the API at /admin/stats.">>},
      {enabled,false},
      {module,n1ql}]},
    {28690,
     [{name,<<"/admin/vitals API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/vitals.">>},
      {enabled,false},
      {module,n1ql}]},
    {28691,
     [{name,<<"/admin/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28692,
     [{name,<<"/admin/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28693,
     [{name,<<"/admin/indexes/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28694,
     [{name,<<"/admin/indexes/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28695,
     [{name,<<"/admin/indexes/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28697,
     [{name,<<"/admin/ping API request">>},
      {description,<<"An HTTP request was made to the API at /admin/ping.">>},
      {enabled,false},
      {module,n1ql}]},
    {28698,
     [{name,<<"/admin/config API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/config.">>},
      {enabled,false},
      {module,n1ql}]},
    {28699,
     [{name,<<"/admin/ssl_cert API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
      {enabled,false},
      {module,n1ql}]},
    {28700,
     [{name,<<"/admin/settings API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/settings.">>},
      {enabled,false},
      {module,n1ql}]},
    {28701,
     [{name,<<"/admin/clusters API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/clusters.">>},
      {enabled,false},
      {module,n1ql}]},
    {28702,
     [{name,<<"/admin/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {32768,
     [{name,<<"Create Function">>},
      {description,<<"Eventing function definition was created or updated">>},
      {enabled,true},
      {module,eventing}]},
    {32769,
     [{name,<<"Delete Function">>},
      {description,<<"Eventing function definition was deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32770,
     [{name,<<"Fetch Functions">>},
      {description,<<"Eventing function definition was read">>},
      {enabled,false},
      {module,eventing}]},
    {32771,
     [{name,<<"List Deployed">>},
      {description,<<"Eventing deployed functions list was read">>},
      {enabled,false},
      {module,eventing}]},
    {32772,
     [{name,<<"Fetch Drafts">>},
      {description,<<"Eventing function draft definitions were read">>},
      {enabled,false},
      {module,eventing}]},
    {32773,
     [{name,<<"Delete Drafts">>},
      {description,<<"Eventing function draft definitions were deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32774,
     [{name,<<"Save Draft">>},
      {description,<<"Save a draft definition to the store">>},
      {enabled,true},
      {module,eventing}]},
    {32775,
     [{name,<<"Start Debug">>},
      {description,<<"Start eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32776,
     [{name,<<"Stop Debug">>},
      {description,<<"Stop eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32777,
     [{name,<<"Start Tracing">>},
      {description,<<"Start tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32778,
     [{name,<<"Stop Tracing">>},
      {description,<<"Stop tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32779,
     [{name,<<"Set Settings">>},
      {description,<<"Save settings for a given app">>},
      {enabled,true},
      {module,eventing}]},
    {32780,
     [{name,<<"Fetch Config">>},
      {description,<<"Get config for eventing">>},
      {enabled,false},
      {module,eventing}]},
    {32781,
     [{name,<<"Save Config">>},
      {description,<<"Save config for eventing">>},
      {enabled,true},
      {module,eventing}]},
    {32782,
     [{name,<<"Cleanup Eventing">>},
      {description,<<"Clears up app definitions and settings from metakv">>},
      {enabled,true},
      {module,eventing}]},
    {32783,
     [{name,<<"Get Settings">>},
      {description,<<"Get settings for a given app">>},
      {enabled,false},
      {module,eventing}]},
    {32784,
     [{name,<<"Import Functions">>},
      {description,<<"Import a list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32785,
     [{name,<<"Export Functions">>},
      {description,<<"Export the list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32786,
     [{name,<<"List Running">>},
      {description,<<"Eventing running function list was read">>},
      {enabled,false},
      {module,eventing}]},
    {36865,
     [{name,<<"Service configuration change">>},
      {description,<<"A successful service configuration change was made.">>},
      {enabled,true},
      {module,analytics}]},
    {36866,
     [{name,<<"Node configuration change">>},
      {description,<<"A successful node configuration change was made.">>},
      {enabled,true},
      {module,analytics}]}]},
  {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
  {autocompaction,
   [{database_fragmentation_threshold,{30,undefined}},
    {view_fragmentation_threshold,{30,undefined}}]},
  {buckets,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]},
    {configs,[]}]},
  {cbas_memory_quota,1024},
  {cert_and_pkey,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQlsomKQ7qhDcAeKZ3inWuCQuv8NxCAMb8M\nXhrVTrshZyFDiXdKS3Xbshyc9dEOiDwuDwAEgfwJQsXzzx0eCRtyTZfWAWTOH06O\nXdQps+9iTfr2KBFj27uag5c5ns+0ojsNyqZhA4+dbS7zK3CZ1dx7LPkL3+4HTlMh\nmH1/2fib3Lbp6dW3B55GV8/RHbkzgcRMyBicYtinqh6JMmmzjO/3KEyVHs3h0W1E\n00JdAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCKWU+bCvjKUlhW\niMiAN7r/3Vxkah7KEqp8BajCnLrlTMeiV+24TlPrsCWz4VBmOgt8OcijS3axdEik\nXeteeJp+R8nb2XPGivHOg/Hx2NlLxCrtXaYVGM0PiVydo24iCv0ZlqMCBsrzRLky\n5otbfQi8ngdfuR88C0/r3RLqvuFnOtFkLbKXuT/qshXfM8O/OgiJkr6CTBFYNd8w\nTCxN2syK41/HXoYzexdA/OTSm+kuEIuDpQYxKS0M4oKKZApJM70y/CYTzwG3JOnp\nuteZPYrwhIqxz01fkbLnj3QLGxPpSexRsp52GOoCv/YEE7tl3Olt4+p+MvhEZPdZ\ndqB53mNJ\n-----END CERTIFICATE-----\n">>,
     <<"*****">>}]},
  {client_cert_auth,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {state,"disable"},
    {prefixes,[]}]},
  {cluster_compat_version,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},
    6,0]},
  {drop_request_memory_threshold_mib,undefined},
  {email_alerts,
   [{recipients,["root@localhost"]},
    {sender,"couchbase@localhost"},
    {enabled,false},
    {email_server,
     [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
    {alerts,
     [auto_failover_node,auto_failover_maximum_reached,
      auto_failover_other_nodes_down,auto_failover_cluster_too_small,
      auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
      ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
      ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
  {fts_memory_quota,256},
  {index_aware_rebalance_disabled,false},
  {log_redaction_default_cfg,[{redact_level,none}]},
  {max_bucket_count,10},
  {memcached,[]},
  {memory_quota,311},
  {nodes_wanted,['ns_1@127.0.0.1']},
  {otp,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
    {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]},
  {password_policy,[{min_length,6},{must_present,[]}]},
  {quorum_nodes,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    'ns_1@127.0.0.1']},
  {read_only_user_creds,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {remote_clusters,[]},
  {replication,[{enabled,true}]},
  {rest,[{port,8091}]},
  {rest_creds,null},
  {roles_definitions,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {scramsha_fallback_salt,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<169,238,80,91,5,165,74,47,79,135,45,74>>]},
  {secure_headers,[]},
  {server_groups,
   [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
  {set_view_update_daemon,
   [{update_interval,5000},
    {update_min_changes,5000},
    {replica_update_min_changes,5000}]},
  {users_upgrade,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {{couchdb,max_parallel_indexers},4},
  {{couchdb,max_parallel_replica_indexers},2},
  {{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{6,63756038732}}]}]},
  {{metakv,<<"/eventing/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"ram_quota\":256}">>]},
  {{metakv,<<"/indexing/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
  {{metakv,<<"/query/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
  {{rbac_upgrade,[5,5]},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {{request_limit,capi},undefined},
  {{request_limit,rest},undefined},
  {{service_map,fts},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{service_map,index},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{service_map,n1ql},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{node,'ns_1@127.0.0.1',audit},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
  {{node,'ns_1@127.0.0.1',capi_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8092]},
  {{node,'ns_1@127.0.0.1',cbas_admin_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9110]},
  {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9113]},
  {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9112]},
  {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9111]},
  {{node,'ns_1@127.0.0.1',cbas_cluster_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9115]},
  {{node,'ns_1@127.0.0.1',cbas_console_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9114]},
  {{node,'ns_1@127.0.0.1',cbas_data_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9116]},
  {{node,'ns_1@127.0.0.1',cbas_debug_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    -1]},
  {{node,'ns_1@127.0.0.1',cbas_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8095]},
  {{node,'ns_1@127.0.0.1',cbas_messaging_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9118]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9119]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9121]},
  {{node,'ns_1@127.0.0.1',cbas_parent_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9122]},
  {{node,'ns_1@127.0.0.1',cbas_replication_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9120]},
  {{node,'ns_1@127.0.0.1',cbas_result_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9117]},
  {{node,'ns_1@127.0.0.1',cbas_ssl_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18095]},
  {{node,'ns_1@127.0.0.1',compaction_daemon},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {check_interval,30},
    {min_db_file_size,131072},
    {min_view_file_size,20971520}]},
  {{node,'ns_1@127.0.0.1',config_version},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {5,5,3}]},
  {{node,'ns_1@127.0.0.1',eventing_debug_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9140]},
  {{node,'ns_1@127.0.0.1',eventing_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8096]},
  {{node,'ns_1@127.0.0.1',eventing_https_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18096]},
  {{node,'ns_1@127.0.0.1',fts_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8094]},
  {{node,'ns_1@127.0.0.1',fts_ssl_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18094]},
  {{node,'ns_1@127.0.0.1',indexer_admin_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9100]},
  {{node,'ns_1@127.0.0.1',indexer_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9102]},
  {{node,'ns_1@127.0.0.1',indexer_https_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    19102]},
  {{node,'ns_1@127.0.0.1',indexer_scan_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9101]},
  {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9104]},
  {{node,'ns_1@127.0.0.1',indexer_stinit_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9103]},
  {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9105]},
  {{node,'ns_1@127.0.0.1',is_enterprise},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',isasl},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
  {{node,'ns_1@127.0.0.1',ldap_enabled},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',membership},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    active]},
  {{node,'ns_1@127.0.0.1',memcached},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,11210},
    {dedicated_port,11209},
    {ssl_port,11207},
    {admin_user,"@ns_server"},
    {other_users,
     ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
      "@cbas"]},
    {admin_pass,"*****"},
    {engines,
     [{membase,
       [{engine,"/opt/couchbase/lib/memcached/ep.so"},
        {static_config_string,"failpartialwarmup=false"}]},
      {memcached,
       [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
        {static_config_string,"vb0=true"}]}]},
    {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
    {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
    {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
    {log_prefix,"memcached.log"},
    {log_generations,20},
    {log_cyclesize,10485760},
    {log_sleeptime,19},
    {log_rotation_period,39003}]},
  {{node,'ns_1@127.0.0.1',memcached_config},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {[{interfaces,
       {memcached_config_mgr,omit_missing_mcd_ports,
        [{[{host,<<"*">>},
           {port,port},
           {maxconn,maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,dedicated_port},
           {maxconn,dedicated_port_maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,ssl_port},
           {maxconn,maxconn},
           {ssl,
            {[{key,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
              {cert,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]}]}},
      {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
      {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
      {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
      {connection_idle_time,connection_idle_time},
      {privilege_debug,privilege_debug},
      {breakpad,
       {[{enabled,breakpad_enabled},
         {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
      {admin,{"~s",[admin_user]}},
      {verbosity,verbosity},
      {audit_file,{"~s",[audit_file]}},
      {rbac_file,{"~s",[rbac_file]}},
      {dedupe_nmvb_maps,dedupe_nmvb_maps},
      {tracing_enabled,tracing_enabled},
      {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
      {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
      {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
      {logger,
       {[{filename,{"~s/~s",[log_path,log_prefix]}},
         {cyclesize,log_cyclesize},
         {sleeptime,log_sleeptime}]}}]}]},
  {{node,'ns_1@127.0.0.1',memcached_defaults},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {maxconn,30000},
    {dedicated_port_maxconn,5000},
    {ssl_cipher_list,"HIGH"},
    {connection_idle_time,0},
    {verbosity,0},
    {privilege_debug,false},
    {breakpad_enabled,true},
    {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
    {dedupe_nmvb_maps,false},
    {tracing_enabled,true},
    {datatype_snappy,true}]},
  {{node,'ns_1@127.0.0.1',moxi},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,11211},
    {verbosity,[]}]},
  {{node,'ns_1@127.0.0.1',ns_log},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
  {{node,'ns_1@127.0.0.1',port_servers},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
  {{node,'ns_1@127.0.0.1',projector_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9999]},
  {{node,'ns_1@127.0.0.1',query_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8093]},
  {{node,'ns_1@127.0.0.1',rest},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,8091},
    {port_meta,global}]},
  {{node,'ns_1@127.0.0.1',ssl_capi_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18092]},
  {{node,'ns_1@127.0.0.1',ssl_query_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18093]},
  {{node,'ns_1@127.0.0.1',ssl_rest_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18091]},
  {{node,'ns_1@127.0.0.1',uuid},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    <<"0f8760945f98b1efdbef0bd1ea6e8446">>]},
  {{node,'ns_1@127.0.0.1',xdcr_rest_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9998]},
  {{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    false]}]]
[ns_server:info,2020-05-07T12:09:33.998Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1138]Here's full dynamic config we loaded + static & default config:
[{{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   false]},
 {{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   <<"0f8760945f98b1efdbef0bd1ea6e8446">>]},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,8091},
   {port_meta,global}]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11211},
   {verbosity,[]}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {privilege_debug,false},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false},
   {tracing_enabled,true},
   {datatype_snappy,true}]},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},
          {port,port},
          {maxconn,maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {privilege_debug,privilege_debug},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {rbac_file,{"~s",[rbac_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps},
     {tracing_enabled,tracing_enabled},
     {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
     {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
     {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
     {logger,
      {[{filename,{"~s/~s",[log_path,log_prefix]}},
        {cyclesize,log_cyclesize},
        {sleeptime,log_sleeptime}]}}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"@ns_server"},
   {other_users,
    ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
     "@cbas"]},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   active]},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   19102]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',fts_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18094]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',eventing_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18096]},
 {{node,'ns_1@127.0.0.1',eventing_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8096]},
 {{node,'ns_1@127.0.0.1',eventing_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9140]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {5,5,3}]},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {{node,'ns_1@127.0.0.1',cbas_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18095]},
 {{node,'ns_1@127.0.0.1',cbas_result_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9117]},
 {{node,'ns_1@127.0.0.1',cbas_replication_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9120]},
 {{node,'ns_1@127.0.0.1',cbas_parent_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9122]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9121]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9119]},
 {{node,'ns_1@127.0.0.1',cbas_messaging_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9118]},
 {{node,'ns_1@127.0.0.1',cbas_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8095]},
 {{node,'ns_1@127.0.0.1',cbas_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]},
 {{node,'ns_1@127.0.0.1',cbas_data_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9116]},
 {{node,'ns_1@127.0.0.1',cbas_console_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9114]},
 {{node,'ns_1@127.0.0.1',cbas_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9115]},
 {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9111]},
 {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9112]},
 {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9113]},
 {{node,'ns_1@127.0.0.1',cbas_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9110]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{service_map,n1ql},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{service_map,index},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{service_map,fts},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{request_limit,rest},undefined},
 {{request_limit,capi},undefined},
 {{rbac_upgrade,[5,5]},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {{metakv,<<"/query/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
 {{metakv,<<"/indexing/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
 {{metakv,<<"/eventing/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"ram_quota\":256}">>]},
 {{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{6,63756038732}}]}]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {users_upgrade,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {secure_headers,[]},
 {scramsha_fallback_salt,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<169,238,80,91,5,165,74,47,79,135,45,74>>]},
 {roles_definitions,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {rest_creds,null},
 {rest,[{port,8091}]},
 {replication,[{enabled,true}]},
 {remote_clusters,[]},
 {read_only_user_creds,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {quorum_nodes,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   'ns_1@127.0.0.1']},
 {password_policy,[{min_length,6},{must_present,[]}]},
 {otp,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
   {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {memory_quota,311},
 {memcached,[]},
 {max_bucket_count,10},
 {log_redaction_default_cfg,[{redact_level,none}]},
 {index_aware_rebalance_disabled,false},
 {fts_memory_quota,256},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
 {drop_request_memory_threshold_mib,undefined},
 {cluster_compat_version,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},
   6,0]},
 {client_cert_auth,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {state,"disable"},
   {prefixes,[]}]},
 {cert_and_pkey,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQlsomKQ7qhDcAeKZ3inWuCQuv8NxCAMb8M\nXhrVTrshZyFDiXdKS3Xbshyc9dEOiDwuDwAEgfwJQsXzzx0eCRtyTZfWAWTOH06O\nXdQps+9iTfr2KBFj27uag5c5ns+0ojsNyqZhA4+dbS7zK3CZ1dx7LPkL3+4HTlMh\nmH1/2fib3Lbp6dW3B55GV8/RHbkzgcRMyBicYtinqh6JMmmzjO/3KEyVHs3h0W1E\n00JdAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCKWU+bCvjKUlhW\niMiAN7r/3Vxkah7KEqp8BajCnLrlTMeiV+24TlPrsCWz4VBmOgt8OcijS3axdEik\nXeteeJp+R8nb2XPGivHOg/Hx2NlLxCrtXaYVGM0PiVydo24iCv0ZlqMCBsrzRLky\n5otbfQi8ngdfuR88C0/r3RLqvuFnOtFkLbKXuT/qshXfM8O/OgiJkr6CTBFYNd8w\nTCxN2syK41/HXoYzexdA/OTSm+kuEIuDpQYxKS0M4oKKZApJM70y/CYTzwG3JOnp\nuteZPYrwhIqxz01fkbLnj3QLGxPpSexRsp52GOoCv/YEE7tl3Olt4+p+MvhEZPdZ\ndqB53mNJ\n-----END CERTIFICATE-----\n">>,
    <<"*****">>}]},
 {cbas_memory_quota,1024},
 {buckets,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]},
   {configs,[]}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
 {audit_decriptors,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {20480,
    [{name,<<"opened DCP connection">>},
     {description,<<"opened DCP connection">>},
     {enabled,true},
     {module,memcached}]},
   {20482,
    [{name,<<"external memcached bucket flush">>},
     {description,
      <<"External user flushed the content of a memcached bucket">>},
     {enabled,true},
     {module,memcached}]},
   {20483,
    [{name,<<"invalid packet">>},
     {description,<<"Rejected an invalid packet">>},
     {enabled,true},
     {module,memcached}]},
   {20485,
    [{name,<<"authentication succeeded">>},
     {description,<<"Authentication to the cluster succeeded">>},
     {enabled,false},
     {module,memcached}]},
   {20488,
    [{name,<<"document read">>},
     {description,<<"Document was read">>},
     {enabled,false},
     {module,memcached}]},
   {20489,
    [{name,<<"document locked">>},
     {description,<<"Document was locked">>},
     {enabled,false},
     {module,memcached}]},
   {20490,
    [{name,<<"document modify">>},
     {description,<<"Document was modified">>},
     {enabled,false},
     {module,memcached}]},
   {20491,
    [{name,<<"document delete">>},
     {description,<<"Document was deleted">>},
     {enabled,false},
     {module,memcached}]},
   {20492,
    [{name,<<"select bucket">>},
     {description,<<"The specified bucket was selected">>},
     {enabled,true},
     {module,memcached}]},
   {28672,
    [{name,<<"SELECT statement">>},
     {description,<<"A N1QL SELECT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28673,
    [{name,<<"EXPLAIN statement">>},
     {description,<<"A N1QL EXPLAIN statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28674,
    [{name,<<"PREPARE statement">>},
     {description,<<"A N1QL PREPARE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28675,
    [{name,<<"INFER statement">>},
     {description,<<"A N1QL INFER statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28676,
    [{name,<<"INSERT statement">>},
     {description,<<"A N1QL INSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28677,
    [{name,<<"UPSERT statement">>},
     {description,<<"A N1QL UPSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28678,
    [{name,<<"DELETE statement">>},
     {description,<<"A N1QL DELETE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28679,
    [{name,<<"UPDATE statement">>},
     {description,<<"A N1QL UPDATE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28680,
    [{name,<<"MERGE statement">>},
     {description,<<"A N1QL MERGE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28681,
    [{name,<<"CREATE INDEX statement">>},
     {description,<<"A N1QL CREATE INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28682,
    [{name,<<"DROP INDEX statement">>},
     {description,<<"A N1QL DROP INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28683,
    [{name,<<"ALTER INDEX statement">>},
     {description,<<"A N1QL ALTER INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28684,
    [{name,<<"BUILD INDEX statement">>},
     {description,<<"A N1QL BUILD INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28685,
    [{name,<<"GRANT ROLE statement">>},
     {description,<<"A N1QL GRANT ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28686,
    [{name,<<"REVOKE ROLE statement">>},
     {description,<<"A N1QL REVOKE ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28687,
    [{name,<<"UNRECOGNIZED statement">>},
     {description,
      <<"An unrecognized statement was received by the N1QL query engine">>},
     {enabled,false},
     {module,n1ql}]},
   {28688,
    [{name,<<"CREATE PRIMARY INDEX statement">>},
     {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28689,
    [{name,<<"/admin/stats API request">>},
     {description,<<"An HTTP request was made to the API at /admin/stats.">>},
     {enabled,false},
     {module,n1ql}]},
   {28690,
    [{name,<<"/admin/vitals API request">>},
     {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
     {enabled,false},
     {module,n1ql}]},
   {28691,
    [{name,<<"/admin/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28692,
    [{name,<<"/admin/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28693,
    [{name,<<"/admin/indexes/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28694,
    [{name,<<"/admin/indexes/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28695,
    [{name,<<"/admin/indexes/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28697,
    [{name,<<"/admin/ping API request">>},
     {description,<<"An HTTP request was made to the API at /admin/ping.">>},
     {enabled,false},
     {module,n1ql}]},
   {28698,
    [{name,<<"/admin/config API request">>},
     {description,<<"An HTTP request was made to the API at /admin/config.">>},
     {enabled,false},
     {module,n1ql}]},
   {28699,
    [{name,<<"/admin/ssl_cert API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
     {enabled,false},
     {module,n1ql}]},
   {28700,
    [{name,<<"/admin/settings API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/settings.">>},
     {enabled,false},
     {module,n1ql}]},
   {28701,
    [{name,<<"/admin/clusters API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/clusters.">>},
     {enabled,false},
     {module,n1ql}]},
   {28702,
    [{name,<<"/admin/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {32768,
    [{name,<<"Create Function">>},
     {description,<<"Eventing function definition was created or updated">>},
     {enabled,true},
     {module,eventing}]},
   {32769,
    [{name,<<"Delete Function">>},
     {description,<<"Eventing function definition was deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32770,
    [{name,<<"Fetch Functions">>},
     {description,<<"Eventing function definition was read">>},
     {enabled,false},
     {module,eventing}]},
   {32771,
    [{name,<<"List Deployed">>},
     {description,<<"Eventing deployed functions list was read">>},
     {enabled,false},
     {module,eventing}]},
   {32772,
    [{name,<<"Fetch Drafts">>},
     {description,<<"Eventing function draft definitions were read">>},
     {enabled,false},
     {module,eventing}]},
   {32773,
    [{name,<<"Delete Drafts">>},
     {description,<<"Eventing function draft definitions were deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32774,
    [{name,<<"Save Draft">>},
     {description,<<"Save a draft definition to the store">>},
     {enabled,true},
     {module,eventing}]},
   {32775,
    [{name,<<"Start Debug">>},
     {description,<<"Start eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32776,
    [{name,<<"Stop Debug">>},
     {description,<<"Stop eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32777,
    [{name,<<"Start Tracing">>},
     {description,<<"Start tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32778,
    [{name,<<"Stop Tracing">>},
     {description,<<"Stop tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32779,
    [{name,<<"Set Settings">>},
     {description,<<"Save settings for a given app">>},
     {enabled,true},
     {module,eventing}]},
   {32780,
    [{name,<<"Fetch Config">>},
     {description,<<"Get config for eventing">>},
     {enabled,false},
     {module,eventing}]},
   {32781,
    [{name,<<"Save Config">>},
     {description,<<"Save config for eventing">>},
     {enabled,true},
     {module,eventing}]},
   {32782,
    [{name,<<"Cleanup Eventing">>},
     {description,<<"Clears up app definitions and settings from metakv">>},
     {enabled,true},
     {module,eventing}]},
   {32783,
    [{name,<<"Get Settings">>},
     {description,<<"Get settings for a given app">>},
     {enabled,false},
     {module,eventing}]},
   {32784,
    [{name,<<"Import Functions">>},
     {description,<<"Import a list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32785,
    [{name,<<"Export Functions">>},
     {description,<<"Export the list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32786,
    [{name,<<"List Running">>},
     {description,<<"Eventing running function list was read">>},
     {enabled,false},
     {module,eventing}]},
   {36865,
    [{name,<<"Service configuration change">>},
     {description,<<"A successful service configuration change was made.">>},
     {enabled,true},
     {module,analytics}]},
   {36866,
    [{name,<<"Node configuration change">>},
     {description,<<"A successful node configuration change was made.">>},
     {enabled,true},
     {module,analytics}]}]},
 {audit,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {enabled,[]},
   {disabled_users,[]},
   {auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {auto_failover_cfg,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {enabled,true},
   {timeout,120},
   {count,0},
   {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
   {failover_server_group,false},
   {max_count,1},
   {failed_over_server_groups,[]}]}]
[error_logger:info,2020-05-07T12:09:34.005Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.157.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:34.006Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.163.0>},
                       {name,ns_config_remote},
                       {mfargs,{ns_config_replica,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:34.008Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.164.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:34.008Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:34.010Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.166.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:34.011Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.167.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:34.021Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.170.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:34.023Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2020-05-07T12:09:34.023Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.171.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:34.023Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.172.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:34.028Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.173.0>},
                       {name,memcached_refresh},
                       {mfargs,{memcached_refresh,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:34.029Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.175.0>},
                       {name,ssl_service_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ssl_service_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:34.045Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:init:419]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem-ca"},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[error_logger:info,2020-05-07T12:09:34.097Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.176.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:34.110Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T12:09:34.110Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T12:09:34.110Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T12:09:34.110Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[ns_server:debug,2020-05-07T12:09:34.124Z,ns_1@127.0.0.1:<0.178.0>:restartable:start_child:98]Started child process <0.179.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2020-05-07T12:09:34.124Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.178.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:34.124Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.174.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:34.126Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.197.0>},
                       {name,user_storage_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,user_storage_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:34.132Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.199.0>},
                       {name,users_replicator},
                       {mfargs,{menelaus_users,start_replicator,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:34.137Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:55]Start waiting for startup
[ns_server:debug,2020-05-07T12:09:34.140Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_storage:anounce_startup:69]Announce my startup to <0.199.0>
[ns_server:debug,2020-05-07T12:09:34.140Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:58]Received replicated storage registration from <0.200.0>
[ns_server:debug,2020-05-07T12:09:34.142Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:open:212]Opening file "/opt/couchbase/var/lib/couchbase/config/users.dets"
[error_logger:info,2020-05-07T12:09:34.142Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.200.0>},
                       {name,users_storage},
                       {mfargs,{menelaus_users,start_storage,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:34.142Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.198.0>},
                       {name,users_storage_sup},
                       {mfargs,{users_storage_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:09:34.152Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:init:44]Starting versioned cache compiled_roles_cache
[error_logger:info,2020-05-07T12:09:34.152Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.202.0>},
                       {name,compiled_roles_cache},
                       {mfargs,{menelaus_roles,start_compiled_roles_cache,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:34.152Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.196.0>},
                       {name,users_sup},
                       {mfargs,{users_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:34.157Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.206.0>},
                       {name,dets_sup},
                       {mfargs,{dets_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:34.157Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.207.0>},
                       {name,dets},
                       {mfargs,{dets_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:34.171Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:convert_docs_to_55_in_dets:243]Checking for pre 5.5 records in dets: users_storage
[ns_server:debug,2020-05-07T12:09:34.171Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,'$1','_','$2'},
                                      [],
                                      [{{'$1','$2'}}]}],
                                    100}
[ns_server:debug,2020-05-07T12:09:34.171Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:init_after_ack:204]Loading 0 items, 299 words took 0ms
[ns_server:debug,2020-05-07T12:09:34.172Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.210.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:141]Waiting for ns_couchdb node to start
[error_logger:info,2020-05-07T12:09:34.172Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.205.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:34.173Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T12:09:34.173Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.213.0>,shutdown}}
[ns_server:debug,2020-05-07T12:09:34.173Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T12:09:34.173Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T12:09:34.175Z,ns_1@127.0.0.1:users_replicator<0.199.0>:doc_replicator:loop:60]doing replicate_newnodes_docs
[error_logger:info,2020-05-07T12:09:34.374Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T12:09:34.374Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.216.0>,shutdown}}
[error_logger:info,2020-05-07T12:09:34.374Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T12:09:34.374Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T12:09:34.575Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T12:09:34.575Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.219.0>,shutdown}}
[ns_server:debug,2020-05-07T12:09:34.575Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T12:09:34.575Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T12:09:34.776Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T12:09:34.801Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T12:09:35.002Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T12:09:35.203Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T12:09:35.404Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T12:09:35.605Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[error_logger:info,2020-05-07T12:09:35.972Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.229.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:36.173Z,ns_1@127.0.0.1:ns_couchdb_port<0.205.0>:ns_port_server:log:223]ns_couchdb<0.205.0>: Apache CouchDB v4.5.1-112-gc2b9820 (LogLevel=info) is starting.
ns_couchdb<0.205.0>: Apache CouchDB has started. Time to relax.

[error_logger:info,2020-05-07T12:09:36.284Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.210.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.96617950>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.299Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:ns_storage_conf:setup_db_and_ix_paths:47]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2020-05-07T12:09:36.304Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.232.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.306Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.233.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:36.307Z,ns_1@127.0.0.1:ns_server_sup<0.231.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2020-05-07T12:09:36.315Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.234.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.317Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.235.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.324Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.236.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.324Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.237.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.351Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:memcached_cfg:init:62]Init config writer for memcached_passwords, "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T12:09:36.351Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T12:09:36.390Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.238.0>
[ns_server:debug,2020-05-07T12:09:36.390Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T12:09:36.391Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.238.0>
[ns_server:debug,2020-05-07T12:09:36.404Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[error_logger:info,2020-05-07T12:09:36.404Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.238.0>},
                       {name,memcached_passwords},
                       {mfargs,{memcached_passwords,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T12:09:36.414Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T12:09:36.414Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [isasl] failed. Retry in 1000 ms.
[ns_server:debug,2020-05-07T12:09:36.419Z,ns_1@127.0.0.1:memcached_permissions<0.241.0>:memcached_cfg:init:62]Init config writer for memcached_permissions, "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T12:09:36.419Z,ns_1@127.0.0.1:memcached_permissions<0.241.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T12:09:36.421Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.241.0>
[ns_server:debug,2020-05-07T12:09:36.421Z,ns_1@127.0.0.1:memcached_permissions<0.241.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{user,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T12:09:36.421Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.241.0>
[ns_server:debug,2020-05-07T12:09:36.424Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of rbac requested
[error_logger:info,2020-05-07T12:09:36.424Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.241.0>},
                       {name,memcached_permissions},
                       {mfargs,{memcached_permissions,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.424Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.244.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T12:09:36.424Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T12:09:36.424Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2020-05-07T12:09:36.427Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.246.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.427Z,ns_1@127.0.0.1:ns_node_disco<0.247.0>:ns_node_disco:init:130]Initting ns_node_disco with []
[ns_server:debug,2020-05-07T12:09:36.427Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[user:info,2020-05-07T12:09:36.427Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:127]Node 'ns_1@127.0.0.1' synchronized otp cookie {sanitized,
                                               <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>} from cluster
[ns_server:debug,2020-05-07T12:09:36.427Z,ns_1@127.0.0.1:<0.248.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:09:36.429Z,ns_1@127.0.0.1:<0.248.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[error_logger:info,2020-05-07T12:09:36.429Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.247.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.430Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.249.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.432Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.250.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.434Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.434Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:69]init pulling
[ns_server:debug,2020-05-07T12:09:36.434Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:71]init pushing
[ns_server:debug,2020-05-07T12:09:36.442Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:75]init reannouncing
[ns_server:debug,2020-05-07T12:09:36.442Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2020-05-07T12:09:36.442Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:handle_info:89]Flushing cache compiled_roles_cache due to version change from undefined to {[6,
                                                                              0],
                                                                             {0,
                                                                              1744540976},
                                                                             false,
                                                                             []}
[ns_server:debug,2020-05-07T12:09:36.442Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2020-05-07T12:09:36.442Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T12:09:36.442Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T12:09:36.442Z,ns_1@127.0.0.1:<0.260.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:09:36.442Z,ns_1@127.0.0.1:<0.261.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:09:36.442Z,ns_1@127.0.0.1:<0.260.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:09:36.442Z,ns_1@127.0.0.1:<0.261.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:09:36.444Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2020-05-07T12:09:36.444Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,[]},
 {disabled_users,[]},
 {auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2020-05-07T12:09:36.445Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit_decriptors ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {20480,
  [{name,<<"opened DCP connection">>},
   {description,<<"opened DCP connection">>},
   {enabled,true},
   {module,memcached}]},
 {20482,
  [{name,<<"external memcached bucket flush">>},
   {description,<<"External user flushed the content of a memcached bucket">>},
   {enabled,true},
   {module,memcached}]},
 {20483,
  [{name,<<"invalid packet">>},
   {description,<<"Rejected an invalid packet">>},
   {enabled,true},
   {module,memcached}]},
 {20485,
  [{name,<<"authentication succeeded">>},
   {description,<<"Authentication to the cluster succeeded">>},
   {enabled,false},
   {module,memcached}]},
 {20488,
  [{name,<<"document read">>},
   {description,<<"Document was read">>},
   {enabled,false},
   {module,memcached}]},
 {20489,
  [{name,<<"document locked">>},
   {description,<<"Document was locked">>},
   {enabled,false},
   {module,memcached}]},
 {20490,
  [{name,<<"document modify">>},
   {description,<<"Document was modified">>},
   {enabled,false},
   {module,memcached}]},
 {20491,
  [{name,<<"document delete">>},
   {description,<<"Document was deleted">>},
   {enabled,false},
   {module,memcached}]},
 {20492,
  [{name,<<"select bucket">>},
   {description,<<"The specified bucket was selected">>},
   {enabled,true},
   {module,memcached}]},
 {28672,
  [{name,<<"SELECT statement">>},
   {description,<<"A N1QL SELECT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28673,
  [{name,<<"EXPLAIN statement">>},
   {description,<<"A N1QL EXPLAIN statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28674,
  [{name,<<"PREPARE statement">>},
   {description,<<"A N1QL PREPARE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28675,
  [{name,<<"INFER statement">>},
   {description,<<"A N1QL INFER statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28676,
  [{name,<<"INSERT statement">>},
   {description,<<"A N1QL INSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28677,
  [{name,<<"UPSERT statement">>},
   {description,<<"A N1QL UPSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28678,
  [{name,<<"DELETE statement">>},
   {description,<<"A N1QL DELETE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28679,
  [{name,<<"UPDATE statement">>},
   {description,<<"A N1QL UPDATE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28680,
  [{name,<<"MERGE statement">>},
   {description,<<"A N1QL MERGE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28681,
  [{name,<<"CREATE INDEX statement">>},
   {description,<<"A N1QL CREATE INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28682,
  [{name,<<"DROP INDEX statement">>},
   {description,<<"A N1QL DROP INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28683,
  [{name,<<"ALTER INDEX statement">>},
   {description,<<"A N1QL ALTER INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28684,
  [{name,<<"BUILD INDEX statement">>},
   {description,<<"A N1QL BUILD INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28685,
  [{name,<<"GRANT ROLE statement">>},
   {description,<<"A N1QL GRANT ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28686,
  [{name,<<"REVOKE ROLE statement">>},
   {description,<<"A N1QL REVOKE ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28687,
  [{name,<<"UNRECOGNIZED statement">>},
   {description,<<"An unrecognized statement was received by the N1QL query engine">>},
   {enabled,false},
   {module,n1ql}]},
 {28688,
  [{name,<<"CREATE PRIMARY INDEX statement">>},
   {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28689,
  [{name,<<"/admin/stats API request">>},
   {description,<<"An HTTP request was made to the API at /admin/stats.">>},
   {enabled,false},
   {module,n1ql}]},
 {28690,
  [{name,<<"/admin/vitals API request">>},
   {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
   {enabled,false},
   {module,n1ql}]},
 {28691,
  [{name,<<"/admin/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28692,
  [{name,<<"/admin/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28693,
  [{name,<<"/admin/indexes/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28694,
  [{name,<<"/admin/indexes/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28695,
  [{name,<<"/admin/indexes/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28697,
  [{name,<<"/admin/ping API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ping.">>},
   {enabled,false},
   {module,n1ql}]},
 {28698,
  [{name,<<"/admin/config API request">>},
   {description,<<"An HTTP request was made to the API at /admin/config.">>},
   {enabled,false},
   {module,n1ql}]},
 {28699,
  [{name,<<"/admin/ssl_cert API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ssl_cert.">>},
   {enabled,false},
   {module,n1ql}]},
 {28700,
  [{name,<<"/admin/settings API request">>},
   {description,<<"An HTTP request was made to the API at /admin/settings.">>},
   {enabled,false},
   {module,n1ql}]},
 {28701,
  [{name,<<"/admin/clusters API request">>},
   {description,<<"An HTTP request was made to the API at /admin/clusters.">>},
   {enabled,false},
   {module,n1ql}]},
 {28702,
  [{name,<<"/admin/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {32768,
  [{name,<<"Create Function">>},
   {description,<<"Eventing function definition was created or updated">>},
   {enabled,true},
   {module,eventing}]},
 {32769,
  [{name,<<"Delete Function">>},
   {description,<<"Eventing function definition was deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32770,
  [{name,<<"Fetch Functions">>},
   {description,<<"Eventing function definition was read">>},
   {enabled,false},
   {module,eventing}]},
 {32771,
  [{name,<<"List Deployed">>},
   {description,<<"Eventing deployed functions list was read">>},
   {enabled,false},
   {module,eventing}]},
 {32772,
  [{name,<<"Fetch Drafts">>},
   {description,<<"Eventing function draft definitions were read">>},
   {enabled,false},
   {module,eventing}]},
 {32773,
  [{name,<<"Delete Drafts">>},
   {description,<<"Eventing function draft definitions were deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32774,
  [{name,<<"Save Draft">>},
   {description,<<"Save a draft definition to the store">>},
   {enabled,true},
   {module,eventing}]},
 {32775,
  [{name,<<"Start Debug">>},
   {description,<<"Start eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32776,
  [{name,<<"Stop Debug">>},
   {description,<<"Stop eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32777,
  [{name,<<"Start Tracing">>},
   {description,<<"Start tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32778,
  [{name,<<"Stop Tracing">>},
   {description,<<"Stop tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32779,
  [{name,<<"Set Settings">>},
   {description,<<"Save settings for a given app">>},
   {enabled,true},
   {module,eventing}]},
 {32780,
  [{name,<<"Fetch Config">>},
   {description,<<"Get config for eventing">>},
   {enabled,false},
   {module,eventing}]},
 {32781,
  [{name,<<"Save Config">>},
   {description,<<"Save config for eventing">>},
   {enabled,true},
   {module,eventing}]},
 {32782,
  [{name,<<"Cleanup Eventing">>},
   {description,<<"Clears up app definitions and settings from metakv">>},
   {enabled,true},
   {module,eventing}]},
 {32783,
  [{name,<<"Get Settings">>},
   {description,<<"Get settings for a given app">>},
   {enabled,false},
   {module,eventing}]},
 {32784,
  [{name,<<"Import Functions">>},
   {description,<<"Import a list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32785,
  [{name,<<"Export Functions">>},
   {description,<<"Export the list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32786,
  [{name,<<"List Running">>},
   {description,<<"Eventing running function list was read">>},
   {enabled,false},
   {module,eventing}]},
 {36865,
  [{name,<<"Service configuration change">>},
   {description,<<"A successful service configuration change was made.">>},
   {enabled,true},
   {module,analytics}]},
 {36866,
  [{name,<<"Node configuration change">>},
   {description,<<"A successful node configuration change was made.">>},
   {enabled,true},
   {module,analytics}]}]
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_reprovision_cfg ->
[{enabled,true},{max_nodes,1},{count,0}]
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
buckets ->
[[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}],{configs,[]}]
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cbas_memory_quota ->
1024
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cert_and_pkey ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQ"...>>,
  <<"*****">>}]
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
client_cert_auth ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {state,"disable"},
 {prefixes,[]}]
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cluster_compat_version ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},6,0]
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded,communication_issue]}]
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
fts_memory_quota ->
256
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
log_redaction_default_cfg ->
[{redact_level,none}]
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
max_bucket_count ->
10
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memcached ->
[]
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memory_quota ->
311
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
otp ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
 {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
password_policy ->
[{min_length,6},{must_present,[]}]
[ns_server:debug,2020-05-07T12:09:36.446Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
quorum_nodes ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
read_only_user_creds ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
remote_clusters ->
[]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest ->
[{port,8091}]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest_creds ->
null
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
roles_definitions ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
scramsha_fallback_salt ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<169,238,80,91,5,165,74,47,79,135,45,74>>]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
secure_headers ->
[]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
users_upgrade ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{6,63756038732}}]}]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/eventing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"ram_quota\":256}">>]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/query/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{rbac_upgrade,[5,5]} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,fts} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,index} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8092]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9110]
[ns_server:debug,2020-05-07T12:09:36.447Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_client_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9113]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9112]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9111]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9115]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_console_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9114]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_data_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9116]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8095]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_messaging_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9118]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_callback_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9119]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9121]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_parent_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9122]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_replication_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9120]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_result_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9117]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18095]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {5,5,3}]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9140]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8096]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18096]
[ns_server:debug,2020-05-07T12:09:36.448Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8094]
[ns_server:debug,2020-05-07T12:09:36.455Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18094]
[ns_server:debug,2020-05-07T12:09:36.455Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9100]
[ns_server:debug,2020-05-07T12:09:36.455Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9102]
[ns_server:debug,2020-05-07T12:09:36.456Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|19102]
[ns_server:debug,2020-05-07T12:09:36.456Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9101]
[ns_server:debug,2020-05-07T12:09:36.456Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9104]
[ns_server:debug,2020-05-07T12:09:36.456Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9103]
[ns_server:debug,2020-05-07T12:09:36.456Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9105]
[ns_server:debug,2020-05-07T12:09:36.456Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:debug,2020-05-07T12:09:36.456Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2020-05-07T12:09:36.456Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:debug,2020-05-07T12:09:36.456Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 active]
[ns_server:debug,2020-05-07T12:09:36.456Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"@ns_server"},
 {other_users,["@cbq-engine","@projector","@goxdcr","@index","@fts",
               "@eventing","@cbas"]},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2020-05-07T12:09:36.456Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},
        {port,port},
        {maxconn,maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {privilege_debug,privilege_debug},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {rbac_file,{"~s",[rbac_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps},
   {tracing_enabled,tracing_enabled},
   {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
   {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
   {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
   {logger,
    {[{filename,{"~s/~s",[log_path,log_prefix]}},
      {cyclesize,log_cyclesize},
      {sleeptime,log_sleeptime}]}}]}]
[ns_server:debug,2020-05-07T12:09:36.457Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {privilege_debug,false},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false},
 {tracing_enabled,true},
 {datatype_snappy,true}]
[ns_server:debug,2020-05-07T12:09:36.457Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2020-05-07T12:09:36.457Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2020-05-07T12:09:36.457Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T12:09:36.457Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9999]
[ns_server:debug,2020-05-07T12:09:36.457Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8093]
[ns_server:debug,2020-05-07T12:09:36.457Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2020-05-07T12:09:36.457Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18092]
[ns_server:debug,2020-05-07T12:09:36.457Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18093]
[ns_server:debug,2020-05-07T12:09:36.457Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18091]
[ns_server:debug,2020-05-07T12:09:36.457Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 <<"0f8760945f98b1efdbef0bd1ea6e8446">>]
[ns_server:debug,2020-05-07T12:09:36.457Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9998]
[ns_server:debug,2020-05-07T12:09:36.457Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|false]
[ns_server:debug,2020-05-07T12:09:36.465Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T12:09:36.472Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:trigger_ssl_reload:565]Notify services [capi_ssl_service] about secure_headers_changed change
[ns_server:debug,2020-05-07T12:09:36.472Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:525]Going to notify following services: [capi_ssl_service]
[ns_server:info,2020-05-07T12:09:36.479Z,ns_1@127.0.0.1:<0.267.0>:ns_ssl_services_setup:notify_service:708]Successfully notified service capi_ssl_service
[ns_server:info,2020-05-07T12:09:36.479Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:541]Succesfully notified services [capi_ssl_service]
[ns_server:debug,2020-05-07T12:09:36.481Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([alert_limits,audit,audit_decriptors,
                               auto_failover_cfg,auto_reprovision_cfg,
                               autocompaction,buckets,cbas_memory_quota,
                               cert_and_pkey,client_cert_auth,
                               cluster_compat_version,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,
                               index_aware_rebalance_disabled,
                               log_redaction_default_cfg,max_bucket_count,
                               memcached,memory_quota,nodes_wanted,otp,
                               password_policy,quorum_nodes,
                               read_only_user_creds,remote_clusters,
                               replication,rest,rest_creds,roles_definitions,
                               scramsha_fallback_salt,secure_headers,
                               server_groups,set_view_update_daemon,
                               users_upgrade,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>},
                               {metakv,<<"/eventing/settings/config">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {metakv,<<"/query/settings/config">>},
                               {rbac_upgrade,[5,5]},
                               {request_limit,capi},
                               {request_limit,rest},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',cbas_admin_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_client_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_http_port},
                               {node,'ns_1@127.0.0.1',cbas_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_console_port},
                               {node,'ns_1@127.0.0.1',cbas_data_port},
                               {node,'ns_1@127.0.0.1',cbas_debug_port},
                               {node,'ns_1@127.0.0.1',cbas_http_port},
                               {node,'ns_1@127.0.0.1',cbas_messaging_port},
                               {node,'ns_1@127.0.0.1',
                                   cbas_metadata_callback_port},
                               {node,'ns_1@127.0.0.1',cbas_metadata_port},
                               {node,'ns_1@127.0.0.1',cbas_parent_port},
                               {node,'ns_1@127.0.0.1',cbas_replication_port},
                               {node,'ns_1@127.0.0.1',cbas_result_port},
                               {node,'ns_1@127.0.0.1',cbas_ssl_port}]..)
[ns_server:info,2020-05-07T12:09:36.485Z,ns_1@127.0.0.1:ns_couchdb_port<0.205.0>:ns_port_server:log:223]ns_couchdb<0.205.0>: 173: Booted. Waiting for shutdown request

[error_logger:info,2020-05-07T12:09:36.487Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.252.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.487Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.245.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:09:36.498Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.238.0>
[ns_server:debug,2020-05-07T12:09:36.498Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[error_logger:info,2020-05-07T12:09:36.498Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.274.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.499Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.238.0>
[ns_server:debug,2020-05-07T12:09:36.526Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[error_logger:info,2020-05-07T12:09:36.527Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.276.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.528Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.279.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.528Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.280.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T12:09:36.528Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T12:09:36.528Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2020-05-07T12:09:36.531Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.282.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.531Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.281.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:36.531Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.283.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.531Z,ns_1@127.0.0.1:ns_log_events<0.244.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2020-05-07T12:09:36.536Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.284.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.540Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.286.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.540Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.290.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.540Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.285.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:36.542Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.295.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.551Z,ns_1@127.0.0.1:ns_heart<0.286.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2020-05-07T12:09:36.552Z,ns_1@127.0.0.1:ns_heart<0.286.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]}]}}

[error_logger:info,2020-05-07T12:09:36.555Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.297.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.555Z,ns_1@127.0.0.1:<0.293.0>:restartable:start_child:98]Started child process <0.294.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2020-05-07T12:09:36.555Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.293.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:36.555Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.300.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.559Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.301.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.559Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.302.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.559Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.303.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.559Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.304.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.561Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.306.0>},
                       {name,query_settings_manager},
                       {mfargs,{query_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.565Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.308.0>},
                       {name,eventing_settings_manager},
                       {mfargs,{eventing_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.565Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.310.0>},
                       {name,audit_events},
                       {mfargs,{gen_event,start_link,[{local,audit_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.585Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.313.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.585Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.315.0>},
                       {name,scram_sha},
                       {mfargs,{scram_sha,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.589Z,ns_1@127.0.0.1:ns_heart<0.286.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2020-05-07T12:09:36.590Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.316.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.610Z,ns_1@127.0.0.1:ns_heart<0.286.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T12:09:36.616Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.318.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.624Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.321.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.624Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.322.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:36.624Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T12:09:36.625Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T12:09:36.625Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T12:09:36.625Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[error_logger:info,2020-05-07T12:09:36.625Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.323.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.631Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.340.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.637Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.341.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.640Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.342.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.641Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.290.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,244}]},
                 {proc_lib,init_p_do_apply,3,
                           [{file,"proc_lib.erl"},{line,239}]}]}}

[ns_server:debug,2020-05-07T12:09:36.641Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.290.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,244}]}]}}

[ns_server:debug,2020-05-07T12:09:36.642Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.290.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T12:09:36.642Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.290.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T12:09:36.643Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.356.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2020-05-07T12:09:36.643Z,ns_1@127.0.0.1:ns_server_sup<0.231.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "6.0.3-2895-enterprise".
[error_logger:info,2020-05-07T12:09:36.643Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.311.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:36.643Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.362.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.648Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.367.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:36.649Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.369.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.31986353>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.649Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.365.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:09:36.658Z,ns_1@127.0.0.1:ns_ports_setup<0.362.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,goxdcr]
[error_logger:info,2020-05-07T12:09:36.670Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.371.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.671Z,ns_1@127.0.0.1:ns_audit_cfg<0.372.0>:ns_audit_cfg:write_audit_json:265]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{descriptors_path,
                                                                                <<"/opt/couchbase/etc/security">>},
                                                                               {version,
                                                                                2},
                                                                               {uuid,
                                                                                <<"18411111">>},
                                                                               {event_states,
                                                                                {[]}},
                                                                               {filtering_enabled,
                                                                                true},
                                                                               {disabled_userids,
                                                                                []},
                                                                               {auditd_enabled,
                                                                                false},
                                                                               {log_path,
                                                                                <<"/opt/couchbase/var/lib/couchbase/logs">>},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []}]
[ns_server:debug,2020-05-07T12:09:36.689Z,ns_1@127.0.0.1:ns_audit_cfg<0.372.0>:ns_audit_cfg:notify_memcached:170]Instruct memcached to reload audit config
[error_logger:info,2020-05-07T12:09:36.689Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.372.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T12:09:36.690Z,ns_1@127.0.0.1:<0.375.0>:ns_memcached:connect:1230]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2020-05-07T12:09:36.697Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.376.0>},
                       {name,ns_audit},
                       {mfargs,{ns_audit,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.699Z,ns_1@127.0.0.1:memcached_config_mgr<0.377.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2020-05-07T12:09:36.699Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.377.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:36.706Z,ns_1@127.0.0.1:<0.378.0>:ns_memcached_log_rotator:init:42]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2020-05-07T12:09:36.706Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.706Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.379.0>},
                       {name,testconditions_store},
                       {mfargs,{simple_store,start_link,[testconditions]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.708Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.381.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.710Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.383.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.711Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.382.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:36.711Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.380.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:36.724Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.384.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.724Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.388.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.727Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.390.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.736Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.391.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.736Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.393.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.753Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.394.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.754Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.396.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.765Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.397.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.769Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.399.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.769Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.401.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:36.785Z,ns_1@127.0.0.1:ns_couchdb_port<0.205.0>:ns_port_server:log:223]ns_couchdb<0.205.0>: working as port

[error_logger:info,2020-05-07T12:09:36.834Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.402.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.842Z,ns_1@127.0.0.1:ns_ports_setup<0.362.0>:ns_ports_setup:set_children:90]Monitor ns_child_ports_sup <12401.74.0>
[ns_server:debug,2020-05-07T12:09:36.842Z,ns_1@127.0.0.1:memcached_config_mgr<0.377.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:info,2020-05-07T12:09:36.877Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.406.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.881Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.406.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T12:09:36.881Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.406.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T12:09:36.918Z,ns_1@127.0.0.1:memcached_config_mgr<0.377.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.80.0>
[ns_server:debug,2020-05-07T12:09:36.939Z,ns_1@127.0.0.1:memcached_config_mgr<0.377.0>:memcached_config_mgr:init:79]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[error_logger:info,2020-05-07T12:09:36.941Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.412.0>},
                       {name,service_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_stats_children_sup},
                                services_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:36.945Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.414.0>},
                       {name,service_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [service_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.949Z,ns_1@127.0.0.1:memcached_config_mgr<0.377.0>:memcached_config_mgr:init:82]activated memcached port server
[error_logger:info,2020-05-07T12:09:36.963Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.415.0>},
                       {name,service_status_keeper_index},
                       {mfargs,{service_index,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.966Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.418.0>},
                       {name,service_status_keeper_fts},
                       {mfargs,{service_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.970Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.421.0>},
                       {name,service_status_keeper_eventing},
                       {mfargs,{service_eventing,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.970Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.413.0>},
                       {name,service_status_keeper_sup},
                       {mfargs,{service_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:36.971Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.424.0>},
                       {name,service_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<services_stats_sup.0.41280346>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:36.971Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.411.0>},
                       {name,services_stats_sup},
                       {mfargs,{services_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:36.986Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.426.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:36.999Z,ns_1@127.0.0.1:<0.429.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.429.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2020-05-07T12:09:37.002Z,ns_1@127.0.0.1:compaction_new_daemon<0.427.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:09:37.002Z,ns_1@127.0.0.1:compaction_new_daemon<0.427.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:09:37.002Z,ns_1@127.0.0.1:compaction_new_daemon<0.427.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[error_logger:info,2020-05-07T12:09:37.002Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.427.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:37.002Z,ns_1@127.0.0.1:compaction_new_daemon<0.427.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:09:37.002Z,ns_1@127.0.0.1:compaction_new_daemon<0.427.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:09:37.002Z,ns_1@127.0.0.1:compaction_new_daemon<0.427.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2020-05-07T12:09:37.004Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.431.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:37.004Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.430.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:37.006Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.432.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:37.022Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.436.0>},
                       {name,leader_activities},
                       {mfargs,{leader_activities,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T12:09:37.029Z,ns_1@127.0.0.1:leader_lease_agent<0.437.0>:leader_lease_agent:maybe_recover_persisted_lease:397]Found persisted lease [{node,'ns_1@127.0.0.1'},
                       {uuid,<<"510c4d8812fc511414a6608f96c5fb7e">>},
                       {time_left,15000},
                       {status,active}]
[error_logger:info,2020-05-07T12:09:37.029Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.437.0>},
                       {name,leader_lease_agent},
                       {mfargs,{leader_lease_agent,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:37.029Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.435.0>},
                       {name,leader_leases_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_leases_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:37.029Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.439.0>},
                       {name,leader_events},
                       {mfargs,{gen_event,start_link,[{local,leader_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:37.033Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.440.0>},
                       {name,leader_registry_server},
                       {mfargs,{leader_registry_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:37.036Z,ns_1@127.0.0.1:leader_registry_sup<0.438.0>:mb_master:check_master_takeover_needed:270]Sending master node question to the following nodes: []
[ns_server:debug,2020-05-07T12:09:37.036Z,ns_1@127.0.0.1:leader_registry_sup<0.438.0>:mb_master:check_master_takeover_needed:272]Got replies: []
[ns_server:debug,2020-05-07T12:09:37.036Z,ns_1@127.0.0.1:leader_registry_sup<0.438.0>:mb_master:check_master_takeover_needed:278]Was unable to discover master, not going to force mastership takeover
[user:info,2020-05-07T12:09:37.036Z,ns_1@127.0.0.1:mb_master<0.443.0>:mb_master:init:90]I'm the only node, so I'm the master.
[ns_server:debug,2020-05-07T12:09:37.036Z,ns_1@127.0.0.1:leader_registry<0.440.0>:leader_registry_server:handle_new_leader:241]New leader is 'ns_1@127.0.0.1'. Invalidating name cache.
[error_logger:info,2020-05-07T12:09:37.048Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.446.0>},
                       {name,leader_lease_acquirer},
                       {mfargs,{leader_lease_acquirer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:37.050Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.448.0>:leader_quorum_nodes_manager:pull_config:114]Attempting to pull config from nodes:
[]
[error_logger:info,2020-05-07T12:09:37.050Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.448.0>},
                       {name,leader_quorum_nodes_manager},
                       {mfargs,{leader_quorum_nodes_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:37.050Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.448.0>:leader_quorum_nodes_manager:pull_config:119]Pulled config successfully.
[ns_server:warn,2020-05-07T12:09:37.055Z,ns_1@127.0.0.1:<0.454.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 14973ms)
[ns_server:info,2020-05-07T12:09:37.061Z,ns_1@127.0.0.1:mb_master_sup<0.445.0>:misc:start_singleton:758]start_singleton(gen_server, ns_tick, [], []): started as <0.457.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T12:09:37.061Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.457.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:37.070Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.460.0>},
                       {name,ns_janitor_server},
                       {mfargs,{ns_janitor_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:37.071Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.459.0>:misc:start_singleton:758]start_singleton(gen_server, auto_reprovision, [], []): started as <0.461.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T12:09:37.071Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.461.0>},
                       {name,auto_reprovision},
                       {mfargs,{auto_reprovision,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:37.071Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.459.0>:misc:start_singleton:758]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.462.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T12:09:37.072Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.462.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:37.072Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.459.0>},
                       {name,ns_orchestrator_child_sup},
                       {mfargs,{ns_orchestrator_child_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:09:37.074Z,ns_1@127.0.0.1:<0.464.0>:auto_failover:init:211]init auto_failover.
[user:info,2020-05-07T12:09:37.074Z,ns_1@127.0.0.1:<0.464.0>:auto_failover:handle_call:242]Enabled auto-failover with timeout 120 and max count 1
[ns_server:debug,2020-05-07T12:09:37.082Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{7,63756072577}}]}]
[ns_server:debug,2020-05-07T12:09:37.082Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([auto_failover_cfg,
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>}]..)
[ns_server:info,2020-05-07T12:09:37.082Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.458.0>:misc:start_singleton:758]start_singleton(gen_server, auto_failover, [], []): started as <0.464.0> on 'ns_1@127.0.0.1'

[ns_server:debug,2020-05-07T12:09:37.082Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[error_logger:info,2020-05-07T12:09:37.082Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.464.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:37.082Z,ns_1@127.0.0.1:<0.433.0>:restartable:start_child:98]Started child process <0.434.0>
  MFA: {leader_services_sup,start_link,[]}
[error_logger:info,2020-05-07T12:09:37.082Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.458.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:37.082Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.443.0>},
                       {name,mb_master},
                       {mfargs,{mb_master,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:37.082Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.438.0>},
                       {name,leader_registry_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_registry_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:37.082Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.433.0>},
                       {name,leader_services_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{leader_services_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:37.082Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.472.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:37.083Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.473.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:37.092Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.474.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:37.094Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.475.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:37.123Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.478.0>},
                       {name,ns_server_monitor},
                       {mfargs,{ns_server_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:37.124Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.480.0>},
                       {name,service_monitor_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_monitor_children_sup},
                                health_monitor_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:37.124Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.481.0>},
                       {name,service_monitor_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<health_monitor_sup.0.81875396>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:37.131Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.489.0>},
                       {name,node_monitor},
                       {mfargs,{node_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:37.132Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.497.0>},
                       {name,node_status_analyzer},
                       {mfargs,{node_status_analyzer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:37.132Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.477.0>},
                       {name,health_monitor_sup},
                       {mfargs,{health_monitor_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:09:37.132Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[error_logger:info,2020-05-07T12:09:37.132Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.231.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:09:37.132Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.169.0>
[ns_server:debug,2020-05-07T12:09:37.132Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2020-05-07T12:09:37.132Z,ns_1@127.0.0.1:<0.168.0>:restartable:start_child:98]Started child process <0.169.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[error_logger:info,2020-05-07T12:09:37.132Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.168.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:37.132Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:debug,2020-05-07T12:09:37.133Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:130]139: Entered child_loop
[ns_server:debug,2020-05-07T12:09:37.137Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@",admin}
[ns_server:debug,2020-05-07T12:09:37.151Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.500.0>:json_rpc_connection:init:73]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.500.0>
[ns_server:debug,2020-05-07T12:09:37.152Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.501.0>:json_rpc_connection:init:73]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.501.0>
[ns_server:debug,2020-05-07T12:09:37.152Z,ns_1@127.0.0.1:menelaus_cbauth<0.356.0>:menelaus_cbauth:handle_cast:102]Observed json rpc process {"goxdcr-cbauth",<0.501.0>} started
[ns_server:debug,2020-05-07T12:09:37.164Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@goxdcr-cbauth",admin}
[ns_server:debug,2020-05-07T12:09:37.426Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:89]Refresh of [rbac,isasl] succeeded
[ns_server:debug,2020-05-07T12:09:38.075Z,ns_1@127.0.0.1:<0.464.0>:auto_failover_logic:log_master_activity:170]Transitioned node {'ns_1@127.0.0.1',<<"0f8760945f98b1efdbef0bd1ea6e8446">>} state new -> up
[ns_server:info,2020-05-07T12:09:58.442Z,nonode@nohost:<0.89.0>:ns_server:init_logging:150]Started & configured logging
[ns_server:info,2020-05-07T12:09:58.453Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_access,info},
 {disk_sink_opts,[{rotation,[{compress,true},
                             {size,41943040},
                             {num_files,10},
                             {buffer_size_max,52428800}]}]},
 {disk_sink_opts_json_rpc,[{rotation,[{compress,true},
                                      {size,41943040},
                                      {num_files,2},
                                      {buffer_size_max,52428800}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2020-05-07T12:09:58.453Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.453Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.453Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.453Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_json_rpc, which is given from command line
[ns_server:warn,2020-05-07T12:09:58.454Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2020-05-07T12:09:58.469Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.138.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:58.474Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,76}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-378cfab] [64-bit] [smp:2:2] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2020,5,7},{12,9,58}}},
               {memory,
                   [{total,110208888},
                    {processes,9335160},
                    {processes_used,9333416},
                    {system,100873728},
                    {atom,339441},
                    {atom_used,322610},
                    {binary,78472},
                    {code,7796739},
                    {ets,2241584}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,path_config,calendar,
                    ale_default_formatter,'ale_logger-metakv',
                    'ale_logger-rebalance','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-json_rpc',
                    'ale_logger-access','ale_logger-ns_server',
                    'ale_logger-user','ale_logger-ns_doctor',io_lib_fread,
                    'ale_logger-cluster','ale_logger-xdcr',otp_internal,
                    ns_log_sink,ale_disk_sink,misc,couch_util,ns_server,
                    filelib,cpu_sup,memsup,disksup,os_mon,io,release_handler,
                    overload,alarm_handler,sasl,timer,tftp_sup,httpd_sup,
                    httpc_handler_sup,httpc_cookie,inets_trace,httpc_manager,
                    httpc,httpc_profile_sup,httpc_sup,ftp_sup,inets_sup,
                    inets_app,ssl,lhttpc_manager,lhttpc_sup,lhttpc,
                    tls_connection_sup,ssl_session_cache,ssl_pkix_db,
                    ssl_manager,ssl_sup,ssl_app,crypto_server,crypto_sup,
                    crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_io,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","6.0.3-2895-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","6.0.3-2895-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,105},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [lhttpc_sup,code_server,ale_stats_events,'sink-ns_log',
                    ns_server_cluster_sup,lhttpc_manager,
                    application_controller,ale,httpd_sup,release_handler,
                    kernel_safe_sup,standard_error,ale_sup,overload,
                    'sink-disk_json_rpc',error_logger,alarm_handler,
                    'sink-disk_metakv',ale_dynamic_sup,timer_server,
                    'sink-disk_access_int',standard_error_sup,
                    'sink-disk_access','sink-disk_reports',crypto_server,
                    crypto_sup,sasl_safe_sup,'sink-disk_stats',
                    'sink-disk_xdcr',tftp_sup,inet_db,init,os_mon_sup,
                    'sink-disk_debug',rex,tls_connection_sup,user,
                    'sink-disk_error',ssl_sup,kernel_sup,cpu_sup,
                    global_name_server,memsup,'sink-disk_default',disksup,
                    httpc_sup,file_server_2,ssl_manager,local_tasks,
                    global_group,httpc_profile_sup,httpc_manager,
                    httpc_handler_sup,ftp_sup,sasl_sup,erl_prim_loader,
                    inets_sup]},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,1}]
[ns_server:info,2020-05-07T12:09:58.480Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:27]Manifest:
["<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\" />",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\" />",
 "  ","  <default remote=\"couchbase\" revision=\"master\" />","  ",
 "  <project groups=\"kv\" name=\"HdrHistogram_c\" path=\"third_party/HdrHistogram_c\" remote=\"couchbasedeps\" revision=\"d200fc0f68695d4aef1fad5c3c8cc55f8c033014\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"analytics-dcp-client\" path=\"analytics/java-dcp-client\" revision=\"d6ba66b51c0e589e9d4571264afcb0e33d507aea\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"asterixdb\" path=\"analytics/asterixdb\" revision=\"e8e59d0e6e72ba3fd96074c021ff7180261dcd59\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"c5b9dd8ec0910d2890d215075a7d2da1d6a494c9\" />",
 "  <project groups=\"kv\" name=\"benchmark\" remote=\"couchbasedeps\" revision=\"9e3465560240ffb242b50a47cb7f19251a12ee42\" />",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\" />",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5cd1345cca3ed72f1e63d41d622fcda73e63fea8\" />",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"822d01dab8721cf469beb6d8304c9eadd9c58160\" />",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"f551b6d4f32bb920a83dd28c705bddd5de0d03b2\" />",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"4b158bb555a3297565afecf6fae675c74f1e47df\" />",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\" />",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\" />",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"dc55cf8e9613ddf1bd6db4a662d1ecc3668223da\">",
 "    <annotation name=\"RELEASE\" value=\"alice\" />",
 "    <annotation name=\"PRODUCT\" value=\"couchbase-server\" />",
 "    <annotation name=\"BLD_NUM\" value=\"2895\" />",
 "    <annotation name=\"VERSION\" value=\"6.0.3\" />","  </project>",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas\" path=\"goproj/src/github.com/couchbaselabs/cbas\" remote=\"couchbase-priv\" revision=\"73fa77cd9133a9f779a484ac2caffb0b46a1dd82\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas-core\" path=\"analytics\" remote=\"couchbase-priv\" revision=\"7e513c6bd60a030c3a2477af683b264d61932a75\" />",
 "  <project groups=\"analytics\" name=\"cbas-ui\" revision=\"d8f601c3109887a30deccab09b2177bf499c8711\" />",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"0df84c7e3c6d95ff435c12a3c08c6f064db11e97\" />",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"80d2ad8892d806f5103f602fec0d80adaa4b628f\" />",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"8d4105a904e0282a6928de7392e266c58ea3c7a2\" />",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"0a94f40b9080e0ecb11d3b7531a58c5e6a4a4465\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"93d26dbc120c4f9874abb65aafa4d815334273c6\" />",
 "  <project name=\"cbsummary\" path=\"goproj/src/github.com/couchbase/cbsummary\" revision=\"dbfa1c0d73f0e49f6f04e390f03de8f9a6cee769\" />",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"dcae66272b24600ae0005fa06b511cfae8914d3d\" />",
 "  <project name=\"cobra\" path=\"godeps/src/github.com/spf13/cobra\" remote=\"couchbasedeps\" revision=\"0f056af21f5f368e5b0646079d0094a2c64150f7\" />",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\" />",
 "  <project groups=\"notdefault,kv_ee,enterprise\" name=\"couch_rocks\" remote=\"couchbase-priv\" revision=\"75f37fa46bfe5e445dee077157303968a3e09126\" />",
 "  <project name=\"couchbase-cli\" revision=\"9b383603860ce58885c27015c92635a7b42d3a1f\" />",
 "  <project name=\"couchdb\" revision=\"c2b98200b800f9fbed927c47074884b9f5f53eb4\" />",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"69aa5d92e195a30e06184911d72b8fffcf2534fe\" />",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"c2c458ff2cf93ee63bf4b0386f495b22535daf96\" />",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\" />",
 "  <project name=\"cuckoofilter\" path=\"godeps/src/github.com/seiflotfy/cuckoofilter\" remote=\"couchbasedeps\" revision=\"d04838794ab86926d32b124345777e55e6f43974\" />",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\" />",
 "  <project name=\"docloader\" path=\"goproj/src/github.com/couchbase/docloader\" revision=\"05067021a042a1b63e100a486afd7ebddab4c535\" />",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\" />",
 "  <project name=\"errors\" path=\"godeps/src/github.com/pkg/errors\" remote=\"couchbasedeps\" revision=\"30136e27e2ac8d167177e8a583aa4c3fea5be833\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"eventing\" path=\"goproj/src/github.com/couchbase/eventing\" revision=\"1da67e30a4c8faaf24f067eae280f5764d943dc2\" upstream=\"alice\" />",
 "  <project name=\"flatbuffers\" path=\"godeps/src/github.com/google/flatbuffers\" remote=\"couchbasedeps\" revision=\"1a8968225130caeddd16e227678e6f8af1926303\" />",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"c338e06e6847140f749058184d66de1f2a43474a\" />",
 "  <project name=\"fwd\" path=\"godeps/src/github.com/philhofer/fwd\" remote=\"couchbasedeps\" revision=\"bb6d471dc95d4fe11e432687f8b70ff496cf3136\" />",
 "  <project name=\"geocouch\" revision=\"2a0e73f43451045f157640eec59ced72da18471f\" />",
 "  <project name=\"ghistogram\" path=\"godeps/src/github.com/couchbase/ghistogram\" revision=\"d910dd063dd68fb4d2a1ba344440f834ebb4ef62\" />",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\" />",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"5c0ac9ef0ba7a0356279cee7eadd8874c4a8f8c1\" />",
 "  <project name=\"go-curl\" path=\"godeps/src/github.com/andelf/go-curl\" remote=\"couchbasedeps\" revision=\"f0b2afc926ec79be5d7f30393b3485352781a705\" />",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\" />",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\" />",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\" />",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\" />",
 "  <project name=\"go-sqlite3\" path=\"godeps/src/github.com/mattn/go-sqlite3\" remote=\"couchbasedeps\" revision=\"47fc4e5e9153645da45af6a86a5bce95e63a0f9e\" />",
 "  <project name=\"go-unsnap-stream\" path=\"godeps/src/github.com/glycerine/go-unsnap-stream\" remote=\"couchbasedeps\" revision=\"62a9a9eb44fd8932157b1a8ace2149eff5971af6\" />",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\" />",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"d2f15a425a9c8e4d8447e5f5b89ce14845f7fa05\" />",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\" />",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"699b13a51af5dd4f80ff3deedf41bba60debad32\" />",
 "  <project name=\"gocbconnstr\" path=\"godeps/src/gopkg.in/couchbaselabs/gocbconnstr.v1\" remote=\"couchbaselabs\" revision=\"710456e087a6d497e87f41d0a9d98d6a75672186\" />",
 "  <project name=\"gocbcore\" path=\"godeps/src/gopkg.in/couchbase/gocbcore.v7\" revision=\"a0d26c2d6f5de912499d35a5aba573006e5e036f\" />",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"aecdbe5a5a91f0688df7bdf260ca962178c06828\" />",
 "  <project name=\"gofarmhash\" path=\"godeps/src/github.com/leemcloughlin/gofarmhash\" remote=\"couchbasedeps\" revision=\"0a055c5b87a8c55ce83459cbf2776b563822a942\" />",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\" />",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\" />",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\" />",
 "  <project name=\"golang-tools\" path=\"godeps/src/golang.org/x/tools\" remote=\"couchbasedeps\" revision=\"a28dfb48e06b2296b66678872c2cb638f0304f20\" />",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\" />",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"e05ec3550789be1da2981787ef6444fef75e10bc\" />",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"4809dd3aa2ab88013b1dfce15516d717a35cb6e8\" />",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\" />",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\" />",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\" />",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"f98adca8eb365032cab838ef4d99453931afa112\" />",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"122ae25ed207cca30ceaee9ac66342a603d43a31\" />",
 "  <project groups=\"kv\" name=\"gsl-lite\" path=\"third_party/gsl-lite\" remote=\"couchbasedeps\" revision=\"57542c7e7ced375346e9ac55dad85b942cfad556\" />",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\" />",
 "  <project name=\"httprouter\" path=\"godeps/src/github.com/julienschmidt/httprouter\" remote=\"couchbasedeps\" revision=\"975b5c4c7c21c0e3d2764200bf2aa8e34657ae6e\" />",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"95ed84aad6bf8ecd99da2372dceede6d93f3d43a\" />",
 "  <project name=\"json-iterator-go\" path=\"godeps/src/github.com/json-iterator/go\" remote=\"couchbasedeps\" revision=\"f7279a603edee96fe7764d3de9c6ff8cf9970994\" />",
 "  <project name=\"jsonx\" path=\"godeps/src/gopkg.in/couchbaselabs/jsonx.v1\" remote=\"couchbaselabs\" revision=\"5b7baa20429a46a5543ee259664cc86502738cad\" />",
 "  <project groups=\"kv\" name=\"kv_engine\" revision=\"a30fd9d57cc2101078c8cd2c44968458df965c2b\" />",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"libcouchbase\" revision=\"081e8b16b991bf706eb77f8243935c6fba31b895\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"3681c2a912330352991ecdd642f257efe5b85518\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\" />",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\" />",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\" />",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"956632ec1bc3e28276d00ee2f22c3202f06efb12\" />",
 "  <project name=\"mossScope\" path=\"godeps/src/github.com/couchbase/mossScope\" revision=\"abd3b58b422dbc2e9463a589d0f3d93441726e23\" />",
 "  <project name=\"mousetrap\" path=\"godeps/src/github.com/inconshreveable/mousetrap\" remote=\"couchbasedeps\" revision=\"76626ae9c91c4f2a10f34cad8ce83ea42c93bb75\" />",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"cd8da46b9b953800d430c8b0aa4667790727ed6f\" />",
 "  <project name=\"msgp\" path=\"godeps/src/github.com/tinylib/msgp\" remote=\"couchbasedeps\" revision=\"5bb5e1aed7ba5bcc93307153b020e7ffe79b0509\" />",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"043ee6597c29786140136a5747b6a886364f5282\" />",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"62685c2d7ca23c807425dca88b11a3e2323dab41\" />",
 "  <project name=\"nitro\" path=\"goproj/src/github.com/couchbase/nitro\" revision=\"f3bef3551997be504612a2d05a8b324b3bfdfe1b\" />",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\" />",
 "  <project name=\"ns_server\" revision=\"8117c5307974f397ad831a2b870fb3ee0fd8364d\" />",
 "  <project name=\"opentracing-go\" path=\"godeps/src/github.com/opentracing/opentracing-go\" remote=\"couchbasedeps\" revision=\"1949ddbfd147afd4d964a9f00b24eb291e0e7c38\" />",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\" />",
 "  <project name=\"pflag\" path=\"godeps/src/github.com/spf13/pflag\" remote=\"couchbasedeps\" revision=\"a232f6d9f87afaaa08bafaff5da685f974b83313\" />",
 "  <project groups=\"kv\" name=\"phosphor\" revision=\"96501c57bb0fd61c85cba6f63101aed2bcf41d38\" />",
 "  <project name=\"pierrec-lz4\" path=\"godeps/src/github.com/pierrec/lz4\" remote=\"couchbasedeps\" revision=\"ed8d4cc3b461464e69798080a0092bd028910298\" />",
 "  <project name=\"pierrec-xxHash\" path=\"godeps/src/github.com/pierrec/xxHash\" remote=\"couchbasedeps\" revision=\"a0006b13c722f7f12368c00a3d3c2ae8a999a0c6\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"plasma\" path=\"goproj/src/github.com/couchbase/plasma\" remote=\"couchbase-priv\" revision=\"c0792c8cfb1463ef029f064f34e366442f1f0064\" />",
 "  <project groups=\"kv\" name=\"platform\" revision=\"de77d527bd23012dc67794c81a7b1e76e46e3abd\" />",
 "  <project groups=\"kv\" name=\"product-texts\" revision=\"8cf7d25a1dcb5434ea44983c0bed202fb9cc8351\" />",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\" />",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"d2011f6ee9f6e1dca5d3922d44fbcf86dad78150\" />",
 "  <project name=\"query-ui\" revision=\"15a6461f437fe810e411a6613ec7c143991cd1c6\" />",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\" />",
 "  <project name=\"roaring\" path=\"godeps/src/github.com/RoaringBitmap/roaring\" remote=\"couchbasedeps\" revision=\"fe09428be4c233d726797a1380f7438f4f71a31a\" />",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"762005e7a34fd909a84586299f1dd457371d36ee\" />",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"73353fe6dad8f3d67409feefb9b17f90f6de917b\" />",
 "  <project name=\"snowballstem\" path=\"godeps/src/github.com/blevesearch/snowballstem\" remote=\"blevesearch\" revision=\"26b06a2c243d4f8ca5db3486f94409dd5b2a7467\" />",
 "  <project groups=\"kv\" name=\"spdlog\" path=\"third_party/spdlog\" remote=\"couchbasedeps\" revision=\"4fba14c79f356ae48d6141c561bf9fd7ba33fabd\" />",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\" />",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"c30c3d4c250e68e81c57aa1e8ae91ffd21243cdb\" />",
 "  <project name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\" />",
 "  <project name=\"testrunner\" revision=\"4133fd785987f1ddcdb49dab736ff6e5e67d7c95\" upstream=\"alice\" />",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\" />",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"6dadf98e19803cc10ce9552bf4d9121cc2528965\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\" />",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\" />",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\" />",
 "    <copyfile dest=\".clang-format\" src=\"dot-clang-format\" />",
 "    <copyfile dest=\"third_party/CMakeLists.txt\" src=\"third-party-CMakeLists.txt\" />",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\" />",
 "  <project name=\"uuid\" path=\"godeps/src/github.com/google/uuid\" remote=\"couchbasedeps\" revision=\"dec09d789f3dba190787f8b4454c7d3c936fed9e\" />",
 "  <project name=\"vellum\" path=\"godeps/src/github.com/couchbase/vellum\" revision=\"0ceea4a37442f76199b9259840baf48d17af3c1a\" />",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"b3d83fe61db37bb38a46cd8dee434e5682cba2c7\" />",
 "  <project name=\"zstd\" path=\"godeps/src/github.com/DataDog/zstd\" remote=\"couchbasedeps\" revision=\"aebefd9fcb99f22cd691ef778a12ed68f0e6a1ab\" />",
 "</manifest>"]

[error_logger:info,2020-05-07T12:09:58.510Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.139.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:58.512Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2020-05-07T12:09:58.513Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2020-05-07T12:09:58.513Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:init:243]ip config not found. Looks like we're brand new node
[error_logger:info,2020-05-07T12:09:58.513Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.143.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2020-05-07T12:09:58.513Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.142.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:58.655Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:bringup:295]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2020-05-07T12:09:58.664Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.145.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.664Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.146.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:58.665Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:configure_net_kernel:339]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2020-05-07T12:09:58.664Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.147.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.665Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.144.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2020-05-07T12:09:58.670Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:save_node:227]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2020-05-07T12:09:58.680Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:bringup:309]Attempted to save node name to disk: ok
[ns_server:debug,2020-05-07T12:09:58.680Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:316]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2020-05-07T12:09:58.680Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T12:09:58.689Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:328]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2020-05-07T12:09:58.689Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.697Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.697Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:58.699Z,ns_1@127.0.0.1:ns_config_sup<0.154.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2020-05-07T12:09:58.699Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.155.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.699Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.156.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:58.731Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1095]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2020-05-07T12:09:58.732Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1109]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:debug,2020-05-07T12:09:58.747Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1117]Here's full dynamic config we loaded:
[[{auto_failover_cfg,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {enabled,true},
    {timeout,120},
    {count,0},
    {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
    {failover_server_group,false},
    {max_count,1},
    {failed_over_server_groups,[]}]},
  {alert_limits,
   [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
  {audit,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {enabled,[]},
    {disabled_users,[]},
    {auditd_enabled,false},
    {rotate_interval,86400},
    {rotate_size,20971520},
    {disabled,[]},
    {sync,[]},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
  {audit_decriptors,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {20480,
     [{name,<<"opened DCP connection">>},
      {description,<<"opened DCP connection">>},
      {enabled,true},
      {module,memcached}]},
    {20482,
     [{name,<<"external memcached bucket flush">>},
      {description,
       <<"External user flushed the content of a memcached bucket">>},
      {enabled,true},
      {module,memcached}]},
    {20483,
     [{name,<<"invalid packet">>},
      {description,<<"Rejected an invalid packet">>},
      {enabled,true},
      {module,memcached}]},
    {20485,
     [{name,<<"authentication succeeded">>},
      {description,<<"Authentication to the cluster succeeded">>},
      {enabled,false},
      {module,memcached}]},
    {20488,
     [{name,<<"document read">>},
      {description,<<"Document was read">>},
      {enabled,false},
      {module,memcached}]},
    {20489,
     [{name,<<"document locked">>},
      {description,<<"Document was locked">>},
      {enabled,false},
      {module,memcached}]},
    {20490,
     [{name,<<"document modify">>},
      {description,<<"Document was modified">>},
      {enabled,false},
      {module,memcached}]},
    {20491,
     [{name,<<"document delete">>},
      {description,<<"Document was deleted">>},
      {enabled,false},
      {module,memcached}]},
    {20492,
     [{name,<<"select bucket">>},
      {description,<<"The specified bucket was selected">>},
      {enabled,true},
      {module,memcached}]},
    {28672,
     [{name,<<"SELECT statement">>},
      {description,<<"A N1QL SELECT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28673,
     [{name,<<"EXPLAIN statement">>},
      {description,<<"A N1QL EXPLAIN statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28674,
     [{name,<<"PREPARE statement">>},
      {description,<<"A N1QL PREPARE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28675,
     [{name,<<"INFER statement">>},
      {description,<<"A N1QL INFER statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28676,
     [{name,<<"INSERT statement">>},
      {description,<<"A N1QL INSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28677,
     [{name,<<"UPSERT statement">>},
      {description,<<"A N1QL UPSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28678,
     [{name,<<"DELETE statement">>},
      {description,<<"A N1QL DELETE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28679,
     [{name,<<"UPDATE statement">>},
      {description,<<"A N1QL UPDATE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28680,
     [{name,<<"MERGE statement">>},
      {description,<<"A N1QL MERGE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28681,
     [{name,<<"CREATE INDEX statement">>},
      {description,<<"A N1QL CREATE INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28682,
     [{name,<<"DROP INDEX statement">>},
      {description,<<"A N1QL DROP INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28683,
     [{name,<<"ALTER INDEX statement">>},
      {description,<<"A N1QL ALTER INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28684,
     [{name,<<"BUILD INDEX statement">>},
      {description,<<"A N1QL BUILD INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28685,
     [{name,<<"GRANT ROLE statement">>},
      {description,<<"A N1QL GRANT ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28686,
     [{name,<<"REVOKE ROLE statement">>},
      {description,<<"A N1QL REVOKE ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28687,
     [{name,<<"UNRECOGNIZED statement">>},
      {description,
       <<"An unrecognized statement was received by the N1QL query engine">>},
      {enabled,false},
      {module,n1ql}]},
    {28688,
     [{name,<<"CREATE PRIMARY INDEX statement">>},
      {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28689,
     [{name,<<"/admin/stats API request">>},
      {description,<<"An HTTP request was made to the API at /admin/stats.">>},
      {enabled,false},
      {module,n1ql}]},
    {28690,
     [{name,<<"/admin/vitals API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/vitals.">>},
      {enabled,false},
      {module,n1ql}]},
    {28691,
     [{name,<<"/admin/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28692,
     [{name,<<"/admin/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28693,
     [{name,<<"/admin/indexes/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28694,
     [{name,<<"/admin/indexes/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28695,
     [{name,<<"/admin/indexes/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28697,
     [{name,<<"/admin/ping API request">>},
      {description,<<"An HTTP request was made to the API at /admin/ping.">>},
      {enabled,false},
      {module,n1ql}]},
    {28698,
     [{name,<<"/admin/config API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/config.">>},
      {enabled,false},
      {module,n1ql}]},
    {28699,
     [{name,<<"/admin/ssl_cert API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
      {enabled,false},
      {module,n1ql}]},
    {28700,
     [{name,<<"/admin/settings API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/settings.">>},
      {enabled,false},
      {module,n1ql}]},
    {28701,
     [{name,<<"/admin/clusters API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/clusters.">>},
      {enabled,false},
      {module,n1ql}]},
    {28702,
     [{name,<<"/admin/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {32768,
     [{name,<<"Create Function">>},
      {description,<<"Eventing function definition was created or updated">>},
      {enabled,true},
      {module,eventing}]},
    {32769,
     [{name,<<"Delete Function">>},
      {description,<<"Eventing function definition was deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32770,
     [{name,<<"Fetch Functions">>},
      {description,<<"Eventing function definition was read">>},
      {enabled,false},
      {module,eventing}]},
    {32771,
     [{name,<<"List Deployed">>},
      {description,<<"Eventing deployed functions list was read">>},
      {enabled,false},
      {module,eventing}]},
    {32772,
     [{name,<<"Fetch Drafts">>},
      {description,<<"Eventing function draft definitions were read">>},
      {enabled,false},
      {module,eventing}]},
    {32773,
     [{name,<<"Delete Drafts">>},
      {description,<<"Eventing function draft definitions were deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32774,
     [{name,<<"Save Draft">>},
      {description,<<"Save a draft definition to the store">>},
      {enabled,true},
      {module,eventing}]},
    {32775,
     [{name,<<"Start Debug">>},
      {description,<<"Start eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32776,
     [{name,<<"Stop Debug">>},
      {description,<<"Stop eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32777,
     [{name,<<"Start Tracing">>},
      {description,<<"Start tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32778,
     [{name,<<"Stop Tracing">>},
      {description,<<"Stop tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32779,
     [{name,<<"Set Settings">>},
      {description,<<"Save settings for a given app">>},
      {enabled,true},
      {module,eventing}]},
    {32780,
     [{name,<<"Fetch Config">>},
      {description,<<"Get config for eventing">>},
      {enabled,false},
      {module,eventing}]},
    {32781,
     [{name,<<"Save Config">>},
      {description,<<"Save config for eventing">>},
      {enabled,true},
      {module,eventing}]},
    {32782,
     [{name,<<"Cleanup Eventing">>},
      {description,<<"Clears up app definitions and settings from metakv">>},
      {enabled,true},
      {module,eventing}]},
    {32783,
     [{name,<<"Get Settings">>},
      {description,<<"Get settings for a given app">>},
      {enabled,false},
      {module,eventing}]},
    {32784,
     [{name,<<"Import Functions">>},
      {description,<<"Import a list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32785,
     [{name,<<"Export Functions">>},
      {description,<<"Export the list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32786,
     [{name,<<"List Running">>},
      {description,<<"Eventing running function list was read">>},
      {enabled,false},
      {module,eventing}]},
    {36865,
     [{name,<<"Service configuration change">>},
      {description,<<"A successful service configuration change was made.">>},
      {enabled,true},
      {module,analytics}]},
    {36866,
     [{name,<<"Node configuration change">>},
      {description,<<"A successful node configuration change was made.">>},
      {enabled,true},
      {module,analytics}]}]},
  {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
  {autocompaction,
   [{database_fragmentation_threshold,{30,undefined}},
    {view_fragmentation_threshold,{30,undefined}}]},
  {buckets,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]},
    {configs,[]}]},
  {cbas_memory_quota,1024},
  {cert_and_pkey,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQlsomKQ7qhDcAeKZ3inWuCQuv8NxCAMb8M\nXhrVTrshZyFDiXdKS3Xbshyc9dEOiDwuDwAEgfwJQsXzzx0eCRtyTZfWAWTOH06O\nXdQps+9iTfr2KBFj27uag5c5ns+0ojsNyqZhA4+dbS7zK3CZ1dx7LPkL3+4HTlMh\nmH1/2fib3Lbp6dW3B55GV8/RHbkzgcRMyBicYtinqh6JMmmzjO/3KEyVHs3h0W1E\n00JdAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCKWU+bCvjKUlhW\niMiAN7r/3Vxkah7KEqp8BajCnLrlTMeiV+24TlPrsCWz4VBmOgt8OcijS3axdEik\nXeteeJp+R8nb2XPGivHOg/Hx2NlLxCrtXaYVGM0PiVydo24iCv0ZlqMCBsrzRLky\n5otbfQi8ngdfuR88C0/r3RLqvuFnOtFkLbKXuT/qshXfM8O/OgiJkr6CTBFYNd8w\nTCxN2syK41/HXoYzexdA/OTSm+kuEIuDpQYxKS0M4oKKZApJM70y/CYTzwG3JOnp\nuteZPYrwhIqxz01fkbLnj3QLGxPpSexRsp52GOoCv/YEE7tl3Olt4+p+MvhEZPdZ\ndqB53mNJ\n-----END CERTIFICATE-----\n">>,
     <<"*****">>}]},
  {client_cert_auth,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {state,"disable"},
    {prefixes,[]}]},
  {cluster_compat_version,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},
    6,0]},
  {drop_request_memory_threshold_mib,undefined},
  {email_alerts,
   [{recipients,["root@localhost"]},
    {sender,"couchbase@localhost"},
    {enabled,false},
    {email_server,
     [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
    {alerts,
     [auto_failover_node,auto_failover_maximum_reached,
      auto_failover_other_nodes_down,auto_failover_cluster_too_small,
      auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
      ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
      ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
  {fts_memory_quota,256},
  {index_aware_rebalance_disabled,false},
  {log_redaction_default_cfg,[{redact_level,none}]},
  {max_bucket_count,10},
  {memcached,[]},
  {memory_quota,311},
  {nodes_wanted,['ns_1@127.0.0.1']},
  {otp,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
    {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]},
  {password_policy,[{min_length,6},{must_present,[]}]},
  {quorum_nodes,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    'ns_1@127.0.0.1']},
  {read_only_user_creds,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {remote_clusters,[]},
  {replication,[{enabled,true}]},
  {rest,[{port,8091}]},
  {rest_creds,null},
  {roles_definitions,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {scramsha_fallback_salt,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<169,238,80,91,5,165,74,47,79,135,45,74>>]},
  {secure_headers,[]},
  {server_groups,
   [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
  {set_view_update_daemon,
   [{update_interval,5000},
    {update_min_changes,5000},
    {replica_update_min_changes,5000}]},
  {users_upgrade,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {{couchdb,max_parallel_indexers},4},
  {{couchdb,max_parallel_replica_indexers},2},
  {{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{7,63756072577}}]}]},
  {{metakv,<<"/eventing/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"ram_quota\":256}">>]},
  {{metakv,<<"/indexing/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
  {{metakv,<<"/query/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
  {{rbac_upgrade,[5,5]},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {{request_limit,capi},undefined},
  {{request_limit,rest},undefined},
  {{service_map,fts},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{service_map,index},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{service_map,n1ql},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{node,'ns_1@127.0.0.1',audit},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
  {{node,'ns_1@127.0.0.1',capi_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8092]},
  {{node,'ns_1@127.0.0.1',cbas_admin_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9110]},
  {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9113]},
  {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9112]},
  {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9111]},
  {{node,'ns_1@127.0.0.1',cbas_cluster_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9115]},
  {{node,'ns_1@127.0.0.1',cbas_console_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9114]},
  {{node,'ns_1@127.0.0.1',cbas_data_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9116]},
  {{node,'ns_1@127.0.0.1',cbas_debug_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    -1]},
  {{node,'ns_1@127.0.0.1',cbas_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8095]},
  {{node,'ns_1@127.0.0.1',cbas_messaging_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9118]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9119]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9121]},
  {{node,'ns_1@127.0.0.1',cbas_parent_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9122]},
  {{node,'ns_1@127.0.0.1',cbas_replication_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9120]},
  {{node,'ns_1@127.0.0.1',cbas_result_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9117]},
  {{node,'ns_1@127.0.0.1',cbas_ssl_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18095]},
  {{node,'ns_1@127.0.0.1',compaction_daemon},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {check_interval,30},
    {min_db_file_size,131072},
    {min_view_file_size,20971520}]},
  {{node,'ns_1@127.0.0.1',config_version},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {5,5,3}]},
  {{node,'ns_1@127.0.0.1',eventing_debug_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9140]},
  {{node,'ns_1@127.0.0.1',eventing_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8096]},
  {{node,'ns_1@127.0.0.1',eventing_https_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18096]},
  {{node,'ns_1@127.0.0.1',fts_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8094]},
  {{node,'ns_1@127.0.0.1',fts_ssl_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18094]},
  {{node,'ns_1@127.0.0.1',indexer_admin_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9100]},
  {{node,'ns_1@127.0.0.1',indexer_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9102]},
  {{node,'ns_1@127.0.0.1',indexer_https_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    19102]},
  {{node,'ns_1@127.0.0.1',indexer_scan_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9101]},
  {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9104]},
  {{node,'ns_1@127.0.0.1',indexer_stinit_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9103]},
  {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9105]},
  {{node,'ns_1@127.0.0.1',is_enterprise},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',isasl},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
  {{node,'ns_1@127.0.0.1',ldap_enabled},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',membership},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    active]},
  {{node,'ns_1@127.0.0.1',memcached},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,11210},
    {dedicated_port,11209},
    {ssl_port,11207},
    {admin_user,"@ns_server"},
    {other_users,
     ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
      "@cbas"]},
    {admin_pass,"*****"},
    {engines,
     [{membase,
       [{engine,"/opt/couchbase/lib/memcached/ep.so"},
        {static_config_string,"failpartialwarmup=false"}]},
      {memcached,
       [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
        {static_config_string,"vb0=true"}]}]},
    {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
    {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
    {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
    {log_prefix,"memcached.log"},
    {log_generations,20},
    {log_cyclesize,10485760},
    {log_sleeptime,19},
    {log_rotation_period,39003}]},
  {{node,'ns_1@127.0.0.1',memcached_config},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {[{interfaces,
       {memcached_config_mgr,omit_missing_mcd_ports,
        [{[{host,<<"*">>},
           {port,port},
           {maxconn,maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,dedicated_port},
           {maxconn,dedicated_port_maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,ssl_port},
           {maxconn,maxconn},
           {ssl,
            {[{key,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
              {cert,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]}]}},
      {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
      {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
      {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
      {connection_idle_time,connection_idle_time},
      {privilege_debug,privilege_debug},
      {breakpad,
       {[{enabled,breakpad_enabled},
         {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
      {admin,{"~s",[admin_user]}},
      {verbosity,verbosity},
      {audit_file,{"~s",[audit_file]}},
      {rbac_file,{"~s",[rbac_file]}},
      {dedupe_nmvb_maps,dedupe_nmvb_maps},
      {tracing_enabled,tracing_enabled},
      {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
      {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
      {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
      {logger,
       {[{filename,{"~s/~s",[log_path,log_prefix]}},
         {cyclesize,log_cyclesize},
         {sleeptime,log_sleeptime}]}}]}]},
  {{node,'ns_1@127.0.0.1',memcached_defaults},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {maxconn,30000},
    {dedicated_port_maxconn,5000},
    {ssl_cipher_list,"HIGH"},
    {connection_idle_time,0},
    {verbosity,0},
    {privilege_debug,false},
    {breakpad_enabled,true},
    {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
    {dedupe_nmvb_maps,false},
    {tracing_enabled,true},
    {datatype_snappy,true}]},
  {{node,'ns_1@127.0.0.1',moxi},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,11211},
    {verbosity,[]}]},
  {{node,'ns_1@127.0.0.1',ns_log},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
  {{node,'ns_1@127.0.0.1',port_servers},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
  {{node,'ns_1@127.0.0.1',projector_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9999]},
  {{node,'ns_1@127.0.0.1',query_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8093]},
  {{node,'ns_1@127.0.0.1',rest},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,8091},
    {port_meta,global}]},
  {{node,'ns_1@127.0.0.1',ssl_capi_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18092]},
  {{node,'ns_1@127.0.0.1',ssl_query_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18093]},
  {{node,'ns_1@127.0.0.1',ssl_rest_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18091]},
  {{node,'ns_1@127.0.0.1',uuid},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    <<"0f8760945f98b1efdbef0bd1ea6e8446">>]},
  {{node,'ns_1@127.0.0.1',xdcr_rest_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9998]},
  {{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    false]}]]
[ns_server:info,2020-05-07T12:09:58.753Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1138]Here's full dynamic config we loaded + static & default config:
[{{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   false]},
 {{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   <<"0f8760945f98b1efdbef0bd1ea6e8446">>]},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,8091},
   {port_meta,global}]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11211},
   {verbosity,[]}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {privilege_debug,false},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false},
   {tracing_enabled,true},
   {datatype_snappy,true}]},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},
          {port,port},
          {maxconn,maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {privilege_debug,privilege_debug},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {rbac_file,{"~s",[rbac_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps},
     {tracing_enabled,tracing_enabled},
     {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
     {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
     {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
     {logger,
      {[{filename,{"~s/~s",[log_path,log_prefix]}},
        {cyclesize,log_cyclesize},
        {sleeptime,log_sleeptime}]}}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"@ns_server"},
   {other_users,
    ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
     "@cbas"]},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   active]},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   19102]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',fts_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18094]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',eventing_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18096]},
 {{node,'ns_1@127.0.0.1',eventing_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8096]},
 {{node,'ns_1@127.0.0.1',eventing_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9140]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {5,5,3}]},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {{node,'ns_1@127.0.0.1',cbas_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18095]},
 {{node,'ns_1@127.0.0.1',cbas_result_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9117]},
 {{node,'ns_1@127.0.0.1',cbas_replication_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9120]},
 {{node,'ns_1@127.0.0.1',cbas_parent_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9122]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9121]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9119]},
 {{node,'ns_1@127.0.0.1',cbas_messaging_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9118]},
 {{node,'ns_1@127.0.0.1',cbas_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8095]},
 {{node,'ns_1@127.0.0.1',cbas_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]},
 {{node,'ns_1@127.0.0.1',cbas_data_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9116]},
 {{node,'ns_1@127.0.0.1',cbas_console_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9114]},
 {{node,'ns_1@127.0.0.1',cbas_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9115]},
 {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9111]},
 {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9112]},
 {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9113]},
 {{node,'ns_1@127.0.0.1',cbas_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9110]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{service_map,n1ql},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{service_map,index},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{service_map,fts},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{request_limit,rest},undefined},
 {{request_limit,capi},undefined},
 {{rbac_upgrade,[5,5]},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {{metakv,<<"/query/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
 {{metakv,<<"/indexing/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
 {{metakv,<<"/eventing/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"ram_quota\":256}">>]},
 {{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{7,63756072577}}]}]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {users_upgrade,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {secure_headers,[]},
 {scramsha_fallback_salt,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<169,238,80,91,5,165,74,47,79,135,45,74>>]},
 {roles_definitions,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {rest_creds,null},
 {rest,[{port,8091}]},
 {replication,[{enabled,true}]},
 {remote_clusters,[]},
 {read_only_user_creds,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {quorum_nodes,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   'ns_1@127.0.0.1']},
 {password_policy,[{min_length,6},{must_present,[]}]},
 {otp,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
   {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {memory_quota,311},
 {memcached,[]},
 {max_bucket_count,10},
 {log_redaction_default_cfg,[{redact_level,none}]},
 {index_aware_rebalance_disabled,false},
 {fts_memory_quota,256},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
 {drop_request_memory_threshold_mib,undefined},
 {cluster_compat_version,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},
   6,0]},
 {client_cert_auth,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {state,"disable"},
   {prefixes,[]}]},
 {cert_and_pkey,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQlsomKQ7qhDcAeKZ3inWuCQuv8NxCAMb8M\nXhrVTrshZyFDiXdKS3Xbshyc9dEOiDwuDwAEgfwJQsXzzx0eCRtyTZfWAWTOH06O\nXdQps+9iTfr2KBFj27uag5c5ns+0ojsNyqZhA4+dbS7zK3CZ1dx7LPkL3+4HTlMh\nmH1/2fib3Lbp6dW3B55GV8/RHbkzgcRMyBicYtinqh6JMmmzjO/3KEyVHs3h0W1E\n00JdAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCKWU+bCvjKUlhW\niMiAN7r/3Vxkah7KEqp8BajCnLrlTMeiV+24TlPrsCWz4VBmOgt8OcijS3axdEik\nXeteeJp+R8nb2XPGivHOg/Hx2NlLxCrtXaYVGM0PiVydo24iCv0ZlqMCBsrzRLky\n5otbfQi8ngdfuR88C0/r3RLqvuFnOtFkLbKXuT/qshXfM8O/OgiJkr6CTBFYNd8w\nTCxN2syK41/HXoYzexdA/OTSm+kuEIuDpQYxKS0M4oKKZApJM70y/CYTzwG3JOnp\nuteZPYrwhIqxz01fkbLnj3QLGxPpSexRsp52GOoCv/YEE7tl3Olt4+p+MvhEZPdZ\ndqB53mNJ\n-----END CERTIFICATE-----\n">>,
    <<"*****">>}]},
 {cbas_memory_quota,1024},
 {buckets,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]},
   {configs,[]}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
 {audit_decriptors,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {20480,
    [{name,<<"opened DCP connection">>},
     {description,<<"opened DCP connection">>},
     {enabled,true},
     {module,memcached}]},
   {20482,
    [{name,<<"external memcached bucket flush">>},
     {description,
      <<"External user flushed the content of a memcached bucket">>},
     {enabled,true},
     {module,memcached}]},
   {20483,
    [{name,<<"invalid packet">>},
     {description,<<"Rejected an invalid packet">>},
     {enabled,true},
     {module,memcached}]},
   {20485,
    [{name,<<"authentication succeeded">>},
     {description,<<"Authentication to the cluster succeeded">>},
     {enabled,false},
     {module,memcached}]},
   {20488,
    [{name,<<"document read">>},
     {description,<<"Document was read">>},
     {enabled,false},
     {module,memcached}]},
   {20489,
    [{name,<<"document locked">>},
     {description,<<"Document was locked">>},
     {enabled,false},
     {module,memcached}]},
   {20490,
    [{name,<<"document modify">>},
     {description,<<"Document was modified">>},
     {enabled,false},
     {module,memcached}]},
   {20491,
    [{name,<<"document delete">>},
     {description,<<"Document was deleted">>},
     {enabled,false},
     {module,memcached}]},
   {20492,
    [{name,<<"select bucket">>},
     {description,<<"The specified bucket was selected">>},
     {enabled,true},
     {module,memcached}]},
   {28672,
    [{name,<<"SELECT statement">>},
     {description,<<"A N1QL SELECT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28673,
    [{name,<<"EXPLAIN statement">>},
     {description,<<"A N1QL EXPLAIN statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28674,
    [{name,<<"PREPARE statement">>},
     {description,<<"A N1QL PREPARE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28675,
    [{name,<<"INFER statement">>},
     {description,<<"A N1QL INFER statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28676,
    [{name,<<"INSERT statement">>},
     {description,<<"A N1QL INSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28677,
    [{name,<<"UPSERT statement">>},
     {description,<<"A N1QL UPSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28678,
    [{name,<<"DELETE statement">>},
     {description,<<"A N1QL DELETE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28679,
    [{name,<<"UPDATE statement">>},
     {description,<<"A N1QL UPDATE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28680,
    [{name,<<"MERGE statement">>},
     {description,<<"A N1QL MERGE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28681,
    [{name,<<"CREATE INDEX statement">>},
     {description,<<"A N1QL CREATE INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28682,
    [{name,<<"DROP INDEX statement">>},
     {description,<<"A N1QL DROP INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28683,
    [{name,<<"ALTER INDEX statement">>},
     {description,<<"A N1QL ALTER INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28684,
    [{name,<<"BUILD INDEX statement">>},
     {description,<<"A N1QL BUILD INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28685,
    [{name,<<"GRANT ROLE statement">>},
     {description,<<"A N1QL GRANT ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28686,
    [{name,<<"REVOKE ROLE statement">>},
     {description,<<"A N1QL REVOKE ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28687,
    [{name,<<"UNRECOGNIZED statement">>},
     {description,
      <<"An unrecognized statement was received by the N1QL query engine">>},
     {enabled,false},
     {module,n1ql}]},
   {28688,
    [{name,<<"CREATE PRIMARY INDEX statement">>},
     {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28689,
    [{name,<<"/admin/stats API request">>},
     {description,<<"An HTTP request was made to the API at /admin/stats.">>},
     {enabled,false},
     {module,n1ql}]},
   {28690,
    [{name,<<"/admin/vitals API request">>},
     {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
     {enabled,false},
     {module,n1ql}]},
   {28691,
    [{name,<<"/admin/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28692,
    [{name,<<"/admin/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28693,
    [{name,<<"/admin/indexes/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28694,
    [{name,<<"/admin/indexes/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28695,
    [{name,<<"/admin/indexes/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28697,
    [{name,<<"/admin/ping API request">>},
     {description,<<"An HTTP request was made to the API at /admin/ping.">>},
     {enabled,false},
     {module,n1ql}]},
   {28698,
    [{name,<<"/admin/config API request">>},
     {description,<<"An HTTP request was made to the API at /admin/config.">>},
     {enabled,false},
     {module,n1ql}]},
   {28699,
    [{name,<<"/admin/ssl_cert API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
     {enabled,false},
     {module,n1ql}]},
   {28700,
    [{name,<<"/admin/settings API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/settings.">>},
     {enabled,false},
     {module,n1ql}]},
   {28701,
    [{name,<<"/admin/clusters API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/clusters.">>},
     {enabled,false},
     {module,n1ql}]},
   {28702,
    [{name,<<"/admin/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {32768,
    [{name,<<"Create Function">>},
     {description,<<"Eventing function definition was created or updated">>},
     {enabled,true},
     {module,eventing}]},
   {32769,
    [{name,<<"Delete Function">>},
     {description,<<"Eventing function definition was deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32770,
    [{name,<<"Fetch Functions">>},
     {description,<<"Eventing function definition was read">>},
     {enabled,false},
     {module,eventing}]},
   {32771,
    [{name,<<"List Deployed">>},
     {description,<<"Eventing deployed functions list was read">>},
     {enabled,false},
     {module,eventing}]},
   {32772,
    [{name,<<"Fetch Drafts">>},
     {description,<<"Eventing function draft definitions were read">>},
     {enabled,false},
     {module,eventing}]},
   {32773,
    [{name,<<"Delete Drafts">>},
     {description,<<"Eventing function draft definitions were deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32774,
    [{name,<<"Save Draft">>},
     {description,<<"Save a draft definition to the store">>},
     {enabled,true},
     {module,eventing}]},
   {32775,
    [{name,<<"Start Debug">>},
     {description,<<"Start eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32776,
    [{name,<<"Stop Debug">>},
     {description,<<"Stop eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32777,
    [{name,<<"Start Tracing">>},
     {description,<<"Start tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32778,
    [{name,<<"Stop Tracing">>},
     {description,<<"Stop tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32779,
    [{name,<<"Set Settings">>},
     {description,<<"Save settings for a given app">>},
     {enabled,true},
     {module,eventing}]},
   {32780,
    [{name,<<"Fetch Config">>},
     {description,<<"Get config for eventing">>},
     {enabled,false},
     {module,eventing}]},
   {32781,
    [{name,<<"Save Config">>},
     {description,<<"Save config for eventing">>},
     {enabled,true},
     {module,eventing}]},
   {32782,
    [{name,<<"Cleanup Eventing">>},
     {description,<<"Clears up app definitions and settings from metakv">>},
     {enabled,true},
     {module,eventing}]},
   {32783,
    [{name,<<"Get Settings">>},
     {description,<<"Get settings for a given app">>},
     {enabled,false},
     {module,eventing}]},
   {32784,
    [{name,<<"Import Functions">>},
     {description,<<"Import a list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32785,
    [{name,<<"Export Functions">>},
     {description,<<"Export the list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32786,
    [{name,<<"List Running">>},
     {description,<<"Eventing running function list was read">>},
     {enabled,false},
     {module,eventing}]},
   {36865,
    [{name,<<"Service configuration change">>},
     {description,<<"A successful service configuration change was made.">>},
     {enabled,true},
     {module,analytics}]},
   {36866,
    [{name,<<"Node configuration change">>},
     {description,<<"A successful node configuration change was made.">>},
     {enabled,true},
     {module,analytics}]}]},
 {audit,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {enabled,[]},
   {disabled_users,[]},
   {auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {auto_failover_cfg,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {enabled,true},
   {timeout,120},
   {count,0},
   {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
   {failover_server_group,false},
   {max_count,1},
   {failed_over_server_groups,[]}]}]
[error_logger:info,2020-05-07T12:09:58.760Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.157.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.762Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.163.0>},
                       {name,ns_config_remote},
                       {mfargs,{ns_config_replica,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.764Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.164.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.764Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:58.765Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.166.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.767Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.167.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:58.775Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.170.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:58.777Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2020-05-07T12:09:58.777Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.171.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.777Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.172.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.780Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.173.0>},
                       {name,memcached_refresh},
                       {mfargs,{memcached_refresh,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.782Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.175.0>},
                       {name,ssl_service_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ssl_service_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:58.796Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:init:419]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem-ca"},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[error_logger:info,2020-05-07T12:09:58.850Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.176.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:58.862Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T12:09:58.862Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T12:09:58.862Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T12:09:58.862Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[ns_server:debug,2020-05-07T12:09:58.877Z,ns_1@127.0.0.1:<0.178.0>:restartable:start_child:98]Started child process <0.179.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2020-05-07T12:09:58.877Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.178.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.877Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.174.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:58.878Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.197.0>},
                       {name,user_storage_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,user_storage_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.886Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.199.0>},
                       {name,users_replicator},
                       {mfargs,{menelaus_users,start_replicator,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:58.888Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:55]Start waiting for startup
[ns_server:debug,2020-05-07T12:09:58.895Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_storage:anounce_startup:69]Announce my startup to <0.199.0>
[ns_server:debug,2020-05-07T12:09:58.895Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:58]Received replicated storage registration from <0.200.0>
[ns_server:debug,2020-05-07T12:09:58.898Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:open:212]Opening file "/opt/couchbase/var/lib/couchbase/config/users.dets"
[error_logger:info,2020-05-07T12:09:58.898Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.200.0>},
                       {name,users_storage},
                       {mfargs,{menelaus_users,start_storage,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.898Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.198.0>},
                       {name,users_storage_sup},
                       {mfargs,{users_storage_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:09:58.909Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:init:44]Starting versioned cache compiled_roles_cache
[error_logger:info,2020-05-07T12:09:58.909Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.202.0>},
                       {name,compiled_roles_cache},
                       {mfargs,{menelaus_roles,start_compiled_roles_cache,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:09:58.909Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.196.0>},
                       {name,users_sup},
                       {mfargs,{users_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:58.910Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.205.0>},
                       {name,dets_sup},
                       {mfargs,{dets_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:09:58.910Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.206.0>},
                       {name,dets},
                       {mfargs,{dets_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:09:58.935Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:convert_docs_to_55_in_dets:243]Checking for pre 5.5 records in dets: users_storage
[ns_server:debug,2020-05-07T12:09:58.936Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,'$1','_','$2'},
                                      [],
                                      [{{'$1','$2'}}]}],
                                    100}
[ns_server:debug,2020-05-07T12:09:58.936Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:init_after_ack:204]Loading 0 items, 299 words took 0ms
[ns_server:debug,2020-05-07T12:09:58.938Z,ns_1@127.0.0.1:users_replicator<0.199.0>:doc_replicator:loop:60]doing replicate_newnodes_docs
[error_logger:info,2020-05-07T12:09:58.948Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.209.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:09:58.948Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.210.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:141]Waiting for ns_couchdb node to start
[error_logger:info,2020-05-07T12:09:58.948Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T12:09:58.949Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T12:09:58.949Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.213.0>,shutdown}}
[error_logger:info,2020-05-07T12:09:58.949Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T12:09:59.150Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T12:09:59.150Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.216.0>,shutdown}}
[error_logger:info,2020-05-07T12:09:59.150Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T12:09:59.150Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T12:09:59.351Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T12:09:59.351Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.219.0>,shutdown}}
[ns_server:debug,2020-05-07T12:09:59.351Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T12:09:59.351Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T12:09:59.552Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T12:09:59.597Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T12:09:59.798Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T12:09:59.999Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T12:10:00.200Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[error_logger:info,2020-05-07T12:10:00.680Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.228.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:10:00.881Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: Apache CouchDB v4.5.1-112-gc2b9820 (LogLevel=info) is starting.
ns_couchdb<0.209.0>: Apache CouchDB has started. Time to relax.

[error_logger:info,2020-05-07T12:10:00.974Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.210.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.96617950>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:00.987Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:ns_storage_conf:setup_db_and_ix_paths:47]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2020-05-07T12:10:00.992Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.231.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:00.994Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.232.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:10:00.995Z,ns_1@127.0.0.1:ns_server_sup<0.230.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2020-05-07T12:10:01.006Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.233.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.007Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.234.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.011Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.235.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.011Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.236.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.044Z,ns_1@127.0.0.1:memcached_passwords<0.237.0>:memcached_cfg:init:62]Init config writer for memcached_passwords, "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T12:10:01.044Z,ns_1@127.0.0.1:memcached_passwords<0.237.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T12:10:01.092Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.237.0>
[ns_server:debug,2020-05-07T12:10:01.092Z,ns_1@127.0.0.1:memcached_passwords<0.237.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T12:10:01.093Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.237.0>
[ns_server:debug,2020-05-07T12:10:01.104Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[error_logger:info,2020-05-07T12:10:01.104Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.237.0>},
                       {name,memcached_passwords},
                       {mfargs,{memcached_passwords,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T12:10:01.109Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T12:10:01.109Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [isasl] failed. Retry in 1000 ms.
[ns_server:debug,2020-05-07T12:10:01.114Z,ns_1@127.0.0.1:memcached_permissions<0.240.0>:memcached_cfg:init:62]Init config writer for memcached_permissions, "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T12:10:01.115Z,ns_1@127.0.0.1:memcached_permissions<0.240.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T12:10:01.119Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.240.0>
[ns_server:debug,2020-05-07T12:10:01.119Z,ns_1@127.0.0.1:memcached_permissions<0.240.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{user,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T12:10:01.120Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.240.0>
[ns_server:debug,2020-05-07T12:10:01.122Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of rbac requested
[ns_server:warn,2020-05-07T12:10:01.123Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T12:10:01.123Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2020-05-07T12:10:01.122Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.240.0>},
                       {name,memcached_permissions},
                       {mfargs,{memcached_permissions,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.125Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.243.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.125Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.245.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.126Z,ns_1@127.0.0.1:ns_node_disco<0.246.0>:ns_node_disco:init:130]Initting ns_node_disco with []
[ns_server:debug,2020-05-07T12:10:01.126Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[user:info,2020-05-07T12:10:01.126Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:127]Node 'ns_1@127.0.0.1' synchronized otp cookie {sanitized,
                                               <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>} from cluster
[ns_server:debug,2020-05-07T12:10:01.126Z,ns_1@127.0.0.1:<0.247.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:10:01.127Z,ns_1@127.0.0.1:<0.247.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[error_logger:info,2020-05-07T12:10:01.127Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.246.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.132Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.248.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.134Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.249.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.141Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.250.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.141Z,ns_1@127.0.0.1:ns_config_rep<0.251.0>:ns_config_rep:init:69]init pulling
[ns_server:debug,2020-05-07T12:10:01.141Z,ns_1@127.0.0.1:ns_config_rep<0.251.0>:ns_config_rep:init:71]init pushing
[ns_server:debug,2020-05-07T12:10:01.147Z,ns_1@127.0.0.1:ns_config_rep<0.251.0>:ns_config_rep:init:75]init reannouncing
[ns_server:debug,2020-05-07T12:10:01.147Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:handle_info:89]Flushing cache compiled_roles_cache due to version change from undefined to {[6,
                                                                              0],
                                                                             {0,
                                                                              2450133253},
                                                                             false,
                                                                             []}
[ns_server:debug,2020-05-07T12:10:01.148Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2020-05-07T12:10:01.148Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2020-05-07T12:10:01.148Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2020-05-07T12:10:01.148Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,[]},
 {disabled_users,[]},
 {auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2020-05-07T12:10:01.151Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit_decriptors ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {20480,
  [{name,<<"opened DCP connection">>},
   {description,<<"opened DCP connection">>},
   {enabled,true},
   {module,memcached}]},
 {20482,
  [{name,<<"external memcached bucket flush">>},
   {description,<<"External user flushed the content of a memcached bucket">>},
   {enabled,true},
   {module,memcached}]},
 {20483,
  [{name,<<"invalid packet">>},
   {description,<<"Rejected an invalid packet">>},
   {enabled,true},
   {module,memcached}]},
 {20485,
  [{name,<<"authentication succeeded">>},
   {description,<<"Authentication to the cluster succeeded">>},
   {enabled,false},
   {module,memcached}]},
 {20488,
  [{name,<<"document read">>},
   {description,<<"Document was read">>},
   {enabled,false},
   {module,memcached}]},
 {20489,
  [{name,<<"document locked">>},
   {description,<<"Document was locked">>},
   {enabled,false},
   {module,memcached}]},
 {20490,
  [{name,<<"document modify">>},
   {description,<<"Document was modified">>},
   {enabled,false},
   {module,memcached}]},
 {20491,
  [{name,<<"document delete">>},
   {description,<<"Document was deleted">>},
   {enabled,false},
   {module,memcached}]},
 {20492,
  [{name,<<"select bucket">>},
   {description,<<"The specified bucket was selected">>},
   {enabled,true},
   {module,memcached}]},
 {28672,
  [{name,<<"SELECT statement">>},
   {description,<<"A N1QL SELECT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28673,
  [{name,<<"EXPLAIN statement">>},
   {description,<<"A N1QL EXPLAIN statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28674,
  [{name,<<"PREPARE statement">>},
   {description,<<"A N1QL PREPARE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28675,
  [{name,<<"INFER statement">>},
   {description,<<"A N1QL INFER statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28676,
  [{name,<<"INSERT statement">>},
   {description,<<"A N1QL INSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28677,
  [{name,<<"UPSERT statement">>},
   {description,<<"A N1QL UPSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28678,
  [{name,<<"DELETE statement">>},
   {description,<<"A N1QL DELETE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28679,
  [{name,<<"UPDATE statement">>},
   {description,<<"A N1QL UPDATE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28680,
  [{name,<<"MERGE statement">>},
   {description,<<"A N1QL MERGE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28681,
  [{name,<<"CREATE INDEX statement">>},
   {description,<<"A N1QL CREATE INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28682,
  [{name,<<"DROP INDEX statement">>},
   {description,<<"A N1QL DROP INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28683,
  [{name,<<"ALTER INDEX statement">>},
   {description,<<"A N1QL ALTER INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28684,
  [{name,<<"BUILD INDEX statement">>},
   {description,<<"A N1QL BUILD INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28685,
  [{name,<<"GRANT ROLE statement">>},
   {description,<<"A N1QL GRANT ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28686,
  [{name,<<"REVOKE ROLE statement">>},
   {description,<<"A N1QL REVOKE ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28687,
  [{name,<<"UNRECOGNIZED statement">>},
   {description,<<"An unrecognized statement was received by the N1QL query engine">>},
   {enabled,false},
   {module,n1ql}]},
 {28688,
  [{name,<<"CREATE PRIMARY INDEX statement">>},
   {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28689,
  [{name,<<"/admin/stats API request">>},
   {description,<<"An HTTP request was made to the API at /admin/stats.">>},
   {enabled,false},
   {module,n1ql}]},
 {28690,
  [{name,<<"/admin/vitals API request">>},
   {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
   {enabled,false},
   {module,n1ql}]},
 {28691,
  [{name,<<"/admin/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28692,
  [{name,<<"/admin/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28693,
  [{name,<<"/admin/indexes/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28694,
  [{name,<<"/admin/indexes/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28695,
  [{name,<<"/admin/indexes/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28697,
  [{name,<<"/admin/ping API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ping.">>},
   {enabled,false},
   {module,n1ql}]},
 {28698,
  [{name,<<"/admin/config API request">>},
   {description,<<"An HTTP request was made to the API at /admin/config.">>},
   {enabled,false},
   {module,n1ql}]},
 {28699,
  [{name,<<"/admin/ssl_cert API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ssl_cert.">>},
   {enabled,false},
   {module,n1ql}]},
 {28700,
  [{name,<<"/admin/settings API request">>},
   {description,<<"An HTTP request was made to the API at /admin/settings.">>},
   {enabled,false},
   {module,n1ql}]},
 {28701,
  [{name,<<"/admin/clusters API request">>},
   {description,<<"An HTTP request was made to the API at /admin/clusters.">>},
   {enabled,false},
   {module,n1ql}]},
 {28702,
  [{name,<<"/admin/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {32768,
  [{name,<<"Create Function">>},
   {description,<<"Eventing function definition was created or updated">>},
   {enabled,true},
   {module,eventing}]},
 {32769,
  [{name,<<"Delete Function">>},
   {description,<<"Eventing function definition was deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32770,
  [{name,<<"Fetch Functions">>},
   {description,<<"Eventing function definition was read">>},
   {enabled,false},
   {module,eventing}]},
 {32771,
  [{name,<<"List Deployed">>},
   {description,<<"Eventing deployed functions list was read">>},
   {enabled,false},
   {module,eventing}]},
 {32772,
  [{name,<<"Fetch Drafts">>},
   {description,<<"Eventing function draft definitions were read">>},
   {enabled,false},
   {module,eventing}]},
 {32773,
  [{name,<<"Delete Drafts">>},
   {description,<<"Eventing function draft definitions were deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32774,
  [{name,<<"Save Draft">>},
   {description,<<"Save a draft definition to the store">>},
   {enabled,true},
   {module,eventing}]},
 {32775,
  [{name,<<"Start Debug">>},
   {description,<<"Start eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32776,
  [{name,<<"Stop Debug">>},
   {description,<<"Stop eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32777,
  [{name,<<"Start Tracing">>},
   {description,<<"Start tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32778,
  [{name,<<"Stop Tracing">>},
   {description,<<"Stop tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32779,
  [{name,<<"Set Settings">>},
   {description,<<"Save settings for a given app">>},
   {enabled,true},
   {module,eventing}]},
 {32780,
  [{name,<<"Fetch Config">>},
   {description,<<"Get config for eventing">>},
   {enabled,false},
   {module,eventing}]},
 {32781,
  [{name,<<"Save Config">>},
   {description,<<"Save config for eventing">>},
   {enabled,true},
   {module,eventing}]},
 {32782,
  [{name,<<"Cleanup Eventing">>},
   {description,<<"Clears up app definitions and settings from metakv">>},
   {enabled,true},
   {module,eventing}]},
 {32783,
  [{name,<<"Get Settings">>},
   {description,<<"Get settings for a given app">>},
   {enabled,false},
   {module,eventing}]},
 {32784,
  [{name,<<"Import Functions">>},
   {description,<<"Import a list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32785,
  [{name,<<"Export Functions">>},
   {description,<<"Export the list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32786,
  [{name,<<"List Running">>},
   {description,<<"Eventing running function list was read">>},
   {enabled,false},
   {module,eventing}]},
 {36865,
  [{name,<<"Service configuration change">>},
   {description,<<"A successful service configuration change was made.">>},
   {enabled,true},
   {module,analytics}]},
 {36866,
  [{name,<<"Node configuration change">>},
   {description,<<"A successful node configuration change was made.">>},
   {enabled,true},
   {module,analytics}]}]
[ns_server:debug,2020-05-07T12:10:01.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[ns_server:debug,2020-05-07T12:10:01.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_reprovision_cfg ->
[{enabled,true},{max_nodes,1},{count,0}]
[ns_server:debug,2020-05-07T12:10:01.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2020-05-07T12:10:01.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
buckets ->
[[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}],{configs,[]}]
[ns_server:debug,2020-05-07T12:10:01.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cbas_memory_quota ->
1024
[ns_server:debug,2020-05-07T12:10:01.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cert_and_pkey ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQ"...>>,
  <<"*****">>}]
[ns_server:debug,2020-05-07T12:10:01.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
client_cert_auth ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {state,"disable"},
 {prefixes,[]}]
[ns_server:debug,2020-05-07T12:10:01.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cluster_compat_version ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},6,0]
[ns_server:debug,2020-05-07T12:10:01.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded,communication_issue]}]
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
fts_memory_quota ->
256
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
log_redaction_default_cfg ->
[{redact_level,none}]
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
max_bucket_count ->
10
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memcached ->
[]
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memory_quota ->
311
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
otp ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
 {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
password_policy ->
[{min_length,6},{must_present,[]}]
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
quorum_nodes ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
read_only_user_creds ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
remote_clusters ->
[]
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest ->
[{port,8091}]
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest_creds ->
null
[ns_server:debug,2020-05-07T12:10:01.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
roles_definitions ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T12:10:01.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
scramsha_fallback_salt ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<169,238,80,91,5,165,74,47,79,135,45,74>>]
[ns_server:debug,2020-05-07T12:10:01.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
secure_headers ->
[]
[ns_server:debug,2020-05-07T12:10:01.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2020-05-07T12:10:01.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2020-05-07T12:10:01.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
users_upgrade ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T12:10:01.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2020-05-07T12:10:01.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2020-05-07T12:10:01.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{7,63756072577}}]}]
[ns_server:debug,2020-05-07T12:10:01.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/eventing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"ram_quota\":256}">>]
[ns_server:debug,2020-05-07T12:10:01.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2020-05-07T12:10:01.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/query/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]
[ns_server:debug,2020-05-07T12:10:01.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{rbac_upgrade,[5,5]} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T12:10:01.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2020-05-07T12:10:01.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2020-05-07T12:10:01.155Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,fts} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T12:10:01.155Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T12:10:01.155Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,index} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T12:10:01.155Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T12:10:01.155Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T12:10:01.155Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T12:10:01.155Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8092]
[ns_server:debug,2020-05-07T12:10:01.155Z,ns_1@127.0.0.1:<0.259.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:10:01.155Z,ns_1@127.0.0.1:<0.260.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:10:01.155Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9110]
[ns_server:debug,2020-05-07T12:10:01.156Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_client_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9113]
[ns_server:debug,2020-05-07T12:10:01.156Z,ns_1@127.0.0.1:<0.259.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:10:01.156Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9112]
[ns_server:debug,2020-05-07T12:10:01.156Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9111]
[ns_server:debug,2020-05-07T12:10:01.156Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9115]
[ns_server:debug,2020-05-07T12:10:01.156Z,ns_1@127.0.0.1:<0.260.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:10:01.156Z,ns_1@127.0.0.1:memcached_passwords<0.237.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T12:10:01.157Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_console_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9114]
[ns_server:debug,2020-05-07T12:10:01.157Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:trigger_ssl_reload:565]Notify services [capi_ssl_service] about secure_headers_changed change
[ns_server:debug,2020-05-07T12:10:01.157Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_data_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9116]
[ns_server:debug,2020-05-07T12:10:01.157Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:525]Going to notify following services: [capi_ssl_service]
[ns_server:debug,2020-05-07T12:10:01.157Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]
[ns_server:debug,2020-05-07T12:10:01.158Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8095]
[ns_server:debug,2020-05-07T12:10:01.158Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_messaging_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9118]
[ns_server:debug,2020-05-07T12:10:01.158Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_callback_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9119]
[ns_server:debug,2020-05-07T12:10:01.159Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9121]
[ns_server:debug,2020-05-07T12:10:01.160Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_parent_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9122]
[ns_server:debug,2020-05-07T12:10:01.161Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_replication_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9120]
[ns_server:debug,2020-05-07T12:10:01.161Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_result_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9117]
[ns_server:debug,2020-05-07T12:10:01.161Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18095]
[ns_server:debug,2020-05-07T12:10:01.161Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2020-05-07T12:10:01.161Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {5,5,3}]
[ns_server:debug,2020-05-07T12:10:01.161Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9140]
[ns_server:debug,2020-05-07T12:10:01.161Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8096]
[ns_server:debug,2020-05-07T12:10:01.162Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18096]
[ns_server:debug,2020-05-07T12:10:01.162Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8094]
[ns_server:debug,2020-05-07T12:10:01.162Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18094]
[ns_server:debug,2020-05-07T12:10:01.162Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9100]
[ns_server:debug,2020-05-07T12:10:01.162Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9102]
[ns_server:debug,2020-05-07T12:10:01.162Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|19102]
[ns_server:debug,2020-05-07T12:10:01.163Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9101]
[ns_server:debug,2020-05-07T12:10:01.163Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9104]
[ns_server:debug,2020-05-07T12:10:01.163Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9103]
[ns_server:debug,2020-05-07T12:10:01.163Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9105]
[ns_server:debug,2020-05-07T12:10:01.163Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:info,2020-05-07T12:10:01.169Z,ns_1@127.0.0.1:<0.266.0>:ns_ssl_services_setup:notify_service:708]Successfully notified service capi_ssl_service
[ns_server:debug,2020-05-07T12:10:01.163Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2020-05-07T12:10:01.173Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:debug,2020-05-07T12:10:01.173Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 active]
[ns_server:debug,2020-05-07T12:10:01.174Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"@ns_server"},
 {other_users,["@cbq-engine","@projector","@goxdcr","@index","@fts",
               "@eventing","@cbas"]},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2020-05-07T12:10:01.174Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},
        {port,port},
        {maxconn,maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {privilege_debug,privilege_debug},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {rbac_file,{"~s",[rbac_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps},
   {tracing_enabled,tracing_enabled},
   {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
   {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
   {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
   {logger,
    {[{filename,{"~s/~s",[log_path,log_prefix]}},
      {cyclesize,log_cyclesize},
      {sleeptime,log_sleeptime}]}}]}]
[ns_server:debug,2020-05-07T12:10:01.174Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {privilege_debug,false},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false},
 {tracing_enabled,true},
 {datatype_snappy,true}]
[ns_server:debug,2020-05-07T12:10:01.174Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2020-05-07T12:10:01.174Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2020-05-07T12:10:01.174Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T12:10:01.174Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9999]
[ns_server:debug,2020-05-07T12:10:01.174Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8093]
[ns_server:debug,2020-05-07T12:10:01.174Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2020-05-07T12:10:01.174Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18092]
[ns_server:info,2020-05-07T12:10:01.175Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:541]Succesfully notified services [capi_ssl_service]
[ns_server:debug,2020-05-07T12:10:01.176Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18093]
[ns_server:debug,2020-05-07T12:10:01.176Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18091]
[ns_server:debug,2020-05-07T12:10:01.176Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 <<"0f8760945f98b1efdbef0bd1ea6e8446">>]
[ns_server:debug,2020-05-07T12:10:01.176Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9998]
[ns_server:debug,2020-05-07T12:10:01.176Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|false]
[ns_server:info,2020-05-07T12:10:01.176Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: 172: Booted. Waiting for shutdown request

[ns_server:debug,2020-05-07T12:10:01.187Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.237.0>
[ns_server:debug,2020-05-07T12:10:01.187Z,ns_1@127.0.0.1:memcached_passwords<0.237.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T12:10:01.187Z,ns_1@127.0.0.1:ns_config_rep<0.251.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([alert_limits,audit,audit_decriptors,
                               auto_failover_cfg,auto_reprovision_cfg,
                               autocompaction,buckets,cbas_memory_quota,
                               cert_and_pkey,client_cert_auth,
                               cluster_compat_version,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,
                               index_aware_rebalance_disabled,
                               log_redaction_default_cfg,max_bucket_count,
                               memcached,memory_quota,nodes_wanted,otp,
                               password_policy,quorum_nodes,
                               read_only_user_creds,remote_clusters,
                               replication,rest,rest_creds,roles_definitions,
                               scramsha_fallback_salt,secure_headers,
                               server_groups,set_view_update_daemon,
                               users_upgrade,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>},
                               {metakv,<<"/eventing/settings/config">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {metakv,<<"/query/settings/config">>},
                               {rbac_upgrade,[5,5]},
                               {request_limit,capi},
                               {request_limit,rest},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',cbas_admin_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_client_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_http_port},
                               {node,'ns_1@127.0.0.1',cbas_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_console_port},
                               {node,'ns_1@127.0.0.1',cbas_data_port},
                               {node,'ns_1@127.0.0.1',cbas_debug_port},
                               {node,'ns_1@127.0.0.1',cbas_http_port},
                               {node,'ns_1@127.0.0.1',cbas_messaging_port},
                               {node,'ns_1@127.0.0.1',
                                   cbas_metadata_callback_port},
                               {node,'ns_1@127.0.0.1',cbas_metadata_port},
                               {node,'ns_1@127.0.0.1',cbas_parent_port},
                               {node,'ns_1@127.0.0.1',cbas_replication_port},
                               {node,'ns_1@127.0.0.1',cbas_result_port},
                               {node,'ns_1@127.0.0.1',cbas_ssl_port}]..)
[error_logger:info,2020-05-07T12:10:01.189Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.189Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.244.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:10:01.190Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.237.0>
[error_logger:info,2020-05-07T12:10:01.198Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.273.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.216Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[ns_server:warn,2020-05-07T12:10:01.217Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T12:10:01.217Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2020-05-07T12:10:01.223Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.275.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.223Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.278.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.223Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.279.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.227Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.281.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.227Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.280.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.227Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.282.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.227Z,ns_1@127.0.0.1:ns_log_events<0.243.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2020-05-07T12:10:01.229Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.283.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.231Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.285.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.232Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.289.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.232Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.284.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.238Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.294.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.239Z,ns_1@127.0.0.1:ns_heart<0.285.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2020-05-07T12:10:01.239Z,ns_1@127.0.0.1:ns_heart<0.285.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]}]}}

[error_logger:info,2020-05-07T12:10:01.243Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.296.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.243Z,ns_1@127.0.0.1:<0.292.0>:restartable:start_child:98]Started child process <0.293.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2020-05-07T12:10:01.243Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.292.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.243Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.299.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.249Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.300.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.249Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.301.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.249Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.302.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.250Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.303.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.254Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.305.0>},
                       {name,query_settings_manager},
                       {mfargs,{query_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.260Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.308.0>},
                       {name,eventing_settings_manager},
                       {mfargs,{eventing_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.260Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.310.0>},
                       {name,audit_events},
                       {mfargs,{gen_event,start_link,[{local,audit_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.265Z,ns_1@127.0.0.1:ns_heart<0.285.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2020-05-07T12:10:01.266Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.312.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.266Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.314.0>},
                       {name,scram_sha},
                       {mfargs,{scram_sha,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.268Z,ns_1@127.0.0.1:ns_heart<0.285.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T12:10:01.292Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.316.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.298Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.289.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,244}]},
                 {proc_lib,init_p_do_apply,3,
                           [{file,"proc_lib.erl"},{line,239}]}]}}

[ns_server:debug,2020-05-07T12:10:01.298Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.289.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,244}]}]}}

[ns_server:debug,2020-05-07T12:10:01.301Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.289.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T12:10:01.302Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.289.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T12:10:01.304Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.332.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.308Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.333.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.309Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.334.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:10:01.309Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T12:10:01.309Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T12:10:01.310Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T12:10:01.310Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[error_logger:info,2020-05-07T12:10:01.310Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.335.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.315Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.354.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.333Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.355.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.337Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.356.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.339Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.357.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2020-05-07T12:10:01.339Z,ns_1@127.0.0.1:ns_server_sup<0.230.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "6.0.3-2895-enterprise".
[error_logger:info,2020-05-07T12:10:01.339Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.311.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.339Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.363.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.341Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.367.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.341Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.368.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.31986353>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.341Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.366.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:10:01.346Z,ns_1@127.0.0.1:ns_ports_setup<0.363.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,goxdcr]
[error_logger:info,2020-05-07T12:10:01.350Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.370.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.350Z,ns_1@127.0.0.1:ns_audit_cfg<0.371.0>:ns_audit_cfg:write_audit_json:265]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{descriptors_path,
                                                                                <<"/opt/couchbase/etc/security">>},
                                                                               {version,
                                                                                2},
                                                                               {uuid,
                                                                                <<"18411111">>},
                                                                               {event_states,
                                                                                {[]}},
                                                                               {filtering_enabled,
                                                                                true},
                                                                               {disabled_userids,
                                                                                []},
                                                                               {auditd_enabled,
                                                                                false},
                                                                               {log_path,
                                                                                <<"/opt/couchbase/var/lib/couchbase/logs">>},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []}]
[ns_server:debug,2020-05-07T12:10:01.363Z,ns_1@127.0.0.1:ns_audit_cfg<0.371.0>:ns_audit_cfg:notify_memcached:170]Instruct memcached to reload audit config
[error_logger:info,2020-05-07T12:10:01.364Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.371.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T12:10:01.365Z,ns_1@127.0.0.1:<0.374.0>:ns_memcached:connect:1230]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2020-05-07T12:10:01.369Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.375.0>},
                       {name,ns_audit},
                       {mfargs,{ns_audit,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.371Z,ns_1@127.0.0.1:memcached_config_mgr<0.376.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2020-05-07T12:10:01.371Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.376.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:10:01.376Z,ns_1@127.0.0.1:<0.377.0>:ns_memcached_log_rotator:init:42]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2020-05-07T12:10:01.377Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.377.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.377Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,testconditions_store},
                       {mfargs,{simple_store,start_link,[testconditions]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.380Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.380.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.388Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.382.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.388Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.381.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.388Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.379.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.394Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.383.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.394Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.387.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.396Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.389.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.404Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.390.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.406Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.392.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.406Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.393.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.406Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.395.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.428Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.396.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.449Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.398.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.450Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.400.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.450Z,ns_1@127.0.0.1:ns_ports_setup<0.363.0>:ns_ports_setup:set_children:90]Monitor ns_child_ports_sup <12401.74.0>
[ns_server:debug,2020-05-07T12:10:01.450Z,ns_1@127.0.0.1:memcached_config_mgr<0.376.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:info,2020-05-07T12:10:01.461Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: working as port

[error_logger:info,2020-05-07T12:10:01.503Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.402.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.526Z,ns_1@127.0.0.1:memcached_config_mgr<0.376.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T12:10:01.548Z,ns_1@127.0.0.1:memcached_config_mgr<0.376.0>:memcached_config_mgr:init:79]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[ns_server:debug,2020-05-07T12:10:01.565Z,ns_1@127.0.0.1:memcached_config_mgr<0.376.0>:memcached_config_mgr:init:82]activated memcached port server
[error_logger:info,2020-05-07T12:10:01.574Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.406.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.582Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.406.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T12:10:01.582Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.406.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2020-05-07T12:10:01.588Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.410.0>},
                       {name,service_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_stats_children_sup},
                                services_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.593Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.412.0>},
                       {name,service_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [service_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.605Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.413.0>},
                       {name,service_status_keeper_index},
                       {mfargs,{service_index,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.607Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.416.0>},
                       {name,service_status_keeper_fts},
                       {mfargs,{service_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.627Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.419.0>},
                       {name,service_status_keeper_eventing},
                       {mfargs,{service_eventing,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.627Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.411.0>},
                       {name,service_status_keeper_sup},
                       {mfargs,{service_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.627Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.422.0>},
                       {name,service_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<services_stats_sup.0.41280346>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.627Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.409.0>},
                       {name,services_stats_sup},
                       {mfargs,{services_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.637Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.424.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.642Z,ns_1@127.0.0.1:<0.427.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.427.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2020-05-07T12:10:01.649Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:10:01.649Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:10:01.649Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:10:01.649Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[error_logger:info,2020-05-07T12:10:01.649Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.425.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.649Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:10:01.649Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2020-05-07T12:10:01.650Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.429.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.650Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.428.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.652Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.430.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.666Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.434.0>},
                       {name,leader_activities},
                       {mfargs,{leader_activities,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T12:10:01.700Z,ns_1@127.0.0.1:leader_lease_agent<0.435.0>:leader_lease_agent:maybe_recover_persisted_lease:397]Found persisted lease [{node,'ns_1@127.0.0.1'},
                       {uuid,<<"510c4d8812fc511414a6608f96c5fb7e">>},
                       {time_left,15000},
                       {status,active}]
[error_logger:info,2020-05-07T12:10:01.700Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.435.0>},
                       {name,leader_lease_agent},
                       {mfargs,{leader_lease_agent,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.700Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.433.0>},
                       {name,leader_leases_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_leases_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.700Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.437.0>},
                       {name,leader_events},
                       {mfargs,{gen_event,start_link,[{local,leader_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.704Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.438.0>},
                       {name,leader_registry_server},
                       {mfargs,{leader_registry_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.706Z,ns_1@127.0.0.1:leader_registry_sup<0.436.0>:mb_master:check_master_takeover_needed:270]Sending master node question to the following nodes: []
[ns_server:debug,2020-05-07T12:10:01.706Z,ns_1@127.0.0.1:leader_registry_sup<0.436.0>:mb_master:check_master_takeover_needed:272]Got replies: []
[ns_server:debug,2020-05-07T12:10:01.706Z,ns_1@127.0.0.1:leader_registry_sup<0.436.0>:mb_master:check_master_takeover_needed:278]Was unable to discover master, not going to force mastership takeover
[user:info,2020-05-07T12:10:01.706Z,ns_1@127.0.0.1:mb_master<0.441.0>:mb_master:init:90]I'm the only node, so I'm the master.
[ns_server:debug,2020-05-07T12:10:01.706Z,ns_1@127.0.0.1:leader_registry<0.438.0>:leader_registry_server:handle_new_leader:241]New leader is 'ns_1@127.0.0.1'. Invalidating name cache.
[error_logger:info,2020-05-07T12:10:01.721Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.444.0>},
                       {name,leader_lease_acquirer},
                       {mfargs,{leader_lease_acquirer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.723Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.446.0>:leader_quorum_nodes_manager:pull_config:114]Attempting to pull config from nodes:
[]
[error_logger:info,2020-05-07T12:10:01.723Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.446.0>},
                       {name,leader_quorum_nodes_manager},
                       {mfargs,{leader_quorum_nodes_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.723Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.446.0>:leader_quorum_nodes_manager:pull_config:119]Pulled config successfully.
[ns_server:warn,2020-05-07T12:10:01.727Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 14972ms)
[ns_server:info,2020-05-07T12:10:01.728Z,ns_1@127.0.0.1:mb_master_sup<0.443.0>:misc:start_singleton:758]start_singleton(gen_server, ns_tick, [], []): started as <0.455.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T12:10:01.728Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.455.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.732Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.458.0>},
                       {name,ns_janitor_server},
                       {mfargs,{ns_janitor_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:10:01.739Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.457.0>:misc:start_singleton:758]start_singleton(gen_server, auto_reprovision, [], []): started as <0.459.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T12:10:01.739Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.459.0>},
                       {name,auto_reprovision},
                       {mfargs,{auto_reprovision,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:10:01.740Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.457.0>:misc:start_singleton:758]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.460.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T12:10:01.740Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.460.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.740Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.457.0>},
                       {name,ns_orchestrator_child_sup},
                       {mfargs,{ns_orchestrator_child_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:10:01.743Z,ns_1@127.0.0.1:<0.462.0>:auto_failover:init:211]init auto_failover.
[user:info,2020-05-07T12:10:01.743Z,ns_1@127.0.0.1:<0.462.0>:auto_failover:handle_call:242]Enabled auto-failover with timeout 120 and max count 1
[ns_server:debug,2020-05-07T12:10:01.746Z,ns_1@127.0.0.1:ns_config_rep<0.251.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([auto_failover_cfg,
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>}]..)
[ns_server:info,2020-05-07T12:10:01.747Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.456.0>:misc:start_singleton:758]start_singleton(gen_server, auto_failover, [], []): started as <0.462.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T12:10:01.747Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.462.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:10:01.747Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756072601}}]}]
[ns_server:debug,2020-05-07T12:10:01.747Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[error_logger:info,2020-05-07T12:10:01.748Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.456.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.748Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.441.0>},
                       {name,mb_master},
                       {mfargs,{mb_master,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.748Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.436.0>},
                       {name,leader_registry_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_registry_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:10:01.748Z,ns_1@127.0.0.1:<0.431.0>:restartable:start_child:98]Started child process <0.432.0>
  MFA: {leader_services_sup,start_link,[]}
[error_logger:info,2020-05-07T12:10:01.748Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.431.0>},
                       {name,leader_services_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{leader_services_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.748Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.470.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.749Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.471.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.758Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.472.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.772Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.473.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.791Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.476.0>},
                       {name,ns_server_monitor},
                       {mfargs,{ns_server_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.791Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.478.0>},
                       {name,service_monitor_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_monitor_children_sup},
                                health_monitor_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.792Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.479.0>},
                       {name,service_monitor_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<health_monitor_sup.0.81875396>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.794Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.487.0>},
                       {name,node_monitor},
                       {mfargs,{node_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.796Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.495.0>},
                       {name,node_status_analyzer},
                       {mfargs,{node_status_analyzer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:10:01.796Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.475.0>},
                       {name,health_monitor_sup},
                       {mfargs,{health_monitor_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:10:01.796Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[error_logger:info,2020-05-07T12:10:01.796Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.230.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:10:01.796Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.169.0>
[ns_server:debug,2020-05-07T12:10:01.796Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2020-05-07T12:10:01.796Z,ns_1@127.0.0.1:<0.168.0>:restartable:start_child:98]Started child process <0.169.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[error_logger:info,2020-05-07T12:10:01.796Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.168.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:10:01.796Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:debug,2020-05-07T12:10:01.797Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:130]138: Entered child_loop
[ns_server:debug,2020-05-07T12:10:01.819Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@",admin}
[ns_server:debug,2020-05-07T12:10:01.839Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.499.0>:json_rpc_connection:init:73]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.499.0>
[ns_server:debug,2020-05-07T12:10:01.839Z,ns_1@127.0.0.1:menelaus_cbauth<0.357.0>:menelaus_cbauth:handle_cast:102]Observed json rpc process {"goxdcr-cbauth",<0.499.0>} started
[ns_server:debug,2020-05-07T12:10:01.839Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.500.0>:json_rpc_connection:init:73]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.500.0>
[ns_server:debug,2020-05-07T12:10:01.844Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@goxdcr-cbauth",admin}
[ns_server:debug,2020-05-07T12:10:02.125Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:89]Refresh of [rbac,isasl] succeeded
[ns_server:debug,2020-05-07T12:10:02.745Z,ns_1@127.0.0.1:<0.462.0>:auto_failover_logic:log_master_activity:170]Transitioned node {'ns_1@127.0.0.1',<<"0f8760945f98b1efdbef0bd1ea6e8446">>} state new -> up
[ns_server:warn,2020-05-07T12:10:16.700Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:warn,2020-05-07T12:10:16.700Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:warn,2020-05-07T12:10:16.700Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:warn,2020-05-07T12:10:16.700Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:warn,2020-05-07T12:10:16.700Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:warn,2020-05-07T12:10:16.700Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:warn,2020-05-07T12:10:16.700Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:warn,2020-05-07T12:10:16.700Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:warn,2020-05-07T12:10:16.700Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:warn,2020-05-07T12:10:16.700Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:warn,2020-05-07T12:10:16.700Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:warn,2020-05-07T12:10:16.700Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:warn,2020-05-07T12:10:16.700Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:warn,2020-05-07T12:10:16.700Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:debug,2020-05-07T12:10:16.701Z,ns_1@127.0.0.1:leader_lease_agent<0.435.0>:leader_lease_agent:handle_lease_expired:284]Lease held by {lease_holder,<<"510c4d8812fc511414a6608f96c5fb7e">>,
                            'ns_1@127.0.0.1'} expired. Starting expirer.
[ns_server:warn,2020-05-07T12:10:16.701Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"510c4d8812fc511414a6608f96c5fb7e">>} (valid for 0ms)
[ns_server:debug,2020-05-07T12:10:16.702Z,ns_1@127.0.0.1:leader_lease_agent<0.435.0>:leader_lease_agent:do_handle_acquire_lease:147]Granting lease to {lease_holder,<<"8383a6f8218c46cdb84a637963c66dd3">>,
                                'ns_1@127.0.0.1'} for 15000ms
[ns_server:info,2020-05-07T12:10:16.715Z,ns_1@127.0.0.1:<0.452.0>:leader_lease_acquire_worker:handle_fresh_lease_acquired:302]Acquired lease from node 'ns_1@127.0.0.1' (lease uuid: <<"8383a6f8218c46cdb84a637963c66dd3">>)
[ns_server:debug,2020-05-07T12:10:31.650Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:10:31.650Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:10:31.650Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:10:31.650Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[error_logger:info,2020-05-07T12:10:57.846Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
       alarm_handler: {set,{system_memory_high_watermark,[]}}

[ns_server:debug,2020-05-07T12:11:01.651Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:11:01.651Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:11:01.651Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:11:01.651Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:11:31.652Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:11:31.652Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:11:31.652Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:11:31.652Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:12:01.653Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:12:01.653Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:12:01.653Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:12:01.653Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:12:31.654Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:12:31.654Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:12:31.654Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:12:31.654Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:13:01.655Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:13:01.655Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:13:01.655Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:13:01.655Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:13:31.656Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:13:31.656Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:13:31.656Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:13:31.656Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:14:01.657Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:14:01.657Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:14:01.657Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:14:01.657Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:14:31.658Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:14:31.658Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:14:31.658Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:14:31.658Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:15:01.659Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:15:01.659Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:15:01.659Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:15:01.659Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:15:31.660Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:15:31.660Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:15:31.660Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:15:31.660Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:16:01.661Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:16:01.661Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:16:01.661Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:16:01.661Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:16:31.662Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:16:31.662Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:16:31.662Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:16:31.662Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:17:01.663Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:17:01.663Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:17:01.663Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:17:01.663Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:17:31.664Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:17:31.664Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:17:31.664Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:17:31.664Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:18:01.665Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:18:01.665Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:18:01.665Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:18:01.665Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:18:31.666Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:18:31.666Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:18:31.666Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:18:31.666Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:19:01.667Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:19:01.667Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:19:01.667Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:19:01.667Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:19:31.668Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:19:31.668Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:19:31.668Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:19:31.668Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:20:01.669Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:20:01.669Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:20:01.669Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:20:01.669Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:20:31.670Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:20:31.670Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:20:31.670Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:20:31.670Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:21:01.671Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:21:01.671Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:21:01.671Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:21:01.671Z,ns_1@127.0.0.1:compaction_new_daemon<0.425.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:info,2020-05-07T12:21:49.345Z,nonode@nohost:<0.89.0>:ns_server:init_logging:150]Started & configured logging
[ns_server:info,2020-05-07T12:21:49.357Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_access,info},
 {disk_sink_opts,[{rotation,[{compress,true},
                             {size,41943040},
                             {num_files,10},
                             {buffer_size_max,52428800}]}]},
 {disk_sink_opts_json_rpc,[{rotation,[{compress,true},
                                      {size,41943040},
                                      {num_files,2},
                                      {buffer_size_max,52428800}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2020-05-07T12:21:49.357Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.357Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.357Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.357Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.357Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.357Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.357Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.357Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.357Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.357Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_json_rpc, which is given from command line
[ns_server:warn,2020-05-07T12:21:49.358Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2020-05-07T12:21:49.385Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.138.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:49.395Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,76}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-378cfab] [64-bit] [smp:2:2] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2020,5,7},{12,21,49}}},
               {memory,
                   [{total,110452712},
                    {processes,9583544},
                    {processes_used,9582496},
                    {system,100869168},
                    {atom,339441},
                    {atom_used,322610},
                    {binary,77080},
                    {code,7796739},
                    {ets,2241584}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,path_config,calendar,
                    ale_default_formatter,'ale_logger-metakv',
                    'ale_logger-rebalance','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-json_rpc',
                    'ale_logger-access','ale_logger-ns_server',
                    'ale_logger-user','ale_logger-ns_doctor',io_lib_fread,
                    'ale_logger-cluster','ale_logger-xdcr',otp_internal,
                    ns_log_sink,ale_disk_sink,misc,couch_util,ns_server,
                    filelib,cpu_sup,memsup,disksup,os_mon,io,release_handler,
                    overload,alarm_handler,sasl,timer,tftp_sup,httpd_sup,
                    httpc_handler_sup,httpc_cookie,inets_trace,httpc_manager,
                    httpc,httpc_profile_sup,httpc_sup,ftp_sup,inets_sup,
                    inets_app,ssl,lhttpc_manager,lhttpc_sup,lhttpc,
                    tls_connection_sup,ssl_session_cache,ssl_pkix_db,
                    ssl_manager,ssl_sup,ssl_app,crypto_server,crypto_sup,
                    crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_io,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","6.0.3-2895-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","6.0.3-2895-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,105},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [lhttpc_sup,code_server,ale_stats_events,'sink-ns_log',
                    ns_server_cluster_sup,lhttpc_manager,
                    application_controller,ale,httpd_sup,release_handler,
                    kernel_safe_sup,standard_error,ale_sup,overload,
                    'sink-disk_json_rpc',error_logger,alarm_handler,
                    'sink-disk_metakv',ale_dynamic_sup,timer_server,
                    'sink-disk_access_int',standard_error_sup,
                    'sink-disk_access','sink-disk_reports',crypto_server,
                    crypto_sup,sasl_safe_sup,'sink-disk_stats',
                    'sink-disk_xdcr',tftp_sup,inet_db,init,os_mon_sup,
                    'sink-disk_debug',rex,tls_connection_sup,user,
                    'sink-disk_error',ssl_sup,kernel_sup,cpu_sup,
                    global_name_server,memsup,'sink-disk_default',disksup,
                    httpc_sup,file_server_2,ssl_manager,local_tasks,
                    global_group,httpc_profile_sup,httpc_manager,
                    httpc_handler_sup,ftp_sup,sasl_sup,erl_prim_loader,
                    inets_sup]},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,1}]
[ns_server:info,2020-05-07T12:21:49.399Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:27]Manifest:
["<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\" />",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\" />",
 "  ","  <default remote=\"couchbase\" revision=\"master\" />","  ",
 "  <project groups=\"kv\" name=\"HdrHistogram_c\" path=\"third_party/HdrHistogram_c\" remote=\"couchbasedeps\" revision=\"d200fc0f68695d4aef1fad5c3c8cc55f8c033014\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"analytics-dcp-client\" path=\"analytics/java-dcp-client\" revision=\"d6ba66b51c0e589e9d4571264afcb0e33d507aea\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"asterixdb\" path=\"analytics/asterixdb\" revision=\"e8e59d0e6e72ba3fd96074c021ff7180261dcd59\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"c5b9dd8ec0910d2890d215075a7d2da1d6a494c9\" />",
 "  <project groups=\"kv\" name=\"benchmark\" remote=\"couchbasedeps\" revision=\"9e3465560240ffb242b50a47cb7f19251a12ee42\" />",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\" />",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5cd1345cca3ed72f1e63d41d622fcda73e63fea8\" />",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"822d01dab8721cf469beb6d8304c9eadd9c58160\" />",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"f551b6d4f32bb920a83dd28c705bddd5de0d03b2\" />",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"4b158bb555a3297565afecf6fae675c74f1e47df\" />",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\" />",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\" />",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"dc55cf8e9613ddf1bd6db4a662d1ecc3668223da\">",
 "    <annotation name=\"RELEASE\" value=\"alice\" />",
 "    <annotation name=\"PRODUCT\" value=\"couchbase-server\" />",
 "    <annotation name=\"BLD_NUM\" value=\"2895\" />",
 "    <annotation name=\"VERSION\" value=\"6.0.3\" />","  </project>",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas\" path=\"goproj/src/github.com/couchbaselabs/cbas\" remote=\"couchbase-priv\" revision=\"73fa77cd9133a9f779a484ac2caffb0b46a1dd82\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas-core\" path=\"analytics\" remote=\"couchbase-priv\" revision=\"7e513c6bd60a030c3a2477af683b264d61932a75\" />",
 "  <project groups=\"analytics\" name=\"cbas-ui\" revision=\"d8f601c3109887a30deccab09b2177bf499c8711\" />",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"0df84c7e3c6d95ff435c12a3c08c6f064db11e97\" />",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"80d2ad8892d806f5103f602fec0d80adaa4b628f\" />",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"8d4105a904e0282a6928de7392e266c58ea3c7a2\" />",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"0a94f40b9080e0ecb11d3b7531a58c5e6a4a4465\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"93d26dbc120c4f9874abb65aafa4d815334273c6\" />",
 "  <project name=\"cbsummary\" path=\"goproj/src/github.com/couchbase/cbsummary\" revision=\"dbfa1c0d73f0e49f6f04e390f03de8f9a6cee769\" />",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"dcae66272b24600ae0005fa06b511cfae8914d3d\" />",
 "  <project name=\"cobra\" path=\"godeps/src/github.com/spf13/cobra\" remote=\"couchbasedeps\" revision=\"0f056af21f5f368e5b0646079d0094a2c64150f7\" />",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\" />",
 "  <project groups=\"notdefault,kv_ee,enterprise\" name=\"couch_rocks\" remote=\"couchbase-priv\" revision=\"75f37fa46bfe5e445dee077157303968a3e09126\" />",
 "  <project name=\"couchbase-cli\" revision=\"9b383603860ce58885c27015c92635a7b42d3a1f\" />",
 "  <project name=\"couchdb\" revision=\"c2b98200b800f9fbed927c47074884b9f5f53eb4\" />",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"69aa5d92e195a30e06184911d72b8fffcf2534fe\" />",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"c2c458ff2cf93ee63bf4b0386f495b22535daf96\" />",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\" />",
 "  <project name=\"cuckoofilter\" path=\"godeps/src/github.com/seiflotfy/cuckoofilter\" remote=\"couchbasedeps\" revision=\"d04838794ab86926d32b124345777e55e6f43974\" />",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\" />",
 "  <project name=\"docloader\" path=\"goproj/src/github.com/couchbase/docloader\" revision=\"05067021a042a1b63e100a486afd7ebddab4c535\" />",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\" />",
 "  <project name=\"errors\" path=\"godeps/src/github.com/pkg/errors\" remote=\"couchbasedeps\" revision=\"30136e27e2ac8d167177e8a583aa4c3fea5be833\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"eventing\" path=\"goproj/src/github.com/couchbase/eventing\" revision=\"1da67e30a4c8faaf24f067eae280f5764d943dc2\" upstream=\"alice\" />",
 "  <project name=\"flatbuffers\" path=\"godeps/src/github.com/google/flatbuffers\" remote=\"couchbasedeps\" revision=\"1a8968225130caeddd16e227678e6f8af1926303\" />",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"c338e06e6847140f749058184d66de1f2a43474a\" />",
 "  <project name=\"fwd\" path=\"godeps/src/github.com/philhofer/fwd\" remote=\"couchbasedeps\" revision=\"bb6d471dc95d4fe11e432687f8b70ff496cf3136\" />",
 "  <project name=\"geocouch\" revision=\"2a0e73f43451045f157640eec59ced72da18471f\" />",
 "  <project name=\"ghistogram\" path=\"godeps/src/github.com/couchbase/ghistogram\" revision=\"d910dd063dd68fb4d2a1ba344440f834ebb4ef62\" />",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\" />",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"5c0ac9ef0ba7a0356279cee7eadd8874c4a8f8c1\" />",
 "  <project name=\"go-curl\" path=\"godeps/src/github.com/andelf/go-curl\" remote=\"couchbasedeps\" revision=\"f0b2afc926ec79be5d7f30393b3485352781a705\" />",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\" />",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\" />",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\" />",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\" />",
 "  <project name=\"go-sqlite3\" path=\"godeps/src/github.com/mattn/go-sqlite3\" remote=\"couchbasedeps\" revision=\"47fc4e5e9153645da45af6a86a5bce95e63a0f9e\" />",
 "  <project name=\"go-unsnap-stream\" path=\"godeps/src/github.com/glycerine/go-unsnap-stream\" remote=\"couchbasedeps\" revision=\"62a9a9eb44fd8932157b1a8ace2149eff5971af6\" />",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\" />",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"d2f15a425a9c8e4d8447e5f5b89ce14845f7fa05\" />",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\" />",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"699b13a51af5dd4f80ff3deedf41bba60debad32\" />",
 "  <project name=\"gocbconnstr\" path=\"godeps/src/gopkg.in/couchbaselabs/gocbconnstr.v1\" remote=\"couchbaselabs\" revision=\"710456e087a6d497e87f41d0a9d98d6a75672186\" />",
 "  <project name=\"gocbcore\" path=\"godeps/src/gopkg.in/couchbase/gocbcore.v7\" revision=\"a0d26c2d6f5de912499d35a5aba573006e5e036f\" />",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"aecdbe5a5a91f0688df7bdf260ca962178c06828\" />",
 "  <project name=\"gofarmhash\" path=\"godeps/src/github.com/leemcloughlin/gofarmhash\" remote=\"couchbasedeps\" revision=\"0a055c5b87a8c55ce83459cbf2776b563822a942\" />",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\" />",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\" />",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\" />",
 "  <project name=\"golang-tools\" path=\"godeps/src/golang.org/x/tools\" remote=\"couchbasedeps\" revision=\"a28dfb48e06b2296b66678872c2cb638f0304f20\" />",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\" />",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"e05ec3550789be1da2981787ef6444fef75e10bc\" />",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"4809dd3aa2ab88013b1dfce15516d717a35cb6e8\" />",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\" />",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\" />",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\" />",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"f98adca8eb365032cab838ef4d99453931afa112\" />",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"122ae25ed207cca30ceaee9ac66342a603d43a31\" />",
 "  <project groups=\"kv\" name=\"gsl-lite\" path=\"third_party/gsl-lite\" remote=\"couchbasedeps\" revision=\"57542c7e7ced375346e9ac55dad85b942cfad556\" />",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\" />",
 "  <project name=\"httprouter\" path=\"godeps/src/github.com/julienschmidt/httprouter\" remote=\"couchbasedeps\" revision=\"975b5c4c7c21c0e3d2764200bf2aa8e34657ae6e\" />",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"95ed84aad6bf8ecd99da2372dceede6d93f3d43a\" />",
 "  <project name=\"json-iterator-go\" path=\"godeps/src/github.com/json-iterator/go\" remote=\"couchbasedeps\" revision=\"f7279a603edee96fe7764d3de9c6ff8cf9970994\" />",
 "  <project name=\"jsonx\" path=\"godeps/src/gopkg.in/couchbaselabs/jsonx.v1\" remote=\"couchbaselabs\" revision=\"5b7baa20429a46a5543ee259664cc86502738cad\" />",
 "  <project groups=\"kv\" name=\"kv_engine\" revision=\"a30fd9d57cc2101078c8cd2c44968458df965c2b\" />",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"libcouchbase\" revision=\"081e8b16b991bf706eb77f8243935c6fba31b895\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"3681c2a912330352991ecdd642f257efe5b85518\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\" />",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\" />",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\" />",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"956632ec1bc3e28276d00ee2f22c3202f06efb12\" />",
 "  <project name=\"mossScope\" path=\"godeps/src/github.com/couchbase/mossScope\" revision=\"abd3b58b422dbc2e9463a589d0f3d93441726e23\" />",
 "  <project name=\"mousetrap\" path=\"godeps/src/github.com/inconshreveable/mousetrap\" remote=\"couchbasedeps\" revision=\"76626ae9c91c4f2a10f34cad8ce83ea42c93bb75\" />",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"cd8da46b9b953800d430c8b0aa4667790727ed6f\" />",
 "  <project name=\"msgp\" path=\"godeps/src/github.com/tinylib/msgp\" remote=\"couchbasedeps\" revision=\"5bb5e1aed7ba5bcc93307153b020e7ffe79b0509\" />",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"043ee6597c29786140136a5747b6a886364f5282\" />",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"62685c2d7ca23c807425dca88b11a3e2323dab41\" />",
 "  <project name=\"nitro\" path=\"goproj/src/github.com/couchbase/nitro\" revision=\"f3bef3551997be504612a2d05a8b324b3bfdfe1b\" />",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\" />",
 "  <project name=\"ns_server\" revision=\"8117c5307974f397ad831a2b870fb3ee0fd8364d\" />",
 "  <project name=\"opentracing-go\" path=\"godeps/src/github.com/opentracing/opentracing-go\" remote=\"couchbasedeps\" revision=\"1949ddbfd147afd4d964a9f00b24eb291e0e7c38\" />",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\" />",
 "  <project name=\"pflag\" path=\"godeps/src/github.com/spf13/pflag\" remote=\"couchbasedeps\" revision=\"a232f6d9f87afaaa08bafaff5da685f974b83313\" />",
 "  <project groups=\"kv\" name=\"phosphor\" revision=\"96501c57bb0fd61c85cba6f63101aed2bcf41d38\" />",
 "  <project name=\"pierrec-lz4\" path=\"godeps/src/github.com/pierrec/lz4\" remote=\"couchbasedeps\" revision=\"ed8d4cc3b461464e69798080a0092bd028910298\" />",
 "  <project name=\"pierrec-xxHash\" path=\"godeps/src/github.com/pierrec/xxHash\" remote=\"couchbasedeps\" revision=\"a0006b13c722f7f12368c00a3d3c2ae8a999a0c6\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"plasma\" path=\"goproj/src/github.com/couchbase/plasma\" remote=\"couchbase-priv\" revision=\"c0792c8cfb1463ef029f064f34e366442f1f0064\" />",
 "  <project groups=\"kv\" name=\"platform\" revision=\"de77d527bd23012dc67794c81a7b1e76e46e3abd\" />",
 "  <project groups=\"kv\" name=\"product-texts\" revision=\"8cf7d25a1dcb5434ea44983c0bed202fb9cc8351\" />",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\" />",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"d2011f6ee9f6e1dca5d3922d44fbcf86dad78150\" />",
 "  <project name=\"query-ui\" revision=\"15a6461f437fe810e411a6613ec7c143991cd1c6\" />",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\" />",
 "  <project name=\"roaring\" path=\"godeps/src/github.com/RoaringBitmap/roaring\" remote=\"couchbasedeps\" revision=\"fe09428be4c233d726797a1380f7438f4f71a31a\" />",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"762005e7a34fd909a84586299f1dd457371d36ee\" />",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"73353fe6dad8f3d67409feefb9b17f90f6de917b\" />",
 "  <project name=\"snowballstem\" path=\"godeps/src/github.com/blevesearch/snowballstem\" remote=\"blevesearch\" revision=\"26b06a2c243d4f8ca5db3486f94409dd5b2a7467\" />",
 "  <project groups=\"kv\" name=\"spdlog\" path=\"third_party/spdlog\" remote=\"couchbasedeps\" revision=\"4fba14c79f356ae48d6141c561bf9fd7ba33fabd\" />",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\" />",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"c30c3d4c250e68e81c57aa1e8ae91ffd21243cdb\" />",
 "  <project name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\" />",
 "  <project name=\"testrunner\" revision=\"4133fd785987f1ddcdb49dab736ff6e5e67d7c95\" upstream=\"alice\" />",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\" />",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"6dadf98e19803cc10ce9552bf4d9121cc2528965\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\" />",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\" />",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\" />",
 "    <copyfile dest=\".clang-format\" src=\"dot-clang-format\" />",
 "    <copyfile dest=\"third_party/CMakeLists.txt\" src=\"third-party-CMakeLists.txt\" />",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\" />",
 "  <project name=\"uuid\" path=\"godeps/src/github.com/google/uuid\" remote=\"couchbasedeps\" revision=\"dec09d789f3dba190787f8b4454c7d3c936fed9e\" />",
 "  <project name=\"vellum\" path=\"godeps/src/github.com/couchbase/vellum\" revision=\"0ceea4a37442f76199b9259840baf48d17af3c1a\" />",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"b3d83fe61db37bb38a46cd8dee434e5682cba2c7\" />",
 "  <project name=\"zstd\" path=\"godeps/src/github.com/DataDog/zstd\" remote=\"couchbasedeps\" revision=\"aebefd9fcb99f22cd691ef778a12ed68f0e6a1ab\" />",
 "</manifest>"]

[error_logger:info,2020-05-07T12:21:49.430Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.139.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:49.431Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2020-05-07T12:21:49.432Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2020-05-07T12:21:49.433Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:init:243]ip config not found. Looks like we're brand new node
[error_logger:info,2020-05-07T12:21:49.433Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.143.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2020-05-07T12:21:49.433Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.142.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:49.570Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:bringup:295]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2020-05-07T12:21:49.575Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.145.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.576Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.146.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:49.576Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:configure_net_kernel:339]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2020-05-07T12:21:49.576Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.147.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.576Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.144.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2020-05-07T12:21:49.578Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:save_node:227]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2020-05-07T12:21:49.584Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:bringup:309]Attempted to save node name to disk: ok
[ns_server:debug,2020-05-07T12:21:49.584Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:316]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2020-05-07T12:21:49.584Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T12:21:49.600Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:328]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2020-05-07T12:21:49.600Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.604Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.605Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:49.606Z,ns_1@127.0.0.1:ns_config_sup<0.154.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2020-05-07T12:21:49.607Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.155.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.607Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.156.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:49.638Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1095]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2020-05-07T12:21:49.638Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1109]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:debug,2020-05-07T12:21:49.651Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1117]Here's full dynamic config we loaded:
[[{auto_failover_cfg,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {enabled,true},
    {timeout,120},
    {count,0},
    {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
    {failover_server_group,false},
    {max_count,1},
    {failed_over_server_groups,[]}]},
  {alert_limits,
   [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
  {audit,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {enabled,[]},
    {disabled_users,[]},
    {auditd_enabled,false},
    {rotate_interval,86400},
    {rotate_size,20971520},
    {disabled,[]},
    {sync,[]},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
  {audit_decriptors,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {20480,
     [{name,<<"opened DCP connection">>},
      {description,<<"opened DCP connection">>},
      {enabled,true},
      {module,memcached}]},
    {20482,
     [{name,<<"external memcached bucket flush">>},
      {description,
       <<"External user flushed the content of a memcached bucket">>},
      {enabled,true},
      {module,memcached}]},
    {20483,
     [{name,<<"invalid packet">>},
      {description,<<"Rejected an invalid packet">>},
      {enabled,true},
      {module,memcached}]},
    {20485,
     [{name,<<"authentication succeeded">>},
      {description,<<"Authentication to the cluster succeeded">>},
      {enabled,false},
      {module,memcached}]},
    {20488,
     [{name,<<"document read">>},
      {description,<<"Document was read">>},
      {enabled,false},
      {module,memcached}]},
    {20489,
     [{name,<<"document locked">>},
      {description,<<"Document was locked">>},
      {enabled,false},
      {module,memcached}]},
    {20490,
     [{name,<<"document modify">>},
      {description,<<"Document was modified">>},
      {enabled,false},
      {module,memcached}]},
    {20491,
     [{name,<<"document delete">>},
      {description,<<"Document was deleted">>},
      {enabled,false},
      {module,memcached}]},
    {20492,
     [{name,<<"select bucket">>},
      {description,<<"The specified bucket was selected">>},
      {enabled,true},
      {module,memcached}]},
    {28672,
     [{name,<<"SELECT statement">>},
      {description,<<"A N1QL SELECT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28673,
     [{name,<<"EXPLAIN statement">>},
      {description,<<"A N1QL EXPLAIN statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28674,
     [{name,<<"PREPARE statement">>},
      {description,<<"A N1QL PREPARE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28675,
     [{name,<<"INFER statement">>},
      {description,<<"A N1QL INFER statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28676,
     [{name,<<"INSERT statement">>},
      {description,<<"A N1QL INSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28677,
     [{name,<<"UPSERT statement">>},
      {description,<<"A N1QL UPSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28678,
     [{name,<<"DELETE statement">>},
      {description,<<"A N1QL DELETE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28679,
     [{name,<<"UPDATE statement">>},
      {description,<<"A N1QL UPDATE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28680,
     [{name,<<"MERGE statement">>},
      {description,<<"A N1QL MERGE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28681,
     [{name,<<"CREATE INDEX statement">>},
      {description,<<"A N1QL CREATE INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28682,
     [{name,<<"DROP INDEX statement">>},
      {description,<<"A N1QL DROP INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28683,
     [{name,<<"ALTER INDEX statement">>},
      {description,<<"A N1QL ALTER INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28684,
     [{name,<<"BUILD INDEX statement">>},
      {description,<<"A N1QL BUILD INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28685,
     [{name,<<"GRANT ROLE statement">>},
      {description,<<"A N1QL GRANT ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28686,
     [{name,<<"REVOKE ROLE statement">>},
      {description,<<"A N1QL REVOKE ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28687,
     [{name,<<"UNRECOGNIZED statement">>},
      {description,
       <<"An unrecognized statement was received by the N1QL query engine">>},
      {enabled,false},
      {module,n1ql}]},
    {28688,
     [{name,<<"CREATE PRIMARY INDEX statement">>},
      {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28689,
     [{name,<<"/admin/stats API request">>},
      {description,<<"An HTTP request was made to the API at /admin/stats.">>},
      {enabled,false},
      {module,n1ql}]},
    {28690,
     [{name,<<"/admin/vitals API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/vitals.">>},
      {enabled,false},
      {module,n1ql}]},
    {28691,
     [{name,<<"/admin/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28692,
     [{name,<<"/admin/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28693,
     [{name,<<"/admin/indexes/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28694,
     [{name,<<"/admin/indexes/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28695,
     [{name,<<"/admin/indexes/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28697,
     [{name,<<"/admin/ping API request">>},
      {description,<<"An HTTP request was made to the API at /admin/ping.">>},
      {enabled,false},
      {module,n1ql}]},
    {28698,
     [{name,<<"/admin/config API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/config.">>},
      {enabled,false},
      {module,n1ql}]},
    {28699,
     [{name,<<"/admin/ssl_cert API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
      {enabled,false},
      {module,n1ql}]},
    {28700,
     [{name,<<"/admin/settings API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/settings.">>},
      {enabled,false},
      {module,n1ql}]},
    {28701,
     [{name,<<"/admin/clusters API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/clusters.">>},
      {enabled,false},
      {module,n1ql}]},
    {28702,
     [{name,<<"/admin/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {32768,
     [{name,<<"Create Function">>},
      {description,<<"Eventing function definition was created or updated">>},
      {enabled,true},
      {module,eventing}]},
    {32769,
     [{name,<<"Delete Function">>},
      {description,<<"Eventing function definition was deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32770,
     [{name,<<"Fetch Functions">>},
      {description,<<"Eventing function definition was read">>},
      {enabled,false},
      {module,eventing}]},
    {32771,
     [{name,<<"List Deployed">>},
      {description,<<"Eventing deployed functions list was read">>},
      {enabled,false},
      {module,eventing}]},
    {32772,
     [{name,<<"Fetch Drafts">>},
      {description,<<"Eventing function draft definitions were read">>},
      {enabled,false},
      {module,eventing}]},
    {32773,
     [{name,<<"Delete Drafts">>},
      {description,<<"Eventing function draft definitions were deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32774,
     [{name,<<"Save Draft">>},
      {description,<<"Save a draft definition to the store">>},
      {enabled,true},
      {module,eventing}]},
    {32775,
     [{name,<<"Start Debug">>},
      {description,<<"Start eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32776,
     [{name,<<"Stop Debug">>},
      {description,<<"Stop eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32777,
     [{name,<<"Start Tracing">>},
      {description,<<"Start tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32778,
     [{name,<<"Stop Tracing">>},
      {description,<<"Stop tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32779,
     [{name,<<"Set Settings">>},
      {description,<<"Save settings for a given app">>},
      {enabled,true},
      {module,eventing}]},
    {32780,
     [{name,<<"Fetch Config">>},
      {description,<<"Get config for eventing">>},
      {enabled,false},
      {module,eventing}]},
    {32781,
     [{name,<<"Save Config">>},
      {description,<<"Save config for eventing">>},
      {enabled,true},
      {module,eventing}]},
    {32782,
     [{name,<<"Cleanup Eventing">>},
      {description,<<"Clears up app definitions and settings from metakv">>},
      {enabled,true},
      {module,eventing}]},
    {32783,
     [{name,<<"Get Settings">>},
      {description,<<"Get settings for a given app">>},
      {enabled,false},
      {module,eventing}]},
    {32784,
     [{name,<<"Import Functions">>},
      {description,<<"Import a list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32785,
     [{name,<<"Export Functions">>},
      {description,<<"Export the list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32786,
     [{name,<<"List Running">>},
      {description,<<"Eventing running function list was read">>},
      {enabled,false},
      {module,eventing}]},
    {36865,
     [{name,<<"Service configuration change">>},
      {description,<<"A successful service configuration change was made.">>},
      {enabled,true},
      {module,analytics}]},
    {36866,
     [{name,<<"Node configuration change">>},
      {description,<<"A successful node configuration change was made.">>},
      {enabled,true},
      {module,analytics}]}]},
  {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
  {autocompaction,
   [{database_fragmentation_threshold,{30,undefined}},
    {view_fragmentation_threshold,{30,undefined}}]},
  {buckets,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]},
    {configs,[]}]},
  {cbas_memory_quota,1024},
  {cert_and_pkey,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQlsomKQ7qhDcAeKZ3inWuCQuv8NxCAMb8M\nXhrVTrshZyFDiXdKS3Xbshyc9dEOiDwuDwAEgfwJQsXzzx0eCRtyTZfWAWTOH06O\nXdQps+9iTfr2KBFj27uag5c5ns+0ojsNyqZhA4+dbS7zK3CZ1dx7LPkL3+4HTlMh\nmH1/2fib3Lbp6dW3B55GV8/RHbkzgcRMyBicYtinqh6JMmmzjO/3KEyVHs3h0W1E\n00JdAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCKWU+bCvjKUlhW\niMiAN7r/3Vxkah7KEqp8BajCnLrlTMeiV+24TlPrsCWz4VBmOgt8OcijS3axdEik\nXeteeJp+R8nb2XPGivHOg/Hx2NlLxCrtXaYVGM0PiVydo24iCv0ZlqMCBsrzRLky\n5otbfQi8ngdfuR88C0/r3RLqvuFnOtFkLbKXuT/qshXfM8O/OgiJkr6CTBFYNd8w\nTCxN2syK41/HXoYzexdA/OTSm+kuEIuDpQYxKS0M4oKKZApJM70y/CYTzwG3JOnp\nuteZPYrwhIqxz01fkbLnj3QLGxPpSexRsp52GOoCv/YEE7tl3Olt4+p+MvhEZPdZ\ndqB53mNJ\n-----END CERTIFICATE-----\n">>,
     <<"*****">>}]},
  {client_cert_auth,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {state,"disable"},
    {prefixes,[]}]},
  {cluster_compat_version,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},
    6,0]},
  {drop_request_memory_threshold_mib,undefined},
  {email_alerts,
   [{recipients,["root@localhost"]},
    {sender,"couchbase@localhost"},
    {enabled,false},
    {email_server,
     [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
    {alerts,
     [auto_failover_node,auto_failover_maximum_reached,
      auto_failover_other_nodes_down,auto_failover_cluster_too_small,
      auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
      ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
      ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
  {fts_memory_quota,256},
  {index_aware_rebalance_disabled,false},
  {log_redaction_default_cfg,[{redact_level,none}]},
  {max_bucket_count,10},
  {memcached,[]},
  {memory_quota,311},
  {nodes_wanted,['ns_1@127.0.0.1']},
  {otp,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
    {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]},
  {password_policy,[{min_length,6},{must_present,[]}]},
  {quorum_nodes,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    'ns_1@127.0.0.1']},
  {read_only_user_creds,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {remote_clusters,[]},
  {replication,[{enabled,true}]},
  {rest,[{port,8091}]},
  {rest_creds,null},
  {roles_definitions,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {scramsha_fallback_salt,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<169,238,80,91,5,165,74,47,79,135,45,74>>]},
  {secure_headers,[]},
  {server_groups,
   [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
  {set_view_update_daemon,
   [{update_interval,5000},
    {update_min_changes,5000},
    {replica_update_min_changes,5000}]},
  {users_upgrade,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {{couchdb,max_parallel_indexers},4},
  {{couchdb,max_parallel_replica_indexers},2},
  {{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756072601}}]}]},
  {{metakv,<<"/eventing/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"ram_quota\":256}">>]},
  {{metakv,<<"/indexing/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
  {{metakv,<<"/query/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
  {{rbac_upgrade,[5,5]},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {{request_limit,capi},undefined},
  {{request_limit,rest},undefined},
  {{service_map,fts},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{service_map,index},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{service_map,n1ql},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{node,'ns_1@127.0.0.1',audit},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
  {{node,'ns_1@127.0.0.1',capi_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8092]},
  {{node,'ns_1@127.0.0.1',cbas_admin_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9110]},
  {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9113]},
  {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9112]},
  {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9111]},
  {{node,'ns_1@127.0.0.1',cbas_cluster_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9115]},
  {{node,'ns_1@127.0.0.1',cbas_console_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9114]},
  {{node,'ns_1@127.0.0.1',cbas_data_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9116]},
  {{node,'ns_1@127.0.0.1',cbas_debug_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    -1]},
  {{node,'ns_1@127.0.0.1',cbas_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8095]},
  {{node,'ns_1@127.0.0.1',cbas_messaging_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9118]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9119]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9121]},
  {{node,'ns_1@127.0.0.1',cbas_parent_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9122]},
  {{node,'ns_1@127.0.0.1',cbas_replication_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9120]},
  {{node,'ns_1@127.0.0.1',cbas_result_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9117]},
  {{node,'ns_1@127.0.0.1',cbas_ssl_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18095]},
  {{node,'ns_1@127.0.0.1',compaction_daemon},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {check_interval,30},
    {min_db_file_size,131072},
    {min_view_file_size,20971520}]},
  {{node,'ns_1@127.0.0.1',config_version},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {5,5,3}]},
  {{node,'ns_1@127.0.0.1',eventing_debug_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9140]},
  {{node,'ns_1@127.0.0.1',eventing_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8096]},
  {{node,'ns_1@127.0.0.1',eventing_https_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18096]},
  {{node,'ns_1@127.0.0.1',fts_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8094]},
  {{node,'ns_1@127.0.0.1',fts_ssl_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18094]},
  {{node,'ns_1@127.0.0.1',indexer_admin_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9100]},
  {{node,'ns_1@127.0.0.1',indexer_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9102]},
  {{node,'ns_1@127.0.0.1',indexer_https_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    19102]},
  {{node,'ns_1@127.0.0.1',indexer_scan_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9101]},
  {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9104]},
  {{node,'ns_1@127.0.0.1',indexer_stinit_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9103]},
  {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9105]},
  {{node,'ns_1@127.0.0.1',is_enterprise},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',isasl},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
  {{node,'ns_1@127.0.0.1',ldap_enabled},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',membership},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    active]},
  {{node,'ns_1@127.0.0.1',memcached},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,11210},
    {dedicated_port,11209},
    {ssl_port,11207},
    {admin_user,"@ns_server"},
    {other_users,
     ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
      "@cbas"]},
    {admin_pass,"*****"},
    {engines,
     [{membase,
       [{engine,"/opt/couchbase/lib/memcached/ep.so"},
        {static_config_string,"failpartialwarmup=false"}]},
      {memcached,
       [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
        {static_config_string,"vb0=true"}]}]},
    {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
    {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
    {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
    {log_prefix,"memcached.log"},
    {log_generations,20},
    {log_cyclesize,10485760},
    {log_sleeptime,19},
    {log_rotation_period,39003}]},
  {{node,'ns_1@127.0.0.1',memcached_config},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {[{interfaces,
       {memcached_config_mgr,omit_missing_mcd_ports,
        [{[{host,<<"*">>},
           {port,port},
           {maxconn,maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,dedicated_port},
           {maxconn,dedicated_port_maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,ssl_port},
           {maxconn,maxconn},
           {ssl,
            {[{key,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
              {cert,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]}]}},
      {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
      {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
      {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
      {connection_idle_time,connection_idle_time},
      {privilege_debug,privilege_debug},
      {breakpad,
       {[{enabled,breakpad_enabled},
         {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
      {admin,{"~s",[admin_user]}},
      {verbosity,verbosity},
      {audit_file,{"~s",[audit_file]}},
      {rbac_file,{"~s",[rbac_file]}},
      {dedupe_nmvb_maps,dedupe_nmvb_maps},
      {tracing_enabled,tracing_enabled},
      {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
      {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
      {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
      {logger,
       {[{filename,{"~s/~s",[log_path,log_prefix]}},
         {cyclesize,log_cyclesize},
         {sleeptime,log_sleeptime}]}}]}]},
  {{node,'ns_1@127.0.0.1',memcached_defaults},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {maxconn,30000},
    {dedicated_port_maxconn,5000},
    {ssl_cipher_list,"HIGH"},
    {connection_idle_time,0},
    {verbosity,0},
    {privilege_debug,false},
    {breakpad_enabled,true},
    {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
    {dedupe_nmvb_maps,false},
    {tracing_enabled,true},
    {datatype_snappy,true}]},
  {{node,'ns_1@127.0.0.1',moxi},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,11211},
    {verbosity,[]}]},
  {{node,'ns_1@127.0.0.1',ns_log},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
  {{node,'ns_1@127.0.0.1',port_servers},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
  {{node,'ns_1@127.0.0.1',projector_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9999]},
  {{node,'ns_1@127.0.0.1',query_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8093]},
  {{node,'ns_1@127.0.0.1',rest},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,8091},
    {port_meta,global}]},
  {{node,'ns_1@127.0.0.1',ssl_capi_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18092]},
  {{node,'ns_1@127.0.0.1',ssl_query_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18093]},
  {{node,'ns_1@127.0.0.1',ssl_rest_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18091]},
  {{node,'ns_1@127.0.0.1',uuid},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    <<"0f8760945f98b1efdbef0bd1ea6e8446">>]},
  {{node,'ns_1@127.0.0.1',xdcr_rest_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9998]},
  {{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    false]}]]
[ns_server:info,2020-05-07T12:21:49.657Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1138]Here's full dynamic config we loaded + static & default config:
[{{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   false]},
 {{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   <<"0f8760945f98b1efdbef0bd1ea6e8446">>]},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,8091},
   {port_meta,global}]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11211},
   {verbosity,[]}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {privilege_debug,false},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false},
   {tracing_enabled,true},
   {datatype_snappy,true}]},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},
          {port,port},
          {maxconn,maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {privilege_debug,privilege_debug},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {rbac_file,{"~s",[rbac_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps},
     {tracing_enabled,tracing_enabled},
     {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
     {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
     {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
     {logger,
      {[{filename,{"~s/~s",[log_path,log_prefix]}},
        {cyclesize,log_cyclesize},
        {sleeptime,log_sleeptime}]}}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"@ns_server"},
   {other_users,
    ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
     "@cbas"]},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   active]},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   19102]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',fts_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18094]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',eventing_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18096]},
 {{node,'ns_1@127.0.0.1',eventing_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8096]},
 {{node,'ns_1@127.0.0.1',eventing_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9140]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {5,5,3}]},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {{node,'ns_1@127.0.0.1',cbas_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18095]},
 {{node,'ns_1@127.0.0.1',cbas_result_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9117]},
 {{node,'ns_1@127.0.0.1',cbas_replication_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9120]},
 {{node,'ns_1@127.0.0.1',cbas_parent_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9122]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9121]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9119]},
 {{node,'ns_1@127.0.0.1',cbas_messaging_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9118]},
 {{node,'ns_1@127.0.0.1',cbas_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8095]},
 {{node,'ns_1@127.0.0.1',cbas_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]},
 {{node,'ns_1@127.0.0.1',cbas_data_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9116]},
 {{node,'ns_1@127.0.0.1',cbas_console_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9114]},
 {{node,'ns_1@127.0.0.1',cbas_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9115]},
 {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9111]},
 {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9112]},
 {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9113]},
 {{node,'ns_1@127.0.0.1',cbas_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9110]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{service_map,n1ql},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{service_map,index},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{service_map,fts},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{request_limit,rest},undefined},
 {{request_limit,capi},undefined},
 {{rbac_upgrade,[5,5]},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {{metakv,<<"/query/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
 {{metakv,<<"/indexing/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
 {{metakv,<<"/eventing/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"ram_quota\":256}">>]},
 {{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756072601}}]}]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {users_upgrade,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {secure_headers,[]},
 {scramsha_fallback_salt,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<169,238,80,91,5,165,74,47,79,135,45,74>>]},
 {roles_definitions,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {rest_creds,null},
 {rest,[{port,8091}]},
 {replication,[{enabled,true}]},
 {remote_clusters,[]},
 {read_only_user_creds,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {quorum_nodes,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   'ns_1@127.0.0.1']},
 {password_policy,[{min_length,6},{must_present,[]}]},
 {otp,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
   {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {memory_quota,311},
 {memcached,[]},
 {max_bucket_count,10},
 {log_redaction_default_cfg,[{redact_level,none}]},
 {index_aware_rebalance_disabled,false},
 {fts_memory_quota,256},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
 {drop_request_memory_threshold_mib,undefined},
 {cluster_compat_version,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},
   6,0]},
 {client_cert_auth,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {state,"disable"},
   {prefixes,[]}]},
 {cert_and_pkey,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQlsomKQ7qhDcAeKZ3inWuCQuv8NxCAMb8M\nXhrVTrshZyFDiXdKS3Xbshyc9dEOiDwuDwAEgfwJQsXzzx0eCRtyTZfWAWTOH06O\nXdQps+9iTfr2KBFj27uag5c5ns+0ojsNyqZhA4+dbS7zK3CZ1dx7LPkL3+4HTlMh\nmH1/2fib3Lbp6dW3B55GV8/RHbkzgcRMyBicYtinqh6JMmmzjO/3KEyVHs3h0W1E\n00JdAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCKWU+bCvjKUlhW\niMiAN7r/3Vxkah7KEqp8BajCnLrlTMeiV+24TlPrsCWz4VBmOgt8OcijS3axdEik\nXeteeJp+R8nb2XPGivHOg/Hx2NlLxCrtXaYVGM0PiVydo24iCv0ZlqMCBsrzRLky\n5otbfQi8ngdfuR88C0/r3RLqvuFnOtFkLbKXuT/qshXfM8O/OgiJkr6CTBFYNd8w\nTCxN2syK41/HXoYzexdA/OTSm+kuEIuDpQYxKS0M4oKKZApJM70y/CYTzwG3JOnp\nuteZPYrwhIqxz01fkbLnj3QLGxPpSexRsp52GOoCv/YEE7tl3Olt4+p+MvhEZPdZ\ndqB53mNJ\n-----END CERTIFICATE-----\n">>,
    <<"*****">>}]},
 {cbas_memory_quota,1024},
 {buckets,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]},
   {configs,[]}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
 {audit_decriptors,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {20480,
    [{name,<<"opened DCP connection">>},
     {description,<<"opened DCP connection">>},
     {enabled,true},
     {module,memcached}]},
   {20482,
    [{name,<<"external memcached bucket flush">>},
     {description,
      <<"External user flushed the content of a memcached bucket">>},
     {enabled,true},
     {module,memcached}]},
   {20483,
    [{name,<<"invalid packet">>},
     {description,<<"Rejected an invalid packet">>},
     {enabled,true},
     {module,memcached}]},
   {20485,
    [{name,<<"authentication succeeded">>},
     {description,<<"Authentication to the cluster succeeded">>},
     {enabled,false},
     {module,memcached}]},
   {20488,
    [{name,<<"document read">>},
     {description,<<"Document was read">>},
     {enabled,false},
     {module,memcached}]},
   {20489,
    [{name,<<"document locked">>},
     {description,<<"Document was locked">>},
     {enabled,false},
     {module,memcached}]},
   {20490,
    [{name,<<"document modify">>},
     {description,<<"Document was modified">>},
     {enabled,false},
     {module,memcached}]},
   {20491,
    [{name,<<"document delete">>},
     {description,<<"Document was deleted">>},
     {enabled,false},
     {module,memcached}]},
   {20492,
    [{name,<<"select bucket">>},
     {description,<<"The specified bucket was selected">>},
     {enabled,true},
     {module,memcached}]},
   {28672,
    [{name,<<"SELECT statement">>},
     {description,<<"A N1QL SELECT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28673,
    [{name,<<"EXPLAIN statement">>},
     {description,<<"A N1QL EXPLAIN statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28674,
    [{name,<<"PREPARE statement">>},
     {description,<<"A N1QL PREPARE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28675,
    [{name,<<"INFER statement">>},
     {description,<<"A N1QL INFER statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28676,
    [{name,<<"INSERT statement">>},
     {description,<<"A N1QL INSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28677,
    [{name,<<"UPSERT statement">>},
     {description,<<"A N1QL UPSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28678,
    [{name,<<"DELETE statement">>},
     {description,<<"A N1QL DELETE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28679,
    [{name,<<"UPDATE statement">>},
     {description,<<"A N1QL UPDATE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28680,
    [{name,<<"MERGE statement">>},
     {description,<<"A N1QL MERGE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28681,
    [{name,<<"CREATE INDEX statement">>},
     {description,<<"A N1QL CREATE INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28682,
    [{name,<<"DROP INDEX statement">>},
     {description,<<"A N1QL DROP INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28683,
    [{name,<<"ALTER INDEX statement">>},
     {description,<<"A N1QL ALTER INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28684,
    [{name,<<"BUILD INDEX statement">>},
     {description,<<"A N1QL BUILD INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28685,
    [{name,<<"GRANT ROLE statement">>},
     {description,<<"A N1QL GRANT ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28686,
    [{name,<<"REVOKE ROLE statement">>},
     {description,<<"A N1QL REVOKE ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28687,
    [{name,<<"UNRECOGNIZED statement">>},
     {description,
      <<"An unrecognized statement was received by the N1QL query engine">>},
     {enabled,false},
     {module,n1ql}]},
   {28688,
    [{name,<<"CREATE PRIMARY INDEX statement">>},
     {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28689,
    [{name,<<"/admin/stats API request">>},
     {description,<<"An HTTP request was made to the API at /admin/stats.">>},
     {enabled,false},
     {module,n1ql}]},
   {28690,
    [{name,<<"/admin/vitals API request">>},
     {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
     {enabled,false},
     {module,n1ql}]},
   {28691,
    [{name,<<"/admin/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28692,
    [{name,<<"/admin/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28693,
    [{name,<<"/admin/indexes/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28694,
    [{name,<<"/admin/indexes/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28695,
    [{name,<<"/admin/indexes/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28697,
    [{name,<<"/admin/ping API request">>},
     {description,<<"An HTTP request was made to the API at /admin/ping.">>},
     {enabled,false},
     {module,n1ql}]},
   {28698,
    [{name,<<"/admin/config API request">>},
     {description,<<"An HTTP request was made to the API at /admin/config.">>},
     {enabled,false},
     {module,n1ql}]},
   {28699,
    [{name,<<"/admin/ssl_cert API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
     {enabled,false},
     {module,n1ql}]},
   {28700,
    [{name,<<"/admin/settings API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/settings.">>},
     {enabled,false},
     {module,n1ql}]},
   {28701,
    [{name,<<"/admin/clusters API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/clusters.">>},
     {enabled,false},
     {module,n1ql}]},
   {28702,
    [{name,<<"/admin/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {32768,
    [{name,<<"Create Function">>},
     {description,<<"Eventing function definition was created or updated">>},
     {enabled,true},
     {module,eventing}]},
   {32769,
    [{name,<<"Delete Function">>},
     {description,<<"Eventing function definition was deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32770,
    [{name,<<"Fetch Functions">>},
     {description,<<"Eventing function definition was read">>},
     {enabled,false},
     {module,eventing}]},
   {32771,
    [{name,<<"List Deployed">>},
     {description,<<"Eventing deployed functions list was read">>},
     {enabled,false},
     {module,eventing}]},
   {32772,
    [{name,<<"Fetch Drafts">>},
     {description,<<"Eventing function draft definitions were read">>},
     {enabled,false},
     {module,eventing}]},
   {32773,
    [{name,<<"Delete Drafts">>},
     {description,<<"Eventing function draft definitions were deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32774,
    [{name,<<"Save Draft">>},
     {description,<<"Save a draft definition to the store">>},
     {enabled,true},
     {module,eventing}]},
   {32775,
    [{name,<<"Start Debug">>},
     {description,<<"Start eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32776,
    [{name,<<"Stop Debug">>},
     {description,<<"Stop eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32777,
    [{name,<<"Start Tracing">>},
     {description,<<"Start tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32778,
    [{name,<<"Stop Tracing">>},
     {description,<<"Stop tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32779,
    [{name,<<"Set Settings">>},
     {description,<<"Save settings for a given app">>},
     {enabled,true},
     {module,eventing}]},
   {32780,
    [{name,<<"Fetch Config">>},
     {description,<<"Get config for eventing">>},
     {enabled,false},
     {module,eventing}]},
   {32781,
    [{name,<<"Save Config">>},
     {description,<<"Save config for eventing">>},
     {enabled,true},
     {module,eventing}]},
   {32782,
    [{name,<<"Cleanup Eventing">>},
     {description,<<"Clears up app definitions and settings from metakv">>},
     {enabled,true},
     {module,eventing}]},
   {32783,
    [{name,<<"Get Settings">>},
     {description,<<"Get settings for a given app">>},
     {enabled,false},
     {module,eventing}]},
   {32784,
    [{name,<<"Import Functions">>},
     {description,<<"Import a list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32785,
    [{name,<<"Export Functions">>},
     {description,<<"Export the list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32786,
    [{name,<<"List Running">>},
     {description,<<"Eventing running function list was read">>},
     {enabled,false},
     {module,eventing}]},
   {36865,
    [{name,<<"Service configuration change">>},
     {description,<<"A successful service configuration change was made.">>},
     {enabled,true},
     {module,analytics}]},
   {36866,
    [{name,<<"Node configuration change">>},
     {description,<<"A successful node configuration change was made.">>},
     {enabled,true},
     {module,analytics}]}]},
 {audit,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {enabled,[]},
   {disabled_users,[]},
   {auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {auto_failover_cfg,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {enabled,true},
   {timeout,120},
   {count,0},
   {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
   {failover_server_group,false},
   {max_count,1},
   {failed_over_server_groups,[]}]}]
[error_logger:info,2020-05-07T12:21:49.665Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.157.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.667Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.163.0>},
                       {name,ns_config_remote},
                       {mfargs,{ns_config_replica,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.669Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.164.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.669Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:49.672Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.166.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.673Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.167.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:49.683Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.170.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:49.685Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2020-05-07T12:21:49.685Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.171.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.685Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.172.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.688Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.173.0>},
                       {name,memcached_refresh},
                       {mfargs,{memcached_refresh,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.690Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.175.0>},
                       {name,ssl_service_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ssl_service_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:49.705Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:init:419]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem-ca"},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[error_logger:info,2020-05-07T12:21:49.757Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.176.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:49.769Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T12:21:49.769Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T12:21:49.769Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T12:21:49.769Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[ns_server:debug,2020-05-07T12:21:49.784Z,ns_1@127.0.0.1:<0.178.0>:restartable:start_child:98]Started child process <0.179.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2020-05-07T12:21:49.784Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.178.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.784Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.174.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:49.785Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.197.0>},
                       {name,user_storage_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,user_storage_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.794Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.199.0>},
                       {name,users_replicator},
                       {mfargs,{menelaus_users,start_replicator,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:49.796Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:55]Start waiting for startup
[ns_server:debug,2020-05-07T12:21:49.798Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_storage:anounce_startup:69]Announce my startup to <0.199.0>
[ns_server:debug,2020-05-07T12:21:49.798Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:58]Received replicated storage registration from <0.200.0>
[ns_server:debug,2020-05-07T12:21:49.800Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:open:212]Opening file "/opt/couchbase/var/lib/couchbase/config/users.dets"
[error_logger:info,2020-05-07T12:21:49.800Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.200.0>},
                       {name,users_storage},
                       {mfargs,{menelaus_users,start_storage,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.800Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.198.0>},
                       {name,users_storage_sup},
                       {mfargs,{users_storage_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:21:49.814Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:init:44]Starting versioned cache compiled_roles_cache
[error_logger:info,2020-05-07T12:21:49.814Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.202.0>},
                       {name,compiled_roles_cache},
                       {mfargs,{menelaus_roles,start_compiled_roles_cache,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.814Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.196.0>},
                       {name,users_sup},
                       {mfargs,{users_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:49.815Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.205.0>},
                       {name,dets_sup},
                       {mfargs,{dets_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:49.815Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.206.0>},
                       {name,dets},
                       {mfargs,{dets_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:49.827Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:convert_docs_to_55_in_dets:243]Checking for pre 5.5 records in dets: users_storage
[ns_server:debug,2020-05-07T12:21:49.828Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,'$1','_','$2'},
                                      [],
                                      [{{'$1','$2'}}]}],
                                    100}
[ns_server:debug,2020-05-07T12:21:49.828Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:init_after_ack:204]Loading 0 items, 299 words took 0ms
[ns_server:debug,2020-05-07T12:21:49.832Z,ns_1@127.0.0.1:users_replicator<0.199.0>:doc_replicator:loop:60]doing replicate_newnodes_docs
[ns_server:debug,2020-05-07T12:21:49.833Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.210.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:141]Waiting for ns_couchdb node to start
[error_logger:info,2020-05-07T12:21:49.833Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.209.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:49.833Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T12:21:49.833Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.213.0>,shutdown}}
[ns_server:debug,2020-05-07T12:21:49.833Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T12:21:49.833Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T12:21:50.034Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T12:21:50.034Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.216.0>,shutdown}}
[ns_server:debug,2020-05-07T12:21:50.034Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T12:21:50.034Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T12:21:50.235Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T12:21:50.235Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T12:21:50.235Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.219.0>,shutdown}}
[error_logger:info,2020-05-07T12:21:50.235Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T12:21:50.436Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T12:21:50.456Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T12:21:50.657Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T12:21:50.858Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T12:21:51.059Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T12:21:51.260Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[error_logger:info,2020-05-07T12:21:51.545Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.229.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:51.746Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: Apache CouchDB v4.5.1-112-gc2b9820 (LogLevel=info) is starting.
ns_couchdb<0.209.0>: Apache CouchDB has started. Time to relax.

[error_logger:info,2020-05-07T12:21:51.839Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.210.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.96617950>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:51.844Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:ns_storage_conf:setup_db_and_ix_paths:47]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2020-05-07T12:21:51.852Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.232.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:51.854Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.233.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:51.855Z,ns_1@127.0.0.1:ns_server_sup<0.231.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2020-05-07T12:21:51.864Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.234.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:51.866Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.235.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:51.870Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.236.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:51.870Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.237.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:51.875Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:memcached_cfg:init:62]Init config writer for memcached_passwords, "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T12:21:51.875Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T12:21:51.937Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.238.0>
[ns_server:debug,2020-05-07T12:21:51.937Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T12:21:51.938Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.238.0>
[ns_server:debug,2020-05-07T12:21:51.947Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[error_logger:info,2020-05-07T12:21:51.948Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.238.0>},
                       {name,memcached_passwords},
                       {mfargs,{memcached_passwords,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T12:21:51.952Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T12:21:51.952Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [isasl] failed. Retry in 1000 ms.
[ns_server:debug,2020-05-07T12:21:51.953Z,ns_1@127.0.0.1:memcached_permissions<0.241.0>:memcached_cfg:init:62]Init config writer for memcached_permissions, "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T12:21:51.954Z,ns_1@127.0.0.1:memcached_permissions<0.241.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T12:21:51.956Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.241.0>
[ns_server:debug,2020-05-07T12:21:51.956Z,ns_1@127.0.0.1:memcached_permissions<0.241.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{user,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T12:21:51.956Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.241.0>
[ns_server:debug,2020-05-07T12:21:51.961Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of rbac requested
[error_logger:info,2020-05-07T12:21:51.962Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.241.0>},
                       {name,memcached_permissions},
                       {mfargs,{memcached_permissions,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:51.962Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.244.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T12:21:51.963Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T12:21:51.964Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2020-05-07T12:21:51.964Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.246.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:51.964Z,ns_1@127.0.0.1:ns_node_disco<0.247.0>:ns_node_disco:init:130]Initting ns_node_disco with []
[ns_server:debug,2020-05-07T12:21:51.965Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[user:info,2020-05-07T12:21:51.965Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:127]Node 'ns_1@127.0.0.1' synchronized otp cookie {sanitized,
                                               <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>} from cluster
[ns_server:debug,2020-05-07T12:21:51.965Z,ns_1@127.0.0.1:<0.248.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:21:51.969Z,ns_1@127.0.0.1:<0.248.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[error_logger:info,2020-05-07T12:21:51.969Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.247.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:51.970Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.249.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:51.971Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.250.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:51.976Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:51.976Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:69]init pulling
[ns_server:debug,2020-05-07T12:21:51.976Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:71]init pushing
[ns_server:debug,2020-05-07T12:21:51.988Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:75]init reannouncing
[ns_server:debug,2020-05-07T12:21:51.988Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:handle_info:89]Flushing cache compiled_roles_cache due to version change from undefined to {[6,
                                                                              0],
                                                                             {0,
                                                                              2881475258},
                                                                             false,
                                                                             []}
[ns_server:debug,2020-05-07T12:21:51.988Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2020-05-07T12:21:51.988Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2020-05-07T12:21:51.988Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T12:21:51.988Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T12:21:51.988Z,ns_1@127.0.0.1:<0.260.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:21:51.989Z,ns_1@127.0.0.1:<0.261.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:21:51.989Z,ns_1@127.0.0.1:<0.260.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:21:51.989Z,ns_1@127.0.0.1:<0.261.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T12:21:51.989Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2020-05-07T12:21:51.990Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,[]},
 {disabled_users,[]},
 {auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2020-05-07T12:21:51.991Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T12:21:51.994Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit_decriptors ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {20480,
  [{name,<<"opened DCP connection">>},
   {description,<<"opened DCP connection">>},
   {enabled,true},
   {module,memcached}]},
 {20482,
  [{name,<<"external memcached bucket flush">>},
   {description,<<"External user flushed the content of a memcached bucket">>},
   {enabled,true},
   {module,memcached}]},
 {20483,
  [{name,<<"invalid packet">>},
   {description,<<"Rejected an invalid packet">>},
   {enabled,true},
   {module,memcached}]},
 {20485,
  [{name,<<"authentication succeeded">>},
   {description,<<"Authentication to the cluster succeeded">>},
   {enabled,false},
   {module,memcached}]},
 {20488,
  [{name,<<"document read">>},
   {description,<<"Document was read">>},
   {enabled,false},
   {module,memcached}]},
 {20489,
  [{name,<<"document locked">>},
   {description,<<"Document was locked">>},
   {enabled,false},
   {module,memcached}]},
 {20490,
  [{name,<<"document modify">>},
   {description,<<"Document was modified">>},
   {enabled,false},
   {module,memcached}]},
 {20491,
  [{name,<<"document delete">>},
   {description,<<"Document was deleted">>},
   {enabled,false},
   {module,memcached}]},
 {20492,
  [{name,<<"select bucket">>},
   {description,<<"The specified bucket was selected">>},
   {enabled,true},
   {module,memcached}]},
 {28672,
  [{name,<<"SELECT statement">>},
   {description,<<"A N1QL SELECT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28673,
  [{name,<<"EXPLAIN statement">>},
   {description,<<"A N1QL EXPLAIN statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28674,
  [{name,<<"PREPARE statement">>},
   {description,<<"A N1QL PREPARE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28675,
  [{name,<<"INFER statement">>},
   {description,<<"A N1QL INFER statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28676,
  [{name,<<"INSERT statement">>},
   {description,<<"A N1QL INSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28677,
  [{name,<<"UPSERT statement">>},
   {description,<<"A N1QL UPSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28678,
  [{name,<<"DELETE statement">>},
   {description,<<"A N1QL DELETE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28679,
  [{name,<<"UPDATE statement">>},
   {description,<<"A N1QL UPDATE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28680,
  [{name,<<"MERGE statement">>},
   {description,<<"A N1QL MERGE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28681,
  [{name,<<"CREATE INDEX statement">>},
   {description,<<"A N1QL CREATE INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28682,
  [{name,<<"DROP INDEX statement">>},
   {description,<<"A N1QL DROP INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28683,
  [{name,<<"ALTER INDEX statement">>},
   {description,<<"A N1QL ALTER INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28684,
  [{name,<<"BUILD INDEX statement">>},
   {description,<<"A N1QL BUILD INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28685,
  [{name,<<"GRANT ROLE statement">>},
   {description,<<"A N1QL GRANT ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28686,
  [{name,<<"REVOKE ROLE statement">>},
   {description,<<"A N1QL REVOKE ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28687,
  [{name,<<"UNRECOGNIZED statement">>},
   {description,<<"An unrecognized statement was received by the N1QL query engine">>},
   {enabled,false},
   {module,n1ql}]},
 {28688,
  [{name,<<"CREATE PRIMARY INDEX statement">>},
   {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28689,
  [{name,<<"/admin/stats API request">>},
   {description,<<"An HTTP request was made to the API at /admin/stats.">>},
   {enabled,false},
   {module,n1ql}]},
 {28690,
  [{name,<<"/admin/vitals API request">>},
   {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
   {enabled,false},
   {module,n1ql}]},
 {28691,
  [{name,<<"/admin/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28692,
  [{name,<<"/admin/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28693,
  [{name,<<"/admin/indexes/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28694,
  [{name,<<"/admin/indexes/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28695,
  [{name,<<"/admin/indexes/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28697,
  [{name,<<"/admin/ping API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ping.">>},
   {enabled,false},
   {module,n1ql}]},
 {28698,
  [{name,<<"/admin/config API request">>},
   {description,<<"An HTTP request was made to the API at /admin/config.">>},
   {enabled,false},
   {module,n1ql}]},
 {28699,
  [{name,<<"/admin/ssl_cert API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ssl_cert.">>},
   {enabled,false},
   {module,n1ql}]},
 {28700,
  [{name,<<"/admin/settings API request">>},
   {description,<<"An HTTP request was made to the API at /admin/settings.">>},
   {enabled,false},
   {module,n1ql}]},
 {28701,
  [{name,<<"/admin/clusters API request">>},
   {description,<<"An HTTP request was made to the API at /admin/clusters.">>},
   {enabled,false},
   {module,n1ql}]},
 {28702,
  [{name,<<"/admin/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {32768,
  [{name,<<"Create Function">>},
   {description,<<"Eventing function definition was created or updated">>},
   {enabled,true},
   {module,eventing}]},
 {32769,
  [{name,<<"Delete Function">>},
   {description,<<"Eventing function definition was deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32770,
  [{name,<<"Fetch Functions">>},
   {description,<<"Eventing function definition was read">>},
   {enabled,false},
   {module,eventing}]},
 {32771,
  [{name,<<"List Deployed">>},
   {description,<<"Eventing deployed functions list was read">>},
   {enabled,false},
   {module,eventing}]},
 {32772,
  [{name,<<"Fetch Drafts">>},
   {description,<<"Eventing function draft definitions were read">>},
   {enabled,false},
   {module,eventing}]},
 {32773,
  [{name,<<"Delete Drafts">>},
   {description,<<"Eventing function draft definitions were deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32774,
  [{name,<<"Save Draft">>},
   {description,<<"Save a draft definition to the store">>},
   {enabled,true},
   {module,eventing}]},
 {32775,
  [{name,<<"Start Debug">>},
   {description,<<"Start eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32776,
  [{name,<<"Stop Debug">>},
   {description,<<"Stop eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32777,
  [{name,<<"Start Tracing">>},
   {description,<<"Start tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32778,
  [{name,<<"Stop Tracing">>},
   {description,<<"Stop tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32779,
  [{name,<<"Set Settings">>},
   {description,<<"Save settings for a given app">>},
   {enabled,true},
   {module,eventing}]},
 {32780,
  [{name,<<"Fetch Config">>},
   {description,<<"Get config for eventing">>},
   {enabled,false},
   {module,eventing}]},
 {32781,
  [{name,<<"Save Config">>},
   {description,<<"Save config for eventing">>},
   {enabled,true},
   {module,eventing}]},
 {32782,
  [{name,<<"Cleanup Eventing">>},
   {description,<<"Clears up app definitions and settings from metakv">>},
   {enabled,true},
   {module,eventing}]},
 {32783,
  [{name,<<"Get Settings">>},
   {description,<<"Get settings for a given app">>},
   {enabled,false},
   {module,eventing}]},
 {32784,
  [{name,<<"Import Functions">>},
   {description,<<"Import a list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32785,
  [{name,<<"Export Functions">>},
   {description,<<"Export the list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32786,
  [{name,<<"List Running">>},
   {description,<<"Eventing running function list was read">>},
   {enabled,false},
   {module,eventing}]},
 {36865,
  [{name,<<"Service configuration change">>},
   {description,<<"A successful service configuration change was made.">>},
   {enabled,true},
   {module,analytics}]},
 {36866,
  [{name,<<"Node configuration change">>},
   {description,<<"A successful node configuration change was made.">>},
   {enabled,true},
   {module,analytics}]}]
[ns_server:debug,2020-05-07T12:21:51.994Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[ns_server:debug,2020-05-07T12:21:51.995Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_reprovision_cfg ->
[{enabled,true},{max_nodes,1},{count,0}]
[ns_server:debug,2020-05-07T12:21:51.995Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2020-05-07T12:21:51.995Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
buckets ->
[[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}],{configs,[]}]
[ns_server:debug,2020-05-07T12:21:51.996Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cbas_memory_quota ->
1024
[ns_server:debug,2020-05-07T12:21:51.997Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cert_and_pkey ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQ"...>>,
  <<"*****">>}]
[ns_server:debug,2020-05-07T12:21:51.998Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
client_cert_auth ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {state,"disable"},
 {prefixes,[]}]
[ns_server:debug,2020-05-07T12:21:51.998Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cluster_compat_version ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},6,0]
[ns_server:debug,2020-05-07T12:21:51.998Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2020-05-07T12:21:51.999Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:trigger_ssl_reload:565]Notify services [capi_ssl_service] about secure_headers_changed change
[ns_server:debug,2020-05-07T12:21:51.999Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:525]Going to notify following services: [capi_ssl_service]
[ns_server:debug,2020-05-07T12:21:51.999Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded,communication_issue]}]
[ns_server:debug,2020-05-07T12:21:51.999Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
fts_memory_quota ->
256
[ns_server:debug,2020-05-07T12:21:51.999Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2020-05-07T12:21:51.999Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
log_redaction_default_cfg ->
[{redact_level,none}]
[ns_server:debug,2020-05-07T12:21:51.999Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
max_bucket_count ->
10
[ns_server:debug,2020-05-07T12:21:51.999Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memcached ->
[]
[ns_server:debug,2020-05-07T12:21:51.999Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memory_quota ->
311
[ns_server:debug,2020-05-07T12:21:51.999Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T12:21:51.999Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
otp ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
 {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
password_policy ->
[{min_length,6},{must_present,[]}]
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
quorum_nodes ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
read_only_user_creds ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
remote_clusters ->
[]
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest ->
[{port,8091}]
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest_creds ->
null
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
roles_definitions ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
scramsha_fallback_salt ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<169,238,80,91,5,165,74,47,79,135,45,74>>]
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
secure_headers ->
[]
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
users_upgrade ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756072601}}]}]
[ns_server:debug,2020-05-07T12:21:52.000Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/eventing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"ram_quota\":256}">>]
[ns_server:debug,2020-05-07T12:21:52.001Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2020-05-07T12:21:52.001Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/query/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]
[ns_server:debug,2020-05-07T12:21:52.001Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{rbac_upgrade,[5,5]} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T12:21:52.001Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2020-05-07T12:21:52.001Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2020-05-07T12:21:52.001Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,fts} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T12:21:52.001Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,index} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T12:21:52.001Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T12:21:52.001Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T12:21:52.001Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8092]
[ns_server:debug,2020-05-07T12:21:52.002Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9110]
[ns_server:debug,2020-05-07T12:21:52.002Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_client_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9113]
[ns_server:debug,2020-05-07T12:21:52.002Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9112]
[ns_server:debug,2020-05-07T12:21:52.002Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9111]
[ns_server:debug,2020-05-07T12:21:52.002Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9115]
[ns_server:debug,2020-05-07T12:21:52.002Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_console_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9114]
[ns_server:debug,2020-05-07T12:21:52.002Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_data_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9116]
[ns_server:debug,2020-05-07T12:21:52.002Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]
[ns_server:debug,2020-05-07T12:21:52.003Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8095]
[ns_server:debug,2020-05-07T12:21:52.003Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_messaging_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9118]
[ns_server:debug,2020-05-07T12:21:52.003Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_callback_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9119]
[ns_server:debug,2020-05-07T12:21:52.003Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9121]
[ns_server:debug,2020-05-07T12:21:52.003Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_parent_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9122]
[ns_server:debug,2020-05-07T12:21:52.003Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_replication_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9120]
[ns_server:debug,2020-05-07T12:21:52.003Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_result_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9117]
[ns_server:debug,2020-05-07T12:21:52.003Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18095]
[ns_server:debug,2020-05-07T12:21:52.003Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2020-05-07T12:21:52.004Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {5,5,3}]
[ns_server:debug,2020-05-07T12:21:52.004Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9140]
[ns_server:debug,2020-05-07T12:21:52.004Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8096]
[ns_server:debug,2020-05-07T12:21:52.004Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18096]
[ns_server:debug,2020-05-07T12:21:52.005Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8094]
[ns_server:debug,2020-05-07T12:21:52.005Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18094]
[ns_server:debug,2020-05-07T12:21:52.005Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9100]
[ns_server:debug,2020-05-07T12:21:52.009Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9102]
[ns_server:debug,2020-05-07T12:21:52.009Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|19102]
[ns_server:debug,2020-05-07T12:21:52.009Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9101]
[ns_server:debug,2020-05-07T12:21:52.009Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9104]
[ns_server:debug,2020-05-07T12:21:52.009Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9103]
[ns_server:debug,2020-05-07T12:21:52.009Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9105]
[ns_server:debug,2020-05-07T12:21:52.009Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:debug,2020-05-07T12:21:52.009Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2020-05-07T12:21:52.009Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:debug,2020-05-07T12:21:52.009Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 active]
[ns_server:debug,2020-05-07T12:21:52.009Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"@ns_server"},
 {other_users,["@cbq-engine","@projector","@goxdcr","@index","@fts",
               "@eventing","@cbas"]},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2020-05-07T12:21:52.009Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},
        {port,port},
        {maxconn,maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {privilege_debug,privilege_debug},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {rbac_file,{"~s",[rbac_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps},
   {tracing_enabled,tracing_enabled},
   {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
   {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
   {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
   {logger,
    {[{filename,{"~s/~s",[log_path,log_prefix]}},
      {cyclesize,log_cyclesize},
      {sleeptime,log_sleeptime}]}}]}]
[ns_server:debug,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {privilege_debug,false},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false},
 {tracing_enabled,true},
 {datatype_snappy,true}]
[ns_server:debug,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9999]
[ns_server:debug,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8093]
[ns_server:debug,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18092]
[ns_server:debug,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18093]
[ns_server:debug,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18091]
[ns_server:debug,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 <<"0f8760945f98b1efdbef0bd1ea6e8446">>]
[ns_server:debug,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9998]
[ns_server:debug,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|false]
[error_logger:info,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.252.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.011Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.245.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:21:52.010Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([alert_limits,audit,audit_decriptors,
                               auto_failover_cfg,auto_reprovision_cfg,
                               autocompaction,buckets,cbas_memory_quota,
                               cert_and_pkey,client_cert_auth,
                               cluster_compat_version,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,
                               index_aware_rebalance_disabled,
                               log_redaction_default_cfg,max_bucket_count,
                               memcached,memory_quota,nodes_wanted,otp,
                               password_policy,quorum_nodes,
                               read_only_user_creds,remote_clusters,
                               replication,rest,rest_creds,roles_definitions,
                               scramsha_fallback_salt,secure_headers,
                               server_groups,set_view_update_daemon,
                               users_upgrade,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>},
                               {metakv,<<"/eventing/settings/config">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {metakv,<<"/query/settings/config">>},
                               {rbac_upgrade,[5,5]},
                               {request_limit,capi},
                               {request_limit,rest},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',cbas_admin_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_client_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_http_port},
                               {node,'ns_1@127.0.0.1',cbas_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_console_port},
                               {node,'ns_1@127.0.0.1',cbas_data_port},
                               {node,'ns_1@127.0.0.1',cbas_debug_port},
                               {node,'ns_1@127.0.0.1',cbas_http_port},
                               {node,'ns_1@127.0.0.1',cbas_messaging_port},
                               {node,'ns_1@127.0.0.1',
                                   cbas_metadata_callback_port},
                               {node,'ns_1@127.0.0.1',cbas_metadata_port},
                               {node,'ns_1@127.0.0.1',cbas_parent_port},
                               {node,'ns_1@127.0.0.1',cbas_replication_port},
                               {node,'ns_1@127.0.0.1',cbas_result_port},
                               {node,'ns_1@127.0.0.1',cbas_ssl_port}]..)
[ns_server:info,2020-05-07T12:21:52.012Z,ns_1@127.0.0.1:<0.267.0>:ns_ssl_services_setup:notify_service:708]Successfully notified service capi_ssl_service
[ns_server:info,2020-05-07T12:21:52.013Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:541]Succesfully notified services [capi_ssl_service]
[ns_server:debug,2020-05-07T12:21:52.018Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.238.0>
[ns_server:debug,2020-05-07T12:21:52.018Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T12:21:52.018Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.238.0>
[error_logger:info,2020-05-07T12:21:52.018Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.274.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:52.040Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: 172: Booted. Waiting for shutdown request

[ns_server:debug,2020-05-07T12:21:52.040Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[ns_server:warn,2020-05-07T12:21:52.043Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T12:21:52.043Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2020-05-07T12:21:52.043Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.276.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.043Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.279.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.043Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.280.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.046Z,ns_1@127.0.0.1:ns_log_events<0.244.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2020-05-07T12:21:52.046Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.282.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.046Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.281.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.046Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.283.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.050Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.284.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.053Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.286.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.053Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.290.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.053Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.285.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.055Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.295.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.058Z,ns_1@127.0.0.1:ns_heart<0.286.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2020-05-07T12:21:52.058Z,ns_1@127.0.0.1:ns_heart<0.286.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]}]}}

[ns_server:debug,2020-05-07T12:21:52.063Z,ns_1@127.0.0.1:<0.293.0>:restartable:start_child:98]Started child process <0.294.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2020-05-07T12:21:52.063Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.297.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.063Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.293.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.063Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.300.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.077Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.301.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.077Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.302.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.077Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.303.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.078Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.304.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.079Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.306.0>},
                       {name,query_settings_manager},
                       {mfargs,{query_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.082Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.308.0>},
                       {name,eventing_settings_manager},
                       {mfargs,{eventing_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.082Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.310.0>},
                       {name,audit_events},
                       {mfargs,{gen_event,start_link,[{local,audit_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.100Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.313.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.100Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.315.0>},
                       {name,scram_sha},
                       {mfargs,{scram_sha,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.110Z,ns_1@127.0.0.1:ns_heart<0.286.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2020-05-07T12:21:52.111Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.316.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.132Z,ns_1@127.0.0.1:ns_heart<0.286.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T12:21:52.138Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.318.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.142Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.319.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.142Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.320.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:52.143Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T12:21:52.144Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T12:21:52.144Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T12:21:52.144Z,ns_1@127.0.0.1:menelaus_sup<0.311.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[error_logger:info,2020-05-07T12:21:52.144Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.322.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.146Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.340.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.147Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.341.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.153Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.342.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.158Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.343.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2020-05-07T12:21:52.158Z,ns_1@127.0.0.1:ns_server_sup<0.231.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "6.0.3-2895-enterprise".
[error_logger:info,2020-05-07T12:21:52.158Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.311.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.159Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.349.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.160Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.353.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.161Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.354.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.31986353>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.161Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.352.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:21:52.163Z,ns_1@127.0.0.1:ns_ports_setup<0.349.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,goxdcr]
[error_logger:info,2020-05-07T12:21:52.171Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.356.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.171Z,ns_1@127.0.0.1:ns_audit_cfg<0.357.0>:ns_audit_cfg:write_audit_json:265]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{descriptors_path,
                                                                                <<"/opt/couchbase/etc/security">>},
                                                                               {version,
                                                                                2},
                                                                               {uuid,
                                                                                <<"18411111">>},
                                                                               {event_states,
                                                                                {[]}},
                                                                               {filtering_enabled,
                                                                                true},
                                                                               {disabled_userids,
                                                                                []},
                                                                               {auditd_enabled,
                                                                                false},
                                                                               {log_path,
                                                                                <<"/opt/couchbase/var/lib/couchbase/logs">>},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []}]
[ns_server:debug,2020-05-07T12:21:52.178Z,ns_1@127.0.0.1:ns_audit_cfg<0.357.0>:ns_audit_cfg:notify_memcached:170]Instruct memcached to reload audit config
[ns_server:warn,2020-05-07T12:21:52.180Z,ns_1@127.0.0.1:<0.360.0>:ns_memcached:connect:1230]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2020-05-07T12:21:52.180Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.357.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.183Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.361.0>},
                       {name,ns_audit},
                       {mfargs,{ns_audit,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.187Z,ns_1@127.0.0.1:memcached_config_mgr<0.362.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2020-05-07T12:21:52.187Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.362.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:52.189Z,ns_1@127.0.0.1:<0.363.0>:ns_memcached_log_rotator:init:42]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2020-05-07T12:21:52.189Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.363.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.190Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.364.0>},
                       {name,testconditions_store},
                       {mfargs,{simple_store,start_link,[testconditions]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.192Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.366.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.193Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.368.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.194Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.367.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.194Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.365.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.209Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.369.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.210Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.373.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.222Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.375.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.232Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.376.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.233Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.233Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.379.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.235Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.381.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:52.258Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: working as port

[ns_server:debug,2020-05-07T12:21:52.265Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.290.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T12:21:52.265Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.290.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T12:21:52.293Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.395.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.293Z,ns_1@127.0.0.1:ns_ports_setup<0.349.0>:ns_ports_setup:set_children:90]Monitor ns_child_ports_sup <12401.74.0>
[ns_server:debug,2020-05-07T12:21:52.297Z,ns_1@127.0.0.1:memcached_config_mgr<0.362.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:info,2020-05-07T12:21:52.298Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.397.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.298Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.400.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.364Z,ns_1@127.0.0.1:memcached_config_mgr<0.362.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[error_logger:info,2020-05-07T12:21:52.374Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.405.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.401Z,ns_1@127.0.0.1:memcached_config_mgr<0.362.0>:memcached_config_mgr:init:79]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[error_logger:info,2020-05-07T12:21:52.405Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.407.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.406Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.407.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T12:21:52.407Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.407.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T12:21:52.413Z,ns_1@127.0.0.1:memcached_config_mgr<0.362.0>:memcached_config_mgr:init:82]activated memcached port server
[error_logger:info,2020-05-07T12:21:52.433Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.411.0>},
                       {name,service_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_stats_children_sup},
                                services_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.434Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.413.0>},
                       {name,service_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [service_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.442Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.414.0>},
                       {name,service_status_keeper_index},
                       {mfargs,{service_index,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.446Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.417.0>},
                       {name,service_status_keeper_fts},
                       {mfargs,{service_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.447Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.420.0>},
                       {name,service_status_keeper_eventing},
                       {mfargs,{service_eventing,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.447Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.412.0>},
                       {name,service_status_keeper_sup},
                       {mfargs,{service_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.447Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.423.0>},
                       {name,service_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<services_stats_sup.0.41280346>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.447Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.410.0>},
                       {name,services_stats_sup},
                       {mfargs,{services_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.452Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.425.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.463Z,ns_1@127.0.0.1:<0.428.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.428.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2020-05-07T12:21:52.472Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:21:52.472Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[error_logger:info,2020-05-07T12:21:52.472Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.426.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.472Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:21:52.472Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T12:21:52.472Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T12:21:52.473Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2020-05-07T12:21:52.473Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.430.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.473Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.429.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.475Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.431.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.484Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.435.0>},
                       {name,leader_activities},
                       {mfargs,{leader_activities,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T12:21:52.493Z,ns_1@127.0.0.1:leader_lease_agent<0.436.0>:leader_lease_agent:maybe_recover_persisted_lease:397]Found persisted lease [{node,'ns_1@127.0.0.1'},
                       {uuid,<<"8383a6f8218c46cdb84a637963c66dd3">>},
                       {time_left,15000},
                       {status,active}]
[error_logger:info,2020-05-07T12:21:52.494Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.436.0>},
                       {name,leader_lease_agent},
                       {mfargs,{leader_lease_agent,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.494Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.434.0>},
                       {name,leader_leases_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_leases_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.494Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.438.0>},
                       {name,leader_events},
                       {mfargs,{gen_event,start_link,[{local,leader_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.503Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.439.0>},
                       {name,leader_registry_server},
                       {mfargs,{leader_registry_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.505Z,ns_1@127.0.0.1:leader_registry_sup<0.437.0>:mb_master:check_master_takeover_needed:270]Sending master node question to the following nodes: []
[ns_server:debug,2020-05-07T12:21:52.505Z,ns_1@127.0.0.1:leader_registry_sup<0.437.0>:mb_master:check_master_takeover_needed:272]Got replies: []
[ns_server:debug,2020-05-07T12:21:52.505Z,ns_1@127.0.0.1:leader_registry_sup<0.437.0>:mb_master:check_master_takeover_needed:278]Was unable to discover master, not going to force mastership takeover
[user:info,2020-05-07T12:21:52.505Z,ns_1@127.0.0.1:mb_master<0.442.0>:mb_master:init:90]I'm the only node, so I'm the master.
[ns_server:debug,2020-05-07T12:21:52.506Z,ns_1@127.0.0.1:leader_registry<0.439.0>:leader_registry_server:handle_new_leader:241]New leader is 'ns_1@127.0.0.1'. Invalidating name cache.
[error_logger:info,2020-05-07T12:21:52.510Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.445.0>},
                       {name,leader_lease_acquirer},
                       {mfargs,{leader_lease_acquirer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.512Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.447.0>:leader_quorum_nodes_manager:pull_config:114]Attempting to pull config from nodes:
[]
[error_logger:info,2020-05-07T12:21:52.512Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.447.0>},
                       {name,leader_quorum_nodes_manager},
                       {mfargs,{leader_quorum_nodes_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T12:21:52.512Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.447.0>:leader_quorum_nodes_manager:pull_config:119]Pulled config successfully.
[ns_server:warn,2020-05-07T12:21:52.519Z,ns_1@127.0.0.1:<0.453.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"8383a6f8218c46cdb84a637963c66dd3">>} (valid for 14974ms)
[ns_server:info,2020-05-07T12:21:52.536Z,ns_1@127.0.0.1:mb_master_sup<0.444.0>:misc:start_singleton:758]start_singleton(gen_server, ns_tick, [], []): started as <0.456.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T12:21:52.536Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.456.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.545Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.460.0>},
                       {name,ns_janitor_server},
                       {mfargs,{ns_janitor_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:52.565Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.458.0>:misc:start_singleton:758]start_singleton(gen_server, auto_reprovision, [], []): started as <0.461.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T12:21:52.565Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.461.0>},
                       {name,auto_reprovision},
                       {mfargs,{auto_reprovision,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T12:21:52.565Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.458.0>:misc:start_singleton:758]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.462.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T12:21:52.566Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.462.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.566Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.458.0>},
                       {name,ns_orchestrator_child_sup},
                       {mfargs,{ns_orchestrator_child_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:21:52.570Z,ns_1@127.0.0.1:<0.464.0>:auto_failover:init:211]init auto_failover.
[user:info,2020-05-07T12:21:52.570Z,ns_1@127.0.0.1:<0.464.0>:auto_failover:handle_call:242]Enabled auto-failover with timeout 120 and max count 1
[ns_server:info,2020-05-07T12:21:52.585Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.457.0>:misc:start_singleton:758]start_singleton(gen_server, auto_failover, [], []): started as <0.464.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T12:21:52.585Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.464.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.585Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.457.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:21:52.585Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([auto_failover_cfg,
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>}]..)
[ns_server:debug,2020-05-07T12:21:52.586Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{9,63756073312}}]}]
[ns_server:debug,2020-05-07T12:21:52.586Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[error_logger:info,2020-05-07T12:21:52.586Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.442.0>},
                       {name,mb_master},
                       {mfargs,{mb_master,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.586Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.437.0>},
                       {name,leader_registry_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_registry_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:21:52.586Z,ns_1@127.0.0.1:<0.432.0>:restartable:start_child:98]Started child process <0.433.0>
  MFA: {leader_services_sup,start_link,[]}
[error_logger:info,2020-05-07T12:21:52.586Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.432.0>},
                       {name,leader_services_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{leader_services_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.586Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.472.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.586Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.473.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.597Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.474.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.607Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.475.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.614Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.478.0>},
                       {name,ns_server_monitor},
                       {mfargs,{ns_server_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.614Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.480.0>},
                       {name,service_monitor_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_monitor_children_sup},
                                health_monitor_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.615Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.481.0>},
                       {name,service_monitor_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<health_monitor_sup.0.81875396>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.617Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.489.0>},
                       {name,node_monitor},
                       {mfargs,{node_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.619Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.497.0>},
                       {name,node_status_analyzer},
                       {mfargs,{node_status_analyzer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T12:21:52.619Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.477.0>},
                       {name,health_monitor_sup},
                       {mfargs,{health_monitor_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:21:52.619Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[error_logger:info,2020-05-07T12:21:52.620Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.231.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T12:21:52.620Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.169.0>
[ns_server:debug,2020-05-07T12:21:52.620Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2020-05-07T12:21:52.620Z,ns_1@127.0.0.1:<0.168.0>:restartable:start_child:98]Started child process <0.169.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[error_logger:info,2020-05-07T12:21:52.620Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.168.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T12:21:52.620Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:debug,2020-05-07T12:21:52.620Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:130]138: Entered child_loop
[ns_server:debug,2020-05-07T12:21:52.624Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@",admin}
[ns_server:debug,2020-05-07T12:21:52.645Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.500.0>:json_rpc_connection:init:73]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.500.0>
[ns_server:debug,2020-05-07T12:21:52.646Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.501.0>:json_rpc_connection:init:73]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.501.0>
[ns_server:debug,2020-05-07T12:21:52.646Z,ns_1@127.0.0.1:menelaus_cbauth<0.343.0>:menelaus_cbauth:handle_cast:102]Observed json rpc process {"goxdcr-cbauth",<0.501.0>} started
[ns_server:debug,2020-05-07T12:21:52.662Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@goxdcr-cbauth",admin}
[ns_server:debug,2020-05-07T12:21:52.969Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:89]Refresh of [rbac,isasl] succeeded
[ns_server:info,2020-05-07T13:47:54.914Z,nonode@nohost:<0.89.0>:ns_server:init_logging:150]Started & configured logging
[ns_server:info,2020-05-07T13:47:54.932Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_access,info},
 {disk_sink_opts,[{rotation,[{compress,true},
                             {size,41943040},
                             {num_files,10},
                             {buffer_size_max,52428800}]}]},
 {disk_sink_opts_json_rpc,[{rotation,[{compress,true},
                                      {size,41943040},
                                      {num_files,2},
                                      {buffer_size_max,52428800}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_json_rpc, which is given from command line
[ns_server:warn,2020-05-07T13:47:54.933Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2020-05-07T13:47:54.969Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.138.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:54.978Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,76}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-378cfab] [64-bit] [smp:2:2] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2020,5,7},{13,47,54}}},
               {memory,
                   [{total,110430048},
                    {processes,9556248},
                    {processes_used,9554624},
                    {system,100873800},
                    {atom,339441},
                    {atom_used,322610},
                    {binary,78464},
                    {code,7796739},
                    {ets,2241528}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,path_config,calendar,
                    ale_default_formatter,'ale_logger-metakv',
                    'ale_logger-rebalance','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-json_rpc',
                    'ale_logger-access','ale_logger-ns_server',
                    'ale_logger-user','ale_logger-ns_doctor',io_lib_fread,
                    'ale_logger-cluster','ale_logger-xdcr',otp_internal,
                    ns_log_sink,ale_disk_sink,misc,couch_util,ns_server,
                    filelib,cpu_sup,memsup,disksup,os_mon,io,release_handler,
                    overload,alarm_handler,sasl,timer,tftp_sup,httpd_sup,
                    httpc_handler_sup,httpc_cookie,inets_trace,httpc_manager,
                    httpc,httpc_profile_sup,httpc_sup,ftp_sup,inets_sup,
                    inets_app,ssl,lhttpc_manager,lhttpc_sup,lhttpc,
                    tls_connection_sup,ssl_session_cache,ssl_pkix_db,
                    ssl_manager,ssl_sup,ssl_app,crypto_server,crypto_sup,
                    crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_io,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","6.0.3-2895-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","6.0.3-2895-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,105},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [lhttpc_sup,code_server,ale_stats_events,'sink-ns_log',
                    ns_server_cluster_sup,lhttpc_manager,
                    application_controller,ale,httpd_sup,release_handler,
                    kernel_safe_sup,standard_error,ale_sup,overload,
                    'sink-disk_json_rpc',error_logger,alarm_handler,
                    'sink-disk_metakv',ale_dynamic_sup,timer_server,
                    'sink-disk_access_int',standard_error_sup,
                    'sink-disk_access','sink-disk_reports',crypto_server,
                    crypto_sup,sasl_safe_sup,'sink-disk_stats',
                    'sink-disk_xdcr',tftp_sup,inet_db,init,os_mon_sup,
                    'sink-disk_debug',rex,tls_connection_sup,user,
                    'sink-disk_error',ssl_sup,kernel_sup,cpu_sup,
                    global_name_server,memsup,'sink-disk_default',disksup,
                    httpc_sup,file_server_2,ssl_manager,local_tasks,
                    global_group,httpc_profile_sup,httpc_manager,
                    httpc_handler_sup,ftp_sup,sasl_sup,erl_prim_loader,
                    inets_sup]},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,1}]
[ns_server:info,2020-05-07T13:47:54.983Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:27]Manifest:
["<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\" />",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\" />",
 "  ","  <default remote=\"couchbase\" revision=\"master\" />","  ",
 "  <project groups=\"kv\" name=\"HdrHistogram_c\" path=\"third_party/HdrHistogram_c\" remote=\"couchbasedeps\" revision=\"d200fc0f68695d4aef1fad5c3c8cc55f8c033014\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"analytics-dcp-client\" path=\"analytics/java-dcp-client\" revision=\"d6ba66b51c0e589e9d4571264afcb0e33d507aea\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"asterixdb\" path=\"analytics/asterixdb\" revision=\"e8e59d0e6e72ba3fd96074c021ff7180261dcd59\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"c5b9dd8ec0910d2890d215075a7d2da1d6a494c9\" />",
 "  <project groups=\"kv\" name=\"benchmark\" remote=\"couchbasedeps\" revision=\"9e3465560240ffb242b50a47cb7f19251a12ee42\" />",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\" />",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5cd1345cca3ed72f1e63d41d622fcda73e63fea8\" />",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"822d01dab8721cf469beb6d8304c9eadd9c58160\" />",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"f551b6d4f32bb920a83dd28c705bddd5de0d03b2\" />",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"4b158bb555a3297565afecf6fae675c74f1e47df\" />",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\" />",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\" />",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"dc55cf8e9613ddf1bd6db4a662d1ecc3668223da\">",
 "    <annotation name=\"RELEASE\" value=\"alice\" />",
 "    <annotation name=\"PRODUCT\" value=\"couchbase-server\" />",
 "    <annotation name=\"BLD_NUM\" value=\"2895\" />",
 "    <annotation name=\"VERSION\" value=\"6.0.3\" />","  </project>",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas\" path=\"goproj/src/github.com/couchbaselabs/cbas\" remote=\"couchbase-priv\" revision=\"73fa77cd9133a9f779a484ac2caffb0b46a1dd82\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas-core\" path=\"analytics\" remote=\"couchbase-priv\" revision=\"7e513c6bd60a030c3a2477af683b264d61932a75\" />",
 "  <project groups=\"analytics\" name=\"cbas-ui\" revision=\"d8f601c3109887a30deccab09b2177bf499c8711\" />",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"0df84c7e3c6d95ff435c12a3c08c6f064db11e97\" />",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"80d2ad8892d806f5103f602fec0d80adaa4b628f\" />",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"8d4105a904e0282a6928de7392e266c58ea3c7a2\" />",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"0a94f40b9080e0ecb11d3b7531a58c5e6a4a4465\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"93d26dbc120c4f9874abb65aafa4d815334273c6\" />",
 "  <project name=\"cbsummary\" path=\"goproj/src/github.com/couchbase/cbsummary\" revision=\"dbfa1c0d73f0e49f6f04e390f03de8f9a6cee769\" />",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"dcae66272b24600ae0005fa06b511cfae8914d3d\" />",
 "  <project name=\"cobra\" path=\"godeps/src/github.com/spf13/cobra\" remote=\"couchbasedeps\" revision=\"0f056af21f5f368e5b0646079d0094a2c64150f7\" />",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\" />",
 "  <project groups=\"notdefault,kv_ee,enterprise\" name=\"couch_rocks\" remote=\"couchbase-priv\" revision=\"75f37fa46bfe5e445dee077157303968a3e09126\" />",
 "  <project name=\"couchbase-cli\" revision=\"9b383603860ce58885c27015c92635a7b42d3a1f\" />",
 "  <project name=\"couchdb\" revision=\"c2b98200b800f9fbed927c47074884b9f5f53eb4\" />",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"69aa5d92e195a30e06184911d72b8fffcf2534fe\" />",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"c2c458ff2cf93ee63bf4b0386f495b22535daf96\" />",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\" />",
 "  <project name=\"cuckoofilter\" path=\"godeps/src/github.com/seiflotfy/cuckoofilter\" remote=\"couchbasedeps\" revision=\"d04838794ab86926d32b124345777e55e6f43974\" />",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\" />",
 "  <project name=\"docloader\" path=\"goproj/src/github.com/couchbase/docloader\" revision=\"05067021a042a1b63e100a486afd7ebddab4c535\" />",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\" />",
 "  <project name=\"errors\" path=\"godeps/src/github.com/pkg/errors\" remote=\"couchbasedeps\" revision=\"30136e27e2ac8d167177e8a583aa4c3fea5be833\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"eventing\" path=\"goproj/src/github.com/couchbase/eventing\" revision=\"1da67e30a4c8faaf24f067eae280f5764d943dc2\" upstream=\"alice\" />",
 "  <project name=\"flatbuffers\" path=\"godeps/src/github.com/google/flatbuffers\" remote=\"couchbasedeps\" revision=\"1a8968225130caeddd16e227678e6f8af1926303\" />",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"c338e06e6847140f749058184d66de1f2a43474a\" />",
 "  <project name=\"fwd\" path=\"godeps/src/github.com/philhofer/fwd\" remote=\"couchbasedeps\" revision=\"bb6d471dc95d4fe11e432687f8b70ff496cf3136\" />",
 "  <project name=\"geocouch\" revision=\"2a0e73f43451045f157640eec59ced72da18471f\" />",
 "  <project name=\"ghistogram\" path=\"godeps/src/github.com/couchbase/ghistogram\" revision=\"d910dd063dd68fb4d2a1ba344440f834ebb4ef62\" />",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\" />",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"5c0ac9ef0ba7a0356279cee7eadd8874c4a8f8c1\" />",
 "  <project name=\"go-curl\" path=\"godeps/src/github.com/andelf/go-curl\" remote=\"couchbasedeps\" revision=\"f0b2afc926ec79be5d7f30393b3485352781a705\" />",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\" />",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\" />",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\" />",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\" />",
 "  <project name=\"go-sqlite3\" path=\"godeps/src/github.com/mattn/go-sqlite3\" remote=\"couchbasedeps\" revision=\"47fc4e5e9153645da45af6a86a5bce95e63a0f9e\" />",
 "  <project name=\"go-unsnap-stream\" path=\"godeps/src/github.com/glycerine/go-unsnap-stream\" remote=\"couchbasedeps\" revision=\"62a9a9eb44fd8932157b1a8ace2149eff5971af6\" />",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\" />",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"d2f15a425a9c8e4d8447e5f5b89ce14845f7fa05\" />",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\" />",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"699b13a51af5dd4f80ff3deedf41bba60debad32\" />",
 "  <project name=\"gocbconnstr\" path=\"godeps/src/gopkg.in/couchbaselabs/gocbconnstr.v1\" remote=\"couchbaselabs\" revision=\"710456e087a6d497e87f41d0a9d98d6a75672186\" />",
 "  <project name=\"gocbcore\" path=\"godeps/src/gopkg.in/couchbase/gocbcore.v7\" revision=\"a0d26c2d6f5de912499d35a5aba573006e5e036f\" />",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"aecdbe5a5a91f0688df7bdf260ca962178c06828\" />",
 "  <project name=\"gofarmhash\" path=\"godeps/src/github.com/leemcloughlin/gofarmhash\" remote=\"couchbasedeps\" revision=\"0a055c5b87a8c55ce83459cbf2776b563822a942\" />",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\" />",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\" />",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\" />",
 "  <project name=\"golang-tools\" path=\"godeps/src/golang.org/x/tools\" remote=\"couchbasedeps\" revision=\"a28dfb48e06b2296b66678872c2cb638f0304f20\" />",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\" />",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"e05ec3550789be1da2981787ef6444fef75e10bc\" />",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"4809dd3aa2ab88013b1dfce15516d717a35cb6e8\" />",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\" />",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\" />",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\" />",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"f98adca8eb365032cab838ef4d99453931afa112\" />",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"122ae25ed207cca30ceaee9ac66342a603d43a31\" />",
 "  <project groups=\"kv\" name=\"gsl-lite\" path=\"third_party/gsl-lite\" remote=\"couchbasedeps\" revision=\"57542c7e7ced375346e9ac55dad85b942cfad556\" />",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\" />",
 "  <project name=\"httprouter\" path=\"godeps/src/github.com/julienschmidt/httprouter\" remote=\"couchbasedeps\" revision=\"975b5c4c7c21c0e3d2764200bf2aa8e34657ae6e\" />",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"95ed84aad6bf8ecd99da2372dceede6d93f3d43a\" />",
 "  <project name=\"json-iterator-go\" path=\"godeps/src/github.com/json-iterator/go\" remote=\"couchbasedeps\" revision=\"f7279a603edee96fe7764d3de9c6ff8cf9970994\" />",
 "  <project name=\"jsonx\" path=\"godeps/src/gopkg.in/couchbaselabs/jsonx.v1\" remote=\"couchbaselabs\" revision=\"5b7baa20429a46a5543ee259664cc86502738cad\" />",
 "  <project groups=\"kv\" name=\"kv_engine\" revision=\"a30fd9d57cc2101078c8cd2c44968458df965c2b\" />",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"libcouchbase\" revision=\"081e8b16b991bf706eb77f8243935c6fba31b895\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"3681c2a912330352991ecdd642f257efe5b85518\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\" />",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\" />",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\" />",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"956632ec1bc3e28276d00ee2f22c3202f06efb12\" />",
 "  <project name=\"mossScope\" path=\"godeps/src/github.com/couchbase/mossScope\" revision=\"abd3b58b422dbc2e9463a589d0f3d93441726e23\" />",
 "  <project name=\"mousetrap\" path=\"godeps/src/github.com/inconshreveable/mousetrap\" remote=\"couchbasedeps\" revision=\"76626ae9c91c4f2a10f34cad8ce83ea42c93bb75\" />",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"cd8da46b9b953800d430c8b0aa4667790727ed6f\" />",
 "  <project name=\"msgp\" path=\"godeps/src/github.com/tinylib/msgp\" remote=\"couchbasedeps\" revision=\"5bb5e1aed7ba5bcc93307153b020e7ffe79b0509\" />",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"043ee6597c29786140136a5747b6a886364f5282\" />",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"62685c2d7ca23c807425dca88b11a3e2323dab41\" />",
 "  <project name=\"nitro\" path=\"goproj/src/github.com/couchbase/nitro\" revision=\"f3bef3551997be504612a2d05a8b324b3bfdfe1b\" />",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\" />",
 "  <project name=\"ns_server\" revision=\"8117c5307974f397ad831a2b870fb3ee0fd8364d\" />",
 "  <project name=\"opentracing-go\" path=\"godeps/src/github.com/opentracing/opentracing-go\" remote=\"couchbasedeps\" revision=\"1949ddbfd147afd4d964a9f00b24eb291e0e7c38\" />",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\" />",
 "  <project name=\"pflag\" path=\"godeps/src/github.com/spf13/pflag\" remote=\"couchbasedeps\" revision=\"a232f6d9f87afaaa08bafaff5da685f974b83313\" />",
 "  <project groups=\"kv\" name=\"phosphor\" revision=\"96501c57bb0fd61c85cba6f63101aed2bcf41d38\" />",
 "  <project name=\"pierrec-lz4\" path=\"godeps/src/github.com/pierrec/lz4\" remote=\"couchbasedeps\" revision=\"ed8d4cc3b461464e69798080a0092bd028910298\" />",
 "  <project name=\"pierrec-xxHash\" path=\"godeps/src/github.com/pierrec/xxHash\" remote=\"couchbasedeps\" revision=\"a0006b13c722f7f12368c00a3d3c2ae8a999a0c6\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"plasma\" path=\"goproj/src/github.com/couchbase/plasma\" remote=\"couchbase-priv\" revision=\"c0792c8cfb1463ef029f064f34e366442f1f0064\" />",
 "  <project groups=\"kv\" name=\"platform\" revision=\"de77d527bd23012dc67794c81a7b1e76e46e3abd\" />",
 "  <project groups=\"kv\" name=\"product-texts\" revision=\"8cf7d25a1dcb5434ea44983c0bed202fb9cc8351\" />",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\" />",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"d2011f6ee9f6e1dca5d3922d44fbcf86dad78150\" />",
 "  <project name=\"query-ui\" revision=\"15a6461f437fe810e411a6613ec7c143991cd1c6\" />",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\" />",
 "  <project name=\"roaring\" path=\"godeps/src/github.com/RoaringBitmap/roaring\" remote=\"couchbasedeps\" revision=\"fe09428be4c233d726797a1380f7438f4f71a31a\" />",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"762005e7a34fd909a84586299f1dd457371d36ee\" />",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"73353fe6dad8f3d67409feefb9b17f90f6de917b\" />",
 "  <project name=\"snowballstem\" path=\"godeps/src/github.com/blevesearch/snowballstem\" remote=\"blevesearch\" revision=\"26b06a2c243d4f8ca5db3486f94409dd5b2a7467\" />",
 "  <project groups=\"kv\" name=\"spdlog\" path=\"third_party/spdlog\" remote=\"couchbasedeps\" revision=\"4fba14c79f356ae48d6141c561bf9fd7ba33fabd\" />",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\" />",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"c30c3d4c250e68e81c57aa1e8ae91ffd21243cdb\" />",
 "  <project name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\" />",
 "  <project name=\"testrunner\" revision=\"4133fd785987f1ddcdb49dab736ff6e5e67d7c95\" upstream=\"alice\" />",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\" />",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"6dadf98e19803cc10ce9552bf4d9121cc2528965\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\" />",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\" />",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\" />",
 "    <copyfile dest=\".clang-format\" src=\"dot-clang-format\" />",
 "    <copyfile dest=\"third_party/CMakeLists.txt\" src=\"third-party-CMakeLists.txt\" />",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\" />",
 "  <project name=\"uuid\" path=\"godeps/src/github.com/google/uuid\" remote=\"couchbasedeps\" revision=\"dec09d789f3dba190787f8b4454c7d3c936fed9e\" />",
 "  <project name=\"vellum\" path=\"godeps/src/github.com/couchbase/vellum\" revision=\"0ceea4a37442f76199b9259840baf48d17af3c1a\" />",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"b3d83fe61db37bb38a46cd8dee434e5682cba2c7\" />",
 "  <project name=\"zstd\" path=\"godeps/src/github.com/DataDog/zstd\" remote=\"couchbasedeps\" revision=\"aebefd9fcb99f22cd691ef778a12ed68f0e6a1ab\" />",
 "</manifest>"]

[error_logger:info,2020-05-07T13:47:55.014Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.139.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:55.016Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2020-05-07T13:47:55.017Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2020-05-07T13:47:55.018Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:init:243]ip config not found. Looks like we're brand new node
[error_logger:info,2020-05-07T13:47:55.018Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.143.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2020-05-07T13:47:55.019Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.142.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:55.159Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:bringup:295]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2020-05-07T13:47:55.166Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.145.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.166Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.146.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:55.167Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:configure_net_kernel:339]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2020-05-07T13:47:55.167Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.147.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.167Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.144.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2020-05-07T13:47:55.169Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:save_node:227]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2020-05-07T13:47:55.180Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:bringup:309]Attempted to save node name to disk: ok
[ns_server:debug,2020-05-07T13:47:55.180Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:316]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2020-05-07T13:47:55.180Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T13:47:55.189Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:328]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2020-05-07T13:47:55.189Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.194Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.194Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:55.196Z,ns_1@127.0.0.1:ns_config_sup<0.154.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2020-05-07T13:47:55.196Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.155.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.197Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.156.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:55.241Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1095]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2020-05-07T13:47:55.242Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1109]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:debug,2020-05-07T13:47:55.255Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1117]Here's full dynamic config we loaded:
[[{auto_failover_cfg,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {enabled,true},
    {timeout,120},
    {count,0},
    {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
    {failover_server_group,false},
    {max_count,1},
    {failed_over_server_groups,[]}]},
  {alert_limits,
   [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
  {audit,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {enabled,[]},
    {disabled_users,[]},
    {auditd_enabled,false},
    {rotate_interval,86400},
    {rotate_size,20971520},
    {disabled,[]},
    {sync,[]},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
  {audit_decriptors,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {20480,
     [{name,<<"opened DCP connection">>},
      {description,<<"opened DCP connection">>},
      {enabled,true},
      {module,memcached}]},
    {20482,
     [{name,<<"external memcached bucket flush">>},
      {description,
       <<"External user flushed the content of a memcached bucket">>},
      {enabled,true},
      {module,memcached}]},
    {20483,
     [{name,<<"invalid packet">>},
      {description,<<"Rejected an invalid packet">>},
      {enabled,true},
      {module,memcached}]},
    {20485,
     [{name,<<"authentication succeeded">>},
      {description,<<"Authentication to the cluster succeeded">>},
      {enabled,false},
      {module,memcached}]},
    {20488,
     [{name,<<"document read">>},
      {description,<<"Document was read">>},
      {enabled,false},
      {module,memcached}]},
    {20489,
     [{name,<<"document locked">>},
      {description,<<"Document was locked">>},
      {enabled,false},
      {module,memcached}]},
    {20490,
     [{name,<<"document modify">>},
      {description,<<"Document was modified">>},
      {enabled,false},
      {module,memcached}]},
    {20491,
     [{name,<<"document delete">>},
      {description,<<"Document was deleted">>},
      {enabled,false},
      {module,memcached}]},
    {20492,
     [{name,<<"select bucket">>},
      {description,<<"The specified bucket was selected">>},
      {enabled,true},
      {module,memcached}]},
    {28672,
     [{name,<<"SELECT statement">>},
      {description,<<"A N1QL SELECT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28673,
     [{name,<<"EXPLAIN statement">>},
      {description,<<"A N1QL EXPLAIN statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28674,
     [{name,<<"PREPARE statement">>},
      {description,<<"A N1QL PREPARE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28675,
     [{name,<<"INFER statement">>},
      {description,<<"A N1QL INFER statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28676,
     [{name,<<"INSERT statement">>},
      {description,<<"A N1QL INSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28677,
     [{name,<<"UPSERT statement">>},
      {description,<<"A N1QL UPSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28678,
     [{name,<<"DELETE statement">>},
      {description,<<"A N1QL DELETE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28679,
     [{name,<<"UPDATE statement">>},
      {description,<<"A N1QL UPDATE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28680,
     [{name,<<"MERGE statement">>},
      {description,<<"A N1QL MERGE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28681,
     [{name,<<"CREATE INDEX statement">>},
      {description,<<"A N1QL CREATE INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28682,
     [{name,<<"DROP INDEX statement">>},
      {description,<<"A N1QL DROP INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28683,
     [{name,<<"ALTER INDEX statement">>},
      {description,<<"A N1QL ALTER INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28684,
     [{name,<<"BUILD INDEX statement">>},
      {description,<<"A N1QL BUILD INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28685,
     [{name,<<"GRANT ROLE statement">>},
      {description,<<"A N1QL GRANT ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28686,
     [{name,<<"REVOKE ROLE statement">>},
      {description,<<"A N1QL REVOKE ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28687,
     [{name,<<"UNRECOGNIZED statement">>},
      {description,
       <<"An unrecognized statement was received by the N1QL query engine">>},
      {enabled,false},
      {module,n1ql}]},
    {28688,
     [{name,<<"CREATE PRIMARY INDEX statement">>},
      {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28689,
     [{name,<<"/admin/stats API request">>},
      {description,<<"An HTTP request was made to the API at /admin/stats.">>},
      {enabled,false},
      {module,n1ql}]},
    {28690,
     [{name,<<"/admin/vitals API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/vitals.">>},
      {enabled,false},
      {module,n1ql}]},
    {28691,
     [{name,<<"/admin/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28692,
     [{name,<<"/admin/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28693,
     [{name,<<"/admin/indexes/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28694,
     [{name,<<"/admin/indexes/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28695,
     [{name,<<"/admin/indexes/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28697,
     [{name,<<"/admin/ping API request">>},
      {description,<<"An HTTP request was made to the API at /admin/ping.">>},
      {enabled,false},
      {module,n1ql}]},
    {28698,
     [{name,<<"/admin/config API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/config.">>},
      {enabled,false},
      {module,n1ql}]},
    {28699,
     [{name,<<"/admin/ssl_cert API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
      {enabled,false},
      {module,n1ql}]},
    {28700,
     [{name,<<"/admin/settings API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/settings.">>},
      {enabled,false},
      {module,n1ql}]},
    {28701,
     [{name,<<"/admin/clusters API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/clusters.">>},
      {enabled,false},
      {module,n1ql}]},
    {28702,
     [{name,<<"/admin/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {32768,
     [{name,<<"Create Function">>},
      {description,<<"Eventing function definition was created or updated">>},
      {enabled,true},
      {module,eventing}]},
    {32769,
     [{name,<<"Delete Function">>},
      {description,<<"Eventing function definition was deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32770,
     [{name,<<"Fetch Functions">>},
      {description,<<"Eventing function definition was read">>},
      {enabled,false},
      {module,eventing}]},
    {32771,
     [{name,<<"List Deployed">>},
      {description,<<"Eventing deployed functions list was read">>},
      {enabled,false},
      {module,eventing}]},
    {32772,
     [{name,<<"Fetch Drafts">>},
      {description,<<"Eventing function draft definitions were read">>},
      {enabled,false},
      {module,eventing}]},
    {32773,
     [{name,<<"Delete Drafts">>},
      {description,<<"Eventing function draft definitions were deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32774,
     [{name,<<"Save Draft">>},
      {description,<<"Save a draft definition to the store">>},
      {enabled,true},
      {module,eventing}]},
    {32775,
     [{name,<<"Start Debug">>},
      {description,<<"Start eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32776,
     [{name,<<"Stop Debug">>},
      {description,<<"Stop eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32777,
     [{name,<<"Start Tracing">>},
      {description,<<"Start tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32778,
     [{name,<<"Stop Tracing">>},
      {description,<<"Stop tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32779,
     [{name,<<"Set Settings">>},
      {description,<<"Save settings for a given app">>},
      {enabled,true},
      {module,eventing}]},
    {32780,
     [{name,<<"Fetch Config">>},
      {description,<<"Get config for eventing">>},
      {enabled,false},
      {module,eventing}]},
    {32781,
     [{name,<<"Save Config">>},
      {description,<<"Save config for eventing">>},
      {enabled,true},
      {module,eventing}]},
    {32782,
     [{name,<<"Cleanup Eventing">>},
      {description,<<"Clears up app definitions and settings from metakv">>},
      {enabled,true},
      {module,eventing}]},
    {32783,
     [{name,<<"Get Settings">>},
      {description,<<"Get settings for a given app">>},
      {enabled,false},
      {module,eventing}]},
    {32784,
     [{name,<<"Import Functions">>},
      {description,<<"Import a list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32785,
     [{name,<<"Export Functions">>},
      {description,<<"Export the list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32786,
     [{name,<<"List Running">>},
      {description,<<"Eventing running function list was read">>},
      {enabled,false},
      {module,eventing}]},
    {36865,
     [{name,<<"Service configuration change">>},
      {description,<<"A successful service configuration change was made.">>},
      {enabled,true},
      {module,analytics}]},
    {36866,
     [{name,<<"Node configuration change">>},
      {description,<<"A successful node configuration change was made.">>},
      {enabled,true},
      {module,analytics}]}]},
  {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
  {autocompaction,
   [{database_fragmentation_threshold,{30,undefined}},
    {view_fragmentation_threshold,{30,undefined}}]},
  {buckets,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]},
    {configs,[]}]},
  {cbas_memory_quota,1024},
  {cert_and_pkey,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQlsomKQ7qhDcAeKZ3inWuCQuv8NxCAMb8M\nXhrVTrshZyFDiXdKS3Xbshyc9dEOiDwuDwAEgfwJQsXzzx0eCRtyTZfWAWTOH06O\nXdQps+9iTfr2KBFj27uag5c5ns+0ojsNyqZhA4+dbS7zK3CZ1dx7LPkL3+4HTlMh\nmH1/2fib3Lbp6dW3B55GV8/RHbkzgcRMyBicYtinqh6JMmmzjO/3KEyVHs3h0W1E\n00JdAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCKWU+bCvjKUlhW\niMiAN7r/3Vxkah7KEqp8BajCnLrlTMeiV+24TlPrsCWz4VBmOgt8OcijS3axdEik\nXeteeJp+R8nb2XPGivHOg/Hx2NlLxCrtXaYVGM0PiVydo24iCv0ZlqMCBsrzRLky\n5otbfQi8ngdfuR88C0/r3RLqvuFnOtFkLbKXuT/qshXfM8O/OgiJkr6CTBFYNd8w\nTCxN2syK41/HXoYzexdA/OTSm+kuEIuDpQYxKS0M4oKKZApJM70y/CYTzwG3JOnp\nuteZPYrwhIqxz01fkbLnj3QLGxPpSexRsp52GOoCv/YEE7tl3Olt4+p+MvhEZPdZ\ndqB53mNJ\n-----END CERTIFICATE-----\n">>,
     <<"*****">>}]},
  {client_cert_auth,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {state,"disable"},
    {prefixes,[]}]},
  {cluster_compat_version,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},
    6,0]},
  {drop_request_memory_threshold_mib,undefined},
  {email_alerts,
   [{recipients,["root@localhost"]},
    {sender,"couchbase@localhost"},
    {enabled,false},
    {email_server,
     [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
    {alerts,
     [auto_failover_node,auto_failover_maximum_reached,
      auto_failover_other_nodes_down,auto_failover_cluster_too_small,
      auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
      ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
      ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
  {fts_memory_quota,256},
  {index_aware_rebalance_disabled,false},
  {log_redaction_default_cfg,[{redact_level,none}]},
  {max_bucket_count,10},
  {memcached,[]},
  {memory_quota,311},
  {nodes_wanted,['ns_1@127.0.0.1']},
  {otp,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
    {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]},
  {password_policy,[{min_length,6},{must_present,[]}]},
  {quorum_nodes,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    'ns_1@127.0.0.1']},
  {read_only_user_creds,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {remote_clusters,[]},
  {replication,[{enabled,true}]},
  {rest,[{port,8091}]},
  {rest_creds,null},
  {roles_definitions,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {scramsha_fallback_salt,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<169,238,80,91,5,165,74,47,79,135,45,74>>]},
  {secure_headers,[]},
  {server_groups,
   [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
  {set_view_update_daemon,
   [{update_interval,5000},
    {update_min_changes,5000},
    {replica_update_min_changes,5000}]},
  {users_upgrade,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {{couchdb,max_parallel_indexers},4},
  {{couchdb,max_parallel_replica_indexers},2},
  {{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{9,63756073312}}]}]},
  {{metakv,<<"/eventing/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"ram_quota\":256}">>]},
  {{metakv,<<"/indexing/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
  {{metakv,<<"/query/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
  {{rbac_upgrade,[5,5]},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {{request_limit,capi},undefined},
  {{request_limit,rest},undefined},
  {{service_map,fts},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{service_map,index},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{service_map,n1ql},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{node,'ns_1@127.0.0.1',audit},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
  {{node,'ns_1@127.0.0.1',capi_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8092]},
  {{node,'ns_1@127.0.0.1',cbas_admin_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9110]},
  {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9113]},
  {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9112]},
  {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9111]},
  {{node,'ns_1@127.0.0.1',cbas_cluster_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9115]},
  {{node,'ns_1@127.0.0.1',cbas_console_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9114]},
  {{node,'ns_1@127.0.0.1',cbas_data_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9116]},
  {{node,'ns_1@127.0.0.1',cbas_debug_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    -1]},
  {{node,'ns_1@127.0.0.1',cbas_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8095]},
  {{node,'ns_1@127.0.0.1',cbas_messaging_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9118]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9119]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9121]},
  {{node,'ns_1@127.0.0.1',cbas_parent_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9122]},
  {{node,'ns_1@127.0.0.1',cbas_replication_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9120]},
  {{node,'ns_1@127.0.0.1',cbas_result_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9117]},
  {{node,'ns_1@127.0.0.1',cbas_ssl_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18095]},
  {{node,'ns_1@127.0.0.1',compaction_daemon},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {check_interval,30},
    {min_db_file_size,131072},
    {min_view_file_size,20971520}]},
  {{node,'ns_1@127.0.0.1',config_version},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {5,5,3}]},
  {{node,'ns_1@127.0.0.1',eventing_debug_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9140]},
  {{node,'ns_1@127.0.0.1',eventing_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8096]},
  {{node,'ns_1@127.0.0.1',eventing_https_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18096]},
  {{node,'ns_1@127.0.0.1',fts_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8094]},
  {{node,'ns_1@127.0.0.1',fts_ssl_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18094]},
  {{node,'ns_1@127.0.0.1',indexer_admin_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9100]},
  {{node,'ns_1@127.0.0.1',indexer_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9102]},
  {{node,'ns_1@127.0.0.1',indexer_https_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    19102]},
  {{node,'ns_1@127.0.0.1',indexer_scan_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9101]},
  {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9104]},
  {{node,'ns_1@127.0.0.1',indexer_stinit_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9103]},
  {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9105]},
  {{node,'ns_1@127.0.0.1',is_enterprise},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',isasl},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
  {{node,'ns_1@127.0.0.1',ldap_enabled},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',membership},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    active]},
  {{node,'ns_1@127.0.0.1',memcached},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,11210},
    {dedicated_port,11209},
    {ssl_port,11207},
    {admin_user,"@ns_server"},
    {other_users,
     ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
      "@cbas"]},
    {admin_pass,"*****"},
    {engines,
     [{membase,
       [{engine,"/opt/couchbase/lib/memcached/ep.so"},
        {static_config_string,"failpartialwarmup=false"}]},
      {memcached,
       [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
        {static_config_string,"vb0=true"}]}]},
    {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
    {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
    {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
    {log_prefix,"memcached.log"},
    {log_generations,20},
    {log_cyclesize,10485760},
    {log_sleeptime,19},
    {log_rotation_period,39003}]},
  {{node,'ns_1@127.0.0.1',memcached_config},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {[{interfaces,
       {memcached_config_mgr,omit_missing_mcd_ports,
        [{[{host,<<"*">>},
           {port,port},
           {maxconn,maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,dedicated_port},
           {maxconn,dedicated_port_maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,ssl_port},
           {maxconn,maxconn},
           {ssl,
            {[{key,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
              {cert,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]}]}},
      {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
      {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
      {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
      {connection_idle_time,connection_idle_time},
      {privilege_debug,privilege_debug},
      {breakpad,
       {[{enabled,breakpad_enabled},
         {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
      {admin,{"~s",[admin_user]}},
      {verbosity,verbosity},
      {audit_file,{"~s",[audit_file]}},
      {rbac_file,{"~s",[rbac_file]}},
      {dedupe_nmvb_maps,dedupe_nmvb_maps},
      {tracing_enabled,tracing_enabled},
      {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
      {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
      {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
      {logger,
       {[{filename,{"~s/~s",[log_path,log_prefix]}},
         {cyclesize,log_cyclesize},
         {sleeptime,log_sleeptime}]}}]}]},
  {{node,'ns_1@127.0.0.1',memcached_defaults},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {maxconn,30000},
    {dedicated_port_maxconn,5000},
    {ssl_cipher_list,"HIGH"},
    {connection_idle_time,0},
    {verbosity,0},
    {privilege_debug,false},
    {breakpad_enabled,true},
    {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
    {dedupe_nmvb_maps,false},
    {tracing_enabled,true},
    {datatype_snappy,true}]},
  {{node,'ns_1@127.0.0.1',moxi},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,11211},
    {verbosity,[]}]},
  {{node,'ns_1@127.0.0.1',ns_log},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
  {{node,'ns_1@127.0.0.1',port_servers},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
  {{node,'ns_1@127.0.0.1',projector_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9999]},
  {{node,'ns_1@127.0.0.1',query_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8093]},
  {{node,'ns_1@127.0.0.1',rest},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,8091},
    {port_meta,global}]},
  {{node,'ns_1@127.0.0.1',ssl_capi_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18092]},
  {{node,'ns_1@127.0.0.1',ssl_query_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18093]},
  {{node,'ns_1@127.0.0.1',ssl_rest_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18091]},
  {{node,'ns_1@127.0.0.1',uuid},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    <<"0f8760945f98b1efdbef0bd1ea6e8446">>]},
  {{node,'ns_1@127.0.0.1',xdcr_rest_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9998]},
  {{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    false]}]]
[ns_server:info,2020-05-07T13:47:55.261Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1138]Here's full dynamic config we loaded + static & default config:
[{{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   false]},
 {{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   <<"0f8760945f98b1efdbef0bd1ea6e8446">>]},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,8091},
   {port_meta,global}]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11211},
   {verbosity,[]}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {privilege_debug,false},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false},
   {tracing_enabled,true},
   {datatype_snappy,true}]},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},
          {port,port},
          {maxconn,maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {privilege_debug,privilege_debug},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {rbac_file,{"~s",[rbac_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps},
     {tracing_enabled,tracing_enabled},
     {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
     {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
     {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
     {logger,
      {[{filename,{"~s/~s",[log_path,log_prefix]}},
        {cyclesize,log_cyclesize},
        {sleeptime,log_sleeptime}]}}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"@ns_server"},
   {other_users,
    ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
     "@cbas"]},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   active]},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   19102]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',fts_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18094]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',eventing_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18096]},
 {{node,'ns_1@127.0.0.1',eventing_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8096]},
 {{node,'ns_1@127.0.0.1',eventing_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9140]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {5,5,3}]},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {{node,'ns_1@127.0.0.1',cbas_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18095]},
 {{node,'ns_1@127.0.0.1',cbas_result_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9117]},
 {{node,'ns_1@127.0.0.1',cbas_replication_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9120]},
 {{node,'ns_1@127.0.0.1',cbas_parent_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9122]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9121]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9119]},
 {{node,'ns_1@127.0.0.1',cbas_messaging_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9118]},
 {{node,'ns_1@127.0.0.1',cbas_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8095]},
 {{node,'ns_1@127.0.0.1',cbas_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]},
 {{node,'ns_1@127.0.0.1',cbas_data_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9116]},
 {{node,'ns_1@127.0.0.1',cbas_console_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9114]},
 {{node,'ns_1@127.0.0.1',cbas_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9115]},
 {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9111]},
 {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9112]},
 {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9113]},
 {{node,'ns_1@127.0.0.1',cbas_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9110]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{service_map,n1ql},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{service_map,index},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{service_map,fts},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{request_limit,rest},undefined},
 {{request_limit,capi},undefined},
 {{rbac_upgrade,[5,5]},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {{metakv,<<"/query/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
 {{metakv,<<"/indexing/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
 {{metakv,<<"/eventing/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"ram_quota\":256}">>]},
 {{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{9,63756073312}}]}]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {users_upgrade,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {secure_headers,[]},
 {scramsha_fallback_salt,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<169,238,80,91,5,165,74,47,79,135,45,74>>]},
 {roles_definitions,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {rest_creds,null},
 {rest,[{port,8091}]},
 {replication,[{enabled,true}]},
 {remote_clusters,[]},
 {read_only_user_creds,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {quorum_nodes,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   'ns_1@127.0.0.1']},
 {password_policy,[{min_length,6},{must_present,[]}]},
 {otp,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
   {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {memory_quota,311},
 {memcached,[]},
 {max_bucket_count,10},
 {log_redaction_default_cfg,[{redact_level,none}]},
 {index_aware_rebalance_disabled,false},
 {fts_memory_quota,256},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
 {drop_request_memory_threshold_mib,undefined},
 {cluster_compat_version,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},
   6,0]},
 {client_cert_auth,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {state,"disable"},
   {prefixes,[]}]},
 {cert_and_pkey,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQlsomKQ7qhDcAeKZ3inWuCQuv8NxCAMb8M\nXhrVTrshZyFDiXdKS3Xbshyc9dEOiDwuDwAEgfwJQsXzzx0eCRtyTZfWAWTOH06O\nXdQps+9iTfr2KBFj27uag5c5ns+0ojsNyqZhA4+dbS7zK3CZ1dx7LPkL3+4HTlMh\nmH1/2fib3Lbp6dW3B55GV8/RHbkzgcRMyBicYtinqh6JMmmzjO/3KEyVHs3h0W1E\n00JdAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCKWU+bCvjKUlhW\niMiAN7r/3Vxkah7KEqp8BajCnLrlTMeiV+24TlPrsCWz4VBmOgt8OcijS3axdEik\nXeteeJp+R8nb2XPGivHOg/Hx2NlLxCrtXaYVGM0PiVydo24iCv0ZlqMCBsrzRLky\n5otbfQi8ngdfuR88C0/r3RLqvuFnOtFkLbKXuT/qshXfM8O/OgiJkr6CTBFYNd8w\nTCxN2syK41/HXoYzexdA/OTSm+kuEIuDpQYxKS0M4oKKZApJM70y/CYTzwG3JOnp\nuteZPYrwhIqxz01fkbLnj3QLGxPpSexRsp52GOoCv/YEE7tl3Olt4+p+MvhEZPdZ\ndqB53mNJ\n-----END CERTIFICATE-----\n">>,
    <<"*****">>}]},
 {cbas_memory_quota,1024},
 {buckets,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]},
   {configs,[]}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
 {audit_decriptors,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {20480,
    [{name,<<"opened DCP connection">>},
     {description,<<"opened DCP connection">>},
     {enabled,true},
     {module,memcached}]},
   {20482,
    [{name,<<"external memcached bucket flush">>},
     {description,
      <<"External user flushed the content of a memcached bucket">>},
     {enabled,true},
     {module,memcached}]},
   {20483,
    [{name,<<"invalid packet">>},
     {description,<<"Rejected an invalid packet">>},
     {enabled,true},
     {module,memcached}]},
   {20485,
    [{name,<<"authentication succeeded">>},
     {description,<<"Authentication to the cluster succeeded">>},
     {enabled,false},
     {module,memcached}]},
   {20488,
    [{name,<<"document read">>},
     {description,<<"Document was read">>},
     {enabled,false},
     {module,memcached}]},
   {20489,
    [{name,<<"document locked">>},
     {description,<<"Document was locked">>},
     {enabled,false},
     {module,memcached}]},
   {20490,
    [{name,<<"document modify">>},
     {description,<<"Document was modified">>},
     {enabled,false},
     {module,memcached}]},
   {20491,
    [{name,<<"document delete">>},
     {description,<<"Document was deleted">>},
     {enabled,false},
     {module,memcached}]},
   {20492,
    [{name,<<"select bucket">>},
     {description,<<"The specified bucket was selected">>},
     {enabled,true},
     {module,memcached}]},
   {28672,
    [{name,<<"SELECT statement">>},
     {description,<<"A N1QL SELECT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28673,
    [{name,<<"EXPLAIN statement">>},
     {description,<<"A N1QL EXPLAIN statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28674,
    [{name,<<"PREPARE statement">>},
     {description,<<"A N1QL PREPARE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28675,
    [{name,<<"INFER statement">>},
     {description,<<"A N1QL INFER statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28676,
    [{name,<<"INSERT statement">>},
     {description,<<"A N1QL INSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28677,
    [{name,<<"UPSERT statement">>},
     {description,<<"A N1QL UPSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28678,
    [{name,<<"DELETE statement">>},
     {description,<<"A N1QL DELETE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28679,
    [{name,<<"UPDATE statement">>},
     {description,<<"A N1QL UPDATE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28680,
    [{name,<<"MERGE statement">>},
     {description,<<"A N1QL MERGE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28681,
    [{name,<<"CREATE INDEX statement">>},
     {description,<<"A N1QL CREATE INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28682,
    [{name,<<"DROP INDEX statement">>},
     {description,<<"A N1QL DROP INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28683,
    [{name,<<"ALTER INDEX statement">>},
     {description,<<"A N1QL ALTER INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28684,
    [{name,<<"BUILD INDEX statement">>},
     {description,<<"A N1QL BUILD INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28685,
    [{name,<<"GRANT ROLE statement">>},
     {description,<<"A N1QL GRANT ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28686,
    [{name,<<"REVOKE ROLE statement">>},
     {description,<<"A N1QL REVOKE ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28687,
    [{name,<<"UNRECOGNIZED statement">>},
     {description,
      <<"An unrecognized statement was received by the N1QL query engine">>},
     {enabled,false},
     {module,n1ql}]},
   {28688,
    [{name,<<"CREATE PRIMARY INDEX statement">>},
     {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28689,
    [{name,<<"/admin/stats API request">>},
     {description,<<"An HTTP request was made to the API at /admin/stats.">>},
     {enabled,false},
     {module,n1ql}]},
   {28690,
    [{name,<<"/admin/vitals API request">>},
     {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
     {enabled,false},
     {module,n1ql}]},
   {28691,
    [{name,<<"/admin/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28692,
    [{name,<<"/admin/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28693,
    [{name,<<"/admin/indexes/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28694,
    [{name,<<"/admin/indexes/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28695,
    [{name,<<"/admin/indexes/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28697,
    [{name,<<"/admin/ping API request">>},
     {description,<<"An HTTP request was made to the API at /admin/ping.">>},
     {enabled,false},
     {module,n1ql}]},
   {28698,
    [{name,<<"/admin/config API request">>},
     {description,<<"An HTTP request was made to the API at /admin/config.">>},
     {enabled,false},
     {module,n1ql}]},
   {28699,
    [{name,<<"/admin/ssl_cert API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
     {enabled,false},
     {module,n1ql}]},
   {28700,
    [{name,<<"/admin/settings API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/settings.">>},
     {enabled,false},
     {module,n1ql}]},
   {28701,
    [{name,<<"/admin/clusters API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/clusters.">>},
     {enabled,false},
     {module,n1ql}]},
   {28702,
    [{name,<<"/admin/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {32768,
    [{name,<<"Create Function">>},
     {description,<<"Eventing function definition was created or updated">>},
     {enabled,true},
     {module,eventing}]},
   {32769,
    [{name,<<"Delete Function">>},
     {description,<<"Eventing function definition was deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32770,
    [{name,<<"Fetch Functions">>},
     {description,<<"Eventing function definition was read">>},
     {enabled,false},
     {module,eventing}]},
   {32771,
    [{name,<<"List Deployed">>},
     {description,<<"Eventing deployed functions list was read">>},
     {enabled,false},
     {module,eventing}]},
   {32772,
    [{name,<<"Fetch Drafts">>},
     {description,<<"Eventing function draft definitions were read">>},
     {enabled,false},
     {module,eventing}]},
   {32773,
    [{name,<<"Delete Drafts">>},
     {description,<<"Eventing function draft definitions were deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32774,
    [{name,<<"Save Draft">>},
     {description,<<"Save a draft definition to the store">>},
     {enabled,true},
     {module,eventing}]},
   {32775,
    [{name,<<"Start Debug">>},
     {description,<<"Start eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32776,
    [{name,<<"Stop Debug">>},
     {description,<<"Stop eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32777,
    [{name,<<"Start Tracing">>},
     {description,<<"Start tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32778,
    [{name,<<"Stop Tracing">>},
     {description,<<"Stop tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32779,
    [{name,<<"Set Settings">>},
     {description,<<"Save settings for a given app">>},
     {enabled,true},
     {module,eventing}]},
   {32780,
    [{name,<<"Fetch Config">>},
     {description,<<"Get config for eventing">>},
     {enabled,false},
     {module,eventing}]},
   {32781,
    [{name,<<"Save Config">>},
     {description,<<"Save config for eventing">>},
     {enabled,true},
     {module,eventing}]},
   {32782,
    [{name,<<"Cleanup Eventing">>},
     {description,<<"Clears up app definitions and settings from metakv">>},
     {enabled,true},
     {module,eventing}]},
   {32783,
    [{name,<<"Get Settings">>},
     {description,<<"Get settings for a given app">>},
     {enabled,false},
     {module,eventing}]},
   {32784,
    [{name,<<"Import Functions">>},
     {description,<<"Import a list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32785,
    [{name,<<"Export Functions">>},
     {description,<<"Export the list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32786,
    [{name,<<"List Running">>},
     {description,<<"Eventing running function list was read">>},
     {enabled,false},
     {module,eventing}]},
   {36865,
    [{name,<<"Service configuration change">>},
     {description,<<"A successful service configuration change was made.">>},
     {enabled,true},
     {module,analytics}]},
   {36866,
    [{name,<<"Node configuration change">>},
     {description,<<"A successful node configuration change was made.">>},
     {enabled,true},
     {module,analytics}]}]},
 {audit,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {enabled,[]},
   {disabled_users,[]},
   {auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {auto_failover_cfg,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {enabled,true},
   {timeout,120},
   {count,0},
   {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
   {failover_server_group,false},
   {max_count,1},
   {failed_over_server_groups,[]}]}]
[error_logger:info,2020-05-07T13:47:55.267Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.157.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.269Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.163.0>},
                       {name,ns_config_remote},
                       {mfargs,{ns_config_replica,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.271Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.164.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.271Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:55.273Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.166.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.274Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.167.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:55.284Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.170.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:55.285Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2020-05-07T13:47:55.285Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.171.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.285Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.172.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.289Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.173.0>},
                       {name,memcached_refresh},
                       {mfargs,{memcached_refresh,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.291Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.175.0>},
                       {name,ssl_service_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ssl_service_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:55.305Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:init:419]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem-ca"},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[error_logger:info,2020-05-07T13:47:55.367Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.176.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:55.382Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T13:47:55.382Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T13:47:55.383Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T13:47:55.383Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[ns_server:debug,2020-05-07T13:47:55.398Z,ns_1@127.0.0.1:<0.178.0>:restartable:start_child:98]Started child process <0.179.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2020-05-07T13:47:55.398Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.178.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.398Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.174.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:55.400Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.197.0>},
                       {name,user_storage_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,user_storage_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.407Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.199.0>},
                       {name,users_replicator},
                       {mfargs,{menelaus_users,start_replicator,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:55.408Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:55]Start waiting for startup
[ns_server:debug,2020-05-07T13:47:55.410Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_storage:anounce_startup:69]Announce my startup to <0.199.0>
[ns_server:debug,2020-05-07T13:47:55.411Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:58]Received replicated storage registration from <0.200.0>
[ns_server:debug,2020-05-07T13:47:55.413Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:open:212]Opening file "/opt/couchbase/var/lib/couchbase/config/users.dets"
[error_logger:info,2020-05-07T13:47:55.413Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.200.0>},
                       {name,users_storage},
                       {mfargs,{menelaus_users,start_storage,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.413Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.198.0>},
                       {name,users_storage_sup},
                       {mfargs,{users_storage_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T13:47:55.426Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:init:44]Starting versioned cache compiled_roles_cache
[error_logger:info,2020-05-07T13:47:55.427Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.202.0>},
                       {name,compiled_roles_cache},
                       {mfargs,{menelaus_roles,start_compiled_roles_cache,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.427Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.196.0>},
                       {name,users_sup},
                       {mfargs,{users_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:55.428Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.205.0>},
                       {name,dets_sup},
                       {mfargs,{dets_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:55.428Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.206.0>},
                       {name,dets},
                       {mfargs,{dets_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:55.441Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:convert_docs_to_55_in_dets:243]Checking for pre 5.5 records in dets: users_storage
[ns_server:debug,2020-05-07T13:47:55.441Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,'$1','_','$2'},
                                      [],
                                      [{{'$1','$2'}}]}],
                                    100}
[ns_server:debug,2020-05-07T13:47:55.441Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:init_after_ack:204]Loading 0 items, 299 words took 0ms
[ns_server:debug,2020-05-07T13:47:55.452Z,ns_1@127.0.0.1:users_replicator<0.199.0>:doc_replicator:loop:60]doing replicate_newnodes_docs
[ns_server:debug,2020-05-07T13:47:55.454Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.210.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:141]Waiting for ns_couchdb node to start
[error_logger:info,2020-05-07T13:47:55.454Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.209.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:55.454Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T13:47:55.457Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.213.0>,shutdown}}
[error_logger:info,2020-05-07T13:47:55.457Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T13:47:55.457Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T13:47:55.658Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T13:47:55.658Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.216.0>,shutdown}}
[ns_server:debug,2020-05-07T13:47:55.658Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T13:47:55.658Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T13:47:55.859Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T13:47:55.859Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.219.0>,shutdown}}
[error_logger:info,2020-05-07T13:47:55.859Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T13:47:55.859Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T13:47:56.060Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T13:47:56.081Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T13:47:56.282Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T13:47:56.483Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T13:47:56.684Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T13:47:56.885Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[error_logger:info,2020-05-07T13:47:57.264Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.229.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:57.465Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: Apache CouchDB v4.5.1-112-gc2b9820 (LogLevel=info) is starting.
ns_couchdb<0.209.0>: Apache CouchDB has started. Time to relax.

[error_logger:info,2020-05-07T13:47:57.580Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.210.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.96617950>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.591Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:ns_storage_conf:setup_db_and_ix_paths:47]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2020-05-07T13:47:57.595Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.232.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.599Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.233.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:57.601Z,ns_1@127.0.0.1:ns_server_sup<0.231.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2020-05-07T13:47:57.610Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.234.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.611Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.235.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.615Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.236.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.615Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.237.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.641Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:memcached_cfg:init:62]Init config writer for memcached_passwords, "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T13:47:57.641Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T13:47:57.684Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.238.0>
[ns_server:debug,2020-05-07T13:47:57.684Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T13:47:57.688Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.238.0>
[ns_server:debug,2020-05-07T13:47:57.714Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[error_logger:info,2020-05-07T13:47:57.714Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.238.0>},
                       {name,memcached_passwords},
                       {mfargs,{memcached_passwords,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.722Z,ns_1@127.0.0.1:memcached_permissions<0.241.0>:memcached_cfg:init:62]Init config writer for memcached_permissions, "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T13:47:57.724Z,ns_1@127.0.0.1:memcached_permissions<0.241.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T13:47:57.726Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.241.0>
[ns_server:debug,2020-05-07T13:47:57.726Z,ns_1@127.0.0.1:memcached_permissions<0.241.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{user,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T13:47:57.726Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.241.0>
[error_logger:info,2020-05-07T13:47:57.729Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.241.0>},
                       {name,memcached_permissions},
                       {mfargs,{memcached_permissions,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.729Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.244.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T13:47:57.732Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T13:47:57.732Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [isasl] failed. Retry in 1000 ms.
[ns_server:debug,2020-05-07T13:47:57.732Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of rbac requested
[ns_server:warn,2020-05-07T13:47:57.732Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T13:47:57.732Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2020-05-07T13:47:57.739Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.246.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.740Z,ns_1@127.0.0.1:ns_node_disco<0.247.0>:ns_node_disco:init:130]Initting ns_node_disco with []
[ns_server:debug,2020-05-07T13:47:57.740Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[user:info,2020-05-07T13:47:57.740Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:127]Node 'ns_1@127.0.0.1' synchronized otp cookie {sanitized,
                                               <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>} from cluster
[ns_server:debug,2020-05-07T13:47:57.740Z,ns_1@127.0.0.1:<0.248.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T13:47:57.742Z,ns_1@127.0.0.1:<0.248.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[error_logger:info,2020-05-07T13:47:57.742Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.247.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.743Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.249.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.745Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.250.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.746Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.749Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:69]init pulling
[ns_server:debug,2020-05-07T13:47:57.749Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:71]init pushing
[ns_server:debug,2020-05-07T13:47:57.752Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:75]init reannouncing
[ns_server:debug,2020-05-07T13:47:57.753Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2020-05-07T13:47:57.753Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:handle_info:89]Flushing cache compiled_roles_cache due to version change from undefined to {[6,
                                                                              0],
                                                                             {0,
                                                                              3606033535},
                                                                             false,
                                                                             []}
[ns_server:debug,2020-05-07T13:47:57.753Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2020-05-07T13:47:57.753Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T13:47:57.753Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T13:47:57.753Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T13:47:57.754Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2020-05-07T13:47:57.754Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,[]},
 {disabled_users,[]},
 {auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2020-05-07T13:47:57.754Z,ns_1@127.0.0.1:<0.260.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T13:47:57.754Z,ns_1@127.0.0.1:<0.261.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T13:47:57.754Z,ns_1@127.0.0.1:<0.260.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T13:47:57.755Z,ns_1@127.0.0.1:<0.261.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T13:47:57.755Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit_decriptors ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {20480,
  [{name,<<"opened DCP connection">>},
   {description,<<"opened DCP connection">>},
   {enabled,true},
   {module,memcached}]},
 {20482,
  [{name,<<"external memcached bucket flush">>},
   {description,<<"External user flushed the content of a memcached bucket">>},
   {enabled,true},
   {module,memcached}]},
 {20483,
  [{name,<<"invalid packet">>},
   {description,<<"Rejected an invalid packet">>},
   {enabled,true},
   {module,memcached}]},
 {20485,
  [{name,<<"authentication succeeded">>},
   {description,<<"Authentication to the cluster succeeded">>},
   {enabled,false},
   {module,memcached}]},
 {20488,
  [{name,<<"document read">>},
   {description,<<"Document was read">>},
   {enabled,false},
   {module,memcached}]},
 {20489,
  [{name,<<"document locked">>},
   {description,<<"Document was locked">>},
   {enabled,false},
   {module,memcached}]},
 {20490,
  [{name,<<"document modify">>},
   {description,<<"Document was modified">>},
   {enabled,false},
   {module,memcached}]},
 {20491,
  [{name,<<"document delete">>},
   {description,<<"Document was deleted">>},
   {enabled,false},
   {module,memcached}]},
 {20492,
  [{name,<<"select bucket">>},
   {description,<<"The specified bucket was selected">>},
   {enabled,true},
   {module,memcached}]},
 {28672,
  [{name,<<"SELECT statement">>},
   {description,<<"A N1QL SELECT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28673,
  [{name,<<"EXPLAIN statement">>},
   {description,<<"A N1QL EXPLAIN statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28674,
  [{name,<<"PREPARE statement">>},
   {description,<<"A N1QL PREPARE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28675,
  [{name,<<"INFER statement">>},
   {description,<<"A N1QL INFER statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28676,
  [{name,<<"INSERT statement">>},
   {description,<<"A N1QL INSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28677,
  [{name,<<"UPSERT statement">>},
   {description,<<"A N1QL UPSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28678,
  [{name,<<"DELETE statement">>},
   {description,<<"A N1QL DELETE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28679,
  [{name,<<"UPDATE statement">>},
   {description,<<"A N1QL UPDATE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28680,
  [{name,<<"MERGE statement">>},
   {description,<<"A N1QL MERGE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28681,
  [{name,<<"CREATE INDEX statement">>},
   {description,<<"A N1QL CREATE INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28682,
  [{name,<<"DROP INDEX statement">>},
   {description,<<"A N1QL DROP INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28683,
  [{name,<<"ALTER INDEX statement">>},
   {description,<<"A N1QL ALTER INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28684,
  [{name,<<"BUILD INDEX statement">>},
   {description,<<"A N1QL BUILD INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28685,
  [{name,<<"GRANT ROLE statement">>},
   {description,<<"A N1QL GRANT ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28686,
  [{name,<<"REVOKE ROLE statement">>},
   {description,<<"A N1QL REVOKE ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28687,
  [{name,<<"UNRECOGNIZED statement">>},
   {description,<<"An unrecognized statement was received by the N1QL query engine">>},
   {enabled,false},
   {module,n1ql}]},
 {28688,
  [{name,<<"CREATE PRIMARY INDEX statement">>},
   {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28689,
  [{name,<<"/admin/stats API request">>},
   {description,<<"An HTTP request was made to the API at /admin/stats.">>},
   {enabled,false},
   {module,n1ql}]},
 {28690,
  [{name,<<"/admin/vitals API request">>},
   {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
   {enabled,false},
   {module,n1ql}]},
 {28691,
  [{name,<<"/admin/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28692,
  [{name,<<"/admin/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28693,
  [{name,<<"/admin/indexes/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28694,
  [{name,<<"/admin/indexes/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28695,
  [{name,<<"/admin/indexes/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28697,
  [{name,<<"/admin/ping API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ping.">>},
   {enabled,false},
   {module,n1ql}]},
 {28698,
  [{name,<<"/admin/config API request">>},
   {description,<<"An HTTP request was made to the API at /admin/config.">>},
   {enabled,false},
   {module,n1ql}]},
 {28699,
  [{name,<<"/admin/ssl_cert API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ssl_cert.">>},
   {enabled,false},
   {module,n1ql}]},
 {28700,
  [{name,<<"/admin/settings API request">>},
   {description,<<"An HTTP request was made to the API at /admin/settings.">>},
   {enabled,false},
   {module,n1ql}]},
 {28701,
  [{name,<<"/admin/clusters API request">>},
   {description,<<"An HTTP request was made to the API at /admin/clusters.">>},
   {enabled,false},
   {module,n1ql}]},
 {28702,
  [{name,<<"/admin/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {32768,
  [{name,<<"Create Function">>},
   {description,<<"Eventing function definition was created or updated">>},
   {enabled,true},
   {module,eventing}]},
 {32769,
  [{name,<<"Delete Function">>},
   {description,<<"Eventing function definition was deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32770,
  [{name,<<"Fetch Functions">>},
   {description,<<"Eventing function definition was read">>},
   {enabled,false},
   {module,eventing}]},
 {32771,
  [{name,<<"List Deployed">>},
   {description,<<"Eventing deployed functions list was read">>},
   {enabled,false},
   {module,eventing}]},
 {32772,
  [{name,<<"Fetch Drafts">>},
   {description,<<"Eventing function draft definitions were read">>},
   {enabled,false},
   {module,eventing}]},
 {32773,
  [{name,<<"Delete Drafts">>},
   {description,<<"Eventing function draft definitions were deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32774,
  [{name,<<"Save Draft">>},
   {description,<<"Save a draft definition to the store">>},
   {enabled,true},
   {module,eventing}]},
 {32775,
  [{name,<<"Start Debug">>},
   {description,<<"Start eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32776,
  [{name,<<"Stop Debug">>},
   {description,<<"Stop eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32777,
  [{name,<<"Start Tracing">>},
   {description,<<"Start tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32778,
  [{name,<<"Stop Tracing">>},
   {description,<<"Stop tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32779,
  [{name,<<"Set Settings">>},
   {description,<<"Save settings for a given app">>},
   {enabled,true},
   {module,eventing}]},
 {32780,
  [{name,<<"Fetch Config">>},
   {description,<<"Get config for eventing">>},
   {enabled,false},
   {module,eventing}]},
 {32781,
  [{name,<<"Save Config">>},
   {description,<<"Save config for eventing">>},
   {enabled,true},
   {module,eventing}]},
 {32782,
  [{name,<<"Cleanup Eventing">>},
   {description,<<"Clears up app definitions and settings from metakv">>},
   {enabled,true},
   {module,eventing}]},
 {32783,
  [{name,<<"Get Settings">>},
   {description,<<"Get settings for a given app">>},
   {enabled,false},
   {module,eventing}]},
 {32784,
  [{name,<<"Import Functions">>},
   {description,<<"Import a list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32785,
  [{name,<<"Export Functions">>},
   {description,<<"Export the list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32786,
  [{name,<<"List Running">>},
   {description,<<"Eventing running function list was read">>},
   {enabled,false},
   {module,eventing}]},
 {36865,
  [{name,<<"Service configuration change">>},
   {description,<<"A successful service configuration change was made.">>},
   {enabled,true},
   {module,analytics}]},
 {36866,
  [{name,<<"Node configuration change">>},
   {description,<<"A successful node configuration change was made.">>},
   {enabled,true},
   {module,analytics}]}]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_reprovision_cfg ->
[{enabled,true},{max_nodes,1},{count,0}]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
buckets ->
[[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}],{configs,[]}]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cbas_memory_quota ->
1024
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cert_and_pkey ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQ"...>>,
  <<"*****">>}]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
client_cert_auth ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {state,"disable"},
 {prefixes,[]}]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cluster_compat_version ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},6,0]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded,communication_issue]}]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
fts_memory_quota ->
256
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
log_redaction_default_cfg ->
[{redact_level,none}]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
max_bucket_count ->
10
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memcached ->
[]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memory_quota ->
311
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
otp ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
 {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
password_policy ->
[{min_length,6},{must_present,[]}]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
quorum_nodes ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
read_only_user_creds ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
remote_clusters ->
[]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest ->
[{port,8091}]
[ns_server:debug,2020-05-07T13:47:57.756Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest_creds ->
null
[ns_server:debug,2020-05-07T13:47:57.757Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
roles_definitions ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T13:47:57.757Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
scramsha_fallback_salt ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<169,238,80,91,5,165,74,47,79,135,45,74>>]
[ns_server:debug,2020-05-07T13:47:57.757Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
secure_headers ->
[]
[ns_server:debug,2020-05-07T13:47:57.757Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2020-05-07T13:47:57.757Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2020-05-07T13:47:57.757Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
users_upgrade ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T13:47:57.757Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2020-05-07T13:47:57.757Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2020-05-07T13:47:57.757Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{9,63756073312}}]}]
[ns_server:debug,2020-05-07T13:47:57.757Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/eventing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"ram_quota\":256}">>]
[ns_server:debug,2020-05-07T13:47:57.757Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2020-05-07T13:47:57.757Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/query/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]
[ns_server:debug,2020-05-07T13:47:57.757Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{rbac_upgrade,[5,5]} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T13:47:57.758Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2020-05-07T13:47:57.758Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2020-05-07T13:47:57.758Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,fts} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T13:47:57.758Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,index} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T13:47:57.758Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T13:47:57.758Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T13:47:57.758Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8092]
[ns_server:debug,2020-05-07T13:47:57.758Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9110]
[ns_server:debug,2020-05-07T13:47:57.758Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_client_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9113]
[ns_server:debug,2020-05-07T13:47:57.758Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9112]
[ns_server:debug,2020-05-07T13:47:57.758Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9111]
[ns_server:debug,2020-05-07T13:47:57.759Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9115]
[ns_server:debug,2020-05-07T13:47:57.759Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_console_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9114]
[ns_server:debug,2020-05-07T13:47:57.759Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_data_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9116]
[ns_server:debug,2020-05-07T13:47:57.759Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]
[ns_server:debug,2020-05-07T13:47:57.759Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8095]
[ns_server:debug,2020-05-07T13:47:57.759Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_messaging_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9118]
[ns_server:debug,2020-05-07T13:47:57.759Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_callback_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9119]
[ns_server:debug,2020-05-07T13:47:57.759Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9121]
[ns_server:debug,2020-05-07T13:47:57.759Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_parent_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9122]
[ns_server:debug,2020-05-07T13:47:57.760Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_replication_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9120]
[ns_server:debug,2020-05-07T13:47:57.760Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_result_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9117]
[ns_server:debug,2020-05-07T13:47:57.760Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18095]
[ns_server:debug,2020-05-07T13:47:57.760Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2020-05-07T13:47:57.760Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {5,5,3}]
[ns_server:debug,2020-05-07T13:47:57.760Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9140]
[ns_server:debug,2020-05-07T13:47:57.760Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8096]
[ns_server:debug,2020-05-07T13:47:57.760Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18096]
[ns_server:debug,2020-05-07T13:47:57.760Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8094]
[ns_server:debug,2020-05-07T13:47:57.760Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18094]
[ns_server:debug,2020-05-07T13:47:57.760Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9100]
[ns_server:debug,2020-05-07T13:47:57.760Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9102]
[ns_server:debug,2020-05-07T13:47:57.760Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|19102]
[ns_server:debug,2020-05-07T13:47:57.760Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9101]
[ns_server:debug,2020-05-07T13:47:57.762Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9104]
[ns_server:debug,2020-05-07T13:47:57.762Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9103]
[ns_server:debug,2020-05-07T13:47:57.762Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9105]
[ns_server:debug,2020-05-07T13:47:57.762Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:debug,2020-05-07T13:47:57.762Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2020-05-07T13:47:57.762Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:debug,2020-05-07T13:47:57.762Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 active]
[ns_server:debug,2020-05-07T13:47:57.762Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"@ns_server"},
 {other_users,["@cbq-engine","@projector","@goxdcr","@index","@fts",
               "@eventing","@cbas"]},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2020-05-07T13:47:57.763Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},
        {port,port},
        {maxconn,maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {privilege_debug,privilege_debug},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {rbac_file,{"~s",[rbac_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps},
   {tracing_enabled,tracing_enabled},
   {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
   {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
   {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
   {logger,
    {[{filename,{"~s/~s",[log_path,log_prefix]}},
      {cyclesize,log_cyclesize},
      {sleeptime,log_sleeptime}]}}]}]
[ns_server:debug,2020-05-07T13:47:57.763Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {privilege_debug,false},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false},
 {tracing_enabled,true},
 {datatype_snappy,true}]
[ns_server:debug,2020-05-07T13:47:57.763Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2020-05-07T13:47:57.763Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2020-05-07T13:47:57.763Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T13:47:57.763Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9999]
[ns_server:debug,2020-05-07T13:47:57.763Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8093]
[ns_server:debug,2020-05-07T13:47:57.763Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2020-05-07T13:47:57.763Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18092]
[ns_server:debug,2020-05-07T13:47:57.763Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18093]
[ns_server:debug,2020-05-07T13:47:57.763Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18091]
[ns_server:debug,2020-05-07T13:47:57.763Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 <<"0f8760945f98b1efdbef0bd1ea6e8446">>]
[ns_server:debug,2020-05-07T13:47:57.763Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9998]
[ns_server:debug,2020-05-07T13:47:57.763Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|false]
[error_logger:info,2020-05-07T13:47:57.773Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.252.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.773Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.245.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T13:47:57.773Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([alert_limits,audit,audit_decriptors,
                               auto_failover_cfg,auto_reprovision_cfg,
                               autocompaction,buckets,cbas_memory_quota,
                               cert_and_pkey,client_cert_auth,
                               cluster_compat_version,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,
                               index_aware_rebalance_disabled,
                               log_redaction_default_cfg,max_bucket_count,
                               memcached,memory_quota,nodes_wanted,otp,
                               password_policy,quorum_nodes,
                               read_only_user_creds,remote_clusters,
                               replication,rest,rest_creds,roles_definitions,
                               scramsha_fallback_salt,secure_headers,
                               server_groups,set_view_update_daemon,
                               users_upgrade,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>},
                               {metakv,<<"/eventing/settings/config">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {metakv,<<"/query/settings/config">>},
                               {rbac_upgrade,[5,5]},
                               {request_limit,capi},
                               {request_limit,rest},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',cbas_admin_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_client_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_http_port},
                               {node,'ns_1@127.0.0.1',cbas_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_console_port},
                               {node,'ns_1@127.0.0.1',cbas_data_port},
                               {node,'ns_1@127.0.0.1',cbas_debug_port},
                               {node,'ns_1@127.0.0.1',cbas_http_port},
                               {node,'ns_1@127.0.0.1',cbas_messaging_port},
                               {node,'ns_1@127.0.0.1',
                                   cbas_metadata_callback_port},
                               {node,'ns_1@127.0.0.1',cbas_metadata_port},
                               {node,'ns_1@127.0.0.1',cbas_parent_port},
                               {node,'ns_1@127.0.0.1',cbas_replication_port},
                               {node,'ns_1@127.0.0.1',cbas_result_port},
                               {node,'ns_1@127.0.0.1',cbas_ssl_port}]..)
[ns_server:debug,2020-05-07T13:47:57.775Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:trigger_ssl_reload:565]Notify services [capi_ssl_service] about secure_headers_changed change
[ns_server:debug,2020-05-07T13:47:57.775Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:525]Going to notify following services: [capi_ssl_service]
[ns_server:info,2020-05-07T13:47:57.788Z,ns_1@127.0.0.1:<0.267.0>:ns_ssl_services_setup:notify_service:708]Successfully notified service capi_ssl_service
[ns_server:info,2020-05-07T13:47:57.788Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:541]Succesfully notified services [capi_ssl_service]
[ns_server:debug,2020-05-07T13:47:57.789Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.238.0>
[ns_server:debug,2020-05-07T13:47:57.789Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:info,2020-05-07T13:47:57.789Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: 172: Booted. Waiting for shutdown request

[ns_server:debug,2020-05-07T13:47:57.789Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.238.0>
[error_logger:info,2020-05-07T13:47:57.790Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.274.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.806Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[ns_server:warn,2020-05-07T13:47:57.807Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T13:47:57.807Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2020-05-07T13:47:57.810Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.276.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.810Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.279.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.810Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.280.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.813Z,ns_1@127.0.0.1:ns_log_events<0.244.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2020-05-07T13:47:57.813Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.282.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.813Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.281.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:57.813Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.283.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.818Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.284.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.822Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.286.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.822Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.292.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.822Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.285.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T13:47:57.825Z,ns_1@127.0.0.1:ns_heart<0.286.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2020-05-07T13:47:57.825Z,ns_1@127.0.0.1:ns_heart<0.286.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]}]}}

[error_logger:info,2020-05-07T13:47:57.830Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.296.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.835Z,ns_1@127.0.0.1:<0.293.0>:restartable:start_child:98]Started child process <0.295.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2020-05-07T13:47:57.835Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.297.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.835Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.293.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:57.835Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.300.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.846Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.301.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.847Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.302.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.847Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.303.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.847Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.304.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.850Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.306.0>},
                       {name,query_settings_manager},
                       {mfargs,{query_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.856Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.309.0>},
                       {name,eventing_settings_manager},
                       {mfargs,{eventing_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.856Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.311.0>},
                       {name,audit_events},
                       {mfargs,{gen_event,start_link,[{local,audit_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.865Z,ns_1@127.0.0.1:ns_heart<0.286.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2020-05-07T13:47:57.866Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.313.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.867Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.315.0>},
                       {name,scram_sha},
                       {mfargs,{scram_sha,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.869Z,ns_1@127.0.0.1:ns_heart<0.286.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T13:47:57.870Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.317.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.898Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.318.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.909Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.321.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.909Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.322.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:57.909Z,ns_1@127.0.0.1:menelaus_sup<0.312.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T13:47:57.910Z,ns_1@127.0.0.1:menelaus_sup<0.312.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T13:47:57.910Z,ns_1@127.0.0.1:menelaus_sup<0.312.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T13:47:57.910Z,ns_1@127.0.0.1:menelaus_sup<0.312.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[error_logger:info,2020-05-07T13:47:57.910Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.323.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.913Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.340.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.916Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.341.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.919Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.342.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.922Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.292.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,244}]},
                 {proc_lib,init_p_do_apply,3,
                           [{file,"proc_lib.erl"},{line,239}]}]}}

[error_logger:info,2020-05-07T13:47:57.922Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.353.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.922Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.292.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,244}]}]}}

[user:info,2020-05-07T13:47:57.923Z,ns_1@127.0.0.1:ns_server_sup<0.231.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "6.0.3-2895-enterprise".
[error_logger:info,2020-05-07T13:47:57.923Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.312.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:57.923Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.360.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.924Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.292.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T13:47:57.924Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.292.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T13:47:57.925Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.366.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:57.926Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.367.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.31986353>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.926Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.365.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T13:47:57.935Z,ns_1@127.0.0.1:ns_ports_setup<0.360.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,goxdcr]
[error_logger:info,2020-05-07T13:47:57.969Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.371.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.969Z,ns_1@127.0.0.1:ns_audit_cfg<0.372.0>:ns_audit_cfg:write_audit_json:265]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{descriptors_path,
                                                                                <<"/opt/couchbase/etc/security">>},
                                                                               {version,
                                                                                2},
                                                                               {uuid,
                                                                                <<"18411111">>},
                                                                               {event_states,
                                                                                {[]}},
                                                                               {filtering_enabled,
                                                                                true},
                                                                               {disabled_userids,
                                                                                []},
                                                                               {auditd_enabled,
                                                                                false},
                                                                               {log_path,
                                                                                <<"/opt/couchbase/var/lib/couchbase/logs">>},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []}]
[ns_server:debug,2020-05-07T13:47:57.979Z,ns_1@127.0.0.1:ns_audit_cfg<0.372.0>:ns_audit_cfg:notify_memcached:170]Instruct memcached to reload audit config
[error_logger:info,2020-05-07T13:47:57.979Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.372.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T13:47:57.981Z,ns_1@127.0.0.1:<0.375.0>:ns_memcached:connect:1230]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2020-05-07T13:47:57.984Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.376.0>},
                       {name,ns_audit},
                       {mfargs,{ns_audit,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:57.985Z,ns_1@127.0.0.1:memcached_config_mgr<0.377.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2020-05-07T13:47:57.985Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.377.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:57.987Z,ns_1@127.0.0.1:<0.378.0>:ns_memcached_log_rotator:init:42]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2020-05-07T13:47:57.987Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.991Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.379.0>},
                       {name,testconditions_store},
                       {mfargs,{simple_store,start_link,[testconditions]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.993Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.381.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.995Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.383.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:57.995Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.382.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:57.995Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.380.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:58.004Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.384.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.005Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.388.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.008Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.390.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.008Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.391.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.008Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.393.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.009Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.394.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.009Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.396.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:58.020Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: working as port

[error_logger:info,2020-05-07T13:47:58.030Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.397.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.043Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.399.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.043Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.401.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:58.043Z,ns_1@127.0.0.1:ns_ports_setup<0.360.0>:ns_ports_setup:set_children:90]Monitor ns_child_ports_sup <12401.74.0>
[ns_server:debug,2020-05-07T13:47:58.043Z,ns_1@127.0.0.1:memcached_config_mgr<0.377.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:info,2020-05-07T13:47:58.099Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.403.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:58.127Z,ns_1@127.0.0.1:memcached_config_mgr<0.377.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.81.0>
[ns_server:debug,2020-05-07T13:47:58.174Z,ns_1@127.0.0.1:memcached_config_mgr<0.377.0>:memcached_config_mgr:init:79]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[error_logger:info,2020-05-07T13:47:58.184Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.407.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:58.189Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.407.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T13:47:58.189Z,ns_1@127.0.0.1:memcached_config_mgr<0.377.0>:memcached_config_mgr:init:82]activated memcached port server
[ns_server:debug,2020-05-07T13:47:58.190Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.407.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2020-05-07T13:47:58.198Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.411.0>},
                       {name,service_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_stats_children_sup},
                                services_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:58.201Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.413.0>},
                       {name,service_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [service_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.206Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.414.0>},
                       {name,service_status_keeper_index},
                       {mfargs,{service_index,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.224Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.417.0>},
                       {name,service_status_keeper_fts},
                       {mfargs,{service_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.226Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.420.0>},
                       {name,service_status_keeper_eventing},
                       {mfargs,{service_eventing,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.227Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.412.0>},
                       {name,service_status_keeper_sup},
                       {mfargs,{service_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:58.227Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.423.0>},
                       {name,service_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<services_stats_sup.0.41280346>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.227Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.410.0>},
                       {name,services_stats_sup},
                       {mfargs,{services_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:58.232Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.425.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:58.244Z,ns_1@127.0.0.1:<0.428.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.428.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2020-05-07T13:47:58.246Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T13:47:58.246Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[error_logger:info,2020-05-07T13:47:58.246Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.426.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:58.246Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T13:47:58.247Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T13:47:58.247Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T13:47:58.247Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2020-05-07T13:47:58.248Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.430.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.248Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.429.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:58.249Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.431.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.257Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.435.0>},
                       {name,leader_activities},
                       {mfargs,{leader_activities,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T13:47:58.283Z,ns_1@127.0.0.1:leader_lease_agent<0.436.0>:leader_lease_agent:maybe_recover_persisted_lease:397]Found persisted lease [{node,'ns_1@127.0.0.1'},
                       {uuid,<<"8383a6f8218c46cdb84a637963c66dd3">>},
                       {time_left,15000},
                       {status,active}]
[error_logger:info,2020-05-07T13:47:58.283Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.436.0>},
                       {name,leader_lease_agent},
                       {mfargs,{leader_lease_agent,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.283Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.434.0>},
                       {name,leader_leases_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_leases_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:58.283Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.438.0>},
                       {name,leader_events},
                       {mfargs,{gen_event,start_link,[{local,leader_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.285Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.439.0>},
                       {name,leader_registry_server},
                       {mfargs,{leader_registry_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:58.287Z,ns_1@127.0.0.1:leader_registry_sup<0.437.0>:mb_master:check_master_takeover_needed:270]Sending master node question to the following nodes: []
[ns_server:debug,2020-05-07T13:47:58.287Z,ns_1@127.0.0.1:leader_registry_sup<0.437.0>:mb_master:check_master_takeover_needed:272]Got replies: []
[ns_server:debug,2020-05-07T13:47:58.287Z,ns_1@127.0.0.1:leader_registry_sup<0.437.0>:mb_master:check_master_takeover_needed:278]Was unable to discover master, not going to force mastership takeover
[user:info,2020-05-07T13:47:58.287Z,ns_1@127.0.0.1:mb_master<0.442.0>:mb_master:init:90]I'm the only node, so I'm the master.
[ns_server:debug,2020-05-07T13:47:58.287Z,ns_1@127.0.0.1:leader_registry<0.439.0>:leader_registry_server:handle_new_leader:241]New leader is 'ns_1@127.0.0.1'. Invalidating name cache.
[error_logger:info,2020-05-07T13:47:58.295Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.445.0>},
                       {name,leader_lease_acquirer},
                       {mfargs,{leader_lease_acquirer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:58.298Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.447.0>:leader_quorum_nodes_manager:pull_config:114]Attempting to pull config from nodes:
[]
[error_logger:info,2020-05-07T13:47:58.298Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.447.0>},
                       {name,leader_quorum_nodes_manager},
                       {mfargs,{leader_quorum_nodes_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:58.299Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.447.0>:leader_quorum_nodes_manager:pull_config:119]Pulled config successfully.
[ns_server:warn,2020-05-07T13:47:58.302Z,ns_1@127.0.0.1:<0.453.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"8383a6f8218c46cdb84a637963c66dd3">>} (valid for 14980ms)
[ns_server:info,2020-05-07T13:47:58.304Z,ns_1@127.0.0.1:mb_master_sup<0.444.0>:misc:start_singleton:758]start_singleton(gen_server, ns_tick, [], []): started as <0.456.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T13:47:58.304Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.456.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.309Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.459.0>},
                       {name,ns_janitor_server},
                       {mfargs,{ns_janitor_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:58.311Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.458.0>:misc:start_singleton:758]start_singleton(gen_server, auto_reprovision, [], []): started as <0.460.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T13:47:58.311Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.460.0>},
                       {name,auto_reprovision},
                       {mfargs,{auto_reprovision,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:47:58.312Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.458.0>:misc:start_singleton:758]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.461.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T13:47:58.312Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.461.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.312Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.458.0>},
                       {name,ns_orchestrator_child_sup},
                       {mfargs,{ns_orchestrator_child_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T13:47:58.317Z,ns_1@127.0.0.1:<0.463.0>:auto_failover:init:211]init auto_failover.
[user:info,2020-05-07T13:47:58.317Z,ns_1@127.0.0.1:<0.463.0>:auto_failover:handle_call:242]Enabled auto-failover with timeout 120 and max count 1
[ns_server:debug,2020-05-07T13:47:58.323Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([auto_failover_cfg,
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>}]..)
[ns_server:debug,2020-05-07T13:47:58.323Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{10,63756078478}}]}]
[ns_server:debug,2020-05-07T13:47:58.324Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[ns_server:info,2020-05-07T13:47:58.324Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.457.0>:misc:start_singleton:758]start_singleton(gen_server, auto_failover, [], []): started as <0.463.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T13:47:58.324Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.463.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:58.325Z,ns_1@127.0.0.1:<0.432.0>:restartable:start_child:98]Started child process <0.433.0>
  MFA: {leader_services_sup,start_link,[]}
[error_logger:info,2020-05-07T13:47:58.324Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.457.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:58.333Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.442.0>},
                       {name,mb_master},
                       {mfargs,{mb_master,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:58.334Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.437.0>},
                       {name,leader_registry_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_registry_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:58.334Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.432.0>},
                       {name,leader_services_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{leader_services_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:58.335Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.471.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.335Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.472.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.335Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.473.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.338Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.474.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.360Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.478.0>},
                       {name,ns_server_monitor},
                       {mfargs,{ns_server_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.360Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.480.0>},
                       {name,service_monitor_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_monitor_children_sup},
                                health_monitor_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:58.360Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.481.0>},
                       {name,service_monitor_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<health_monitor_sup.0.81875396>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.365Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.489.0>},
                       {name,node_monitor},
                       {mfargs,{node_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:47:58.372Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[ns_server:debug,2020-05-07T13:47:58.372Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.169.0>
[ns_server:debug,2020-05-07T13:47:58.372Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2020-05-07T13:47:58.372Z,ns_1@127.0.0.1:<0.168.0>:restartable:start_child:98]Started child process <0.169.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[error_logger:info,2020-05-07T13:47:58.372Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.497.0>},
                       {name,node_status_analyzer},
                       {mfargs,{node_status_analyzer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:47:58.372Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.476.0>},
                       {name,health_monitor_sup},
                       {mfargs,{health_monitor_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:58.372Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.231.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:58.372Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.168.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:47:58.373Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:debug,2020-05-07T13:47:58.373Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:130]138: Entered child_loop
[ns_server:debug,2020-05-07T13:47:58.376Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@",admin}
[ns_server:debug,2020-05-07T13:47:58.392Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.499.0>:json_rpc_connection:init:73]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.499.0>
[ns_server:debug,2020-05-07T13:47:58.435Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.502.0>:json_rpc_connection:init:73]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.502.0>
[ns_server:debug,2020-05-07T13:47:58.435Z,ns_1@127.0.0.1:menelaus_cbauth<0.353.0>:menelaus_cbauth:handle_cast:102]Observed json rpc process {"goxdcr-cbauth",<0.502.0>} started
[ns_server:debug,2020-05-07T13:47:58.446Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@goxdcr-cbauth",admin}
[ns_server:debug,2020-05-07T13:47:58.747Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:89]Refresh of [rbac,isasl] succeeded
[ns_server:debug,2020-05-07T13:47:59.318Z,ns_1@127.0.0.1:<0.463.0>:auto_failover_logic:log_master_activity:170]Transitioned node {'ns_1@127.0.0.1',<<"0f8760945f98b1efdbef0bd1ea6e8446">>} state new -> up
[ns_server:warn,2020-05-07T13:48:13.283Z,ns_1@127.0.0.1:<0.453.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"8383a6f8218c46cdb84a637963c66dd3">>} (valid for 0ms)
[ns_server:warn,2020-05-07T13:48:13.283Z,ns_1@127.0.0.1:<0.453.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"8383a6f8218c46cdb84a637963c66dd3">>} (valid for 0ms)
[ns_server:warn,2020-05-07T13:48:13.283Z,ns_1@127.0.0.1:<0.453.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"8383a6f8218c46cdb84a637963c66dd3">>} (valid for 0ms)
[ns_server:warn,2020-05-07T13:48:13.283Z,ns_1@127.0.0.1:<0.453.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"8383a6f8218c46cdb84a637963c66dd3">>} (valid for 0ms)
[ns_server:warn,2020-05-07T13:48:13.283Z,ns_1@127.0.0.1:<0.453.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"8383a6f8218c46cdb84a637963c66dd3">>} (valid for 0ms)
[ns_server:warn,2020-05-07T13:48:13.283Z,ns_1@127.0.0.1:<0.453.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"8383a6f8218c46cdb84a637963c66dd3">>} (valid for 0ms)
[ns_server:debug,2020-05-07T13:48:13.284Z,ns_1@127.0.0.1:leader_lease_agent<0.436.0>:leader_lease_agent:handle_lease_expired:284]Lease held by {lease_holder,<<"8383a6f8218c46cdb84a637963c66dd3">>,
                            'ns_1@127.0.0.1'} expired. Starting expirer.
[ns_server:warn,2020-05-07T13:48:13.284Z,ns_1@127.0.0.1:<0.453.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"8383a6f8218c46cdb84a637963c66dd3">>} (valid for 0ms)
[ns_server:debug,2020-05-07T13:48:13.285Z,ns_1@127.0.0.1:leader_lease_agent<0.436.0>:leader_lease_agent:do_handle_acquire_lease:147]Granting lease to {lease_holder,<<"698fcb839390f66fbf42669913324cf6">>,
                                'ns_1@127.0.0.1'} for 15000ms
[ns_server:info,2020-05-07T13:48:13.302Z,ns_1@127.0.0.1:<0.453.0>:leader_lease_acquire_worker:handle_fresh_lease_acquired:302]Acquired lease from node 'ns_1@127.0.0.1' (lease uuid: <<"698fcb839390f66fbf42669913324cf6">>)
[ns_server:info,2020-05-07T13:48:26.937Z,nonode@nohost:<0.89.0>:ns_server:init_logging:150]Started & configured logging
[ns_server:info,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_access,info},
 {disk_sink_opts,[{rotation,[{compress,true},
                             {size,41943040},
                             {num_files,10},
                             {buffer_size_max,52428800}]}]},
 {disk_sink_opts_json_rpc,[{rotation,[{compress,true},
                                      {size,41943040},
                                      {num_files,2},
                                      {buffer_size_max,52428800}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.951Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.952Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.952Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.952Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.952Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.952Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_json_rpc, which is given from command line
[ns_server:warn,2020-05-07T13:48:26.952Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2020-05-07T13:48:26.968Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.138.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:26.975Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,76}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-378cfab] [64-bit] [smp:2:2] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2020,5,7},{13,48,26}}},
               {memory,
                   [{total,110350560},
                    {processes,9482080},
                    {processes_used,9480888},
                    {system,100868480},
                    {atom,339441},
                    {atom_used,322610},
                    {binary,76336},
                    {code,7796739},
                    {ets,2241584}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,path_config,calendar,
                    ale_default_formatter,'ale_logger-metakv',
                    'ale_logger-rebalance','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-json_rpc',
                    'ale_logger-access','ale_logger-ns_server',
                    'ale_logger-user','ale_logger-ns_doctor',io_lib_fread,
                    'ale_logger-cluster','ale_logger-xdcr',otp_internal,
                    ns_log_sink,ale_disk_sink,misc,couch_util,ns_server,
                    filelib,cpu_sup,memsup,disksup,os_mon,io,release_handler,
                    overload,alarm_handler,sasl,timer,tftp_sup,httpd_sup,
                    httpc_handler_sup,httpc_cookie,inets_trace,httpc_manager,
                    httpc,httpc_profile_sup,httpc_sup,ftp_sup,inets_sup,
                    inets_app,ssl,lhttpc_manager,lhttpc_sup,lhttpc,
                    tls_connection_sup,ssl_session_cache,ssl_pkix_db,
                    ssl_manager,ssl_sup,ssl_app,crypto_server,crypto_sup,
                    crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_io,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","6.0.3-2895-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","6.0.3-2895-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,105},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [lhttpc_sup,code_server,ale_stats_events,'sink-ns_log',
                    ns_server_cluster_sup,lhttpc_manager,
                    application_controller,ale,httpd_sup,release_handler,
                    kernel_safe_sup,standard_error,ale_sup,overload,
                    'sink-disk_json_rpc',error_logger,alarm_handler,
                    'sink-disk_metakv',ale_dynamic_sup,timer_server,
                    'sink-disk_access_int',standard_error_sup,
                    'sink-disk_access','sink-disk_reports',crypto_server,
                    crypto_sup,sasl_safe_sup,'sink-disk_stats',
                    'sink-disk_xdcr',tftp_sup,inet_db,init,os_mon_sup,
                    'sink-disk_debug',rex,tls_connection_sup,user,
                    'sink-disk_error',ssl_sup,kernel_sup,cpu_sup,
                    global_name_server,memsup,'sink-disk_default',disksup,
                    httpc_sup,file_server_2,ssl_manager,local_tasks,
                    global_group,httpc_profile_sup,httpc_manager,
                    httpc_handler_sup,ftp_sup,sasl_sup,erl_prim_loader,
                    inets_sup]},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,1}]
[ns_server:info,2020-05-07T13:48:26.983Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:27]Manifest:
["<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\" />",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\" />",
 "  ","  <default remote=\"couchbase\" revision=\"master\" />","  ",
 "  <project groups=\"kv\" name=\"HdrHistogram_c\" path=\"third_party/HdrHistogram_c\" remote=\"couchbasedeps\" revision=\"d200fc0f68695d4aef1fad5c3c8cc55f8c033014\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"analytics-dcp-client\" path=\"analytics/java-dcp-client\" revision=\"d6ba66b51c0e589e9d4571264afcb0e33d507aea\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"asterixdb\" path=\"analytics/asterixdb\" revision=\"e8e59d0e6e72ba3fd96074c021ff7180261dcd59\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"c5b9dd8ec0910d2890d215075a7d2da1d6a494c9\" />",
 "  <project groups=\"kv\" name=\"benchmark\" remote=\"couchbasedeps\" revision=\"9e3465560240ffb242b50a47cb7f19251a12ee42\" />",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\" />",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5cd1345cca3ed72f1e63d41d622fcda73e63fea8\" />",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"822d01dab8721cf469beb6d8304c9eadd9c58160\" />",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"f551b6d4f32bb920a83dd28c705bddd5de0d03b2\" />",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"4b158bb555a3297565afecf6fae675c74f1e47df\" />",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\" />",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\" />",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"dc55cf8e9613ddf1bd6db4a662d1ecc3668223da\">",
 "    <annotation name=\"RELEASE\" value=\"alice\" />",
 "    <annotation name=\"PRODUCT\" value=\"couchbase-server\" />",
 "    <annotation name=\"BLD_NUM\" value=\"2895\" />",
 "    <annotation name=\"VERSION\" value=\"6.0.3\" />","  </project>",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas\" path=\"goproj/src/github.com/couchbaselabs/cbas\" remote=\"couchbase-priv\" revision=\"73fa77cd9133a9f779a484ac2caffb0b46a1dd82\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas-core\" path=\"analytics\" remote=\"couchbase-priv\" revision=\"7e513c6bd60a030c3a2477af683b264d61932a75\" />",
 "  <project groups=\"analytics\" name=\"cbas-ui\" revision=\"d8f601c3109887a30deccab09b2177bf499c8711\" />",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"0df84c7e3c6d95ff435c12a3c08c6f064db11e97\" />",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"80d2ad8892d806f5103f602fec0d80adaa4b628f\" />",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"8d4105a904e0282a6928de7392e266c58ea3c7a2\" />",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"0a94f40b9080e0ecb11d3b7531a58c5e6a4a4465\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"93d26dbc120c4f9874abb65aafa4d815334273c6\" />",
 "  <project name=\"cbsummary\" path=\"goproj/src/github.com/couchbase/cbsummary\" revision=\"dbfa1c0d73f0e49f6f04e390f03de8f9a6cee769\" />",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"dcae66272b24600ae0005fa06b511cfae8914d3d\" />",
 "  <project name=\"cobra\" path=\"godeps/src/github.com/spf13/cobra\" remote=\"couchbasedeps\" revision=\"0f056af21f5f368e5b0646079d0094a2c64150f7\" />",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\" />",
 "  <project groups=\"notdefault,kv_ee,enterprise\" name=\"couch_rocks\" remote=\"couchbase-priv\" revision=\"75f37fa46bfe5e445dee077157303968a3e09126\" />",
 "  <project name=\"couchbase-cli\" revision=\"9b383603860ce58885c27015c92635a7b42d3a1f\" />",
 "  <project name=\"couchdb\" revision=\"c2b98200b800f9fbed927c47074884b9f5f53eb4\" />",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"69aa5d92e195a30e06184911d72b8fffcf2534fe\" />",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"c2c458ff2cf93ee63bf4b0386f495b22535daf96\" />",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\" />",
 "  <project name=\"cuckoofilter\" path=\"godeps/src/github.com/seiflotfy/cuckoofilter\" remote=\"couchbasedeps\" revision=\"d04838794ab86926d32b124345777e55e6f43974\" />",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\" />",
 "  <project name=\"docloader\" path=\"goproj/src/github.com/couchbase/docloader\" revision=\"05067021a042a1b63e100a486afd7ebddab4c535\" />",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\" />",
 "  <project name=\"errors\" path=\"godeps/src/github.com/pkg/errors\" remote=\"couchbasedeps\" revision=\"30136e27e2ac8d167177e8a583aa4c3fea5be833\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"eventing\" path=\"goproj/src/github.com/couchbase/eventing\" revision=\"1da67e30a4c8faaf24f067eae280f5764d943dc2\" upstream=\"alice\" />",
 "  <project name=\"flatbuffers\" path=\"godeps/src/github.com/google/flatbuffers\" remote=\"couchbasedeps\" revision=\"1a8968225130caeddd16e227678e6f8af1926303\" />",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"c338e06e6847140f749058184d66de1f2a43474a\" />",
 "  <project name=\"fwd\" path=\"godeps/src/github.com/philhofer/fwd\" remote=\"couchbasedeps\" revision=\"bb6d471dc95d4fe11e432687f8b70ff496cf3136\" />",
 "  <project name=\"geocouch\" revision=\"2a0e73f43451045f157640eec59ced72da18471f\" />",
 "  <project name=\"ghistogram\" path=\"godeps/src/github.com/couchbase/ghistogram\" revision=\"d910dd063dd68fb4d2a1ba344440f834ebb4ef62\" />",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\" />",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"5c0ac9ef0ba7a0356279cee7eadd8874c4a8f8c1\" />",
 "  <project name=\"go-curl\" path=\"godeps/src/github.com/andelf/go-curl\" remote=\"couchbasedeps\" revision=\"f0b2afc926ec79be5d7f30393b3485352781a705\" />",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\" />",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\" />",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\" />",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\" />",
 "  <project name=\"go-sqlite3\" path=\"godeps/src/github.com/mattn/go-sqlite3\" remote=\"couchbasedeps\" revision=\"47fc4e5e9153645da45af6a86a5bce95e63a0f9e\" />",
 "  <project name=\"go-unsnap-stream\" path=\"godeps/src/github.com/glycerine/go-unsnap-stream\" remote=\"couchbasedeps\" revision=\"62a9a9eb44fd8932157b1a8ace2149eff5971af6\" />",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\" />",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"d2f15a425a9c8e4d8447e5f5b89ce14845f7fa05\" />",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\" />",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"699b13a51af5dd4f80ff3deedf41bba60debad32\" />",
 "  <project name=\"gocbconnstr\" path=\"godeps/src/gopkg.in/couchbaselabs/gocbconnstr.v1\" remote=\"couchbaselabs\" revision=\"710456e087a6d497e87f41d0a9d98d6a75672186\" />",
 "  <project name=\"gocbcore\" path=\"godeps/src/gopkg.in/couchbase/gocbcore.v7\" revision=\"a0d26c2d6f5de912499d35a5aba573006e5e036f\" />",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"aecdbe5a5a91f0688df7bdf260ca962178c06828\" />",
 "  <project name=\"gofarmhash\" path=\"godeps/src/github.com/leemcloughlin/gofarmhash\" remote=\"couchbasedeps\" revision=\"0a055c5b87a8c55ce83459cbf2776b563822a942\" />",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\" />",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\" />",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\" />",
 "  <project name=\"golang-tools\" path=\"godeps/src/golang.org/x/tools\" remote=\"couchbasedeps\" revision=\"a28dfb48e06b2296b66678872c2cb638f0304f20\" />",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\" />",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"e05ec3550789be1da2981787ef6444fef75e10bc\" />",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"4809dd3aa2ab88013b1dfce15516d717a35cb6e8\" />",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\" />",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\" />",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\" />",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"f98adca8eb365032cab838ef4d99453931afa112\" />",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"122ae25ed207cca30ceaee9ac66342a603d43a31\" />",
 "  <project groups=\"kv\" name=\"gsl-lite\" path=\"third_party/gsl-lite\" remote=\"couchbasedeps\" revision=\"57542c7e7ced375346e9ac55dad85b942cfad556\" />",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\" />",
 "  <project name=\"httprouter\" path=\"godeps/src/github.com/julienschmidt/httprouter\" remote=\"couchbasedeps\" revision=\"975b5c4c7c21c0e3d2764200bf2aa8e34657ae6e\" />",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"95ed84aad6bf8ecd99da2372dceede6d93f3d43a\" />",
 "  <project name=\"json-iterator-go\" path=\"godeps/src/github.com/json-iterator/go\" remote=\"couchbasedeps\" revision=\"f7279a603edee96fe7764d3de9c6ff8cf9970994\" />",
 "  <project name=\"jsonx\" path=\"godeps/src/gopkg.in/couchbaselabs/jsonx.v1\" remote=\"couchbaselabs\" revision=\"5b7baa20429a46a5543ee259664cc86502738cad\" />",
 "  <project groups=\"kv\" name=\"kv_engine\" revision=\"a30fd9d57cc2101078c8cd2c44968458df965c2b\" />",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"libcouchbase\" revision=\"081e8b16b991bf706eb77f8243935c6fba31b895\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"3681c2a912330352991ecdd642f257efe5b85518\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\" />",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\" />",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\" />",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"956632ec1bc3e28276d00ee2f22c3202f06efb12\" />",
 "  <project name=\"mossScope\" path=\"godeps/src/github.com/couchbase/mossScope\" revision=\"abd3b58b422dbc2e9463a589d0f3d93441726e23\" />",
 "  <project name=\"mousetrap\" path=\"godeps/src/github.com/inconshreveable/mousetrap\" remote=\"couchbasedeps\" revision=\"76626ae9c91c4f2a10f34cad8ce83ea42c93bb75\" />",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"cd8da46b9b953800d430c8b0aa4667790727ed6f\" />",
 "  <project name=\"msgp\" path=\"godeps/src/github.com/tinylib/msgp\" remote=\"couchbasedeps\" revision=\"5bb5e1aed7ba5bcc93307153b020e7ffe79b0509\" />",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"043ee6597c29786140136a5747b6a886364f5282\" />",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"62685c2d7ca23c807425dca88b11a3e2323dab41\" />",
 "  <project name=\"nitro\" path=\"goproj/src/github.com/couchbase/nitro\" revision=\"f3bef3551997be504612a2d05a8b324b3bfdfe1b\" />",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\" />",
 "  <project name=\"ns_server\" revision=\"8117c5307974f397ad831a2b870fb3ee0fd8364d\" />",
 "  <project name=\"opentracing-go\" path=\"godeps/src/github.com/opentracing/opentracing-go\" remote=\"couchbasedeps\" revision=\"1949ddbfd147afd4d964a9f00b24eb291e0e7c38\" />",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\" />",
 "  <project name=\"pflag\" path=\"godeps/src/github.com/spf13/pflag\" remote=\"couchbasedeps\" revision=\"a232f6d9f87afaaa08bafaff5da685f974b83313\" />",
 "  <project groups=\"kv\" name=\"phosphor\" revision=\"96501c57bb0fd61c85cba6f63101aed2bcf41d38\" />",
 "  <project name=\"pierrec-lz4\" path=\"godeps/src/github.com/pierrec/lz4\" remote=\"couchbasedeps\" revision=\"ed8d4cc3b461464e69798080a0092bd028910298\" />",
 "  <project name=\"pierrec-xxHash\" path=\"godeps/src/github.com/pierrec/xxHash\" remote=\"couchbasedeps\" revision=\"a0006b13c722f7f12368c00a3d3c2ae8a999a0c6\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"plasma\" path=\"goproj/src/github.com/couchbase/plasma\" remote=\"couchbase-priv\" revision=\"c0792c8cfb1463ef029f064f34e366442f1f0064\" />",
 "  <project groups=\"kv\" name=\"platform\" revision=\"de77d527bd23012dc67794c81a7b1e76e46e3abd\" />",
 "  <project groups=\"kv\" name=\"product-texts\" revision=\"8cf7d25a1dcb5434ea44983c0bed202fb9cc8351\" />",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\" />",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"d2011f6ee9f6e1dca5d3922d44fbcf86dad78150\" />",
 "  <project name=\"query-ui\" revision=\"15a6461f437fe810e411a6613ec7c143991cd1c6\" />",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\" />",
 "  <project name=\"roaring\" path=\"godeps/src/github.com/RoaringBitmap/roaring\" remote=\"couchbasedeps\" revision=\"fe09428be4c233d726797a1380f7438f4f71a31a\" />",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"762005e7a34fd909a84586299f1dd457371d36ee\" />",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"73353fe6dad8f3d67409feefb9b17f90f6de917b\" />",
 "  <project name=\"snowballstem\" path=\"godeps/src/github.com/blevesearch/snowballstem\" remote=\"blevesearch\" revision=\"26b06a2c243d4f8ca5db3486f94409dd5b2a7467\" />",
 "  <project groups=\"kv\" name=\"spdlog\" path=\"third_party/spdlog\" remote=\"couchbasedeps\" revision=\"4fba14c79f356ae48d6141c561bf9fd7ba33fabd\" />",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\" />",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"c30c3d4c250e68e81c57aa1e8ae91ffd21243cdb\" />",
 "  <project name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\" />",
 "  <project name=\"testrunner\" revision=\"4133fd785987f1ddcdb49dab736ff6e5e67d7c95\" upstream=\"alice\" />",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\" />",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"6dadf98e19803cc10ce9552bf4d9121cc2528965\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\" />",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\" />",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\" />",
 "    <copyfile dest=\".clang-format\" src=\"dot-clang-format\" />",
 "    <copyfile dest=\"third_party/CMakeLists.txt\" src=\"third-party-CMakeLists.txt\" />",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\" />",
 "  <project name=\"uuid\" path=\"godeps/src/github.com/google/uuid\" remote=\"couchbasedeps\" revision=\"dec09d789f3dba190787f8b4454c7d3c936fed9e\" />",
 "  <project name=\"vellum\" path=\"godeps/src/github.com/couchbase/vellum\" revision=\"0ceea4a37442f76199b9259840baf48d17af3c1a\" />",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"b3d83fe61db37bb38a46cd8dee434e5682cba2c7\" />",
 "  <project name=\"zstd\" path=\"godeps/src/github.com/DataDog/zstd\" remote=\"couchbasedeps\" revision=\"aebefd9fcb99f22cd691ef778a12ed68f0e6a1ab\" />",
 "</manifest>"]

[error_logger:info,2020-05-07T13:48:27.018Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.139.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:27.021Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2020-05-07T13:48:27.022Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2020-05-07T13:48:27.023Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:init:243]ip config not found. Looks like we're brand new node
[error_logger:info,2020-05-07T13:48:27.023Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.143.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2020-05-07T13:48:27.023Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.142.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:27.164Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:bringup:295]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2020-05-07T13:48:27.179Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.145.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.179Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.146.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:27.179Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:configure_net_kernel:339]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2020-05-07T13:48:27.179Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.147.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.179Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.144.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2020-05-07T13:48:27.181Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:save_node:227]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2020-05-07T13:48:27.219Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:bringup:309]Attempted to save node name to disk: ok
[ns_server:debug,2020-05-07T13:48:27.219Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:316]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2020-05-07T13:48:27.219Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T13:48:27.228Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:328]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2020-05-07T13:48:27.228Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.239Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.239Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:27.241Z,ns_1@127.0.0.1:ns_config_sup<0.154.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2020-05-07T13:48:27.241Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.155.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.241Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.156.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:27.280Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1095]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2020-05-07T13:48:27.280Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1109]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:debug,2020-05-07T13:48:27.313Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1117]Here's full dynamic config we loaded:
[[{auto_failover_cfg,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {enabled,true},
    {timeout,120},
    {count,0},
    {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
    {failover_server_group,false},
    {max_count,1},
    {failed_over_server_groups,[]}]},
  {alert_limits,
   [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
  {audit,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {enabled,[]},
    {disabled_users,[]},
    {auditd_enabled,false},
    {rotate_interval,86400},
    {rotate_size,20971520},
    {disabled,[]},
    {sync,[]},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
  {audit_decriptors,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {20480,
     [{name,<<"opened DCP connection">>},
      {description,<<"opened DCP connection">>},
      {enabled,true},
      {module,memcached}]},
    {20482,
     [{name,<<"external memcached bucket flush">>},
      {description,
       <<"External user flushed the content of a memcached bucket">>},
      {enabled,true},
      {module,memcached}]},
    {20483,
     [{name,<<"invalid packet">>},
      {description,<<"Rejected an invalid packet">>},
      {enabled,true},
      {module,memcached}]},
    {20485,
     [{name,<<"authentication succeeded">>},
      {description,<<"Authentication to the cluster succeeded">>},
      {enabled,false},
      {module,memcached}]},
    {20488,
     [{name,<<"document read">>},
      {description,<<"Document was read">>},
      {enabled,false},
      {module,memcached}]},
    {20489,
     [{name,<<"document locked">>},
      {description,<<"Document was locked">>},
      {enabled,false},
      {module,memcached}]},
    {20490,
     [{name,<<"document modify">>},
      {description,<<"Document was modified">>},
      {enabled,false},
      {module,memcached}]},
    {20491,
     [{name,<<"document delete">>},
      {description,<<"Document was deleted">>},
      {enabled,false},
      {module,memcached}]},
    {20492,
     [{name,<<"select bucket">>},
      {description,<<"The specified bucket was selected">>},
      {enabled,true},
      {module,memcached}]},
    {28672,
     [{name,<<"SELECT statement">>},
      {description,<<"A N1QL SELECT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28673,
     [{name,<<"EXPLAIN statement">>},
      {description,<<"A N1QL EXPLAIN statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28674,
     [{name,<<"PREPARE statement">>},
      {description,<<"A N1QL PREPARE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28675,
     [{name,<<"INFER statement">>},
      {description,<<"A N1QL INFER statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28676,
     [{name,<<"INSERT statement">>},
      {description,<<"A N1QL INSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28677,
     [{name,<<"UPSERT statement">>},
      {description,<<"A N1QL UPSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28678,
     [{name,<<"DELETE statement">>},
      {description,<<"A N1QL DELETE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28679,
     [{name,<<"UPDATE statement">>},
      {description,<<"A N1QL UPDATE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28680,
     [{name,<<"MERGE statement">>},
      {description,<<"A N1QL MERGE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28681,
     [{name,<<"CREATE INDEX statement">>},
      {description,<<"A N1QL CREATE INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28682,
     [{name,<<"DROP INDEX statement">>},
      {description,<<"A N1QL DROP INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28683,
     [{name,<<"ALTER INDEX statement">>},
      {description,<<"A N1QL ALTER INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28684,
     [{name,<<"BUILD INDEX statement">>},
      {description,<<"A N1QL BUILD INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28685,
     [{name,<<"GRANT ROLE statement">>},
      {description,<<"A N1QL GRANT ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28686,
     [{name,<<"REVOKE ROLE statement">>},
      {description,<<"A N1QL REVOKE ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28687,
     [{name,<<"UNRECOGNIZED statement">>},
      {description,
       <<"An unrecognized statement was received by the N1QL query engine">>},
      {enabled,false},
      {module,n1ql}]},
    {28688,
     [{name,<<"CREATE PRIMARY INDEX statement">>},
      {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28689,
     [{name,<<"/admin/stats API request">>},
      {description,<<"An HTTP request was made to the API at /admin/stats.">>},
      {enabled,false},
      {module,n1ql}]},
    {28690,
     [{name,<<"/admin/vitals API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/vitals.">>},
      {enabled,false},
      {module,n1ql}]},
    {28691,
     [{name,<<"/admin/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28692,
     [{name,<<"/admin/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28693,
     [{name,<<"/admin/indexes/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28694,
     [{name,<<"/admin/indexes/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28695,
     [{name,<<"/admin/indexes/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28697,
     [{name,<<"/admin/ping API request">>},
      {description,<<"An HTTP request was made to the API at /admin/ping.">>},
      {enabled,false},
      {module,n1ql}]},
    {28698,
     [{name,<<"/admin/config API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/config.">>},
      {enabled,false},
      {module,n1ql}]},
    {28699,
     [{name,<<"/admin/ssl_cert API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
      {enabled,false},
      {module,n1ql}]},
    {28700,
     [{name,<<"/admin/settings API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/settings.">>},
      {enabled,false},
      {module,n1ql}]},
    {28701,
     [{name,<<"/admin/clusters API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/clusters.">>},
      {enabled,false},
      {module,n1ql}]},
    {28702,
     [{name,<<"/admin/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {32768,
     [{name,<<"Create Function">>},
      {description,<<"Eventing function definition was created or updated">>},
      {enabled,true},
      {module,eventing}]},
    {32769,
     [{name,<<"Delete Function">>},
      {description,<<"Eventing function definition was deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32770,
     [{name,<<"Fetch Functions">>},
      {description,<<"Eventing function definition was read">>},
      {enabled,false},
      {module,eventing}]},
    {32771,
     [{name,<<"List Deployed">>},
      {description,<<"Eventing deployed functions list was read">>},
      {enabled,false},
      {module,eventing}]},
    {32772,
     [{name,<<"Fetch Drafts">>},
      {description,<<"Eventing function draft definitions were read">>},
      {enabled,false},
      {module,eventing}]},
    {32773,
     [{name,<<"Delete Drafts">>},
      {description,<<"Eventing function draft definitions were deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32774,
     [{name,<<"Save Draft">>},
      {description,<<"Save a draft definition to the store">>},
      {enabled,true},
      {module,eventing}]},
    {32775,
     [{name,<<"Start Debug">>},
      {description,<<"Start eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32776,
     [{name,<<"Stop Debug">>},
      {description,<<"Stop eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32777,
     [{name,<<"Start Tracing">>},
      {description,<<"Start tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32778,
     [{name,<<"Stop Tracing">>},
      {description,<<"Stop tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32779,
     [{name,<<"Set Settings">>},
      {description,<<"Save settings for a given app">>},
      {enabled,true},
      {module,eventing}]},
    {32780,
     [{name,<<"Fetch Config">>},
      {description,<<"Get config for eventing">>},
      {enabled,false},
      {module,eventing}]},
    {32781,
     [{name,<<"Save Config">>},
      {description,<<"Save config for eventing">>},
      {enabled,true},
      {module,eventing}]},
    {32782,
     [{name,<<"Cleanup Eventing">>},
      {description,<<"Clears up app definitions and settings from metakv">>},
      {enabled,true},
      {module,eventing}]},
    {32783,
     [{name,<<"Get Settings">>},
      {description,<<"Get settings for a given app">>},
      {enabled,false},
      {module,eventing}]},
    {32784,
     [{name,<<"Import Functions">>},
      {description,<<"Import a list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32785,
     [{name,<<"Export Functions">>},
      {description,<<"Export the list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32786,
     [{name,<<"List Running">>},
      {description,<<"Eventing running function list was read">>},
      {enabled,false},
      {module,eventing}]},
    {36865,
     [{name,<<"Service configuration change">>},
      {description,<<"A successful service configuration change was made.">>},
      {enabled,true},
      {module,analytics}]},
    {36866,
     [{name,<<"Node configuration change">>},
      {description,<<"A successful node configuration change was made.">>},
      {enabled,true},
      {module,analytics}]}]},
  {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
  {autocompaction,
   [{database_fragmentation_threshold,{30,undefined}},
    {view_fragmentation_threshold,{30,undefined}}]},
  {buckets,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]},
    {configs,[]}]},
  {cbas_memory_quota,1024},
  {cert_and_pkey,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQlsomKQ7qhDcAeKZ3inWuCQuv8NxCAMb8M\nXhrVTrshZyFDiXdKS3Xbshyc9dEOiDwuDwAEgfwJQsXzzx0eCRtyTZfWAWTOH06O\nXdQps+9iTfr2KBFj27uag5c5ns+0ojsNyqZhA4+dbS7zK3CZ1dx7LPkL3+4HTlMh\nmH1/2fib3Lbp6dW3B55GV8/RHbkzgcRMyBicYtinqh6JMmmzjO/3KEyVHs3h0W1E\n00JdAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCKWU+bCvjKUlhW\niMiAN7r/3Vxkah7KEqp8BajCnLrlTMeiV+24TlPrsCWz4VBmOgt8OcijS3axdEik\nXeteeJp+R8nb2XPGivHOg/Hx2NlLxCrtXaYVGM0PiVydo24iCv0ZlqMCBsrzRLky\n5otbfQi8ngdfuR88C0/r3RLqvuFnOtFkLbKXuT/qshXfM8O/OgiJkr6CTBFYNd8w\nTCxN2syK41/HXoYzexdA/OTSm+kuEIuDpQYxKS0M4oKKZApJM70y/CYTzwG3JOnp\nuteZPYrwhIqxz01fkbLnj3QLGxPpSexRsp52GOoCv/YEE7tl3Olt4+p+MvhEZPdZ\ndqB53mNJ\n-----END CERTIFICATE-----\n">>,
     <<"*****">>}]},
  {client_cert_auth,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    {state,"disable"},
    {prefixes,[]}]},
  {cluster_compat_version,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},
    6,0]},
  {drop_request_memory_threshold_mib,undefined},
  {email_alerts,
   [{recipients,["root@localhost"]},
    {sender,"couchbase@localhost"},
    {enabled,false},
    {email_server,
     [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
    {alerts,
     [auto_failover_node,auto_failover_maximum_reached,
      auto_failover_other_nodes_down,auto_failover_cluster_too_small,
      auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
      ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
      ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
  {fts_memory_quota,256},
  {index_aware_rebalance_disabled,false},
  {log_redaction_default_cfg,[{redact_level,none}]},
  {max_bucket_count,10},
  {memcached,[]},
  {memory_quota,311},
  {nodes_wanted,['ns_1@127.0.0.1']},
  {otp,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
    {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]},
  {password_policy,[{min_length,6},{must_present,[]}]},
  {quorum_nodes,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
    'ns_1@127.0.0.1']},
  {read_only_user_creds,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {remote_clusters,[]},
  {replication,[{enabled,true}]},
  {rest,[{port,8091}]},
  {rest_creds,null},
  {roles_definitions,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {scramsha_fallback_salt,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<169,238,80,91,5,165,74,47,79,135,45,74>>]},
  {secure_headers,[]},
  {server_groups,
   [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
  {set_view_update_daemon,
   [{update_interval,5000},
    {update_min_changes,5000},
    {replica_update_min_changes,5000}]},
  {users_upgrade,
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {{couchdb,max_parallel_indexers},4},
  {{couchdb,max_parallel_replica_indexers},2},
  {{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{10,63756078478}}]}]},
  {{metakv,<<"/eventing/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"ram_quota\":256}">>]},
  {{metakv,<<"/indexing/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
  {{metakv,<<"/query/settings/config">>},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
  {{rbac_upgrade,[5,5]},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
    '_deleted']},
  {{request_limit,capi},undefined},
  {{request_limit,rest},undefined},
  {{service_map,fts},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{service_map,index},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{service_map,n1ql},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
  {{node,'ns_1@127.0.0.1',audit},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
  {{node,'ns_1@127.0.0.1',capi_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8092]},
  {{node,'ns_1@127.0.0.1',cbas_admin_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9110]},
  {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9113]},
  {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9112]},
  {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9111]},
  {{node,'ns_1@127.0.0.1',cbas_cluster_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9115]},
  {{node,'ns_1@127.0.0.1',cbas_console_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9114]},
  {{node,'ns_1@127.0.0.1',cbas_data_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9116]},
  {{node,'ns_1@127.0.0.1',cbas_debug_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    -1]},
  {{node,'ns_1@127.0.0.1',cbas_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8095]},
  {{node,'ns_1@127.0.0.1',cbas_messaging_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9118]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9119]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9121]},
  {{node,'ns_1@127.0.0.1',cbas_parent_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9122]},
  {{node,'ns_1@127.0.0.1',cbas_replication_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9120]},
  {{node,'ns_1@127.0.0.1',cbas_result_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9117]},
  {{node,'ns_1@127.0.0.1',cbas_ssl_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18095]},
  {{node,'ns_1@127.0.0.1',compaction_daemon},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {check_interval,30},
    {min_db_file_size,131072},
    {min_view_file_size,20971520}]},
  {{node,'ns_1@127.0.0.1',config_version},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {5,5,3}]},
  {{node,'ns_1@127.0.0.1',eventing_debug_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9140]},
  {{node,'ns_1@127.0.0.1',eventing_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8096]},
  {{node,'ns_1@127.0.0.1',eventing_https_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18096]},
  {{node,'ns_1@127.0.0.1',fts_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8094]},
  {{node,'ns_1@127.0.0.1',fts_ssl_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18094]},
  {{node,'ns_1@127.0.0.1',indexer_admin_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9100]},
  {{node,'ns_1@127.0.0.1',indexer_http_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9102]},
  {{node,'ns_1@127.0.0.1',indexer_https_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    19102]},
  {{node,'ns_1@127.0.0.1',indexer_scan_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9101]},
  {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9104]},
  {{node,'ns_1@127.0.0.1',indexer_stinit_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9103]},
  {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9105]},
  {{node,'ns_1@127.0.0.1',is_enterprise},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',isasl},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
  {{node,'ns_1@127.0.0.1',ldap_enabled},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',membership},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    active]},
  {{node,'ns_1@127.0.0.1',memcached},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,11210},
    {dedicated_port,11209},
    {ssl_port,11207},
    {admin_user,"@ns_server"},
    {other_users,
     ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
      "@cbas"]},
    {admin_pass,"*****"},
    {engines,
     [{membase,
       [{engine,"/opt/couchbase/lib/memcached/ep.so"},
        {static_config_string,"failpartialwarmup=false"}]},
      {memcached,
       [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
        {static_config_string,"vb0=true"}]}]},
    {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
    {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
    {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
    {log_prefix,"memcached.log"},
    {log_generations,20},
    {log_cyclesize,10485760},
    {log_sleeptime,19},
    {log_rotation_period,39003}]},
  {{node,'ns_1@127.0.0.1',memcached_config},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    {[{interfaces,
       {memcached_config_mgr,omit_missing_mcd_ports,
        [{[{host,<<"*">>},
           {port,port},
           {maxconn,maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,dedicated_port},
           {maxconn,dedicated_port_maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,ssl_port},
           {maxconn,maxconn},
           {ssl,
            {[{key,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
              {cert,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]}]}},
      {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
      {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
      {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
      {connection_idle_time,connection_idle_time},
      {privilege_debug,privilege_debug},
      {breakpad,
       {[{enabled,breakpad_enabled},
         {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
      {admin,{"~s",[admin_user]}},
      {verbosity,verbosity},
      {audit_file,{"~s",[audit_file]}},
      {rbac_file,{"~s",[rbac_file]}},
      {dedupe_nmvb_maps,dedupe_nmvb_maps},
      {tracing_enabled,tracing_enabled},
      {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
      {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
      {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
      {logger,
       {[{filename,{"~s/~s",[log_path,log_prefix]}},
         {cyclesize,log_cyclesize},
         {sleeptime,log_sleeptime}]}}]}]},
  {{node,'ns_1@127.0.0.1',memcached_defaults},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {maxconn,30000},
    {dedicated_port_maxconn,5000},
    {ssl_cipher_list,"HIGH"},
    {connection_idle_time,0},
    {verbosity,0},
    {privilege_debug,false},
    {breakpad_enabled,true},
    {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
    {dedupe_nmvb_maps,false},
    {tracing_enabled,true},
    {datatype_snappy,true}]},
  {{node,'ns_1@127.0.0.1',moxi},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,11211},
    {verbosity,[]}]},
  {{node,'ns_1@127.0.0.1',ns_log},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
  {{node,'ns_1@127.0.0.1',port_servers},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
  {{node,'ns_1@127.0.0.1',projector_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9999]},
  {{node,'ns_1@127.0.0.1',query_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    8093]},
  {{node,'ns_1@127.0.0.1',rest},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
    {port,8091},
    {port_meta,global}]},
  {{node,'ns_1@127.0.0.1',ssl_capi_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18092]},
  {{node,'ns_1@127.0.0.1',ssl_query_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18093]},
  {{node,'ns_1@127.0.0.1',ssl_rest_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    18091]},
  {{node,'ns_1@127.0.0.1',uuid},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    <<"0f8760945f98b1efdbef0bd1ea6e8446">>]},
  {{node,'ns_1@127.0.0.1',xdcr_rest_port},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    9998]},
  {{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
   [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
    false]}]]
[ns_server:info,2020-05-07T13:48:27.319Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1138]Here's full dynamic config we loaded + static & default config:
[{{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   false]},
 {{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   <<"0f8760945f98b1efdbef0bd1ea6e8446">>]},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,8091},
   {port_meta,global}]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11211},
   {verbosity,[]}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {privilege_debug,false},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false},
   {tracing_enabled,true},
   {datatype_snappy,true}]},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},
          {port,port},
          {maxconn,maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {privilege_debug,privilege_debug},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {rbac_file,{"~s",[rbac_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps},
     {tracing_enabled,tracing_enabled},
     {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
     {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
     {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
     {logger,
      {[{filename,{"~s/~s",[log_path,log_prefix]}},
        {cyclesize,log_cyclesize},
        {sleeptime,log_sleeptime}]}}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"@ns_server"},
   {other_users,
    ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
     "@cbas"]},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   active]},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   19102]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',fts_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18094]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',eventing_https_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18096]},
 {{node,'ns_1@127.0.0.1',eventing_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8096]},
 {{node,'ns_1@127.0.0.1',eventing_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9140]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {5,5,3}]},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {{node,'ns_1@127.0.0.1',cbas_ssl_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   18095]},
 {{node,'ns_1@127.0.0.1',cbas_result_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9117]},
 {{node,'ns_1@127.0.0.1',cbas_replication_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9120]},
 {{node,'ns_1@127.0.0.1',cbas_parent_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9122]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9121]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9119]},
 {{node,'ns_1@127.0.0.1',cbas_messaging_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9118]},
 {{node,'ns_1@127.0.0.1',cbas_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8095]},
 {{node,'ns_1@127.0.0.1',cbas_debug_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]},
 {{node,'ns_1@127.0.0.1',cbas_data_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9116]},
 {{node,'ns_1@127.0.0.1',cbas_console_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9114]},
 {{node,'ns_1@127.0.0.1',cbas_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9115]},
 {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9111]},
 {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9112]},
 {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9113]},
 {{node,'ns_1@127.0.0.1',cbas_admin_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   9110]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]},
 {{service_map,n1ql},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{service_map,index},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{service_map,fts},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]},
 {{request_limit,rest},undefined},
 {{request_limit,capi},undefined},
 {{rbac_upgrade,[5,5]},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {{metakv,<<"/query/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
 {{metakv,<<"/indexing/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
 {{metakv,<<"/eventing/settings/config">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<"{\"ram_quota\":256}">>]},
 {{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>},
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{10,63756078478}}]}]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {users_upgrade,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {secure_headers,[]},
 {scramsha_fallback_salt,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   <<169,238,80,91,5,165,74,47,79,135,45,74>>]},
 {roles_definitions,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {rest_creds,null},
 {rest,[{port,8091}]},
 {replication,[{enabled,true}]},
 {remote_clusters,[]},
 {read_only_user_creds,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
   '_deleted']},
 {quorum_nodes,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   'ns_1@127.0.0.1']},
 {password_policy,[{min_length,6},{must_present,[]}]},
 {otp,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
   {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {memory_quota,311},
 {memcached,[]},
 {max_bucket_count,10},
 {log_redaction_default_cfg,[{redact_level,none}]},
 {index_aware_rebalance_disabled,false},
 {fts_memory_quota,256},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
 {drop_request_memory_threshold_mib,undefined},
 {cluster_compat_version,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},
   6,0]},
 {client_cert_auth,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {state,"disable"},
   {prefixes,[]}]},
 {cert_and_pkey,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
   {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQlsomKQ7qhDcAeKZ3inWuCQuv8NxCAMb8M\nXhrVTrshZyFDiXdKS3Xbshyc9dEOiDwuDwAEgfwJQsXzzx0eCRtyTZfWAWTOH06O\nXdQps+9iTfr2KBFj27uag5c5ns+0ojsNyqZhA4+dbS7zK3CZ1dx7LPkL3+4HTlMh\nmH1/2fib3Lbp6dW3B55GV8/RHbkzgcRMyBicYtinqh6JMmmzjO/3KEyVHs3h0W1E\n00JdAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCKWU+bCvjKUlhW\niMiAN7r/3Vxkah7KEqp8BajCnLrlTMeiV+24TlPrsCWz4VBmOgt8OcijS3axdEik\nXeteeJp+R8nb2XPGivHOg/Hx2NlLxCrtXaYVGM0PiVydo24iCv0ZlqMCBsrzRLky\n5otbfQi8ngdfuR88C0/r3RLqvuFnOtFkLbKXuT/qshXfM8O/OgiJkr6CTBFYNd8w\nTCxN2syK41/HXoYzexdA/OTSm+kuEIuDpQYxKS0M4oKKZApJM70y/CYTzwG3JOnp\nuteZPYrwhIqxz01fkbLnj3QLGxPpSexRsp52GOoCv/YEE7tl3Olt4+p+MvhEZPdZ\ndqB53mNJ\n-----END CERTIFICATE-----\n">>,
    <<"*****">>}]},
 {cbas_memory_quota,1024},
 {buckets,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}]},
   {configs,[]}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
 {audit_decriptors,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {20480,
    [{name,<<"opened DCP connection">>},
     {description,<<"opened DCP connection">>},
     {enabled,true},
     {module,memcached}]},
   {20482,
    [{name,<<"external memcached bucket flush">>},
     {description,
      <<"External user flushed the content of a memcached bucket">>},
     {enabled,true},
     {module,memcached}]},
   {20483,
    [{name,<<"invalid packet">>},
     {description,<<"Rejected an invalid packet">>},
     {enabled,true},
     {module,memcached}]},
   {20485,
    [{name,<<"authentication succeeded">>},
     {description,<<"Authentication to the cluster succeeded">>},
     {enabled,false},
     {module,memcached}]},
   {20488,
    [{name,<<"document read">>},
     {description,<<"Document was read">>},
     {enabled,false},
     {module,memcached}]},
   {20489,
    [{name,<<"document locked">>},
     {description,<<"Document was locked">>},
     {enabled,false},
     {module,memcached}]},
   {20490,
    [{name,<<"document modify">>},
     {description,<<"Document was modified">>},
     {enabled,false},
     {module,memcached}]},
   {20491,
    [{name,<<"document delete">>},
     {description,<<"Document was deleted">>},
     {enabled,false},
     {module,memcached}]},
   {20492,
    [{name,<<"select bucket">>},
     {description,<<"The specified bucket was selected">>},
     {enabled,true},
     {module,memcached}]},
   {28672,
    [{name,<<"SELECT statement">>},
     {description,<<"A N1QL SELECT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28673,
    [{name,<<"EXPLAIN statement">>},
     {description,<<"A N1QL EXPLAIN statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28674,
    [{name,<<"PREPARE statement">>},
     {description,<<"A N1QL PREPARE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28675,
    [{name,<<"INFER statement">>},
     {description,<<"A N1QL INFER statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28676,
    [{name,<<"INSERT statement">>},
     {description,<<"A N1QL INSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28677,
    [{name,<<"UPSERT statement">>},
     {description,<<"A N1QL UPSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28678,
    [{name,<<"DELETE statement">>},
     {description,<<"A N1QL DELETE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28679,
    [{name,<<"UPDATE statement">>},
     {description,<<"A N1QL UPDATE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28680,
    [{name,<<"MERGE statement">>},
     {description,<<"A N1QL MERGE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28681,
    [{name,<<"CREATE INDEX statement">>},
     {description,<<"A N1QL CREATE INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28682,
    [{name,<<"DROP INDEX statement">>},
     {description,<<"A N1QL DROP INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28683,
    [{name,<<"ALTER INDEX statement">>},
     {description,<<"A N1QL ALTER INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28684,
    [{name,<<"BUILD INDEX statement">>},
     {description,<<"A N1QL BUILD INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28685,
    [{name,<<"GRANT ROLE statement">>},
     {description,<<"A N1QL GRANT ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28686,
    [{name,<<"REVOKE ROLE statement">>},
     {description,<<"A N1QL REVOKE ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28687,
    [{name,<<"UNRECOGNIZED statement">>},
     {description,
      <<"An unrecognized statement was received by the N1QL query engine">>},
     {enabled,false},
     {module,n1ql}]},
   {28688,
    [{name,<<"CREATE PRIMARY INDEX statement">>},
     {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28689,
    [{name,<<"/admin/stats API request">>},
     {description,<<"An HTTP request was made to the API at /admin/stats.">>},
     {enabled,false},
     {module,n1ql}]},
   {28690,
    [{name,<<"/admin/vitals API request">>},
     {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
     {enabled,false},
     {module,n1ql}]},
   {28691,
    [{name,<<"/admin/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28692,
    [{name,<<"/admin/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28693,
    [{name,<<"/admin/indexes/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28694,
    [{name,<<"/admin/indexes/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28695,
    [{name,<<"/admin/indexes/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28697,
    [{name,<<"/admin/ping API request">>},
     {description,<<"An HTTP request was made to the API at /admin/ping.">>},
     {enabled,false},
     {module,n1ql}]},
   {28698,
    [{name,<<"/admin/config API request">>},
     {description,<<"An HTTP request was made to the API at /admin/config.">>},
     {enabled,false},
     {module,n1ql}]},
   {28699,
    [{name,<<"/admin/ssl_cert API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
     {enabled,false},
     {module,n1ql}]},
   {28700,
    [{name,<<"/admin/settings API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/settings.">>},
     {enabled,false},
     {module,n1ql}]},
   {28701,
    [{name,<<"/admin/clusters API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/clusters.">>},
     {enabled,false},
     {module,n1ql}]},
   {28702,
    [{name,<<"/admin/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {32768,
    [{name,<<"Create Function">>},
     {description,<<"Eventing function definition was created or updated">>},
     {enabled,true},
     {module,eventing}]},
   {32769,
    [{name,<<"Delete Function">>},
     {description,<<"Eventing function definition was deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32770,
    [{name,<<"Fetch Functions">>},
     {description,<<"Eventing function definition was read">>},
     {enabled,false},
     {module,eventing}]},
   {32771,
    [{name,<<"List Deployed">>},
     {description,<<"Eventing deployed functions list was read">>},
     {enabled,false},
     {module,eventing}]},
   {32772,
    [{name,<<"Fetch Drafts">>},
     {description,<<"Eventing function draft definitions were read">>},
     {enabled,false},
     {module,eventing}]},
   {32773,
    [{name,<<"Delete Drafts">>},
     {description,<<"Eventing function draft definitions were deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32774,
    [{name,<<"Save Draft">>},
     {description,<<"Save a draft definition to the store">>},
     {enabled,true},
     {module,eventing}]},
   {32775,
    [{name,<<"Start Debug">>},
     {description,<<"Start eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32776,
    [{name,<<"Stop Debug">>},
     {description,<<"Stop eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32777,
    [{name,<<"Start Tracing">>},
     {description,<<"Start tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32778,
    [{name,<<"Stop Tracing">>},
     {description,<<"Stop tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32779,
    [{name,<<"Set Settings">>},
     {description,<<"Save settings for a given app">>},
     {enabled,true},
     {module,eventing}]},
   {32780,
    [{name,<<"Fetch Config">>},
     {description,<<"Get config for eventing">>},
     {enabled,false},
     {module,eventing}]},
   {32781,
    [{name,<<"Save Config">>},
     {description,<<"Save config for eventing">>},
     {enabled,true},
     {module,eventing}]},
   {32782,
    [{name,<<"Cleanup Eventing">>},
     {description,<<"Clears up app definitions and settings from metakv">>},
     {enabled,true},
     {module,eventing}]},
   {32783,
    [{name,<<"Get Settings">>},
     {description,<<"Get settings for a given app">>},
     {enabled,false},
     {module,eventing}]},
   {32784,
    [{name,<<"Import Functions">>},
     {description,<<"Import a list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32785,
    [{name,<<"Export Functions">>},
     {description,<<"Export the list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32786,
    [{name,<<"List Running">>},
     {description,<<"Eventing running function list was read">>},
     {enabled,false},
     {module,eventing}]},
   {36865,
    [{name,<<"Service configuration change">>},
     {description,<<"A successful service configuration change was made.">>},
     {enabled,true},
     {module,analytics}]},
   {36866,
    [{name,<<"Node configuration change">>},
     {description,<<"A successful node configuration change was made.">>},
     {enabled,true},
     {module,analytics}]}]},
 {audit,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {enabled,[]},
   {disabled_users,[]},
   {auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {auto_failover_cfg,
  [{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
   {enabled,true},
   {timeout,120},
   {count,0},
   {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
   {failover_server_group,false},
   {max_count,1},
   {failed_over_server_groups,[]}]}]
[error_logger:info,2020-05-07T13:48:27.325Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.157.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.328Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.163.0>},
                       {name,ns_config_remote},
                       {mfargs,{ns_config_replica,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.329Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.164.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.329Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:27.331Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.166.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.332Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.167.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:27.343Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.170.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:27.345Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2020-05-07T13:48:27.345Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.171.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.345Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.172.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.353Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.173.0>},
                       {name,memcached_refresh},
                       {mfargs,{memcached_refresh,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.354Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.175.0>},
                       {name,ssl_service_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ssl_service_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:27.369Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:init:419]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem-ca"},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[error_logger:info,2020-05-07T13:48:27.411Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.176.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:27.428Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T13:48:27.428Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T13:48:27.429Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T13:48:27.429Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[ns_server:debug,2020-05-07T13:48:27.446Z,ns_1@127.0.0.1:<0.178.0>:restartable:start_child:98]Started child process <0.179.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2020-05-07T13:48:27.446Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.178.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.446Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.174.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:27.448Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.197.0>},
                       {name,user_storage_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,user_storage_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.458Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.199.0>},
                       {name,users_replicator},
                       {mfargs,{menelaus_users,start_replicator,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:27.460Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:55]Start waiting for startup
[ns_server:debug,2020-05-07T13:48:27.462Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_storage:anounce_startup:69]Announce my startup to <0.199.0>
[ns_server:debug,2020-05-07T13:48:27.462Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:58]Received replicated storage registration from <0.200.0>
[ns_server:debug,2020-05-07T13:48:27.465Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:open:212]Opening file "/opt/couchbase/var/lib/couchbase/config/users.dets"
[error_logger:info,2020-05-07T13:48:27.465Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.200.0>},
                       {name,users_storage},
                       {mfargs,{menelaus_users,start_storage,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.465Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.198.0>},
                       {name,users_storage_sup},
                       {mfargs,{users_storage_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T13:48:27.479Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:init:44]Starting versioned cache compiled_roles_cache
[error_logger:info,2020-05-07T13:48:27.479Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.202.0>},
                       {name,compiled_roles_cache},
                       {mfargs,{menelaus_roles,start_compiled_roles_cache,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.479Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.196.0>},
                       {name,users_sup},
                       {mfargs,{users_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:27.481Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.205.0>},
                       {name,dets_sup},
                       {mfargs,{dets_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:27.481Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.206.0>},
                       {name,dets},
                       {mfargs,{dets_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:27.496Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:convert_docs_to_55_in_dets:243]Checking for pre 5.5 records in dets: users_storage
[ns_server:debug,2020-05-07T13:48:27.496Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,'$1','_','$2'},
                                      [],
                                      [{{'$1','$2'}}]}],
                                    100}
[ns_server:debug,2020-05-07T13:48:27.496Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:init_after_ack:204]Loading 0 items, 299 words took 0ms
[ns_server:debug,2020-05-07T13:48:27.501Z,ns_1@127.0.0.1:users_replicator<0.199.0>:doc_replicator:loop:60]doing replicate_newnodes_docs
[ns_server:debug,2020-05-07T13:48:27.504Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.210.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:141]Waiting for ns_couchdb node to start
[error_logger:info,2020-05-07T13:48:27.504Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.209.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:27.504Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T13:48:27.505Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.213.0>,shutdown}}
[error_logger:info,2020-05-07T13:48:27.505Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T13:48:27.505Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T13:48:27.706Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T13:48:27.706Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.216.0>,shutdown}}
[error_logger:info,2020-05-07T13:48:27.706Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T13:48:27.706Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T13:48:27.907Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2020-05-07T13:48:27.907Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.219.0>,shutdown}}
[error_logger:info,2020-05-07T13:48:27.907Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T13:48:27.907Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2020-05-07T13:48:28.108Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2020-05-07T13:48:28.132Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T13:48:28.333Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T13:48:28.534Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T13:48:28.735Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2020-05-07T13:48:28.936Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[error_logger:info,2020-05-07T13:48:29.375Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.229.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:29.576Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: Apache CouchDB v4.5.1-112-gc2b9820 (LogLevel=info) is starting.
ns_couchdb<0.209.0>: Apache CouchDB has started. Time to relax.

[error_logger:info,2020-05-07T13:48:29.685Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.210.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.96617950>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:29.698Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:ns_storage_conf:setup_db_and_ix_paths:47]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2020-05-07T13:48:29.708Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.232.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.710Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.233.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:29.711Z,ns_1@127.0.0.1:ns_server_sup<0.231.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2020-05-07T13:48:29.718Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.234.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.720Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.235.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.723Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.236.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.723Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.237.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:29.738Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:memcached_cfg:init:62]Init config writer for memcached_passwords, "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T13:48:29.739Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T13:48:29.775Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.238.0>
[ns_server:debug,2020-05-07T13:48:29.775Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T13:48:29.775Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.238.0>
[ns_server:debug,2020-05-07T13:48:29.784Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[error_logger:info,2020-05-07T13:48:29.784Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.238.0>},
                       {name,memcached_passwords},
                       {mfargs,{memcached_passwords,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:29.793Z,ns_1@127.0.0.1:memcached_permissions<0.241.0>:memcached_cfg:init:62]Init config writer for memcached_permissions, "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2020-05-07T13:48:29.794Z,ns_1@127.0.0.1:memcached_permissions<0.241.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:warn,2020-05-07T13:48:29.794Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T13:48:29.794Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [isasl] failed. Retry in 1000 ms.
[ns_server:debug,2020-05-07T13:48:29.795Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.241.0>
[ns_server:debug,2020-05-07T13:48:29.796Z,ns_1@127.0.0.1:memcached_permissions<0.241.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{user,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T13:48:29.796Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.241.0>
[ns_server:debug,2020-05-07T13:48:29.802Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of rbac requested
[error_logger:info,2020-05-07T13:48:29.802Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.241.0>},
                       {name,memcached_permissions},
                       {mfargs,{memcached_permissions,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.802Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.244.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T13:48:29.803Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T13:48:29.803Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2020-05-07T13:48:29.808Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.246.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:29.808Z,ns_1@127.0.0.1:ns_node_disco<0.247.0>:ns_node_disco:init:130]Initting ns_node_disco with []
[ns_server:debug,2020-05-07T13:48:29.808Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[user:info,2020-05-07T13:48:29.808Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:127]Node 'ns_1@127.0.0.1' synchronized otp cookie {sanitized,
                                               <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>} from cluster
[ns_server:debug,2020-05-07T13:48:29.809Z,ns_1@127.0.0.1:<0.248.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T13:48:29.812Z,ns_1@127.0.0.1:<0.248.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[error_logger:info,2020-05-07T13:48:29.812Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.247.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.814Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.249.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.815Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.250.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.817Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:29.817Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:69]init pulling
[ns_server:debug,2020-05-07T13:48:29.817Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:71]init pushing
[ns_server:debug,2020-05-07T13:48:29.826Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:75]init reannouncing
[ns_server:debug,2020-05-07T13:48:29.826Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:handle_info:89]Flushing cache compiled_roles_cache due to version change from undefined to {[6,
                                                                              0],
                                                                             {0,
                                                                              395463458},
                                                                             false,
                                                                             []}
[ns_server:debug,2020-05-07T13:48:29.828Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2020-05-07T13:48:29.829Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T13:48:29.829Z,ns_1@127.0.0.1:<0.260.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T13:48:29.829Z,ns_1@127.0.0.1:<0.260.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T13:48:29.829Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2020-05-07T13:48:29.829Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2020-05-07T13:48:29.829Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2020-05-07T13:48:29.829Z,ns_1@127.0.0.1:<0.261.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T13:48:29.829Z,ns_1@127.0.0.1:<0.261.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}
[ns_server:debug,2020-05-07T13:48:29.829Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2020-05-07T13:48:29.829Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,[]},
 {disabled_users,[]},
 {auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2020-05-07T13:48:29.831Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit_decriptors ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {20480,
  [{name,<<"opened DCP connection">>},
   {description,<<"opened DCP connection">>},
   {enabled,true},
   {module,memcached}]},
 {20482,
  [{name,<<"external memcached bucket flush">>},
   {description,<<"External user flushed the content of a memcached bucket">>},
   {enabled,true},
   {module,memcached}]},
 {20483,
  [{name,<<"invalid packet">>},
   {description,<<"Rejected an invalid packet">>},
   {enabled,true},
   {module,memcached}]},
 {20485,
  [{name,<<"authentication succeeded">>},
   {description,<<"Authentication to the cluster succeeded">>},
   {enabled,false},
   {module,memcached}]},
 {20488,
  [{name,<<"document read">>},
   {description,<<"Document was read">>},
   {enabled,false},
   {module,memcached}]},
 {20489,
  [{name,<<"document locked">>},
   {description,<<"Document was locked">>},
   {enabled,false},
   {module,memcached}]},
 {20490,
  [{name,<<"document modify">>},
   {description,<<"Document was modified">>},
   {enabled,false},
   {module,memcached}]},
 {20491,
  [{name,<<"document delete">>},
   {description,<<"Document was deleted">>},
   {enabled,false},
   {module,memcached}]},
 {20492,
  [{name,<<"select bucket">>},
   {description,<<"The specified bucket was selected">>},
   {enabled,true},
   {module,memcached}]},
 {28672,
  [{name,<<"SELECT statement">>},
   {description,<<"A N1QL SELECT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28673,
  [{name,<<"EXPLAIN statement">>},
   {description,<<"A N1QL EXPLAIN statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28674,
  [{name,<<"PREPARE statement">>},
   {description,<<"A N1QL PREPARE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28675,
  [{name,<<"INFER statement">>},
   {description,<<"A N1QL INFER statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28676,
  [{name,<<"INSERT statement">>},
   {description,<<"A N1QL INSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28677,
  [{name,<<"UPSERT statement">>},
   {description,<<"A N1QL UPSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28678,
  [{name,<<"DELETE statement">>},
   {description,<<"A N1QL DELETE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28679,
  [{name,<<"UPDATE statement">>},
   {description,<<"A N1QL UPDATE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28680,
  [{name,<<"MERGE statement">>},
   {description,<<"A N1QL MERGE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28681,
  [{name,<<"CREATE INDEX statement">>},
   {description,<<"A N1QL CREATE INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28682,
  [{name,<<"DROP INDEX statement">>},
   {description,<<"A N1QL DROP INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28683,
  [{name,<<"ALTER INDEX statement">>},
   {description,<<"A N1QL ALTER INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28684,
  [{name,<<"BUILD INDEX statement">>},
   {description,<<"A N1QL BUILD INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28685,
  [{name,<<"GRANT ROLE statement">>},
   {description,<<"A N1QL GRANT ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28686,
  [{name,<<"REVOKE ROLE statement">>},
   {description,<<"A N1QL REVOKE ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28687,
  [{name,<<"UNRECOGNIZED statement">>},
   {description,<<"An unrecognized statement was received by the N1QL query engine">>},
   {enabled,false},
   {module,n1ql}]},
 {28688,
  [{name,<<"CREATE PRIMARY INDEX statement">>},
   {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28689,
  [{name,<<"/admin/stats API request">>},
   {description,<<"An HTTP request was made to the API at /admin/stats.">>},
   {enabled,false},
   {module,n1ql}]},
 {28690,
  [{name,<<"/admin/vitals API request">>},
   {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
   {enabled,false},
   {module,n1ql}]},
 {28691,
  [{name,<<"/admin/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28692,
  [{name,<<"/admin/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28693,
  [{name,<<"/admin/indexes/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28694,
  [{name,<<"/admin/indexes/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28695,
  [{name,<<"/admin/indexes/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28697,
  [{name,<<"/admin/ping API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ping.">>},
   {enabled,false},
   {module,n1ql}]},
 {28698,
  [{name,<<"/admin/config API request">>},
   {description,<<"An HTTP request was made to the API at /admin/config.">>},
   {enabled,false},
   {module,n1ql}]},
 {28699,
  [{name,<<"/admin/ssl_cert API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ssl_cert.">>},
   {enabled,false},
   {module,n1ql}]},
 {28700,
  [{name,<<"/admin/settings API request">>},
   {description,<<"An HTTP request was made to the API at /admin/settings.">>},
   {enabled,false},
   {module,n1ql}]},
 {28701,
  [{name,<<"/admin/clusters API request">>},
   {description,<<"An HTTP request was made to the API at /admin/clusters.">>},
   {enabled,false},
   {module,n1ql}]},
 {28702,
  [{name,<<"/admin/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {32768,
  [{name,<<"Create Function">>},
   {description,<<"Eventing function definition was created or updated">>},
   {enabled,true},
   {module,eventing}]},
 {32769,
  [{name,<<"Delete Function">>},
   {description,<<"Eventing function definition was deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32770,
  [{name,<<"Fetch Functions">>},
   {description,<<"Eventing function definition was read">>},
   {enabled,false},
   {module,eventing}]},
 {32771,
  [{name,<<"List Deployed">>},
   {description,<<"Eventing deployed functions list was read">>},
   {enabled,false},
   {module,eventing}]},
 {32772,
  [{name,<<"Fetch Drafts">>},
   {description,<<"Eventing function draft definitions were read">>},
   {enabled,false},
   {module,eventing}]},
 {32773,
  [{name,<<"Delete Drafts">>},
   {description,<<"Eventing function draft definitions were deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32774,
  [{name,<<"Save Draft">>},
   {description,<<"Save a draft definition to the store">>},
   {enabled,true},
   {module,eventing}]},
 {32775,
  [{name,<<"Start Debug">>},
   {description,<<"Start eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32776,
  [{name,<<"Stop Debug">>},
   {description,<<"Stop eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32777,
  [{name,<<"Start Tracing">>},
   {description,<<"Start tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32778,
  [{name,<<"Stop Tracing">>},
   {description,<<"Stop tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32779,
  [{name,<<"Set Settings">>},
   {description,<<"Save settings for a given app">>},
   {enabled,true},
   {module,eventing}]},
 {32780,
  [{name,<<"Fetch Config">>},
   {description,<<"Get config for eventing">>},
   {enabled,false},
   {module,eventing}]},
 {32781,
  [{name,<<"Save Config">>},
   {description,<<"Save config for eventing">>},
   {enabled,true},
   {module,eventing}]},
 {32782,
  [{name,<<"Cleanup Eventing">>},
   {description,<<"Clears up app definitions and settings from metakv">>},
   {enabled,true},
   {module,eventing}]},
 {32783,
  [{name,<<"Get Settings">>},
   {description,<<"Get settings for a given app">>},
   {enabled,false},
   {module,eventing}]},
 {32784,
  [{name,<<"Import Functions">>},
   {description,<<"Import a list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32785,
  [{name,<<"Export Functions">>},
   {description,<<"Export the list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32786,
  [{name,<<"List Running">>},
   {description,<<"Eventing running function list was read">>},
   {enabled,false},
   {module,eventing}]},
 {36865,
  [{name,<<"Service configuration change">>},
   {description,<<"A successful service configuration change was made.">>},
   {enabled,true},
   {module,analytics}]},
 {36866,
  [{name,<<"Node configuration change">>},
   {description,<<"A successful node configuration change was made.">>},
   {enabled,true},
   {module,analytics}]}]
[ns_server:debug,2020-05-07T13:48:29.831Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[ns_server:debug,2020-05-07T13:48:29.831Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_reprovision_cfg ->
[{enabled,true},{max_nodes,1},{count,0}]
[ns_server:debug,2020-05-07T13:48:29.831Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2020-05-07T13:48:29.831Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
buckets ->
[[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{3,63756036166}}],{configs,[]}]
[ns_server:debug,2020-05-07T13:48:29.831Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cbas_memory_quota ->
1024
[ns_server:debug,2020-05-07T13:48:29.831Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cert_and_pkey ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFgycnBwgEV8wDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBkNjJjNTRlYzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgZDYyYzU0\nZWMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCb3t8jaEY6kT/47ram\nSGNW3uEb+UI+9AqFQt5Gw2vOqPjXeRlyN/WrJ44JTmxnck3j84GcqEPQOP1LCDqI\ndRbzyK/pjcW48PqARpw2Sk4TRf9bLHQ"...>>,
  <<"*****">>}]
[ns_server:debug,2020-05-07T13:48:29.831Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
client_cert_auth ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {state,"disable"},
 {prefixes,[]}]
[ns_server:debug,2020-05-07T13:48:29.831Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cluster_compat_version ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{8,63756036166}}]},6,0]
[ns_server:debug,2020-05-07T13:48:29.831Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2020-05-07T13:48:29.831Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded,communication_issue]}]
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
fts_memory_quota ->
256
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
log_redaction_default_cfg ->
[{redact_level,none}]
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
max_bucket_count ->
10
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memcached ->
[]
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memory_quota ->
311
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
otp ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036165}}]},
 {cookie,{sanitized,<<"6dkHxYYfF+ME5ESL9KxV0kWMooAFPb8RjwdIBRcsXDo=">>}}]
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
password_policy ->
[{min_length,6},{must_present,[]}]
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
quorum_nodes ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
read_only_user_creds ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
remote_clusters ->
[]
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest ->
[{port,8091}]
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest_creds ->
null
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
roles_definitions ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
scramsha_fallback_salt ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<169,238,80,91,5,165,74,47,79,135,45,74>>]
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
secure_headers ->
[]
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
users_upgrade ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2020-05-07T13:48:29.832Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{10,63756078478}}]}]
[ns_server:debug,2020-05-07T13:48:29.834Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/eventing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"ram_quota\":256}">>]
[ns_server:debug,2020-05-07T13:48:29.834Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/query/settings/config">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{rbac_upgrade,[5,5]} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}|
 '_deleted']
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,fts} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,index} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]}]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8092]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9110]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_client_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9113]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9112]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9111]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cluster_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9115]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_console_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9114]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_data_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9116]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|-1]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8095]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_messaging_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9118]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_callback_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9119]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9121]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_parent_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9122]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_replication_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9120]
[ns_server:debug,2020-05-07T13:48:29.835Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_result_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9117]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18095]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {5,5,3}]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_debug_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9140]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8096]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18096]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8094]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_ssl_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18094]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9100]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9102]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_https_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|19102]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9101]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9104]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9103]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9105]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|true]
[ns_server:debug,2020-05-07T13:48:29.836Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 active]
[ns_server:debug,2020-05-07T13:48:29.837Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"@ns_server"},
 {other_users,["@cbq-engine","@projector","@goxdcr","@index","@fts",
               "@eventing","@cbas"]},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2020-05-07T13:48:29.837Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},
        {port,port},
        {maxconn,maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {privilege_debug,privilege_debug},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {rbac_file,{"~s",[rbac_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps},
   {tracing_enabled,tracing_enabled},
   {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
   {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
   {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
   {logger,
    {[{filename,{"~s/~s",[log_path,log_prefix]}},
      {cyclesize,log_cyclesize},
      {sleeptime,log_sleeptime}]}}]}]
[ns_server:debug,2020-05-07T13:48:29.837Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {privilege_debug,false},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false},
 {tracing_enabled,true},
 {datatype_snappy,true}]
[ns_server:debug,2020-05-07T13:48:29.837Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2020-05-07T13:48:29.837Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2020-05-07T13:48:29.837Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}]
[ns_server:debug,2020-05-07T13:48:29.837Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9999]
[ns_server:debug,2020-05-07T13:48:29.837Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|8093]
[ns_server:debug,2020-05-07T13:48:29.837Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2020-05-07T13:48:29.837Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18092]
[ns_server:debug,2020-05-07T13:48:29.837Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18093]
[ns_server:debug,2020-05-07T13:48:29.837Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|18091]
[ns_server:debug,2020-05-07T13:48:29.838Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|
 <<"0f8760945f98b1efdbef0bd1ea6e8446">>]
[ns_server:debug,2020-05-07T13:48:29.838Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|9998]
[ns_server:debug,2020-05-07T13:48:29.838Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036162}}]}|false]
[ns_server:debug,2020-05-07T13:48:29.855Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:trigger_ssl_reload:565]Notify services [capi_ssl_service] about secure_headers_changed change
[ns_server:debug,2020-05-07T13:48:29.856Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:525]Going to notify following services: [capi_ssl_service]
[ns_server:debug,2020-05-07T13:48:29.863Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([alert_limits,audit,audit_decriptors,
                               auto_failover_cfg,auto_reprovision_cfg,
                               autocompaction,buckets,cbas_memory_quota,
                               cert_and_pkey,client_cert_auth,
                               cluster_compat_version,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,
                               index_aware_rebalance_disabled,
                               log_redaction_default_cfg,max_bucket_count,
                               memcached,memory_quota,nodes_wanted,otp,
                               password_policy,quorum_nodes,
                               read_only_user_creds,remote_clusters,
                               replication,rest,rest_creds,roles_definitions,
                               scramsha_fallback_salt,secure_headers,
                               server_groups,set_view_update_daemon,
                               users_upgrade,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>},
                               {metakv,<<"/eventing/settings/config">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {metakv,<<"/query/settings/config">>},
                               {rbac_upgrade,[5,5]},
                               {request_limit,capi},
                               {request_limit,rest},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',cbas_admin_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_client_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_http_port},
                               {node,'ns_1@127.0.0.1',cbas_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_console_port},
                               {node,'ns_1@127.0.0.1',cbas_data_port},
                               {node,'ns_1@127.0.0.1',cbas_debug_port},
                               {node,'ns_1@127.0.0.1',cbas_http_port},
                               {node,'ns_1@127.0.0.1',cbas_messaging_port},
                               {node,'ns_1@127.0.0.1',
                                   cbas_metadata_callback_port},
                               {node,'ns_1@127.0.0.1',cbas_metadata_port},
                               {node,'ns_1@127.0.0.1',cbas_parent_port},
                               {node,'ns_1@127.0.0.1',cbas_replication_port},
                               {node,'ns_1@127.0.0.1',cbas_result_port},
                               {node,'ns_1@127.0.0.1',cbas_ssl_port}]..)
[ns_server:info,2020-05-07T13:48:29.867Z,ns_1@127.0.0.1:<0.267.0>:ns_ssl_services_setup:notify_service:708]Successfully notified service capi_ssl_service
[ns_server:info,2020-05-07T13:48:29.867Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:541]Succesfully notified services [capi_ssl_service]
[error_logger:info,2020-05-07T13:48:29.867Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.252.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.867Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.245.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T13:48:29.867Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.238.0>
[ns_server:debug,2020-05-07T13:48:29.867Z,ns_1@127.0.0.1:memcached_passwords<0.238.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2020-05-07T13:48:29.868Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.238.0>
[error_logger:info,2020-05-07T13:48:29.888Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.274.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:29.889Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: 172: Booted. Waiting for shutdown request

[ns_server:debug,2020-05-07T13:48:29.893Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[ns_server:warn,2020-05-07T13:48:29.894Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2020-05-07T13:48:29.894Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2020-05-07T13:48:29.899Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.276.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.900Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.279.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.900Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.280.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.904Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.282.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:29.904Z,ns_1@127.0.0.1:ns_log_events<0.244.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2020-05-07T13:48:29.904Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.281.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:29.904Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.283.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.910Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.284.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.916Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.286.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.916Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.292.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.916Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.285.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T13:48:29.918Z,ns_1@127.0.0.1:ns_heart<0.286.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2020-05-07T13:48:29.918Z,ns_1@127.0.0.1:ns_heart<0.286.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]}]}}

[error_logger:info,2020-05-07T13:48:29.920Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.296.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:29.929Z,ns_1@127.0.0.1:<0.293.0>:restartable:start_child:98]Started child process <0.295.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2020-05-07T13:48:29.929Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.297.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.929Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.293.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:29.929Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.300.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.933Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.301.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.933Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.302.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.933Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.303.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.934Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.304.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.936Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.306.0>},
                       {name,query_settings_manager},
                       {mfargs,{query_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.948Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.309.0>},
                       {name,eventing_settings_manager},
                       {mfargs,{eventing_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.948Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.311.0>},
                       {name,audit_events},
                       {mfargs,{gen_event,start_link,[{local,audit_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:29.958Z,ns_1@127.0.0.1:ns_heart<0.286.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2020-05-07T13:48:29.958Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.313.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.959Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.315.0>},
                       {name,scram_sha},
                       {mfargs,{scram_sha,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:29.961Z,ns_1@127.0.0.1:ns_heart<0.286.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2020-05-07T13:48:29.963Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.317.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.987Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.320.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.994Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.321.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:29.994Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.322.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:29.995Z,ns_1@127.0.0.1:menelaus_sup<0.312.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2020-05-07T13:48:29.995Z,ns_1@127.0.0.1:menelaus_sup<0.312.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2020-05-07T13:48:29.995Z,ns_1@127.0.0.1:menelaus_sup<0.312.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2020-05-07T13:48:29.996Z,ns_1@127.0.0.1:menelaus_sup<0.312.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[error_logger:info,2020-05-07T13:48:29.996Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.323.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.001Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.340.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.003Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.341.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.005Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.342.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.011Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.343.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2020-05-07T13:48:30.011Z,ns_1@127.0.0.1:ns_server_sup<0.231.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "6.0.3-2895-enterprise".
[error_logger:info,2020-05-07T13:48:30.011Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.312.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:30.011Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.349.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.015Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.353.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:30.015Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.354.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.31986353>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.015Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.352.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T13:48:30.018Z,ns_1@127.0.0.1:ns_ports_setup<0.349.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,goxdcr]
[error_logger:info,2020-05-07T13:48:30.021Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.356.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:30.021Z,ns_1@127.0.0.1:ns_audit_cfg<0.357.0>:ns_audit_cfg:write_audit_json:265]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{descriptors_path,
                                                                                <<"/opt/couchbase/etc/security">>},
                                                                               {version,
                                                                                2},
                                                                               {uuid,
                                                                                <<"18411111">>},
                                                                               {event_states,
                                                                                {[]}},
                                                                               {filtering_enabled,
                                                                                true},
                                                                               {disabled_userids,
                                                                                []},
                                                                               {auditd_enabled,
                                                                                false},
                                                                               {log_path,
                                                                                <<"/opt/couchbase/var/lib/couchbase/logs">>},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []}]
[ns_server:debug,2020-05-07T13:48:30.028Z,ns_1@127.0.0.1:ns_audit_cfg<0.357.0>:ns_audit_cfg:notify_memcached:170]Instruct memcached to reload audit config
[error_logger:info,2020-05-07T13:48:30.029Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.357.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T13:48:30.029Z,ns_1@127.0.0.1:<0.360.0>:ns_memcached:connect:1230]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2020-05-07T13:48:30.036Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.361.0>},
                       {name,ns_audit},
                       {mfargs,{ns_audit,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:30.040Z,ns_1@127.0.0.1:memcached_config_mgr<0.362.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2020-05-07T13:48:30.040Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.362.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:30.042Z,ns_1@127.0.0.1:<0.363.0>:ns_memcached_log_rotator:init:42]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2020-05-07T13:48:30.042Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.363.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.043Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.364.0>},
                       {name,testconditions_store},
                       {mfargs,{simple_store,start_link,[testconditions]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.044Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.366.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.046Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.368.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.046Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.367.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:30.046Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.365.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:30.061Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.369.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.062Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.373.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.064Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.375.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.065Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.376.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.065Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.082Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.379.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.082Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.381.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:30.155Z,ns_1@127.0.0.1:ns_ports_setup<0.349.0>:ns_ports_setup:set_children:90]Monitor ns_child_ports_sup <12401.74.0>
[error_logger:info,2020-05-07T13:48:30.152Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.382.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:30.162Z,ns_1@127.0.0.1:memcached_config_mgr<0.362.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:info,2020-05-07T13:48:30.163Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.384.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.167Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.386.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.167Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.388.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:30.175Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.292.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T13:48:30.175Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.292.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[ns_server:info,2020-05-07T13:48:30.185Z,ns_1@127.0.0.1:ns_couchdb_port<0.209.0>:ns_port_server:log:223]ns_couchdb<0.209.0>: working as port

[error_logger:info,2020-05-07T13:48:30.194Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.405.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:30.197Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.405.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T13:48:30.200Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.405.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2020-05-07T13:48:30.215Z,ns_1@127.0.0.1:memcached_config_mgr<0.362.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12401.80.0>
[ns_server:debug,2020-05-07T13:48:30.265Z,ns_1@127.0.0.1:memcached_config_mgr<0.362.0>:memcached_config_mgr:init:79]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[error_logger:info,2020-05-07T13:48:30.271Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.411.0>},
                       {name,service_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_stats_children_sup},
                                services_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T13:48:30.273Z,ns_1@127.0.0.1:memcached_config_mgr<0.362.0>:memcached_config_mgr:init:82]activated memcached port server
[error_logger:info,2020-05-07T13:48:30.295Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.413.0>},
                       {name,service_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [service_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.301Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.414.0>},
                       {name,service_status_keeper_index},
                       {mfargs,{service_index,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.303Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.417.0>},
                       {name,service_status_keeper_fts},
                       {mfargs,{service_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.306Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.420.0>},
                       {name,service_status_keeper_eventing},
                       {mfargs,{service_eventing,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.306Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.412.0>},
                       {name,service_status_keeper_sup},
                       {mfargs,{service_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:30.306Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.423.0>},
                       {name,service_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<services_stats_sup.0.41280346>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.306Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.410.0>},
                       {name,services_stats_sup},
                       {mfargs,{services_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:30.311Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.425.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:30.325Z,ns_1@127.0.0.1:<0.428.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.428.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2020-05-07T13:48:30.336Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T13:48:30.336Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T13:48:30.337Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T13:48:30.337Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[error_logger:info,2020-05-07T13:48:30.336Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.426.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:30.337Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2020-05-07T13:48:30.337Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2020-05-07T13:48:30.341Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.430.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.342Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.429.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:30.343Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.431.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.359Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.435.0>},
                       {name,leader_activities},
                       {mfargs,{leader_activities,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:warn,2020-05-07T13:48:30.367Z,ns_1@127.0.0.1:leader_lease_agent<0.436.0>:leader_lease_agent:maybe_recover_persisted_lease:397]Found persisted lease [{node,'ns_1@127.0.0.1'},
                       {uuid,<<"698fcb839390f66fbf42669913324cf6">>},
                       {time_left,15000},
                       {status,active}]
[error_logger:info,2020-05-07T13:48:30.367Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.436.0>},
                       {name,leader_lease_agent},
                       {mfargs,{leader_lease_agent,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.368Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.434.0>},
                       {name,leader_leases_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_leases_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:30.368Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.438.0>},
                       {name,leader_events},
                       {mfargs,{gen_event,start_link,[{local,leader_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.372Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.439.0>},
                       {name,leader_registry_server},
                       {mfargs,{leader_registry_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:30.380Z,ns_1@127.0.0.1:leader_registry_sup<0.437.0>:mb_master:check_master_takeover_needed:270]Sending master node question to the following nodes: []
[ns_server:debug,2020-05-07T13:48:30.381Z,ns_1@127.0.0.1:leader_registry_sup<0.437.0>:mb_master:check_master_takeover_needed:272]Got replies: []
[ns_server:debug,2020-05-07T13:48:30.381Z,ns_1@127.0.0.1:leader_registry_sup<0.437.0>:mb_master:check_master_takeover_needed:278]Was unable to discover master, not going to force mastership takeover
[user:info,2020-05-07T13:48:30.381Z,ns_1@127.0.0.1:mb_master<0.442.0>:mb_master:init:90]I'm the only node, so I'm the master.
[ns_server:debug,2020-05-07T13:48:30.381Z,ns_1@127.0.0.1:leader_registry<0.439.0>:leader_registry_server:handle_new_leader:241]New leader is 'ns_1@127.0.0.1'. Invalidating name cache.
[error_logger:info,2020-05-07T13:48:30.387Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.445.0>},
                       {name,leader_lease_acquirer},
                       {mfargs,{leader_lease_acquirer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:30.389Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.447.0>:leader_quorum_nodes_manager:pull_config:114]Attempting to pull config from nodes:
[]
[error_logger:info,2020-05-07T13:48:30.389Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.447.0>},
                       {name,leader_quorum_nodes_manager},
                       {mfargs,{leader_quorum_nodes_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:30.389Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.447.0>:leader_quorum_nodes_manager:pull_config:119]Pulled config successfully.
[ns_server:warn,2020-05-07T13:48:30.398Z,ns_1@127.0.0.1:<0.453.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"698fcb839390f66fbf42669913324cf6">>} (valid for 14969ms)
[ns_server:info,2020-05-07T13:48:30.399Z,ns_1@127.0.0.1:mb_master_sup<0.444.0>:misc:start_singleton:758]start_singleton(gen_server, ns_tick, [], []): started as <0.456.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T13:48:30.399Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.456.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.409Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.459.0>},
                       {name,ns_janitor_server},
                       {mfargs,{ns_janitor_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:30.412Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.458.0>:misc:start_singleton:758]start_singleton(gen_server, auto_reprovision, [], []): started as <0.460.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T13:48:30.412Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.460.0>},
                       {name,auto_reprovision},
                       {mfargs,{auto_reprovision,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2020-05-07T13:48:30.412Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.458.0>:misc:start_singleton:758]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.461.0> on 'ns_1@127.0.0.1'

[error_logger:info,2020-05-07T13:48:30.413Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.461.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.413Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.458.0>},
                       {name,ns_orchestrator_child_sup},
                       {mfargs,{ns_orchestrator_child_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T13:48:30.416Z,ns_1@127.0.0.1:<0.463.0>:auto_failover:init:211]init auto_failover.
[user:info,2020-05-07T13:48:30.416Z,ns_1@127.0.0.1:<0.463.0>:auto_failover:handle_call:242]Enabled auto-failover with timeout 120 and max count 1
[ns_server:debug,2020-05-07T13:48:30.424Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"0f8760945f98b1efdbef0bd1ea6e8446">>} ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{11,63756078510}}]}]
[ns_server:debug,2020-05-07T13:48:30.424Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([auto_failover_cfg,
                               {local_changes_count,
                                   <<"0f8760945f98b1efdbef0bd1ea6e8446">>}]..)
[ns_server:info,2020-05-07T13:48:30.424Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.457.0>:misc:start_singleton:758]start_singleton(gen_server, auto_failover, [], []): started as <0.463.0> on 'ns_1@127.0.0.1'

[ns_server:debug,2020-05-07T13:48:30.424Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"0f8760945f98b1efdbef0bd1ea6e8446">>,{1,63756036166}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[error_logger:info,2020-05-07T13:48:30.425Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.463.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.425Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.457.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T13:48:30.425Z,ns_1@127.0.0.1:<0.432.0>:restartable:start_child:98]Started child process <0.433.0>
  MFA: {leader_services_sup,start_link,[]}
[error_logger:info,2020-05-07T13:48:30.425Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.442.0>},
                       {name,mb_master},
                       {mfargs,{mb_master,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:30.425Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.437.0>},
                       {name,leader_registry_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_registry_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:30.425Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.432.0>},
                       {name,leader_services_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{leader_services_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:30.425Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.471.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.425Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.472.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.430Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.473.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.432Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.474.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.459Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.477.0>},
                       {name,ns_server_monitor},
                       {mfargs,{ns_server_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.459Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.479.0>},
                       {name,service_monitor_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_monitor_children_sup},
                                health_monitor_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:30.459Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.480.0>},
                       {name,service_monitor_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<health_monitor_sup.0.81875396>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2020-05-07T13:48:30.466Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.488.0>},
                       {name,node_monitor},
                       {mfargs,{node_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:30.467Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[error_logger:info,2020-05-07T13:48:30.467Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.496.0>},
                       {name,node_status_analyzer},
                       {mfargs,{node_status_analyzer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2020-05-07T13:48:30.467Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.169.0>
[ns_server:debug,2020-05-07T13:48:30.467Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[error_logger:info,2020-05-07T13:48:30.467Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.476.0>},
                       {name,health_monitor_sup},
                       {mfargs,{health_monitor_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T13:48:30.467Z,ns_1@127.0.0.1:<0.168.0>:restartable:start_child:98]Started child process <0.169.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[error_logger:info,2020-05-07T13:48:30.467Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.231.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2020-05-07T13:48:30.467Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:130]138: Entered child_loop
[error_logger:info,2020-05-07T13:48:30.467Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.168.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2020-05-07T13:48:30.468Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:debug,2020-05-07T13:48:30.490Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@",admin}
[ns_server:debug,2020-05-07T13:48:30.506Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.499.0>:json_rpc_connection:init:73]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.499.0>
[ns_server:debug,2020-05-07T13:48:30.530Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.502.0>:json_rpc_connection:init:73]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.502.0>
[ns_server:debug,2020-05-07T13:48:30.530Z,ns_1@127.0.0.1:menelaus_cbauth<0.343.0>:menelaus_cbauth:handle_cast:102]Observed json rpc process {"goxdcr-cbauth",<0.502.0>} started
[ns_server:debug,2020-05-07T13:48:30.537Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@goxdcr-cbauth",admin}
[ns_server:debug,2020-05-07T13:48:30.807Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:89]Refresh of [rbac,isasl] succeeded
[ns_server:debug,2020-05-07T13:48:31.417Z,ns_1@127.0.0.1:<0.463.0>:auto_failover_logic:log_master_activity:170]Transitioned node {'ns_1@127.0.0.1',<<"0f8760945f98b1efdbef0bd1ea6e8446">>} state new -> up
[ns_server:debug,2020-05-07T13:48:45.368Z,ns_1@127.0.0.1:leader_lease_agent<0.436.0>:leader_lease_agent:handle_lease_expired:284]Lease held by {lease_holder,<<"698fcb839390f66fbf42669913324cf6">>,
                            'ns_1@127.0.0.1'} expired. Starting expirer.
[ns_server:warn,2020-05-07T13:48:45.368Z,ns_1@127.0.0.1:<0.453.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"698fcb839390f66fbf42669913324cf6">>} (valid for 0ms)
[ns_server:debug,2020-05-07T13:48:45.369Z,ns_1@127.0.0.1:leader_lease_agent<0.436.0>:leader_lease_agent:do_handle_acquire_lease:147]Granting lease to {lease_holder,<<"88b7d1e10120cfa9adbda75d7215bd02">>,
                                'ns_1@127.0.0.1'} for 15000ms
[ns_server:info,2020-05-07T13:48:45.402Z,ns_1@127.0.0.1:<0.453.0>:leader_lease_acquire_worker:handle_fresh_lease_acquired:302]Acquired lease from node 'ns_1@127.0.0.1' (lease uuid: <<"88b7d1e10120cfa9adbda75d7215bd02">>)
[ns_server:debug,2020-05-07T13:49:00.337Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T13:49:00.337Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T13:49:00.337Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T13:49:00.337Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[error_logger:info,2020-05-07T13:49:26.325Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
       alarm_handler: {set,{system_memory_high_watermark,[]}}

[ns_server:debug,2020-05-07T13:49:30.338Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2020-05-07T13:49:30.338Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2020-05-07T13:49:30.338Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2020-05-07T13:49:30.338Z,ns_1@127.0.0.1:compaction_new_daemon<0.426.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
